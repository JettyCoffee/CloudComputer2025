<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d13" for="edge" attr.name="truncate" attr.type="string" />
  <key id="d12" for="edge" attr.name="created_at" attr.type="long" />
  <key id="d11" for="edge" attr.name="file_path" attr.type="string" />
  <key id="d10" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d9" for="edge" attr.name="keywords" attr.type="string" />
  <key id="d8" for="edge" attr.name="description" attr.type="string" />
  <key id="d7" for="edge" attr.name="weight" attr.type="double" />
  <key id="d6" for="node" attr.name="truncate" attr.type="string" />
  <key id="d5" for="node" attr.name="created_at" attr.type="long" />
  <key id="d4" for="node" attr.name="file_path" attr.type="string" />
  <key id="d3" for="node" attr.name="source_id" attr.type="string" />
  <key id="d2" for="node" attr.name="description" attr.type="string" />
  <key id="d1" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d0" for="node" attr.name="entity_id" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="熵">
      <data key="d0">熵</data>
      <data key="d1">concept</data>
      <data key="d2">熵是一个在热力学、统计物理学和信息论等多个学科中具有核心重要性的概念，其核心含义是衡量系统或信息的不确定性、无序度或混乱程度。

在物理学领域，熵最初由鲁道夫·克劳修斯引入，是一个热力学概念，用于量化系统的无序度，其变化由公式 ΔS = ΔQ/T 描述。根据热力学第二定律，孤立系统的熵总是趋向于增加至最大值。路德维希·玻尔兹曼给出了熵的微观统计解释，其定义公式为 S = k * ln W，其中W代表系统的微观状态数。生命体等开放系统通过消耗能量和物质来抵抗熵增，维持有序结构。

在信息论领域，熵由克劳德·香农定义，通常表示为H(p)，是随机变量不确定性的度量，也是接收每条消息时所包含的平均信息量，被称为信息熵或平均自信息量。其数学定义为对概率分布中所有可能结果的信息量求和，用以量化平均信息内容。以2为底的对数所计算的信息熵，是平均编码长度的度量。KL散度（相对熵）可以通过信息熵与交叉熵来表达，而交叉熵损失函数也基于此概念。

在机器学习领域，熵被用作度量数据集中不确定性、不纯度或无序度的指标。它在决策树算法（如ID3）中至关重要，用于计算经验熵和经验条件熵，进而作为计算信息增益和信息增益比的基础，以评估候选分割点。

熵的概念具有统一性，既度量物理系统的无序度，也度量信息中的不确定性。它也可以被视为一种分散度的度量，例如在经济学中，能使交易分布熵最大化的分配是在给定约束下最分散的可能状态。&lt;SEP&gt;一个系统无序度或信息不确定性的度量。&lt;SEP&gt;Entropy is a concept from information theory and thermodynamics, measuring uncertainty or disorder, covered in the lecture.&lt;SEP&gt;熵是最大熵模型中的核心概念，代表概率分布的不确定性或信息量，模型旨在最大化此值。</data>
      <data key="d3">chunk-380e2aedf9b91dc7de5d8747a6aa5723&lt;SEP&gt;chunk-9e4905d7255ffcf74cb7aad95daffceb&lt;SEP&gt;chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-0c9d3f43376e35055643ae46b0d5a233&lt;SEP&gt;chunk-d4b315e54e592e86c3a5acfef7099954&lt;SEP&gt;chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a&lt;SEP&gt;chunk-76741d601c3b02adb5beb29cf0c31924&lt;SEP&gt;chunk-6135ecccd835afdfdaba2f58578ed61e&lt;SEP&gt;chunk-ed0ca1ab77e5b700d5a4eb0d861cccb4&lt;SEP&gt;chunk-1248b4cdb9c5b6a4f15c20d0991319ae&lt;SEP&gt;chunk-31dfc0a8415a0647f471a1cab88d6e36&lt;SEP&gt;chunk-74f709ca5bbf7d60213a39cdce19a507&lt;SEP&gt;chunk-0662825c74f8b5ee226b4f32d6eae491&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973&lt;SEP&gt;chunk-0da87cc9d247bbbc97d0642c59a0a3ce&lt;SEP&gt;chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5&lt;SEP&gt;chunk-93b5920864ffe7c0f735f87ccf578d34&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6&lt;SEP&gt;chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0&lt;SEP&gt;chunk-16343ccef51a9f838ddefbe4951cc3c0&lt;SEP&gt;chunk-2dd1a13b5c662bd9e747f8aa4b9d3361</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976228</data>
      <data key="d6" />
    </node>
    <node id="概率分布">
      <data key="d0">概率分布</data>
      <data key="d1">concept</data>
      <data key="d2">概率分布是数学和统计学中的一个核心概念，用于描述随机变量所有可能取值及其对应概率的完整情况。它本质上是一个数学函数，为某个实验或随机过程的不同可能结果分配其发生的概率，通常记作 p(x) 或 q(x)。在机器学习和信息论的上下文中，概率分布具有特别重要的意义。它是计算信息熵和交叉熵等关键度量的基础，这些度量用于量化信息或比较不同分布之间的差异。

在多类分类模型的场景中，模型的输出通常就是一个概率分布，它表示输入样本属于每个可能类别的概率。在相关讨论中，概率分布常被区分为两种：一种是真实的数据分布（即期望输出，常表示为 p(x)），另一种是模型学习或预测出的分布（即实际输出，常表示为 q(x)）。因此，概率分布既是描述随机现象的理论工具，也是评估和优化预测模型性能的实践基础。&lt;SEP&gt;描述随机变量各可能取值发生概率的函数。</data>
      <data key="d3">chunk-380e2aedf9b91dc7de5d8747a6aa5723&lt;SEP&gt;chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-726d03cb1277ab1c0a32f929ee13c3fc&lt;SEP&gt;chunk-23713b5f1cb0ee19178382510009449e&lt;SEP&gt;chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-c83ff92607271cc36071ca55ac4a8385&lt;SEP&gt;chunk-408bf4ea5cb0bf2933de13a97fd69ee6&lt;SEP&gt;chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976199</data>
      <data key="d6" />
    </node>
    <node id="信息论">
      <data key="d0">信息论</data>
      <data key="d1">concept</data>
      <data key="d2">信息论（Information Theory）是由克劳德·香农（Claude Shannon）创立的数学理论，是数学和计算机科学的一个分支。它主要研究信息的量化、存储、传输和处理，其核心在于阐述信息的本质是消除不确定性。信息论的核心概念之一是熵，该理论为交叉熵提供了理论基础。

信息论是数字通信理论的基础，旨在解决通信中的基本问题。它也为脉冲耦合神经网络等相关研究提供了领域背景。作为一个基础性理论，信息论在机器学习、自然语言处理等多个现代科技领域有着广泛的应用。此外，该领域的研究也提供了将博弈论与实证证据联系起来的推理框架。在相关文档的元数据中，信息论常被标识为所提及的研究领域或学科。&lt;SEP&gt;研究信息传输、处理和度量的科学领域。&lt;SEP&gt;信息论是研究信息传输、处理、量化和应用的科学领域。&lt;SEP&gt;The domain or field of study mentioned in the document metadata.&lt;SEP&gt;信息论是交叉熵损失函数概念起源的学科领域。</data>
      <data key="d3">chunk-9e4905d7255ffcf74cb7aad95daffceb&lt;SEP&gt;chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577&lt;SEP&gt;chunk-31dfc0a8415a0647f471a1cab88d6e36&lt;SEP&gt;chunk-c236f82f4d1c6b66d541fbb6f8076051&lt;SEP&gt;chunk-b3aee2cd221856b5ea7d30d3400aa8dd&lt;SEP&gt;chunk-8c2cb0873e78699bf2531a59b921954f&lt;SEP&gt;chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973&lt;SEP&gt;chunk-0da87cc9d247bbbc97d0642c59a0a3ce&lt;SEP&gt;chunk-c78284e4671aee8befd9c6871d1db529&lt;SEP&gt;chunk-5d34d389fc9a72d98bce995b723199a6&lt;SEP&gt;chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975616</data>
      <data key="d6" />
    </node>
    <node id="信息熵">
      <data key="d0">信息熵</data>
      <data key="d1">concept</data>
      <data key="d2">信息熵是熵的别称，指接收的每条消息中包含的信息的平均量。&lt;SEP&gt;Information entropy, a concept compared with cross-entropy in the calculation of KL divergence.&lt;SEP&gt;信息熵是香农提出的概念，用于量化信息的不确定性。&lt;SEP&gt;A concept from information theory, often referred to as Entropy.&lt;SEP&gt;信息熵又称信息量，用于量化在通信过程中传递了多少信息，其值取决于事件发生的概率。&lt;SEP&gt;信息熵是信息论中度量随机变量不确定性的平均信息量，公式为H(X)=∑p(x)log2(1/p(x))，其值非负。</data>
      <data key="d3">chunk-9e4905d7255ffcf74cb7aad95daffceb&lt;SEP&gt;chunk-bcb9e2b1f343c904193b0f647416ae0e&lt;SEP&gt;chunk-0662825c74f8b5ee226b4f32d6eae491&lt;SEP&gt;chunk-33949af9012de6222abbb5ee9e909273&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974405</data>
      <data key="d6" />
    </node>
    <node id="信源熵">
      <data key="d0">信源熵</data>
      <data key="d1">concept</data>
      <data key="d2">信源熵是熵的别称，指接收的每条消息中包含的信息的平均量。</data>
      <data key="d3">chunk-9e4905d7255ffcf74cb7aad95daffceb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972807</data>
      <data key="d6" />
    </node>
    <node id="平均自信息量">
      <data key="d0">平均自信息量</data>
      <data key="d1">concept</data>
      <data key="d2">平均自信息量是熵的别称，指接收的每条消息中包含的信息的平均量。</data>
      <data key="d3">chunk-9e4905d7255ffcf74cb7aad95daffceb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972807</data>
      <data key="d6" />
    </node>
    <node id="消息">
      <data key="d0">消息</data>
      <data key="d1">concept</data>
      <data key="d2">消息代表来自分布或数据流中的事件、样本或特征，是信息论中信息的载体。</data>
      <data key="d3">chunk-9e4905d7255ffcf74cb7aad95daffceb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972807</data>
      <data key="d6" />
    </node>
    <node id="比特">
      <data key="d0">比特</data>
      <data key="d1">concept</data>
      <data key="d2">比特是熵的常用单位，用于度量信息量。</data>
      <data key="d3">chunk-9e4905d7255ffcf74cb7aad95daffceb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972815</data>
      <data key="d6" />
    </node>
    <node id="EMCNN">
      <data key="d0">EMCNN</data>
      <data key="d1">method</data>
      <data key="d2">A proposed method for predicting node influence in networks, showing high correlation with infection counts in SIR models.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972861</data>
      <data key="d6" />
    </node>
    <node id="SIR Model">
      <data key="d0">SIR Model</data>
      <data key="d1">method</data>
      <data key="d2">An epidemiological model used to simulate the spread of infections and generate ground truth for node influence in networks.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972861</data>
      <data key="d6" />
    </node>
    <node id="Degree">
      <data key="d0">Degree</data>
      <data key="d1">method</data>
      <data key="d2">A traditional network centrality metric measuring the number of connections a node has, showing weak correlation with actual influence in highly clustered networks.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972869</data>
      <data key="d6" />
    </node>
    <node id="H-index">
      <data key="d0">H-index</data>
      <data key="d1">method</data>
      <data key="d2">A traditional metric for measuring influence, showing weak correlation with actual spread influence in the context of the experiments.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972863</data>
      <data key="d6" />
    </node>
    <node id="PageRank">
      <data key="d0">PageRank</data>
      <data key="d1">method</data>
      <data key="d2">An algorithm for ranking nodes based on random walks, which shows poor identification of high-influence nodes in strongly clustered networks due to path sensitivity.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972863</data>
      <data key="d6" />
    </node>
    <node id="InfGCN">
      <data key="d0">InfGCN</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning-based method for node influence prediction, which performed poorly due to insufficient fusion of global and local network structure information.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972863</data>
      <data key="d6" />
    </node>
    <node id="Node Influence">
      <data key="d0">Node Influence</data>
      <data key="d1">concept</data>
      <data key="d2">The importance or spreading capability of a node within a network, measured and predicted by various algorithms.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972863</data>
      <data key="d6" />
    </node>
    <node id="Network">
      <data key="d0">Network</data>
      <data key="d1">concept</data>
      <data key="d2">A structure consisting of nodes and edges, used as the testbed for evaluating influence prediction algorithms.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972864</data>
      <data key="d6" />
    </node>
    <node id="Community Structure">
      <data key="d0">Community Structure</data>
      <data key="d1">concept</data>
      <data key="d2">A property of networks where nodes form densely connected groups, which can limit the correlation between local metrics like degree and global influence.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972864</data>
      <data key="d6" />
    </node>
    <node id="Correlation Experiment">
      <data key="d0">Correlation Experiment</data>
      <data key="d1">event</data>
      <data key="d2">An experiment analyzing the correlation between algorithm-predicted node influence and real influence generated by the SIR model across nine networks.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972864</data>
      <data key="d6" />
    </node>
    <node id="Facebook Network">
      <data key="d0">Facebook Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (a).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972864</data>
      <data key="d6" />
    </node>
    <node id="Netscience Network">
      <data key="d0">Netscience Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (b).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972865</data>
      <data key="d6" />
    </node>
    <node id="Protain Network">
      <data key="d0">Protain Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (c).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972865</data>
      <data key="d6" />
    </node>
    <node id="Yeast Network">
      <data key="d0">Yeast Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (d).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972865</data>
      <data key="d6" />
    </node>
    <node id="CA-GrQc Network">
      <data key="d0">CA-GrQc Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (e).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972865</data>
      <data key="d6" />
    </node>
    <node id="Lesmis Network">
      <data key="d0">Lesmis Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (f).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972866</data>
      <data key="d6" />
    </node>
    <node id="Jazz Network">
      <data key="d0">Jazz Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (g).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972866</data>
      <data key="d6" />
    </node>
    <node id="USAir Network">
      <data key="d0">USAir Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (h).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972866</data>
      <data key="d6" />
    </node>
    <node id="Faa Network">
      <data key="d0">Faa Network</data>
      <data key="d1">data</data>
      <data key="d2">One of the nine networks used in the correlation experiment, referenced as dataset (i).</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972866</data>
      <data key="d6" />
    </node>
    <node id="Infection Probability">
      <data key="d0">Infection Probability</data>
      <data key="d1">concept</data>
      <data key="d2">The parameter beta (β) set for each network in the SIR model experiments to control the spread of infection.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972866</data>
      <data key="d6" />
    </node>
    <node id="Infection Count">
      <data key="d0">Infection Count</data>
      <data key="d1">data</data>
      <data key="d2">The actual number of infected nodes generated by the SIR model simulation, representing the real spreading influence of a node.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972867</data>
      <data key="d6" />
    </node>
    <node id="Node Importance Ranking">
      <data key="d0">Node Importance Ranking</data>
      <data key="d1">concept</data>
      <data key="d2">The process of ordering nodes based on their predicted influence, with accuracy measured by correlation to SIR results.</data>
      <data key="d3">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972875</data>
      <data key="d6" />
    </node>
    <node id="交叉熵">
      <data key="d0">交叉熵</data>
      <data key="d1">method</data>
      <data key="d2">交叉熵（Cross-entropy）是信息论中的一个核心概念，用于衡量两个概率分布之间的差异或距离。在数学上，它被表示为 H(p, q) 或 H_p(q)，其含义是使用一个为概率分布 q 设计的编码方案，来编码来自真实概率分布 p 的事件时，所需的平均比特数。其计算公式通常为对真实分布 p(x) 与模型分布 q(x) 的对数期望求和，即 -Σ p(x) log q(x)（或以 1/q(x) 的形式表达）。交叉熵的值越小，表明两个概率分布越接近。

这一概念与信息熵和KL散度（Kullback–Leibler divergence）的计算密切相关，常被用作比较分布差异的度量。在机器学习领域，特别是神经网络中，交叉熵被广泛用作损失函数，以量化模型预测的概率分布与真实标签分布之间的差异，从而指导模型的优化过程。从认知角度看，交叉熵也可以理解为当使用一个主观预期的概率分布去观测随机变量，而真实分布与之不同时所感受到的平均“惊讶”程度。</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-bcb9e2b1f343c904193b0f647416ae0e&lt;SEP&gt;chunk-0c9d3f43376e35055643ae46b0d5a233&lt;SEP&gt;chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973&lt;SEP&gt;chunk-c83ff92607271cc36071ca55ac4a8385&lt;SEP&gt;chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975587</data>
      <data key="d6" />
    </node>
    <node id="相对熵">
      <data key="d0">相对熵</data>
      <data key="d1">concept</data>
      <data key="d2">Relative entropy, also known as Kullback-Leibler divergence and denoted as D_q(p), measures the difference between two probability distributions p(x) and q(x), calculated as the sum over x of p(x) times the base-2 logarithm of p(x)/q(x).&lt;SEP&gt;Relative entropy, also known as KL divergence, is a measure of the difference between two probability distributions P and Q. It is asymmetric and quantifies the extra bits needed to encode samples from P using a code optimized for Q.&lt;SEP&gt;相对熵，又称KL散度，是由交叉熵引申而来的概念，它衡量后验交叉熵与先验信息熵的差值，表示一个相对的吃惊程度。&lt;SEP&gt;相对熵是信息论中与交叉熵相关的概念，是交叉熵损失函数的基础之一。</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-0c9d3f43376e35055643ae46b0d5a233&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975617</data>
      <data key="d6" />
    </node>
    <node id="联合熵">
      <data key="d0">联合熵</data>
      <data key="d1">concept</data>
      <data key="d2">Joint entropy, denoted as H(X, Y), measures the total uncertainty of two random variables X and Y together, calculated as the sum over x and y of p(x, y) times the base-2 logarithm of 1/p(x, y).&lt;SEP&gt;The joint entropy of P and W, which is maximized under constraints in the inference problem.</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973435</data>
      <data key="d6" />
    </node>
    <node id="条件熵">
      <data key="d0">条件熵</data>
      <data key="d1">concept</data>
      <data key="d2">Conditional entropy, denoted as H(X|Y), measures the remaining uncertainty in a random variable X given knowledge of another random variable Y, calculated as the sum over x and y of p(x, y) times the base-2 logarithm of 1/p(x|y).</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972926</data>
      <data key="d6" />
    </node>
    <node id="互信息">
      <data key="d0">互信息</data>
      <data key="d1">concept</data>
      <data key="d2">Mutual information, denoted as I(X, Y), measures the amount of information obtained about one random variable through observing another random variable, calculated as the sum over x and y of p(x, y) times the base-2 logarithm of p(x, y)/(p(x)p(y)).</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972926</data>
      <data key="d6" />
    </node>
    <node id="对数似然比">
      <data key="d0">对数似然比</data>
      <data key="d1">concept</data>
      <data key="d2">The log-likelihood ratio, expressed as log_2(p(x)/q(x)), describes the difference in coding length for each symbol between two different coding schemes based on distributions p(x) and q(x).</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972927</data>
      <data key="d6" />
    </node>
    <node id="拉格朗日乘数法方程组">
      <data key="d0">拉格朗日乘数法方程组</data>
      <data key="d1">method</data>
      <data key="d2">A system of equations involving Lagrange multipliers, used to find the extremum of a function subject to constraints, as shown in the provided mathematical notation.</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972927</data>
      <data key="d6" />
    </node>
    <node id="随机变量">
      <data key="d0">随机变量</data>
      <data key="d1">concept</data>
      <data key="d2">A variable whose possible values are numerical outcomes of a random phenomenon, denoted as X and Y in the context of joint, conditional entropy, and mutual information.&lt;SEP&gt;在信息论中，未知的信息内容(如男孩要说的话)可以被视为一个随机变量X，其信息量与其发生的概率相关。&lt;SEP&gt;随机变量是一个变量，其可能值由随机现象的结果决定，信息熵的计算与其概率分布有关。</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974405</data>
      <data key="d6" />
    </node>
    <node id="编码长度">
      <data key="d0">编码长度</data>
      <data key="d1">concept</data>
      <data key="d2">The number of bits required to represent a symbol or event, with the log-likelihood ratio describing the difference in coding length between two schemes.</data>
      <data key="d3">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972927</data>
      <data key="d6" />
    </node>
    <node id="www.showmeai.tech">
      <data key="d0">www.showmeai.tech</data>
      <data key="d1">organization</data>
      <data key="d2">A website domain that is the subject of a security certificate warning.&lt;SEP&gt;A website domain that is experiencing a security certificate expiration warning.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976095</data>
      <data key="d6" />
    </node>
    <node id="TrustAsia DV TLS RSA CA 2025">
      <data key="d0">TrustAsia DV TLS RSA CA 2025</data>
      <data key="d1">organization</data>
      <data key="d2">The issuer of a security certificate that has expired.&lt;SEP&gt;A Certificate Authority that issued the security certificate for www.showmeai.tech.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976095</data>
      <data key="d6" />
    </node>
    <node id="Security Certificate">
      <data key="d0">Security Certificate</data>
      <data key="d1">artifact</data>
      <data key="d2">A digital certificate used to prove the identity of a website, which has expired.&lt;SEP&gt;A digital certificate used to establish a secure connection, which has expired for www.showmeai.tech.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976096</data>
      <data key="d6" />
    </node>
    <node id="ERR_CERT_DATE_INVALID">
      <data key="d0">ERR_CERT_DATE_INVALID</data>
      <data key="d1">concept</data>
      <data key="d2">A browser error indicating that a website's security certificate is not valid due to date issues.&lt;SEP&gt;A browser error indicating that a website's security certificate is invalid due to an expiration date issue.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976097</data>
      <data key="d6" />
    </node>
    <node id="Attackers">
      <data key="d0">Attackers</data>
      <data key="d1">organization</data>
      <data key="d2">Potential malicious entities that might exploit an insecure connection to steal information.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972962</data>
      <data key="d6" />
    </node>
    <node id="Information">
      <data key="d0">Information</data>
      <data key="d1">data</data>
      <data key="d2">Sensitive data such as passwords, messages, or credit cards that could be at risk.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972963</data>
      <data key="d6" />
    </node>
    <node id="PEM Encoded Chain">
      <data key="d0">PEM Encoded Chain</data>
      <data key="d1">data</data>
      <data key="d2">The encoded data of the security certificate chain, presented in a specific text format.&lt;SEP&gt;The textual representation of the security certificate's data chain.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976098</data>
      <data key="d6" />
    </node>
    <node id="System Clock">
      <data key="d0">System Clock</data>
      <data key="d1">artifact</data>
      <data key="d2">The user's computer clock, which is set to a specific date and may need correction.</data>
      <data key="d3">chunk-03892a1548c3ca50ed164db6a524dac7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768972964</data>
      <data key="d6" />
    </node>
    <node id="老饼">
      <data key="d0">老饼</data>
      <data key="d1">person</data>
      <data key="d2">The author of the article, published on 2023-10-11 and last updated on 2025-06-25.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973030</data>
      <data key="d6" />
    </node>
    <node id="矩阵LU分解">
      <data key="d0">矩阵LU分解</data>
      <data key="d1">method</data>
      <data key="d2">A matrix decomposition method, with specific variants including Doolittle decomposition, Crout decomposition, and Cholesky decomposition.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973030</data>
      <data key="d6" />
    </node>
    <node id="Doolittle分解">
      <data key="d0">Doolittle分解</data>
      <data key="d1">method</data>
      <data key="d2">A specific variant of LU matrix decomposition.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973024</data>
      <data key="d6" />
    </node>
    <node id="Crout分解">
      <data key="d0">Crout分解</data>
      <data key="d1">method</data>
      <data key="d2">A specific variant of LU matrix decomposition.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973025</data>
      <data key="d6" />
    </node>
    <node id="Cholesky分解">
      <data key="d0">Cholesky分解</data>
      <data key="d1">method</data>
      <data key="d2">A specific variant of LU matrix decomposition.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973025</data>
      <data key="d6" />
    </node>
    <node id="KL散度">
      <data key="d0">KL散度</data>
      <data key="d1">concept</data>
      <data key="d2">Kullback-Leibler divergence, a measure used to calculate the distance or difference between two probability distributions.&lt;SEP&gt;KL散度是一种度量，用于衡量使用基于分布Q的编码来编码来自分布P的样本平均所需的额外比特数。&lt;SEP&gt;KL divergence, short for Kullback–Leibler divergence, is another name for relative entropy. It measures the non-symmetric difference between two probability distributions.&lt;SEP&gt;KL散度是一种用于衡量两个概率分布之间差异的目标函数，在比较学习概率分布和源概率分布时被使用。&lt;SEP&gt;KL散度是相对熵的另一种称呼，用于衡量两个概率分布之间的差异。</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e&lt;SEP&gt;chunk-e7d56d1a1382da4ef9c8e90e4d8fd39f&lt;SEP&gt;chunk-0c9d3f43376e35055643ae46b0d5a233&lt;SEP&gt;chunk-726d03cb1277ab1c0a32f929ee13c3fc&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974395</data>
      <data key="d6" />
    </node>
    <node id="分布">
      <data key="d0">分布</data>
      <data key="d1">concept</data>
      <data key="d2">Probability distribution, referenced as P(X) and Q(X) in the context of calculating KL divergence.&lt;SEP&gt;描述字母出现概率的整体情况。&lt;SEP&gt;The arrangement or spread of particles across different states in a system.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e&lt;SEP&gt;chunk-0da87cc9d247bbbc97d0642c59a0a3ce&lt;SEP&gt;chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975455</data>
      <data key="d6" />
    </node>
    <node id="老饼讲解-机器学习">
      <data key="d0">老饼讲解-机器学习</data>
      <data key="d1">content</data>
      <data key="d2">A website or content series about machine learning, located at www.bbbdata.com, where the article originates.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973026</data>
      <data key="d6" />
    </node>
    <node id="Kullback-Leibler Divergence">
      <data key="d0">Kullback-Leibler Divergence</data>
      <data key="d1">concept</data>
      <data key="d2">Also known as KL distance, it is used to calculate the distance (difference) between two distributions.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973027</data>
      <data key="d6" />
    </node>
    <node id="Distribution Q(X)">
      <data key="d0">Distribution Q(X)</data>
      <data key="d1">concept</data>
      <data key="d2">A cognitive distribution compared with the true distribution P(X) in the KL divergence formula.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973027</data>
      <data key="d6" />
    </node>
    <node id="Distribution P(X)">
      <data key="d0">Distribution P(X)</data>
      <data key="d1">concept</data>
      <data key="d2">A true distribution compared with the cognitive distribution Q(X) in the KL divergence formula.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973027</data>
      <data key="d6" />
    </node>
    <node id="KL Divergence Formula">
      <data key="d0">KL Divergence Formula</data>
      <data key="d1">concept</data>
      <data key="d2">The mathematical formula for calculating the KL divergence between distribution Q(X) and distribution P(X).</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973035</data>
      <data key="d6" />
    </node>
    <node id="www.bbbdata.com">
      <data key="d0">www.bbbdata.com</data>
      <data key="d1">location</data>
      <data key="d2">The website address for "老饼讲解-机器学习", the source of the article.</data>
      <data key="d3">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973035</data>
      <data key="d6" />
    </node>
    <node id="分布P">
      <data key="d0">分布P</data>
      <data key="d1">concept</data>
      <data key="d2">分布P通常表示数据的真实分布。</data>
      <data key="d3">chunk-e7d56d1a1382da4ef9c8e90e4d8fd39f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973055</data>
      <data key="d6" />
    </node>
    <node id="分布Q">
      <data key="d0">分布Q</data>
      <data key="d1">concept</data>
      <data key="d2">分布Q通常表示数据的理论分布、模型分布或对分布P的近似分布。</data>
      <data key="d3">chunk-e7d56d1a1382da4ef9c8e90e4d8fd39f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973055</data>
      <data key="d6" />
    </node>
    <node id="基于Q的编码">
      <data key="d0">基于Q的编码</data>
      <data key="d1">method</data>
      <data key="d2">基于Q的编码是一种用于编码来自分布P的样本的编码方法。</data>
      <data key="d3">chunk-e7d56d1a1382da4ef9c8e90e4d8fd39f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973049</data>
      <data key="d6" />
    </node>
    <node id="信息散度">
      <data key="d0">信息散度</data>
      <data key="d1">concept</data>
      <data key="d2">Information divergence is a synonym for relative entropy or KL divergence.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973137</data>
      <data key="d6" />
    </node>
    <node id="信息增益">
      <data key="d0">信息增益</data>
      <data key="d1">concept</data>
      <data key="d2">Information gain is a term used in contexts like Bayesian inference to describe the gain in information when updating beliefs from a prior distribution q to a posterior distribution p, equivalent to KL divergence.&lt;SEP&gt;A criterion used in decision tree algorithms to select the best attribute for splitting data, calculated as the reduction in entropy.&lt;SEP&gt;信息增益是用于度量特征对于决策树的贡献的一个度量标准。&lt;SEP&gt;A criterion for selecting the best feature to split on in a decision tree.&lt;SEP&gt;信息增益是特征对训练数据集的信息增益，定义为集合的经验熵与特征给定条件下经验条件熵之差，是ID3算法使用的特征选择标准。&lt;SEP&gt;信息增益是决策树算法中用于选择最优划分特征的一种度量标准，当信息增益小于阈值ε时，停止划分并返回单节点树。&lt;SEP&gt;A metric used in the ID3 algorithm to evaluate candidate splits in a decision tree.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233&lt;SEP&gt;chunk-93b5920864ffe7c0f735f87ccf578d34&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6&lt;SEP&gt;chunk-a79596200294b5109fdd0cf885110f83&lt;SEP&gt;chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-b787493679d2ca259f397315e308f4b1&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976035</data>
      <data key="d6" />
    </node>
    <node id="概率分布P">
      <data key="d0">概率分布P</data>
      <data key="d1">concept</data>
      <data key="d2">Probability distribution P typically represents the true distribution of data in the context of measuring KL divergence.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973140</data>
      <data key="d6" />
    </node>
    <node id="概率分布Q">
      <data key="d0">概率分布Q</data>
      <data key="d1">concept</data>
      <data key="d2">Probability distribution Q typically represents a theoretical, model, or approximate distribution of data in the context of measuring KL divergence.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973141</data>
      <data key="d6" />
    </node>
    <node id="贝叶斯推理">
      <data key="d0">贝叶斯推理</data>
      <data key="d1">concept</data>
      <data key="d2">Bayesian inference is a method of statistical inference where KL divergence D_KL(p||q) measures the information gain when updating from prior distribution q to posterior distribution p.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973142</data>
      <data key="d6" />
    </node>
    <node id="变分自编码器">
      <data key="d0">变分自编码器</data>
      <data key="d1">method</data>
      <data key="d2">Variational autoencoder (VAE) is a type of generative model whose objective function is composed of KL divergence, used for learning latent space representations.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973143</data>
      <data key="d6" />
    </node>
    <node id="Diederik P. Kingma">
      <data key="d0">Diederik P. Kingma</data>
      <data key="d1">person</data>
      <data key="d2">Diederik P. Kingma is a researcher who, along with Max Welling, proposed the variational autoencoder in 2013, which uses KL divergence in its objective function.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973143</data>
      <data key="d6" />
    </node>
    <node id="Max Welling">
      <data key="d0">Max Welling</data>
      <data key="d1">person</data>
      <data key="d2">Max Welling is a researcher who, along with Diederik P. Kingma, proposed the variational autoencoder in 2013, which uses KL divergence in its objective function.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973144</data>
      <data key="d6" />
    </node>
    <node id="Focal-KLD">
      <data key="d0">Focal-KLD</data>
      <data key="d1">method</data>
      <data key="d2">Focal-KLD is a modified version of KL divergence proposed by Shuai Wang et al. in 2018 for a single-channel multi-speaker recognition framework, giving more weight to hard samples during training.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973144</data>
      <data key="d6" />
    </node>
    <node id="Shuai Wang">
      <data key="d0">Shuai Wang</data>
      <data key="d1">person</data>
      <data key="d2">Shuai Wang is a researcher who, along with colleagues, improved a neural network-based single-channel multi-speaker recognition framework in 2018 by modifying KL divergence to Focal-KLD.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973144</data>
      <data key="d6" />
    </node>
    <node id="单通道多说话人识别框架">
      <data key="d0">单通道多说话人识别框架</data>
      <data key="d1">method</data>
      <data key="d2">This is a neural network-based framework for single-channel multi-speaker recognition that was improved by Shuai Wang et al. in 2018, incorporating a modified KL divergence (Focal-KLD).</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973144</data>
      <data key="d6" />
    </node>
    <node id="Kullback">
      <data key="d0">Kullback</data>
      <data key="d1">person</data>
      <data key="d2">Kullback is one of the individuals (along with Leibler) associated with the proposal of relative entropy (KL divergence) in 1951.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973145</data>
      <data key="d6" />
    </node>
    <node id="Leibler">
      <data key="d0">Leibler</data>
      <data key="d1">person</data>
      <data key="d2">Leibler is one of the individuals (along with Kullback) associated with the proposal of relative entropy (KL divergence) in 1951.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973145</data>
      <data key="d6" />
    </node>
    <node id="Kullback–Leibler Divergence">
      <data key="d0">Kullback–Leibler Divergence</data>
      <data key="d1">concept</data>
      <data key="d2">Kullback–Leibler divergence is the full name for KL divergence, a measure of the difference between two probability distributions.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973145</data>
      <data key="d6" />
    </node>
    <node id="KLD">
      <data key="d0">KLD</data>
      <data key="d1">concept</data>
      <data key="d2">KLD is an abbreviation for Kullback–Leibler divergence.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973145</data>
      <data key="d6" />
    </node>
    <node id="D_KL(p||q)">
      <data key="d0">D_KL(p||q)</data>
      <data key="d1">concept</data>
      <data key="d2">D_KL(p||q) is the notation for the KL divergence from distribution q to distribution p, measuring information gain or loss.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973146</data>
      <data key="d6" />
    </node>
    <node id="D_KL(Q||P)">
      <data key="d0">D_KL(Q||P)</data>
      <data key="d1">concept</data>
      <data key="d2">D_KL(Q||P) is the notation for the KL divergence from distribution P to distribution Q, highlighting the asymmetry of the measure.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973146</data>
      <data key="d6" />
    </node>
    <node id="Hard Samples">
      <data key="d0">Hard Samples</data>
      <data key="d1">concept</data>
      <data key="d2">Hard samples are data points that are difficult for a model to classify or learn from, given more weight in training when using Focal-KLD.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973146</data>
      <data key="d6" />
    </node>
    <node id="Neural Network">
      <data key="d0">Neural Network</data>
      <data key="d1">method</data>
      <data key="d2">Neural network is a computational model used as the basis for the single-channel multi-speaker recognition framework improved by Shuai Wang et al.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973146</data>
      <data key="d6" />
    </node>
    <node id="Baseline System">
      <data key="d0">Baseline System</data>
      <data key="d1">concept</data>
      <data key="d2">The baseline system is the reference system against which Shuai Wang et al. compared their improved single-channel multi-speaker recognition framework.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973147</data>
      <data key="d6" />
    </node>
    <node id="92.47% Correct Rate">
      <data key="d0">92.47% Correct Rate</data>
      <data key="d1">data</data>
      <data key="d2">92.47% is the correct rate achieved by the improved system proposed by Shuai Wang et al. for two-speaker recognition.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973147</data>
      <data key="d6" />
    </node>
    <node id="55.83% Correct Rate">
      <data key="d0">55.83% Correct Rate</data>
      <data key="d1">data</data>
      <data key="d2">55.83% is the correct rate achieved by the improved system proposed by Shuai Wang et al. for three-speaker recognition.</data>
      <data key="d3">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973147</data>
      <data key="d6" />
    </node>
    <node id="Wasserstein距离">
      <data key="d0">Wasserstein距离</data>
      <data key="d1">concept</data>
      <data key="d2">Wasserstein距离，也称为推土机距离，是一种用于衡量概率分布之间差异的真正度量。</data>
      <data key="d3">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973176</data>
      <data key="d6" />
    </node>
    <node id="Bhattacharyya距离">
      <data key="d0">Bhattacharyya距离</data>
      <data key="d1">concept</data>
      <data key="d2">Bhattacharyya距离是一种用于衡量概率分布之间差异的真正度量。</data>
      <data key="d3">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973177</data>
      <data key="d6" />
    </node>
    <node id="目标函数">
      <data key="d0">目标函数</data>
      <data key="d1">concept</data>
      <data key="d2">目标函数是在比较学习概率分布和源概率分布时使用的函数。&lt;SEP&gt;目标函数是需要最大化的函数，在本研究中是网络熵。</data>
      <data key="d3">chunk-726d03cb1277ab1c0a32f929ee13c3fc&lt;SEP&gt;chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973219</data>
      <data key="d6" />
    </node>
    <node id="比较学习">
      <data key="d0">比较学习</data>
      <data key="d1">method</data>
      <data key="d2">比较学习是一种用于比较概率分布和源概率分布的方法。</data>
      <data key="d3">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973178</data>
      <data key="d6" />
    </node>
    <node id="源概率分布">
      <data key="d0">源概率分布</data>
      <data key="d1">concept</data>
      <data key="d2">源概率分布是在比较学习中被用作参考基准的概率分布。</data>
      <data key="d3">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973178</data>
      <data key="d6" />
    </node>
    <node id="最大熵模型">
      <data key="d0">最大熵模型</data>
      <data key="d1">method</data>
      <data key="d2">最大熵模型是基于最大熵原理构建的统计模型，用于在满足给定约束条件下选择熵最大的概率分布。&lt;SEP&gt;最大熵模型是一种典型的分类算法，属于对数线性分类模型，与逻辑回归类似。&lt;SEP&gt;最大熵模型是一种数学模型，其主要工作在于(人工)提取特征，当完成特征提取后，该模型给出了一种最佳的利用特征的方式。&lt;SEP&gt;最大熵模型是一种统计模型，在文本分类中用于计算每个类别的概率。&lt;SEP&gt;最大熵模型是一种基于概率的方法，用于构建概率模型，其核心思想是在给定约束条件下选择熵最大的概率分布。&lt;SEP&gt;A statistical model used for classification, less commonly applied in the era of deep learning.</data>
      <data key="d3">chunk-d4b315e54e592e86c3a5acfef7099954&lt;SEP&gt;chunk-f34ecacf5f99ee02bae6647b8bd65153&lt;SEP&gt;chunk-8985837bff3264915ed561ec4d80111b&lt;SEP&gt;chunk-23713b5f1cb0ee19178382510009449e&lt;SEP&gt;chunk-2dd1a13b5c662bd9e747f8aa4b9d3361&lt;SEP&gt;chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976252</data>
      <data key="d6" />
    </node>
    <node id="最大熵原理">
      <data key="d0">最大熵原理</data>
      <data key="d1">concept</data>
      <data key="d2">最大熵原理认为在所有可能的概率分布中，熵最大的分布是最好的。&lt;SEP&gt;The principle of maximum entropy.&lt;SEP&gt;A principle used to infer probability distributions by maximizing entropy under given constraints, applied in economics, ecology, and other fields.&lt;SEP&gt;A principle used to develop statistical equilibrium models, including quantal response in economic interactions.&lt;SEP&gt;最大熵原理指出，在所有可能的概率分布中，熵最大的分布是最合理的。&lt;SEP&gt;在满足已知约束条件的所有可能概率分布中，选择熵最大的那一个分布的原则。</data>
      <data key="d3">chunk-d4b315e54e592e86c3a5acfef7099954&lt;SEP&gt;chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4&lt;SEP&gt;chunk-40c170209efa5da46edeea817792b434&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6&lt;SEP&gt;chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976196</data>
      <data key="d6" />
    </node>
    <node id="均匀分布">
      <data key="d0">均匀分布</data>
      <data key="d1">concept</data>
      <data key="d2">在没有约束的情况下，均匀分布是熵最大的概率分布。&lt;SEP&gt;一种概率分布，所有可能结果发生的概率均相等。</data>
      <data key="d3">chunk-d4b315e54e592e86c3a5acfef7099954&lt;SEP&gt;chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976202</data>
      <data key="d6" />
    </node>
    <node id="数学">
      <data key="d0">数学</data>
      <data key="d1">concept</data>
      <data key="d2">数学是文本中提到的领域，是最大熵模型和最大熵原理所属的学科。</data>
      <data key="d3">chunk-d4b315e54e592e86c3a5acfef7099954</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973196</data>
      <data key="d6" />
    </node>
    <node id="网络熵">
      <data key="d0">网络熵</data>
      <data key="d1">concept</data>
      <data key="d2">网络熵是目标函数，用于最大化。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973219</data>
      <data key="d6" />
    </node>
    <node id="概率约束">
      <data key="d0">概率约束</data>
      <data key="d1">concept</data>
      <data key="d2">概率约束是模型构建中需要考虑的约束条件之一。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973220</data>
      <data key="d6" />
    </node>
    <node id="成本约束">
      <data key="d0">成本约束</data>
      <data key="d1">concept</data>
      <data key="d2">成本约束是模型构建中需要考虑的约束条件之一。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973222</data>
      <data key="d6" />
    </node>
    <node id="空间约束">
      <data key="d0">空间约束</data>
      <data key="d1">concept</data>
      <data key="d2">空间约束是模型构建中需要考虑的约束条件之一。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973222</data>
      <data key="d6" />
    </node>
    <node id="模型">
      <data key="d0">模型</data>
      <data key="d1">concept</data>
      <data key="d2">模型结合了多种约束，并有一个唯一的解。&lt;SEP&gt;Model refers to a mathematical representation of a system or process, discussed in the context of Bayes classification.</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976192</data>
      <data key="d6" />
    </node>
    <node id="物种">
      <data key="d0">物种</data>
      <data key="d1">concept</data>
      <data key="d2">模型在各种物种中进行拟合。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973222</data>
      <data key="d6" />
    </node>
    <node id="线虫">
      <data key="d0">线虫</data>
      <data key="d1">creature</data>
      <data key="d2">线虫是一种没有脑的生物，被用作模型拟合的示例。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973222</data>
      <data key="d6" />
    </node>
    <node id="研究">
      <data key="d0">研究</data>
      <data key="d1">concept</data>
      <data key="d2">研究表明模型有一个唯一的解。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973230</data>
      <data key="d6" />
    </node>
    <node id="解">
      <data key="d0">解</data>
      <data key="d1">concept</data>
      <data key="d2">模型有一个唯一的解。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973230</data>
      <data key="d6" />
    </node>
    <node id="拟合效果">
      <data key="d0">拟合效果</data>
      <data key="d1">concept</data>
      <data key="d2">模型的拟合效果在各种物种中相当好。</data>
      <data key="d3">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973230</data>
      <data key="d6" />
    </node>
    <node id="逻辑回归">
      <data key="d0">逻辑回归</data>
      <data key="d1">concept</data>
      <data key="d2">逻辑回归是一种分类算法，与最大熵模型同属于对数线性分类模型。</data>
      <data key="d3">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973243</data>
      <data key="d6" />
    </node>
    <node id="对数线性分类模型">
      <data key="d0">对数线性分类模型</data>
      <data key="d1">concept</data>
      <data key="d2">对数线性分类模型是一类分类算法的总称，最大熵模型和逻辑回归都属于此类模型。</data>
      <data key="d3">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973243</data>
      <data key="d6" />
    </node>
    <node id="损失函数">
      <data key="d0">损失函数</data>
      <data key="d1">concept</data>
      <data key="d2">损失函数是机器学习中用于优化模型参数的函数，最大熵模型在优化过程中会使用它。&lt;SEP&gt;A function used in machine learning, particularly in neural network training for classification problems, to measure the error between predicted and actual outcomes.&lt;SEP&gt;损失函数用于衡量模型预测与真实值之间的差异，交叉熵是神经网络中广泛使用的一种损失函数。&lt;SEP&gt;损失函数追踪人工智能模型输出的错误程度，通过量化预测值与实际值之间的差异来实现。&lt;SEP&gt;损失函数是叶结点经验熵的期望，用于评估决策树模型的分类效果，值越小表示分类效果越好。</data>
      <data key="d3">chunk-f34ecacf5f99ee02bae6647b8bd65153&lt;SEP&gt;chunk-6135ecccd835afdfdaba2f58578ed61e&lt;SEP&gt;chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-408bf4ea5cb0bf2933de13a97fd69ee6&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975920</data>
      <data key="d6" />
    </node>
    <node id="Maximum Entropy Model">
      <data key="d0">Maximum Entropy Model</data>
      <data key="d1">method</data>
      <data key="d2">Maximum Entropy Model is a typical classification algorithm, belonging to log-linear classification models, similar to logistic regression.&lt;SEP&gt;最大熵模型是一种基于概率的方法，用于构建概率模型，其核心思想是在给定约束条件下选择熵最大的概率分布。</data>
      <data key="d3">chunk-f34ecacf5f99ee02bae6647b8bd65153&lt;SEP&gt;chunk-2dd1a13b5c662bd9e747f8aa4b9d3361</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976232</data>
      <data key="d6" />
    </node>
    <node id="Logistic Regression">
      <data key="d0">Logistic Regression</data>
      <data key="d1">concept</data>
      <data key="d2">Logistic Regression is a classification algorithm, belonging to log-linear classification models, similar to Maximum Entropy Model.</data>
      <data key="d3">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973245</data>
      <data key="d6" />
    </node>
    <node id="Log-Linear Classification Model">
      <data key="d0">Log-Linear Classification Model</data>
      <data key="d1">concept</data>
      <data key="d2">Log-Linear Classification Model is a category of classification algorithms, which includes both Maximum Entropy Model and Logistic Regression.</data>
      <data key="d3">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973245</data>
      <data key="d6" />
    </node>
    <node id="Loss Function">
      <data key="d0">Loss Function</data>
      <data key="d1">concept</data>
      <data key="d2">Loss Function is used in machine learning to optimize model parameters; the Maximum Entropy Model uses it during optimization.</data>
      <data key="d3">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973246</data>
      <data key="d6" />
    </node>
    <node id="特征函数">
      <data key="d0">特征函数</data>
      <data key="d1">concept</data>
      <data key="d2">特征函数是最大熵模型中使用的函数，当提取了多个特征时，特征函数的数目将是非常可观的。</data>
      <data key="d3">chunk-8985837bff3264915ed561ec4d80111b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973262</data>
      <data key="d6" />
    </node>
    <node id="特征">
      <data key="d0">特征</data>
      <data key="d1">concept</data>
      <data key="d2">特征是最大熵模型处理的对象，模型的主要工作在于(人工)提取特征。&lt;SEP&gt;特征是机器学习模型中的输入变量，其重要性可以通过信息增益来度量。</data>
      <data key="d3">chunk-8985837bff3264915ed561ec4d80111b&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975788</data>
      <data key="d6" />
    </node>
    <node id="特征提取">
      <data key="d0">特征提取</data>
      <data key="d1">method</data>
      <data key="d2">特征提取是最大熵模型中的一项主要工作，通常需要人工完成，旨在从数据中识别和选择关键特征。</data>
      <data key="d3">chunk-8985837bff3264915ed561ec4d80111b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973263</data>
      <data key="d6" />
    </node>
    <node id="Softmax">
      <data key="d0">Softmax</data>
      <data key="d1">concept</data>
      <data key="d2">Softmax函数是一种常用于多分类问题的函数，可以将输出层的多个连续值转换为概率分布。</data>
      <data key="d3">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973287</data>
      <data key="d6" />
    </node>
    <node id="多分类问题">
      <data key="d0">多分类问题</data>
      <data key="d1">concept</data>
      <data key="d2">多分类问题是一种机器学习任务，需要将输入数据分配到多个可能的类别之一。</data>
      <data key="d3">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973288</data>
      <data key="d6" />
    </node>
    <node id="输出层">
      <data key="d0">输出层</data>
      <data key="d1">concept</data>
      <data key="d2">输出层是神经网络中的一个组成部分，负责产生模型的最终输出。</data>
      <data key="d3">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973288</data>
      <data key="d6" />
    </node>
    <node id="文本分类">
      <data key="d0">文本分类</data>
      <data key="d1">concept</data>
      <data key="d2">文本分类是一种自然语言处理任务，旨在将文本文档分配到一个或多个预定义的类别中。</data>
      <data key="d3">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973289</data>
      <data key="d6" />
    </node>
    <node id="Softmax函数">
      <data key="d0">Softmax函数</data>
      <data key="d1">concept</data>
      <data key="d2">Softmax函数是一种常用于多分类问题的函数，可以将输出层的多个连续值转换为概率分布。</data>
      <data key="d3">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973289</data>
      <data key="d6" />
    </node>
    <node id="连续值">
      <data key="d0">连续值</data>
      <data key="d1">concept</data>
      <data key="d2">连续值是输出层产生的未经处理的数值，是Softmax函数的输入。</data>
      <data key="d3">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973289</data>
      <data key="d6" />
    </node>
    <node id="类别">
      <data key="d0">类别</data>
      <data key="d1">concept</data>
      <data key="d2">类别是多分类问题中数据可能被分配到的目标分组。&lt;SEP&gt;类别是分类任务中预定义的组别，本文示例包括政治、经济、娱乐、社会、科技、历史、家庭等七种类型。</data>
      <data key="d3">chunk-23713b5f1cb0ee19178382510009449e&lt;SEP&gt;chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974387</data>
      <data key="d6" />
    </node>
    <node id="随机理论">
      <data key="d0">随机理论</data>
      <data key="d1">concept</data>
      <data key="d2">A statistical model produced by an agent subject to resource and technological constraints.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973425</data>
      <data key="d6" />
    </node>
    <node id="参考文献[16]">
      <data key="d0">参考文献[16]</data>
      <data key="d1">content</data>
      <data key="d2">A reference that extends the theory to a general equilibrium model of a complex economy composed of consumers and producers.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973425</data>
      <data key="d6" />
    </node>
    <node id="参考文献[75]">
      <data key="d0">参考文献[75]</data>
      <data key="d1">content</data>
      <data key="d2">A reference that extends the theory to a general equilibrium model of a complex economy composed of consumers and producers.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973419</data>
      <data key="d6" />
    </node>
    <node id="Foley">
      <data key="d0">Foley</data>
      <data key="d1">person</data>
      <data key="d2">An economist who developed a statistical equilibrium theory of markets based on the sets of offers from market participants.&lt;SEP&gt;Developed the statistical equilibrium theory of markets.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973420</data>
      <data key="d6" />
    </node>
    <node id="统计均衡理论">
      <data key="d0">统计均衡理论</data>
      <data key="d1">concept</data>
      <data key="d2">A theory of market analysis that begins with the set of offers from market agents and maximizes the entropy of the distribution of market transactions.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973420</data>
      <data key="d6" />
    </node>
    <node id="报价集">
      <data key="d0">报价集</data>
      <data key="d1">concept</data>
      <data key="d2">Sets of offers from market agents reflecting their desired and feasible transactions, conditioned on their information, technological possibilities, endowments, and preferences.&lt;SEP&gt;Sets of offers from market participants reflecting their desired and feasible trades, used as the starting point for market analysis in Foley's theory.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973421</data>
      <data key="d6" />
    </node>
    <node id="博弈论">
      <data key="d0">博弈论</data>
      <data key="d1">concept</data>
      <data key="d2">A theoretical framework for modeling strategic interactions among rational agents.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973421</data>
      <data key="d6" />
    </node>
    <node id="McKelvey">
      <data key="d0">McKelvey</data>
      <data key="d1">person</data>
      <data key="d2">Adopted a statistical approach in a game theory setting to establish a quantitative (discrete) choice model.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973423</data>
      <data key="d6" />
    </node>
    <node id="Palfrey">
      <data key="d0">Palfrey</data>
      <data key="d1">person</data>
      <data key="d2">Adopted a statistical approach in a game theory setting to establish a quantitative (discrete) choice model.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973423</data>
      <data key="d6" />
    </node>
    <node id="随机最优反应均衡">
      <data key="d0">随机最优反应均衡</data>
      <data key="d1">concept</data>
      <data key="d2">Also known as Quantal Response Equilibrium (QRE), a fixed point of a process where players choose strategies based on expected utility and a quantal choice model.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973424</data>
      <data key="d6" />
    </node>
    <node id="量子响应均衡">
      <data key="d0">量子响应均衡</data>
      <data key="d1">concept</data>
      <data key="d2">Also known as Quantal Response Equilibrium (QRE), a fixed point of a process where players choose strategies based on expected utility and a quantal choice model.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973424</data>
      <data key="d6" />
    </node>
    <node id="Logit均衡">
      <data key="d0">Logit均衡</data>
      <data key="d1">concept</data>
      <data key="d2">An equilibrium resulting from a specific parameter class of quantal response functions, which is the traditional way to analyze empirical choice models.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973426</data>
      <data key="d6" />
    </node>
    <node id="最大似然Logit模型">
      <data key="d0">最大似然Logit模型</data>
      <data key="d1">method</data>
      <data key="d2">The maximum entropy model for all unordered discrete choice problems.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973427</data>
      <data key="d6" />
    </node>
    <node id="Scharfenaker">
      <data key="d0">Scharfenaker</data>
      <data key="d1">person</data>
      <data key="d2">Adopted the maximum entropy principle to develop a statistical equilibrium of quantal response in economic interaction models, building on previous work.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973427</data>
      <data key="d6" />
    </node>
    <node id="非平衡热力学系统">
      <data key="d0">非平衡热力学系统</data>
      <data key="d1">concept</data>
      <data key="d2">A system where state variables change over time, and constraints imposed by instantaneous values may not accurately predict the instantaneous microscopic distribution.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973428</data>
      <data key="d6" />
    </node>
    <node id="马尔可夫过程">
      <data key="d0">马尔可夫过程</data>
      <data key="d1">method</data>
      <data key="d2">Used to model dynamic processes across disciplines, from population growth to financial markets.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973435</data>
      <data key="d6" />
    </node>
    <node id="条件概率">
      <data key="d0">条件概率</data>
      <data key="d1">concept</data>
      <data key="d2">Rules used to compute the state of a system or individuals within it, often conditioned on environmental, economic, or other factors.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973429</data>
      <data key="d6" />
    </node>
    <node id="最大熵原理马尔可夫问题">
      <data key="d0">最大熵原理马尔可夫问题</data>
      <data key="d1">method</data>
      <data key="d2">A generalized approach using the maximum entropy principle to model conditional Markov processes for complex systems with continuously evolving data.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973429</data>
      <data key="d6" />
    </node>
    <node id="香农熵">
      <data key="d0">香农熵</data>
      <data key="d1">concept</data>
      <data key="d2">The Shannon entropy, which needs to be defined for probability distributions P and uncertainty W in the maximum entropy inference problem.&lt;SEP&gt;Shannon entropy is a concept used in the invention to define a function that measures the likelihood of test cases being misclassified and to rank them.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974171</data>
      <data key="d6" />
    </node>
    <node id="拉格朗日乘子">
      <data key="d0">拉格朗日乘子</data>
      <data key="d1">concept</data>
      <data key="d2">Parameters inferred simultaneously with transition probabilities and uncertainty probabilities during the optimization process.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973430</data>
      <data key="d6" />
    </node>
    <node id="DynaMETE">
      <data key="d0">DynaMETE</data>
      <data key="d1">method</data>
      <data key="d2">A method or model, likely related to dynamic maximum entropy.&lt;SEP&gt;A method mentioned in comparison to the generalized maximum entropy Markov approach.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973430</data>
      <data key="d6" />
    </node>
    <node id="MET E">
      <data key="d0">MET E</data>
      <data key="d1">method</data>
      <data key="d2">A method or model, likely an abbreviation for a maximum entropy theory.&lt;SEP&gt;A method mentioned in comparison to the generalized maximum entropy Markov approach.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973430</data>
      <data key="d6" />
    </node>
    <node id="复杂经济体">
      <data key="d0">复杂经济体</data>
      <data key="d1">concept</data>
      <data key="d2">An economy composed of consumers and producers, modeled in a general equilibrium framework.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973430</data>
      <data key="d6" />
    </node>
    <node id="市场">
      <data key="d0">市场</data>
      <data key="d1">concept</data>
      <data key="d2">The mechanism that allocates agents to offer sets to maximize the entropy of the transaction distribution.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973431</data>
      <data key="d6" />
    </node>
    <node id="市场主体">
      <data key="d0">市场主体</data>
      <data key="d1">concept</data>
      <data key="d2">Agents in the market who have sets of offers based on their information, technology, endowments, and preferences.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973431</data>
      <data key="d6" />
    </node>
    <node id="预期效用">
      <data key="d0">预期效用</data>
      <data key="d1">concept</data>
      <data key="d2">The expected utility upon which players base their strategy choices in the quantal response model.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973431</data>
      <data key="d6" />
    </node>
    <node id="数量选择模型">
      <data key="d0">数量选择模型</data>
      <data key="d1">method</data>
      <data key="d2">A quantal choice model used by players to select strategies based on expected utility.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973432</data>
      <data key="d6" />
    </node>
    <node id="误差结构">
      <data key="d0">误差结构</data>
      <data key="d1">concept</data>
      <data key="d2">A specific error structure assumed in the process leading to the Quantal Response Equilibrium.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973432</data>
      <data key="d6" />
    </node>
    <node id="反应函数">
      <data key="d0">反应函数</data>
      <data key="d1">concept</data>
      <data key="d2">Probabilistic functions resulting from the QRE process, where better responses are more likely to be observed.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973432</data>
      <data key="d6" />
    </node>
    <node id="生态学">
      <data key="d0">生态学</data>
      <data key="d1">concept</data>
      <data key="d2">A discipline where there are examples of prediction failures when state variables change over time.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973433</data>
      <data key="d6" />
    </node>
    <node id="受干扰的生态系统">
      <data key="d0">受干扰的生态系统</data>
      <data key="d1">concept</data>
      <data key="d2">An example of a system where changing state variables can lead to inaccurate predictions of microscopic distributions.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973433</data>
      <data key="d6" />
    </node>
    <node id="转型中的经济">
      <data key="d0">转型中的经济</data>
      <data key="d1">concept</data>
      <data key="d2">An example of a system where changing state variables can lead to inaccurate predictions of microscopic distributions.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973433</data>
      <data key="d6" />
    </node>
    <node id="物种的种群增长">
      <data key="d0">物种的种群增长</data>
      <data key="d1">concept</data>
      <data key="d2">A dynamic process modeled using Markov processes in ecology.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973433</data>
      <data key="d6" />
    </node>
    <node id="金融市场">
      <data key="d0">金融市场</data>
      <data key="d1">concept</data>
      <data key="d2">A domain where the progression of securities is modeled using Markov processes.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973433</data>
      <data key="d6" />
    </node>
    <node id="等级组织">
      <data key="d0">等级组织</data>
      <data key="d1">concept</data>
      <data key="d2">A domain where promotions are modeled using Markov processes.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973433</data>
      <data key="d6" />
    </node>
    <node id="外生变量">
      <data key="d0">外生变量</data>
      <data key="d1">concept</data>
      <data key="d2">Variables that condition transition probabilities, allowing inference of causal effects on those probabilities.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973434</data>
      <data key="d6" />
    </node>
    <node id="观察到的信息Y和X">
      <data key="d0">观察到的信息Y和X</data>
      <data key="d1">data</data>
      <data key="d2">The observed information given as input for inferring transition probabilities and uncertainty using the maximum entropy principle.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973434</data>
      <data key="d6" />
    </node>
    <node id="不确定性">
      <data key="d0">不确定性</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the absence of fuzziness or uncertainty in a system's exact dynamics.&lt;SEP&gt;Treated as a random variable with a probability distribution W (mean zero) in the maximum entropy inference framework.&lt;SEP&gt;Uncertainty is a state of having limited knowledge where it is impossible to exactly describe the existing state, a key concept related to entropy.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5&lt;SEP&gt;chunk-40c170209efa5da46edeea817792b434&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976200</data>
      <data key="d6" />
    </node>
    <node id="概率分布W">
      <data key="d0">概率分布W</data>
      <data key="d1">concept</data>
      <data key="d2">The probability distribution of the uncertainty, treated as a random variable.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973434</data>
      <data key="d6" />
    </node>
    <node id="过渡概率">
      <data key="d0">过渡概率</data>
      <data key="d1">concept</data>
      <data key="d2">Transition probabilities (P) that are inferred simultaneously with uncertainty and Lagrange multipliers.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973435</data>
      <data key="d6" />
    </node>
    <node id="因果解释">
      <data key="d0">因果解释</data>
      <data key="d1">concept</data>
      <data key="d2">A direct interpretation of the impact of each exogenous variable on each inferred transition probability.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973435</data>
      <data key="d6" />
    </node>
    <node id="连续外生变量">
      <data key="d0">连续外生变量</data>
      <data key="d1">concept</data>
      <data key="d2">A type of exogenous variable for which causal effects on transition probabilities can be calculated.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973436</data>
      <data key="d6" />
    </node>
    <node id="离散外生变量">
      <data key="d0">离散外生变量</data>
      <data key="d1">concept</data>
      <data key="d2">A type of exogenous variable for which causal effects on transition probabilities can be calculated.</data>
      <data key="d3">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973436</data>
      <data key="d6" />
    </node>
    <node id="投入产出账户">
      <data key="d0">投入产出账户</data>
      <data key="d1">concept</data>
      <data key="d2">An accounting framework that expands to include accounts from factor payments (value added) to final demand for goods.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973436</data>
      <data key="d6" />
    </node>
    <node id="投入产出表">
      <data key="d0">投入产出表</data>
      <data key="d1">concept</data>
      <data key="d2">A rectangular table used in economics to represent the interdependencies between different sectors of an economy.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973436</data>
      <data key="d6" />
    </node>
    <node id="社会核算矩阵">
      <data key="d0">社会核算矩阵</data>
      <data key="d1">concept</data>
      <data key="d2">A square matrix used in economics where rows equal columns (X=Y and AX=Y), representing a comprehensive framework of economic transactions.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973437</data>
      <data key="d6" />
    </node>
    <node id="METE (生态学最大熵原理)">
      <data key="d0">METE (生态学最大熵原理)</data>
      <data key="d1">concept</data>
      <data key="d2">The Maximum Entropy Theory of Ecology, a theoretical framework that predicts patterns of species abundance, spatial distribution, and energetics across scales and taxa.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973437</data>
      <data key="d6" />
    </node>
    <node id="生态结构函数">
      <data key="d0">生态结构函数</data>
      <data key="d1">concept</data>
      <data key="d2">A joint probability distribution in METE that describes the allocation of individuals among species and their metabolic rates, conditioned on state variables.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973437</data>
      <data key="d6" />
    </node>
    <node id="空间分布">
      <data key="d0">空间分布</data>
      <data key="d1">concept</data>
      <data key="d2">A probability distribution in METE that describes the spatial aggregation of individuals within a species across an area.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973439</data>
      <data key="d6" />
    </node>
    <node id="状态变量">
      <data key="d0">状态变量</data>
      <data key="d1">concept</data>
      <data key="d2">Variables such as area (A0), total number of species (S0), total number of individuals (N0), and total metabolism (E0) that define the state of a system in METE.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973439</data>
      <data key="d6" />
    </node>
    <node id="拉格朗日乘数">
      <data key="d0">拉格朗日乘数</data>
      <data key="d1">concept</data>
      <data key="d2">Multipliers used in constrained optimization problems, such as maximizing entropy under linear constraints.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973441</data>
      <data key="d6" />
    </node>
    <node id="Jaynes">
      <data key="d0">Jaynes</data>
      <data key="d1">person</data>
      <data key="d2">A person credited with deriving statistical mechanics using maximum entropy principles, opening the door for many modern applications.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973441</data>
      <data key="d6" />
    </node>
    <node id="Golan">
      <data key="d0">Golan</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who used the maximum entropy principle to derive a multivariate stochastic theory for the distribution of firm sizes in an economy.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973441</data>
      <data key="d6" />
    </node>
    <node id="经济学">
      <data key="d0">经济学</data>
      <data key="d1">concept</data>
      <data key="d2">A field of study where the maximum entropy principle is frequently applied to problems such as matrix balancing and economic modeling.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973442</data>
      <data key="d6" />
    </node>
    <node id="热力学系统">
      <data key="d0">热力学系统</data>
      <data key="d1">concept</data>
      <data key="d2">A type of system, such as those studied in statistical mechanics, where maximum entropy principles are applied for theoretical construction.&lt;SEP&gt;热力学系统是热力学研究的对象，其熵的增减可以用公式 ΔS = ΔQ/T进行计算和描述。</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4&lt;SEP&gt;chunk-1248b4cdb9c5b6a4f15c20d0991319ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973925</data>
      <data key="d6" />
    </node>
    <node id="生态系统">
      <data key="d0">生态系统</data>
      <data key="d1">concept</data>
      <data key="d2">A type of system studied in ecology, where theories like METE apply maximum entropy principles to predict ecological patterns.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973442</data>
      <data key="d6" />
    </node>
    <node id="经济系统">
      <data key="d0">经济系统</data>
      <data key="d1">concept</data>
      <data key="d2">A type of system where maximum entropy principles are used to build models, such as general equilibrium models of complex economies.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973443</data>
      <data key="d6" />
    </node>
    <node id="矩阵平衡问题">
      <data key="d0">矩阵平衡问题</data>
      <data key="d1">concept</data>
      <data key="d2">A class of problems in economics and related fields where methods like maximum entropy are used to balance matrices under constraints.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973443</data>
      <data key="d6" />
    </node>
    <node id="统计力学">
      <data key="d0">统计力学</data>
      <data key="d1">concept</data>
      <data key="d2">统计力学（Statistical mechanics）是物理学的一个分支。它由杰恩斯（Jaynes）基于最大熵原理发展而来，并为众多应用领域提供了理论基础。该学术领域是玻尔兹曼机（Boltzmann machine）这类神经网络模型所属和讨论的领域。在相关文献的元数据中，统计力学常被标注为所提及文档所属的研究领域或学科范畴。&lt;SEP&gt;Statistical mechanics is the field of study mentioned in the document metadata.&lt;SEP&gt;Statistical mechanics is a branch of physics that applies probability theory to study the behavior of systems composed of a large number of particles.&lt;SEP&gt;统计力学是物理学的一个领域，涉及配分函数等概念。&lt;SEP&gt;The domain or field of study mentioned in the document metadata.&lt;SEP&gt;A field of physics that studies the behavior of large ensembles of particles.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4&lt;SEP&gt;chunk-29b81edcfc109c880298f79878843454&lt;SEP&gt;chunk-74ac9b8a3a08c569f1c072b77c552920&lt;SEP&gt;chunk-b2aa136f0a91bbc88ed87eed07a66512&lt;SEP&gt;chunk-e378397631b5d452d5eb095ebbfde434&lt;SEP&gt;chunk-9be983c468c91cc26e854198668abadf&lt;SEP&gt;chunk-3fa882df56ee354fb7b7e6d63cec74d9&lt;SEP&gt;chunk-f922579134fc1d01217fc44031832b5f&lt;SEP&gt;chunk-bc6cd88a44423ac7bc4a08969a8b99f8&lt;SEP&gt;chunk-7d7618b6fffb013ab6c5a2ca3a3fea50&lt;SEP&gt;chunk-36562522576eae8192339d548d0a1406&lt;SEP&gt;chunk-08c978d767db01aaeef63f40ea958f51&lt;SEP&gt;chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975449</data>
      <data key="d6" />
    </node>
    <node id="一般均衡模型">
      <data key="d0">一般均衡模型</data>
      <data key="d1">concept</data>
      <data key="d2">An economic model extended to complex economies with consumers and producers, using principles from maximum entropy theory.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973450</data>
      <data key="d6" />
    </node>
    <node id="市场的统计均衡理论">
      <data key="d0">市场的统计均衡理论</data>
      <data key="d1">concept</data>
      <data key="d2">A theory of market equilibrium developed by Foley, based on statistical analysis of offers from market participants.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973444</data>
      <data key="d6" />
    </node>
    <node id="马尔科夫例子">
      <data key="d0">马尔科夫例子</data>
      <data key="d1">concept</data>
      <data key="d2">A Markov example mentioned as a generalization of the simple maximum entropy model for matrix balancing.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973444</data>
      <data key="d6" />
    </node>
    <node id="物种丰度">
      <data key="d0">物种丰度</data>
      <data key="d1">concept</data>
      <data key="d2">A predicted ecological pattern in METE, referring to the distribution of species abundances.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973444</data>
      <data key="d6" />
    </node>
    <node id="个体代谢率">
      <data key="d0">个体代谢率</data>
      <data key="d1">concept</data>
      <data key="d2">A predicted ecological pattern in METE, referring to the distribution of individual metabolic rates.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973444</data>
      <data key="d6" />
    </node>
    <node id="种内空间聚集度">
      <data key="d0">种内空间聚集度</data>
      <data key="d1">concept</data>
      <data key="d2">A predicted ecological pattern in METE, referring to the degree of spatial aggregation of individuals within a species.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973445</data>
      <data key="d6" />
    </node>
    <node id="物种多样性">
      <data key="d0">物种多样性</data>
      <data key="d1">concept</data>
      <data key="d2">A predicted ecological pattern in METE, referring to the dependence of species diversity on sampling area.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973445</data>
      <data key="d6" />
    </node>
    <node id="状态方程">
      <data key="d0">状态方程</data>
      <data key="d1">concept</data>
      <data key="d2">An equation of state in METE relating to biomass, metabolic rate, abundance, and species diversity.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973445</data>
      <data key="d6" />
    </node>
    <node id="代谢比例定律">
      <data key="d0">代谢比例定律</data>
      <data key="d1">concept</data>
      <data key="d2">A scaling law assumed in METE to infer metabolic rates from mass when direct measurement is difficult.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973445</data>
      <data key="d6" />
    </node>
    <node id="企业规模分布">
      <data key="d0">企业规模分布</data>
      <data key="d1">concept</data>
      <data key="d2">The distribution of firm sizes in an economy, derived by Golan using the maximum entropy principle.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973446</data>
      <data key="d6" />
    </node>
    <node id="主体生产">
      <data key="d0">主体生产</data>
      <data key="d1">concept</data>
      <data key="d2">Agent production in an economic model, subject to resource and technological constraints in Golan's theory.</data>
      <data key="d3">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973446</data>
      <data key="d6" />
    </node>
    <node id="Information Theory">
      <data key="d0">Information Theory</data>
      <data key="d1">concept</data>
      <data key="d2">A theoretical framework for quantifying information, communication, and uncertainty, serving as a foundation for complexity science.&lt;SEP&gt;Information Theory is a field founded by Shannon, and its principles are used as tools for unsupervised learning.&lt;SEP&gt;Information Theory is the field of study to which the listed papers belong.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1&lt;SEP&gt;chunk-82dd7e184547eda32bd10d04c1cae982&lt;SEP&gt;chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974566</data>
      <data key="d6" />
    </node>
    <node id="Complexity Science">
      <data key="d0">Complexity Science</data>
      <data key="d1">concept</data>
      <data key="d2">A field of science studying complex systems and their behaviors.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973446</data>
      <data key="d6" />
    </node>
    <node id="Modeling">
      <data key="d0">Modeling</data>
      <data key="d1">concept</data>
      <data key="d2">The process of creating abstract representations of systems, central to scientific inquiry.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973447</data>
      <data key="d6" />
    </node>
    <node id="Inference">
      <data key="d0">Inference</data>
      <data key="d1">concept</data>
      <data key="d2">The process of deriving conclusions from premises or evidence, central to scientific reasoning.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973447</data>
      <data key="d6" />
    </node>
    <node id="Maximum Entropy Principle">
      <data key="d0">Maximum Entropy Principle</data>
      <data key="d1">concept</data>
      <data key="d2">A principle for making inferences under uncertainty by selecting the probability distribution that is maximally noncommittal with regard to missing information.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973447</data>
      <data key="d6" />
    </node>
    <node id="Jakob Bernoulli">
      <data key="d0">Jakob Bernoulli</data>
      <data key="d1">person</data>
      <data key="d2">A mathematician who established the mathematical foundation for decision-making under uncertainty and is considered a founder of probability theory.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973447</data>
      <data key="d6" />
    </node>
    <node id="Principle Of Insufficient Reason">
      <data key="d0">Principle Of Insufficient Reason</data>
      <data key="d1">concept</data>
      <data key="d2">A principle stating that in the absence of relevant information, all possible outcomes should be considered equally probable.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973448</data>
      <data key="d6" />
    </node>
    <node id="Thomas Simpson">
      <data key="d0">Thomas Simpson</data>
      <data key="d1">person</data>
      <data key="d2">A mathematician who independently developed more mathematically sound tools for inference.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973448</data>
      <data key="d6" />
    </node>
    <node id="Thomas Bayes">
      <data key="d0">Thomas Bayes</data>
      <data key="d1">person</data>
      <data key="d2">A mathematician who independently developed more mathematically sound tools for inference.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973456</data>
      <data key="d6" />
    </node>
    <node id="Abraham De Moivre">
      <data key="d0">Abraham De Moivre</data>
      <data key="d1">person</data>
      <data key="d2">A mathematician who independently developed more mathematically sound tools for inference.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973456</data>
      <data key="d6" />
    </node>
    <node id="Pierre-Simon Laplace">
      <data key="d0">Pierre-Simon Laplace</data>
      <data key="d1">person</data>
      <data key="d2">A mathematician who laid the foundation for statistical and probabilistic inference with his understanding of inverse probability and "inverse reasoning".</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973448</data>
      <data key="d6" />
    </node>
    <node id="Claude Shannon">
      <data key="d0">Claude Shannon</data>
      <data key="d1">person</data>
      <data key="d2">A scientist whose work on communication theory, particularly his formulation of information entropy, laid the foundation for modern information theory.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973448</data>
      <data key="d6" />
    </node>
    <node id="Information Entropy">
      <data key="d0">Information Entropy</data>
      <data key="d1">concept</data>
      <data key="d2">A measure of uncertainty or information content, formulated by Claude Shannon, foundational to information theory.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973449</data>
      <data key="d6" />
    </node>
    <node id="Edwin Thompson Jaynes">
      <data key="d0">Edwin Thompson Jaynes</data>
      <data key="d1">person</data>
      <data key="d2">A physicist who recognized that Shannon's information entropy provided the key to unbiased inference under uncertainty and formalized the Maximum Entropy Principle.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973449</data>
      <data key="d6" />
    </node>
    <node id="John Skilling">
      <data key="d0">John Skilling</data>
      <data key="d1">person</data>
      <data key="d2">A scientist who proposed using information theory, specifically the Maximum Entropy principle, to predict the behavior of incompletely characterized systems.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973450</data>
      <data key="d6" />
    </node>
    <node id="Probability Distribution">
      <data key="d0">Probability Distribution</data>
      <data key="d1">concept</data>
      <data key="d2">A mathematical function that provides the probabilities of occurrence of different possible outcomes.&lt;SEP&gt;The distribution that an RBM aims to learn, which has 2^(n_v + n_h) possible states, leading to high computational complexity.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1&lt;SEP&gt;chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974823</data>
      <data key="d6" />
    </node>
    <node id="Shannon Entropy">
      <data key="d0">Shannon Entropy</data>
      <data key="d1">concept</data>
      <data key="d2">The information entropy measure formulated by Claude Shannon, used as an objective function to maximize in the Maximum Entropy Principle.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973450</data>
      <data key="d6" />
    </node>
    <node id="Uniform Distribution">
      <data key="d0">Uniform Distribution</data>
      <data key="d1">concept</data>
      <data key="d2">A probability distribution where all outcomes are equally likely, representing a state of maximum uncertainty.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973450</data>
      <data key="d6" />
    </node>
    <node id="Leontief Input-Output Model">
      <data key="d0">Leontief Input-Output Model</data>
      <data key="d1">concept</data>
      <data key="d2">An economic model representing the interdependencies between different sectors of an economy.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973451</data>
      <data key="d6" />
    </node>
    <node id="Social Accounting Matrix">
      <data key="d0">Social Accounting Matrix</data>
      <data key="d1">concept</data>
      <data key="d2">An extension of input-output accounts that adds accounts for factor payments and final demand, forming a square matrix.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973451</data>
      <data key="d6" />
    </node>
    <node id="Amos Golan">
      <data key="d0">Amos Golan</data>
      <data key="d1">person</data>
      <data key="d2">Co-author of the paper "Information theory: A foundation for complexity science."</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973452</data>
      <data key="d6" />
    </node>
    <node id="John Harte">
      <data key="d0">John Harte</data>
      <data key="d1">person</data>
      <data key="d2">Co-author of the paper "Information theory: A foundation for complexity science."</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973452</data>
      <data key="d6" />
    </node>
    <node id="Ars Conjectandi">
      <data key="d0">Ars Conjectandi</data>
      <data key="d1">content</data>
      <data key="d2">A work by Jakob Bernoulli that summarized his contributions to probability theory and the principle of insufficient reason.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973452</data>
      <data key="d6" />
    </node>
    <node id="Probability Theory">
      <data key="d0">Probability Theory</data>
      <data key="d1">concept</data>
      <data key="d2">The branch of mathematics concerned with probability, founded on work by mathematicians like Jakob Bernoulli.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973452</data>
      <data key="d6" />
    </node>
    <node id="Statistical Inference">
      <data key="d0">Statistical Inference</data>
      <data key="d1">concept</data>
      <data key="d2">The process of drawing conclusions from data using principles of statistics and probability, with foundations laid by Pierre-Simon Laplace.</data>
      <data key="d3">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973454</data>
      <data key="d6" />
    </node>
    <node id="连续和离散外生变量的因果效应">
      <data key="d0">连续和离散外生变量的因果效应</data>
      <data key="d1">concept</data>
      <data key="d2">A concept referring to the causal effects of continuous and discrete exogenous variables.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973454</data>
      <data key="d6" />
    </node>
    <node id="广义的最大熵原理马尔可夫问题">
      <data key="d0">广义的最大熵原理马尔可夫问题</data>
      <data key="d1">concept</data>
      <data key="d2">A generalized maximum entropy principle Markov problem.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973455</data>
      <data key="d6" />
    </node>
    <node id="经典的最大熵原理">
      <data key="d0">经典的最大熵原理</data>
      <data key="d1">concept</data>
      <data key="d2">The classical principle of maximum entropy.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973455</data>
      <data key="d6" />
    </node>
    <node id="MaxCal">
      <data key="d0">MaxCal</data>
      <data key="d1">method</data>
      <data key="d2">Maximum Caliber, a method for inferring paths in dynamical systems.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973455</data>
      <data key="d6" />
    </node>
    <node id="马尔科夫框架">
      <data key="d0">马尔科夫框架</data>
      <data key="d1">concept</data>
      <data key="d2">A Markovian framework.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973455</data>
      <data key="d6" />
    </node>
    <node id="广义方法">
      <data key="d0">广义方法</data>
      <data key="d1">method</data>
      <data key="d2">A generalized method discussed for solving complex problems without increasing model complexity.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973456</data>
      <data key="d6" />
    </node>
    <node id="模型复杂性">
      <data key="d0">模型复杂性</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the complexity of a model, which the generalized method does not increase.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973456</data>
      <data key="d6" />
    </node>
    <node id="稳定状态">
      <data key="d0">稳定状态</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to a system being in a steady state.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973456</data>
      <data key="d6" />
    </node>
    <node id="模糊性">
      <data key="d0">模糊性</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the absence of fuzziness in a system's exact dynamics.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973456</data>
      <data key="d6" />
    </node>
    <node id="路径">
      <data key="d0">路径</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to paths or transitions in a system.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973457</data>
      <data key="d6" />
    </node>
    <node id="外部因素">
      <data key="d0">外部因素</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to external factors that can constrain paths or transitions.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973457</data>
      <data key="d6" />
    </node>
    <node id="复杂数据">
      <data key="d0">复杂数据</data>
      <data key="d1">data</data>
      <data key="d2">Refers to complex data that can constrain paths or transitions.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973457</data>
      <data key="d6" />
    </node>
    <node id="[16, 61]">
      <data key="d0">[16, 61]</data>
      <data key="d1">content</data>
      <data key="d2">References to literature, likely citations number 16 and 61.</data>
      <data key="d3">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973457</data>
      <data key="d6" />
    </node>
    <node id="热力学信息神经网络">
      <data key="d0">热力学信息神经网络</data>
      <data key="d1">method</data>
      <data key="d2">采用归纳偏差来执行热力学第一和第二定律的强制执行。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973506</data>
      <data key="d6" />
    </node>
    <node id="归纳偏差">
      <data key="d0">归纳偏差</data>
      <data key="d1">concept</data>
      <data key="d2">用于构建热力学信息神经网络，以强制执行热力学定律。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973506</data>
      <data key="d6" />
    </node>
    <node id="热力学第一定律">
      <data key="d0">热力学第一定律</data>
      <data key="d1">concept</data>
      <data key="d2">热力学基本定律之一，被热力学信息神经网络强制执行。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973507</data>
      <data key="d6" />
    </node>
    <node id="热力学第二定律">
      <data key="d0">热力学第二定律</data>
      <data key="d1">concept</data>
      <data key="d2">热力学基本定律之一，被热力学信息神经网络强制执行。&lt;SEP&gt;热力学第二定律是热力学的三条基本定律之一，它表述了热力学过程的不可逆性。&lt;SEP&gt;热力学第二定律指出，在一个孤立系统中，熵(无序程度)只会不断增加，不会减少，描述了宇宙从有序走向无序的底层趋势。&lt;SEP&gt;A fundamental law of thermodynamics stating that the total entropy of an isolated system can never decrease over time.&lt;SEP&gt;热力学第二定律是物理学中的一个基本定律，其数学表述借助熵的概念来描述热力学系统的不可逆过程。&lt;SEP&gt;热力学第二定律描述了孤立系统的熵总是趋向于增加。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68&lt;SEP&gt;chunk-aedc5bd9c6d5647339e7b59deea0f006&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a&lt;SEP&gt;chunk-d0e494da55d171b3a3a8b96678397514&lt;SEP&gt;chunk-1248b4cdb9c5b6a4f15c20d0991319ae&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975790</data>
      <data key="d6" />
    </node>
    <node id="系统">
      <data key="d0">系统</data>
      <data key="d1">concept</data>
      <data key="d2">具有metriplectic演化的对象。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973508</data>
      <data key="d6" />
    </node>
    <node id="Metriplectic演化">
      <data key="d0">Metriplectic演化</data>
      <data key="d1">concept</data>
      <data key="d2">为构建热力学信息神经网络的归纳偏差而假定的系统演化方式。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973508</data>
      <data key="d6" />
    </node>
    <node id="黑盒子网络">
      <data key="d0">黑盒子网络</data>
      <data key="d1">method</data>
      <data key="d2">未经过信息处理的网络，与热力学信息神经网络相比结果较差。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973516</data>
      <data key="d6" />
    </node>
    <node id="物理学">
      <data key="d0">物理学</data>
      <data key="d1">concept</data>
      <data key="d2">热力学信息神经网络所属的学术领域。&lt;SEP&gt;本研究属于物理学领域。&lt;SEP&gt;Physics is the scientific discipline to which the field of thermodynamics belongs.</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68&lt;SEP&gt;chunk-cc989a9fb47a8cd36db8fe7fb353106b&lt;SEP&gt;chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973875</data>
      <data key="d6" />
    </node>
    <node id="热力学">
      <data key="d0">热力学</data>
      <data key="d1">concept</data>
      <data key="d2">热力学信息神经网络所属的物理学分支。&lt;SEP&gt;热力学是物理学的一个分支，包含三条基本定律。&lt;SEP&gt;本研究属于热力学领域。&lt;SEP&gt;Thermodynamics is a branch of physics dealing with heat, work, and temperature.&lt;SEP&gt;A branch of physics that studies heat, work, and energy, and is the domain in which the concept of entropy is discussed.&lt;SEP&gt;热力学是物理学的一个分支，熵是其核心概念之一。</data>
      <data key="d3">chunk-39fe5cddbd852d7e5e0202a65cc33f68&lt;SEP&gt;chunk-aedc5bd9c6d5647339e7b59deea0f006&lt;SEP&gt;chunk-cc989a9fb47a8cd36db8fe7fb353106b&lt;SEP&gt;chunk-76741d601c3b02adb5beb29cf0c31924&lt;SEP&gt;chunk-6135ecccd835afdfdaba2f58578ed61e&lt;SEP&gt;chunk-31dfc0a8415a0647f471a1cab88d6e36</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973946</data>
      <data key="d6" />
    </node>
    <node id="孤立系统">
      <data key="d0">孤立系统</data>
      <data key="d1">concept</data>
      <data key="d2">孤立系统是热力学第二定律所描述其过程不可逆性的系统。</data>
      <data key="d3">chunk-aedc5bd9c6d5647339e7b59deea0f006</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973519</data>
      <data key="d6" />
    </node>
    <node id="机器智能">
      <data key="d0">机器智能</data>
      <data key="d1">concept</data>
      <data key="d2">Machine intelligence, whose core goal is to effectively organize machines into a precisely operating information-based anti-entropy system.&lt;SEP&gt;机器智能是硅基系统(如人工智能)所具备的智能形态，其本质同样是系统通过吸收信息以抵抗熵增、维系自身秩序的能力，在高速建模与数据处理上具有专长。&lt;SEP&gt;Machine intelligence, discussed in contrast to and in commonality with human intelligence.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973686</data>
      <data key="d6" />
    </node>
    <node id="人类智能">
      <data key="d0">人类智能</data>
      <data key="d1">concept</data>
      <data key="d2">Human intelligence, which shares a physical and functional homology with machine intelligence according to the text.&lt;SEP&gt;人类智能是碳基生命体(人类)所具备的智能形态，其本质是系统通过吸收信息以抵抗熵增、维系自身秩序的能力，在具身探索与推理决策上具有优势。&lt;SEP&gt;Human intelligence, discussed in contrast to and in commonality with machine intelligence.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973686</data>
      <data key="d6" />
    </node>
    <node id="连接主义">
      <data key="d0">连接主义</data>
      <data key="d1">concept</data>
      <data key="d2">人工智能学派，强调人类智能与机器智能在物理和功能上同源，是现代神经网络成功的关键思想基础。&lt;SEP&gt;A school of thought in artificial intelligence that emphasizes the connectionist approach, key to modern AI success.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973688</data>
      <data key="d6" />
    </node>
    <node id="现代神经网络">
      <data key="d0">现代神经网络</data>
      <data key="d1">method</data>
      <data key="d2">可被视为赫布学习定律和图灵思想的工程化结晶，是连接主义学派在人工智能领域的实践体现。&lt;SEP&gt;Modern neural networks, seen as the engineering crystallization of Hebb's learning law and Turing's ideas.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973689</data>
      <data key="d6" />
    </node>
    <node id="赫布学习定律">
      <data key="d0">赫布学习定律</data>
      <data key="d1">concept</data>
      <data key="d2">A learning rule proposed by Donald Hebb stating that neurons that fire together wire together, revealing the brain's plasticity where synaptic connections are strengthened or weakened based on co-activation.&lt;SEP&gt;Hebb's learning law, a foundational concept in neuroscience and connectionism.&lt;SEP&gt;Hebbian learning rule, a theory in neuroscience that explains synaptic plasticity, mentioned as part of the foundation for modern neural networks.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973689</data>
      <data key="d6" />
    </node>
    <node id="图灵">
      <data key="d0">图灵</data>
      <data key="d1">person</data>
      <data key="d2">Turing, whose ideas contributed to the foundation of modern neural networks.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973690</data>
      <data key="d6" />
    </node>
    <node id="维纳">
      <data key="d0">维纳</data>
      <data key="d1">person</data>
      <data key="d2">Wiener, known for the concept of "feedback loops."</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973690</data>
      <data key="d6" />
    </node>
    <node id="反馈回路">
      <data key="d0">反馈回路</data>
      <data key="d1">concept</data>
      <data key="d2">Feedback loops, conceptualized by Wiener and embodied in machine learning as optimization mechanisms.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973691</data>
      <data key="d6" />
    </node>
    <node id="机器学习">
      <data key="d0">机器学习</data>
      <data key="d1">concept</data>
      <data key="d2">机器学习（Machine Learning）是一个研究领域，属于计算机科学和人工智能的范畴。该领域专注于使用算法和统计模型，使计算机系统能够从数据中学习和改进，而无需进行明确的、针对特定任务的编程。机器学习的基础内容涵盖多个方面，包括信息论。在方法上，该领域运用诸如梯度下降等优化机制来训练模型。决策树学习是机器学习领域内的一种具体方法。根据文档及其元数据的指示，当前文本内容所属的领域正是机器学习。&lt;SEP&gt;The domain or field of study to which the document content belongs.&lt;SEP&gt;Machine learning is the field or domain to which the lecture content belongs.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-c83ff92607271cc36071ca55ac4a8385&lt;SEP&gt;chunk-93b5920864ffe7c0f735f87ccf578d34&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6&lt;SEP&gt;chunk-a79596200294b5109fdd0cf885110f83&lt;SEP&gt;chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976194</data>
      <data key="d6" />
    </node>
    <node id="梯度下降">
      <data key="d0">梯度下降</data>
      <data key="d1">method</data>
      <data key="d2">Gradient descent, an optimization mechanism used in machine learning to adjust parameters.&lt;SEP&gt;梯度下降是一种优化方法，MSE损失函数因其易于通过梯度下降进行优化而具有优势。</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975694</data>
      <data key="d6" />
    </node>
    <node id="反向传播">
      <data key="d0">反向传播</data>
      <data key="d1">method</data>
      <data key="d2">Backpropagation, an optimization mechanism used in machine learning for parameter correction.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973691</data>
      <data key="d6" />
    </node>
    <node id="人脑">
      <data key="d0">人脑</data>
      <data key="d1">location</data>
      <data key="d2">The human brain, described as highly complex and the seat of cognitive abilities.&lt;SEP&gt;人脑是包含约860亿个神经元的器官。</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974938</data>
      <data key="d6" />
    </node>
    <node id="莱尔·华特森">
      <data key="d0">莱尔·华特森</data>
      <data key="d1">person</data>
      <data key="d2">Lyall Watson, who made a statement about the complexity of the brain and our ability to understand it.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973692</data>
      <data key="d6" />
    </node>
    <node id="数学模型">
      <data key="d0">数学模型</data>
      <data key="d1">method</data>
      <data key="d2">A mathematical model sought to understand the brain's cognitive mechanisms.&lt;SEP&gt;Mathematical model is the tool being designed to describe the signal dynamics.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974251</data>
      <data key="d6" />
    </node>
    <node id="反问题">
      <data key="d0">反问题</data>
      <data key="d1">concept</data>
      <data key="d2">Inverse problems, a scientific/mathematical task of inferring causes from results, often ill-posed.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973692</data>
      <data key="d6" />
    </node>
    <node id="高层级皮层">
      <data key="d0">高层级皮层</data>
      <data key="d1">concept</data>
      <data key="d2">High-level cortical areas, such as the prefrontal cortex, which generate predictions about the world.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973693</data>
      <data key="d6" />
    </node>
    <node id="前额叶">
      <data key="d0">前额叶</data>
      <data key="d1">concept</data>
      <data key="d2">The prefrontal cortex, part of the high-level cortex involved in generating predictions.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973693</data>
      <data key="d6" />
    </node>
    <node id="低层级感觉区">
      <data key="d0">低层级感觉区</data>
      <data key="d1">concept</data>
      <data key="d2">Low-level sensory areas, such as the visual cortex, responsible for calculating prediction errors.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973693</data>
      <data key="d6" />
    </node>
    <node id="视觉皮层">
      <data key="d0">视觉皮层</data>
      <data key="d1">concept</data>
      <data key="d2">The visual cortex, an example of a low-level sensory area.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973693</data>
      <data key="d6" />
    </node>
    <node id="贝叶斯理论">
      <data key="d0">贝叶斯理论</data>
      <data key="d1">concept</data>
      <data key="d2">Bayesian theory, a persuasive explanation for the brain's operation based on a mathematical formula.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973694</data>
      <data key="d6" />
    </node>
    <node id="贝叶斯定理">
      <data key="d0">贝叶斯定理</data>
      <data key="d1">concept</data>
      <data key="d2">Bayes' theorem, the elegant mathematical formula at the core of Bayesian theory.&lt;SEP&gt;贝叶斯定理是大脑推理所遵循的数学逻辑，用于在最小化自由能的过程中更新信念。</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973694</data>
      <data key="d6" />
    </node>
    <node id="先验">
      <data key="d0">先验</data>
      <data key="d1">concept</data>
      <data key="d2">Prior, the initial belief about the world based on past experience and knowledge.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973694</data>
      <data key="d6" />
    </node>
    <node id="似然">
      <data key="d0">似然</data>
      <data key="d1">concept</data>
      <data key="d2">Likelihood, the degree to which new evidence matches prior beliefs.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973694</data>
      <data key="d6" />
    </node>
    <node id="后验">
      <data key="d0">后验</data>
      <data key="d1">concept</data>
      <data key="d2">Posterior, the updated belief after integrating prior knowledge and new evidence.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973695</data>
      <data key="d6" />
    </node>
    <node id="贝叶斯大脑">
      <data key="d0">贝叶斯大脑</data>
      <data key="d1">concept</data>
      <data key="d2">The Bayesian Brain hypothesis, which posits the brain as an active inference machine making "best guesses."&lt;SEP&gt;贝叶斯大脑是一种认知框架，描述大脑通过贝叶斯推理不断更新对世界的预测模型，以最小化预测误差。&lt;SEP&gt;A unified mathematical framework for human and machine cognition.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973695</data>
      <data key="d6" />
    </node>
    <node id="自由能原理">
      <data key="d0">自由能原理</data>
      <data key="d1">concept</data>
      <data key="d2">The Free Energy Principle, explaining why the brain must operate based on Bayesian logic due to physical constraints of life.&lt;SEP&gt;自由能原理是一个数学框架，描述智能系统(包括大脑和机器)通过最小化自由能(即预测误差)来维持自身在不确定环境中的存续。&lt;SEP&gt;自由能原理由卡尔·弗里斯顿提出，认为生命体必须最小化自由能以在熵增世界中维持自身结构和秩序。&lt;SEP&gt;A principle connecting cognitive frameworks to the physical mechanism of life resisting entropy increase.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973695</data>
      <data key="d6" />
    </node>
    <node id="卡尔·弗里斯顿">
      <data key="d0">卡尔·弗里斯顿</data>
      <data key="d1">person</data>
      <data key="d2">Karl Friston, a British neuroscientist associated with the Free Energy Principle.&lt;SEP&gt;卡尔·弗里斯顿是一位英国神经科学家，提出了自由能原理。</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973695</data>
      <data key="d6" />
    </node>
    <node id="信息化反熵增体系">
      <data key="d0">信息化反熵增体系</data>
      <data key="d1">concept</data>
      <data key="d2">An information-based anti-entropy system, which is the core goal for organizing both machine and human intelligence.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973706</data>
      <data key="d6" />
    </node>
    <node id="归纳推理">
      <data key="d0">归纳推理</data>
      <data key="d1">concept</data>
      <data key="d2">Inductive reasoning, a type of reasoning enabled by Bayesian theorem to handle uncertainty.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973706</data>
      <data key="d6" />
    </node>
    <node id="溯因推理">
      <data key="d0">溯因推理</data>
      <data key="d1">concept</data>
      <data key="d2">Abductive reasoning, a type of reasoning enabled by Bayesian theorem to handle uncertainty.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973699</data>
      <data key="d6" />
    </node>
    <node id="认知科学">
      <data key="d0">认知科学</data>
      <data key="d1">concept</data>
      <data key="d2">Cognitive science, the field which contains the core paradox explained by the Bayesian Brain hypothesis.</data>
      <data key="d3">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973699</data>
      <data key="d6" />
    </node>
    <node id="埃尔温·薛定谔">
      <data key="d0">埃尔温·薛定谔</data>
      <data key="d1">person</data>
      <data key="d2">A physicist who, in 1944, proposed the groundbreaking insight in his book "What is Life?" that life feeds on "negative entropy" and that the program for maintaining order is stored in an "aperiodic crystal."&lt;SEP&gt;埃尔温·薛定谔是物理学家，在其著作《生命是什么？》中提出了“生命以负熵为食”的洞见。</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973699</data>
      <data key="d6" />
    </node>
    <node id="生命是什么？">
      <data key="d0">生命是什么？</data>
      <data key="d1">content</data>
      <data key="d2">A book authored by Erwin Schrödinger in 1944, which introduced the concept of life feeding on "negative entropy" and the idea of an "aperiodic crystal" storing life's programs.&lt;SEP&gt;《生命是什么？》是物理学家埃尔温·薛定谔的著作，其中提出了“生命以负熵为食”的洞见。</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973700</data>
      <data key="d6" />
    </node>
    <node id="负熵">
      <data key="d0">负熵</data>
      <data key="d1">concept</data>
      <data key="d2">A concept proposed by Erwin Schrödinger, meaning that life feeds on "negative entropy" by importing order from the external environment to maintain its highly ordered structure locally.&lt;SEP&gt;负熵是物理学家埃尔温·薛定谔提出的概念，指生命体从外界摄取用以抵抗内部熵增、维持有序状态的能量或信息。&lt;SEP&gt;负熵是系统为维持自身秩序所需要吸收的有序性或信息，是智能系统(包括人类和机器)生存的必要资源。</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973700</data>
      <data key="d6" />
    </node>
    <node id="非周期性晶体">
      <data key="d0">非周期性晶体</data>
      <data key="d1">concept</data>
      <data key="d2">A term proposed by Erwin Schrödinger, referring to a structure with high stability and strong information encoding capability that stores the programs for maintaining order across generations.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973701</data>
      <data key="d6" />
    </node>
    <node id="詹姆斯·沃森">
      <data key="d0">詹姆斯·沃森</data>
      <data key="d1">person</data>
      <data key="d2">An American molecular biologist who, together with Francis Crick, discovered the double-helix structure of DNA in 1953.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973701</data>
      <data key="d6" />
    </node>
    <node id="弗朗西斯·克里克">
      <data key="d0">弗朗西斯·克里克</data>
      <data key="d1">person</data>
      <data key="d2">A British physicist who, together with James Watson, discovered the double-helix structure of DNA in 1953 and later proposed the "central dogma."</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973702</data>
      <data key="d6" />
    </node>
    <node id="DNA双螺旋结构">
      <data key="d0">DNA双螺旋结构</data>
      <data key="d1">concept</data>
      <data key="d2">The molecular structure of DNA discovered by James Watson and Francis Crick, explaining that the arrangement of ATCG bases constitutes the genetic code of life.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973702</data>
      <data key="d6" />
    </node>
    <node id="自然">
      <data key="d0">自然</data>
      <data key="d1">content</data>
      <data key="d2">The scientific journal in which James Watson and Francis Crick published their famous paper on the double-helix structure of DNA.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973702</data>
      <data key="d6" />
    </node>
    <node id="中心法则">
      <data key="d0">中心法则</data>
      <data key="d1">concept</data>
      <data key="d2">A principle proposed by Francis Crick explaining how life produces various proteins according to the DNA program.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973702</data>
      <data key="d6" />
    </node>
    <node id="神经元">
      <data key="d0">神经元</data>
      <data key="d1">creature</data>
      <data key="d2">A type of cell, described as the "chosen one," whose core mission is to process higher-level information to achieve intelligence through signal transmission via axons, dendrites, and synapses.&lt;SEP&gt;Biological neurons in the human brain, considered in a thought experiment about material substitution.&lt;SEP&gt;神经网络中的基本计算单元，具有输入、权重、阈值和状态等特征。&lt;SEP&gt;神经元是大脑细胞，通过生物电讯号激活并相互连接形成网络。</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-52188c2297ba9ea322f462b96137a3c3&lt;SEP&gt;chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974930</data>
      <data key="d6" />
    </node>
    <node id="唐纳德·赫布">
      <data key="d0">唐纳德·赫布</data>
      <data key="d1">person</data>
      <data key="d2">A Canadian psychologist who, in 1949, proposed the influential Hebbian Learning rule.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973703</data>
      <data key="d6" />
    </node>
    <node id="突触可塑性">
      <data key="d0">突触可塑性</data>
      <data key="d1">concept</data>
      <data key="d2">The dynamic plasticity at the synaptic level, where experiences and learning physically alter synaptic strengths and neural network connections, forming the basis of memory and intelligence.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973711</data>
      <data key="d6" />
    </node>
    <node id="生命">
      <data key="d0">生命</data>
      <data key="d1">concept</data>
      <data key="d2">生命是热力学第二定律的“逆行者”，作为开放系统持续与外部环境交换能量与物质，通过摄取“负熵”来维持自身的秩序和结构。&lt;SEP&gt;Life is described as feeding on "negative entropy," maintaining order by exchanging energy and matter with the external environment, and fundamentally characterized by maintaining order within chaos.&lt;SEP&gt;生命是希望在一个熵增世界中维持自身结构和秩序的系统，其物理特性决定了大脑必须遵循贝叶斯逻辑。</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973711</data>
      <data key="d6" />
    </node>
    <node id="蛋白质">
      <data key="d0">蛋白质</data>
      <data key="d1">concept</data>
      <data key="d2">Proteins are produced according to the DNA program, and their existence is for the purpose of processing information more efficiently to enable survival and reproduction.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973704</data>
      <data key="d6" />
    </node>
    <node id="细胞">
      <data key="d0">细胞</data>
      <data key="d1">concept</data>
      <data key="d2">Cells, whose activities are formed through protein interactions, follow the basic principle of negative entropy.</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973705</data>
      <data key="d6" />
    </node>
    <node id="智能">
      <data key="d0">智能</data>
      <data key="d1">concept</data>
      <data key="d2">吸收信息以对抗熵增的能力，其本质不由物理载体决定，核心在于目标设定、行动影响和反馈调节的闭环。&lt;SEP&gt;Intelligence is an adaptive ability that allows organisms to rapidly "iterate" within a single generation through learning and memory, emerging from the coordinated work of neurons.&lt;SEP&gt;智能被理解为一个不断“减少自由能”的过程，核心机制是最小化预测误差。</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973705</data>
      <data key="d6" />
    </node>
    <node id="记忆">
      <data key="d0">记忆</data>
      <data key="d1">concept</data>
      <data key="d2">记忆并非存储在文件中，而是大脑中特定神经元网络的连接模式，是经验、知识和思考过程留下的物理性痕迹。&lt;SEP&gt;Memory is described as the "connection pattern" of specific neural networks in the brain, where experiences and knowledge leave physical traces by altering synaptic strengths and connections.&lt;SEP&gt;记忆是大脑用新证据修正旧模型的过程，是感知和学习的一部分，旨在最小化预测误差。</data>
      <data key="d3">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973705</data>
      <data key="d6" />
    </node>
    <node id="大脑">
      <data key="d0">大脑</data>
      <data key="d1">naturalobject</data>
      <data key="d2">能够通过突触的动态可塑性从经验中学习，提升信息处理效率，并将生命经验写入自身结构的器官。&lt;SEP&gt;大脑是整合先验知识和感官数据后推理出现实的器官，遵循贝叶斯逻辑以最小化自由能。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973706</data>
      <data key="d6" />
    </node>
    <node id="认知模型">
      <data key="d0">认知模型</data>
      <data key="d1">concept</data>
      <data key="d2">认知模型是大脑对世界的预测，与感知数据之间的差距构成自由能。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973707</data>
      <data key="d6" />
    </node>
    <node id="感知数据">
      <data key="d0">感知数据</data>
      <data key="d1">data</data>
      <data key="d2">感知数据是人与环境交换的感官信息，是大脑进行推理和更新模型的依据。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973707</data>
      <data key="d6" />
    </node>
    <node id="预测误差">
      <data key="d0">预测误差</data>
      <data key="d1">data</data>
      <data key="d2">预测误差是认知模型与感知数据之间的差距，最小化预测误差是维持生命体稳定的核心。&lt;SEP&gt;预测误差的中位数是评估预测工具性能的指标。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973832</data>
      <data key="d6" />
    </node>
    <node id="世界模型">
      <data key="d0">世界模型</data>
      <data key="d1">concept</data>
      <data key="d2">世界模型是认知系统对世界运作规律的刻画，在自由能原理框架下追求解释力与简洁性的平衡。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973707</data>
      <data key="d6" />
    </node>
    <node id="大语言模型">
      <data key="d0">大语言模型</data>
      <data key="d1">artifact</data>
      <data key="d2">大语言模型是一种人工智能体的大脑，其认知方式和优化逻辑与人类大脑在最小化自由能上功能相似。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973708</data>
      <data key="d6" />
    </node>
    <node id="下一个词元预测">
      <data key="d0">下一个词元预测</data>
      <data key="d1">method</data>
      <data key="d2">下一个词元预测是大语言模型的核心训练任务，本质上是“最小化预测误差”的体现。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973708</data>
      <data key="d6" />
    </node>
    <node id="主动推断">
      <data key="d0">主动推断</data>
      <data key="d1">method</data>
      <data key="d2">主动推断是智能产生行为的机制，指系统通过行动改变外部世界，使感官输入更接近自身模型的预测。&lt;SEP&gt;A mechanism where a system takes action to make the external world conform to its predictions, reducing the gap between expectation and perception.</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973708</data>
      <data key="d6" />
    </node>
    <node id="宇宙">
      <data key="d0">宇宙</data>
      <data key="d1">naturalobject</data>
      <data key="d2">宇宙具有无序化趋势(熵增)，生命体需要对抗这一趋势以维持自身。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973709</data>
      <data key="d6" />
    </node>
    <node id="学习">
      <data key="d0">学习</data>
      <data key="d1">method</data>
      <data key="d2">学习是系统为最小化自由能而采取的路径之一，即当外界输入与预测不一致时，主动更新内部认知模型。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973709</data>
      <data key="d6" />
    </node>
    <node id="语言模型">
      <data key="d0">语言模型</data>
      <data key="d1">artifact</data>
      <data key="d2">语言模型作为智能体的大脑，其训练过程在功能上模拟了贝叶斯定理中“用新证据更新旧信念”的机制。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973710</data>
      <data key="d6" />
    </node>
    <node id="训练语料">
      <data key="d0">训练语料</data>
      <data key="d1">data</data>
      <data key="d2">训练语料是大语言模型进行优化所依赖的外部证据(海量静态数据)。</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973712</data>
      <data key="d6" />
    </node>
    <node id="图1">
      <data key="d0">图1</data>
      <data key="d1">artifact</data>
      <data key="d2">图1直观呈现了语言模型作为智能体大脑，遵循最小化自由能机制产生行为的过程。&lt;SEP&gt;Figure 1 is a visual representation, likely a graph or chart, showing the partition function of the Karate Club network.&lt;SEP&gt;A figure referenced in the article, likely illustrating the proposed innovative method.</data>
      <data key="d3">chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-7d7618b6fffb013ab6c5a2ca3a3fea50&lt;SEP&gt;chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975395</data>
      <data key="d6" />
    </node>
    <node id="爱思想">
      <data key="d0">爱思想</data>
      <data key="d1">organization</data>
      <data key="d2">A non-profit, pure academic website aimed at promoting academic prosperity and shaping social spirit.&lt;SEP&gt;爱思想(aisixiang.com) is a public welfare academic website that published the article and aims to promote academic prosperity and shape social spirit.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973712</data>
      <data key="d6" />
    </node>
    <node id="aisixiang.com">
      <data key="d0">aisixiang.com</data>
      <data key="d1">organization</data>
      <data key="d2">The domain name of the non-profit academic website爱思想.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973713</data>
      <data key="d6" />
    </node>
    <node id="杨涛">
      <data key="d0">杨涛</data>
      <data key="d1">person</data>
      <data key="d2">An author of the article "人工智能驱动的术语国际传播：模式变革与实践路径".</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973713</data>
      <data key="d6" />
    </node>
    <node id="王辉">
      <data key="d0">王辉</data>
      <data key="d1">person</data>
      <data key="d2">An author of the article "人工智能驱动的术语国际传播：模式变革与实践路径".</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973713</data>
      <data key="d6" />
    </node>
    <node id="周智婉">
      <data key="d0">周智婉</data>
      <data key="d1">person</data>
      <data key="d2">An author of the article "人工智能驱动的术语国际传播：模式变革与实践路径".</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973714</data>
      <data key="d6" />
    </node>
    <node id="人工智能驱动的术语国际传播：模式变革与实践路径">
      <data key="d0">人工智能驱动的术语国际传播：模式变革与实践路径</data>
      <data key="d1">content</data>
      <data key="d2">An article authored by杨涛, 王辉, and周智婉, discussing AI-driven international terminology dissemination.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973714</data>
      <data key="d6" />
    </node>
    <node id="ixiang.com/data/170628.html">
      <data key="d0">ixiang.com/data/170628.html</data>
      <data key="d1">content</data>
      <data key="d2">A specific webpage URL on the爱思想website.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973714</data>
      <data key="d6" />
    </node>
    <node id="Powered by aisixiang.com">
      <data key="d0">Powered by aisixiang.com</data>
      <data key="d1">content</data>
      <data key="d2">A copyright and attribution statement for the website.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973714</data>
      <data key="d6" />
    </node>
    <node id="京ICP备12007865号-1">
      <data key="d0">京ICP备12007865号-1</data>
      <data key="d1">data</data>
      <data key="d2">A Chinese internet content provider license number registered for the website.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973715</data>
      <data key="d6" />
    </node>
    <node id="京公网安备11010602120014号">
      <data key="d0">京公网安备11010602120014号</data>
      <data key="d1">data</data>
      <data key="d2">A Chinese public security network filing number for the website.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973715</data>
      <data key="d6" />
    </node>
    <node id="Powered by aisixiang.com Copyright © 2025 by aisixiang.com All Rights Reserved">
      <data key="d0">Powered by aisixiang.com Copyright © 2025 by aisixiang.com All Rights Reserved</data>
      <data key="d1">content</data>
      <data key="d2">A copyright notice and attribution statement for the website content.</data>
      <data key="d3">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973715</data>
      <data key="d6" />
    </node>
    <node id="新证据">
      <data key="d0">新证据</data>
      <data key="d1">data</data>
      <data key="d2">New evidence used to correct old models.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973715</data>
      <data key="d6" />
    </node>
    <node id="旧模型">
      <data key="d0">旧模型</data>
      <data key="d1">concept</data>
      <data key="d2">Old models that require correction based on new evidence.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973715</data>
      <data key="d6" />
    </node>
    <node id="自由能框架">
      <data key="d0">自由能框架</data>
      <data key="d1">concept</data>
      <data key="d2">A theoretical framework that unifies cognition and action, aiming to minimize free energy by reducing the gap between internal models and sensory input.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973716</data>
      <data key="d6" />
    </node>
    <node id="认知">
      <data key="d0">认知</data>
      <data key="d1">concept</data>
      <data key="d2">The process of understanding and updating knowledge about the world.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973716</data>
      <data key="d6" />
    </node>
    <node id="行动">
      <data key="d0">行动</data>
      <data key="d1">concept</data>
      <data key="d2">The process of taking action to change the external world.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973716</data>
      <data key="d6" />
    </node>
    <node id="具身智能">
      <data key="d0">具身智能</data>
      <data key="d1">concept</data>
      <data key="d2">Intelligence that is not separate from cognition but a natural extension of it at the level of action, explained by the active inference framework.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973716</data>
      <data key="d6" />
    </node>
    <node id="自由能最小化">
      <data key="d0">自由能最小化</data>
      <data key="d1">concept</data>
      <data key="d2">A continuous, closed-loop process where cognition and action work together to reduce free energy and maintain order.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973716</data>
      <data key="d6" />
    </node>
    <node id="智能体">
      <data key="d0">智能体</data>
      <data key="d1">concept</data>
      <data key="d2">An agent, such as an embodied large model, endowed with active inference capabilities.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973717</data>
      <data key="d6" />
    </node>
    <node id="利用">
      <data key="d0">利用</data>
      <data key="d1">method</data>
      <data key="d2">A strategy where an agent chooses actions most likely to yield good outcomes, reflecting reinforcement learning logic.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973717</data>
      <data key="d6" />
    </node>
    <node id="探索">
      <data key="d0">探索</data>
      <data key="d1">method</data>
      <data key="d2">A strategy where an agent chooses actions to learn more, reflecting advanced cognitive functions like curiosity and hypothesis generation.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973719</data>
      <data key="d6" />
    </node>
    <node id="好奇心">
      <data key="d0">好奇心</data>
      <data key="d1">concept</data>
      <data key="d2">An intrinsic drive for an intelligent agent to enhance long-term survival and optimize future decision models in an uncertain world, no longer an "additional trait".</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973719</data>
      <data key="d6" />
    </node>
    <node id="熵增">
      <data key="d0">熵增</data>
      <data key="d1">concept</data>
      <data key="d2">The increase in entropy, a state of disorder, which life resists.&lt;SEP&gt;熵增是热力学第二定律的核心概念，指系统自发趋向于无序和混乱的状态，是宇宙的基本趋势。</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973719</data>
      <data key="d6" />
    </node>
    <node id="人类中心论">
      <data key="d0">人类中心论</data>
      <data key="d1">concept</data>
      <data key="d2">The anthropocentric view that intelligence is a mysterious, unreplicable privilege unique to humans.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973720</data>
      <data key="d6" />
    </node>
    <node id="杰弗里·辛顿">
      <data key="d0">杰弗里·辛顿</data>
      <data key="d1">person</data>
      <data key="d2">杰弗里·辛顿是深度学习奠基者，在2025年世界人工智能大会上指出人类大脑和大语言模型对语言的理解方式几乎相同。&lt;SEP&gt;A person who proposed a thought experiment about replacing neurons with electronic components to question the material basis of intelligence.&lt;SEP&gt;A researcher credited with the invention of the Boltzmann machine.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a&lt;SEP&gt;chunk-d0e494da55d171b3a3a8b96678397514</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973812</data>
      <data key="d6" />
    </node>
    <node id="思想实验">
      <data key="d0">思想实验</data>
      <data key="d1">concept</data>
      <data key="d2">A thought experiment involving the gradual replacement of neurons with electronic components to explore the nature of intelligence and consciousness.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973721</data>
      <data key="d6" />
    </node>
    <node id="电子元件">
      <data key="d0">电子元件</data>
      <data key="d1">artifact</data>
      <data key="d2">Electronic components used in a thought experiment to replace biological neurons.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973721</data>
      <data key="d6" />
    </node>
    <node id="智能的第一性原理">
      <data key="d0">智能的第一性原理</data>
      <data key="d1">concept</data>
      <data key="d2">The first principle of intelligence: a system's ability to use information to maintain its own order and resist entropy increase.&lt;SEP&gt;智能的第一性原理是从物理学、数学与信息论角度理解智能本质的宏观视角，认为智能是用信息抵抗熵增的组织方式。</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973721</data>
      <data key="d6" />
    </node>
    <node id="语言">
      <data key="d0">语言</data>
      <data key="d1">concept</data>
      <data key="d2">A human creation that organizes and transmits thought.&lt;SEP&gt;语言是人类创造的用于组织和传递思维的工具，是反熵增能力外化的早期形式。</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973721</data>
      <data key="d6" />
    </node>
    <node id="文字">
      <data key="d0">文字</data>
      <data key="d1">concept</data>
      <data key="d2">A human creation that provides a tool for expressing cognition and prior knowledge, forming ideas.&lt;SEP&gt;文字是人类创造的为认知与先验知识提供表达的工具，有助于形成和固化思想。</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973721</data>
      <data key="d6" />
    </node>
    <node id="自由能">
      <data key="d0">自由能</data>
      <data key="d1">concept</data>
      <data key="d2">Free energy, a central concept in the framework where minimizing it is the goal of cognition and action.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973722</data>
      <data key="d6" />
    </node>
    <node id="强化学习">
      <data key="d0">强化学习</data>
      <data key="d1">method</data>
      <data key="d2">Reinforcement learning, a logic reflected in the exploitation strategy of intelligent agents.&lt;SEP&gt;A technique combined with autoregressive generative models in the proposed method.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975395</data>
      <data key="d6" />
    </node>
    <node id="假设生成">
      <data key="d0">假设生成</data>
      <data key="d1">method</data>
      <data key="d2">Hypothesis generation, an advanced cognitive function reflected in the exploration strategy.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973723</data>
      <data key="d6" />
    </node>
    <node id="欣赏">
      <data key="d0">欣赏</data>
      <data key="d1">concept</data>
      <data key="d2">Appreciation, an advanced cognitive function mentioned in the context of exploration.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973723</data>
      <data key="d6" />
    </node>
    <node id="物理同源、数学同构">
      <data key="d0">物理同源、数学同构</data>
      <data key="d1">concept</data>
      <data key="d2">物理同源、数学同构是指人类与机器智能在物理基础和数学结构上具有同源性，这引发了关于资源竞争的担忧。&lt;SEP&gt;"Physical homology and mathematical isomorphism", describing the deep commonality between human and machine intelligence.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973723</data>
      <data key="d6" />
    </node>
    <node id="意识">
      <data key="d0">意识</data>
      <data key="d1">concept</data>
      <data key="d2">Consciousness, mentioned in the context of Geoffrey Hinton's thought experiment about a brain made of electronic components.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973723</data>
      <data key="d6" />
    </node>
    <node id="碳基神经元">
      <data key="d0">碳基神经元</data>
      <data key="d1">naturalobject</data>
      <data key="d2">Carbon-based neurons, the biological material of the human brain, contrasted with electronic components in the thought experiment.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973725</data>
      <data key="d6" />
    </node>
    <node id="结构化组织方式">
      <data key="d0">结构化组织方式</data>
      <data key="d1">concept</data>
      <data key="d2">Structured organizational method, the principle intelligence depends on, rather than specific materials.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973726</data>
      <data key="d6" />
    </node>
    <node id="反熵增能力">
      <data key="d0">反熵增能力</data>
      <data key="d1">concept</data>
      <data key="d2">反熵增能力是生命和智能系统为维持自身结构和有序状态而演化出的一套机制，用于对抗熵增。&lt;SEP&gt;Anti-entropy increase capability, the ability accumulated through biological evolution to maintain order.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973726</data>
      <data key="d6" />
    </node>
    <node id="思想">
      <data key="d0">思想</data>
      <data key="d1">concept</data>
      <data key="d2">Thought, formed through the creation of writing as a tool for expressing cognition.</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973727</data>
      <data key="d6" />
    </node>
    <node id="人类">
      <data key="d0">人类</data>
      <data key="d1">creature</data>
      <data key="d2">人类是一种特殊的智能生命形式，通过创造语言、文字和教育等工具，实现了反熵增能力的外化与迁移。&lt;SEP&gt;本研究对人类的代谢反应进行了预测。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525&lt;SEP&gt;chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973833</data>
      <data key="d6" />
    </node>
    <node id="教育">
      <data key="d0">教育</data>
      <data key="d1">concept</data>
      <data key="d2">教育是人类创造的使个体认知能够形成共识、成为知识并得以传承的机制。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973728</data>
      <data key="d6" />
    </node>
    <node id="智能机制">
      <data key="d0">智能机制</data>
      <data key="d1">concept</data>
      <data key="d2">智能机制是生命体对抗熵增、维持有序状态的内在能力，可以被抽象为算法。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973728</data>
      <data key="d6" />
    </node>
    <node id="算法">
      <data key="d0">算法</data>
      <data key="d1">concept</data>
      <data key="d2">算法是智能机制的抽象形式，可以被复制并以硅基材料为载体运行。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973728</data>
      <data key="d6" />
    </node>
    <node id="硅基材料">
      <data key="d0">硅基材料</data>
      <data key="d1">artifact</data>
      <data key="d2">硅基材料是构成智能机器(如计算机)的物理载体，用于承载和运行算法。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973728</data>
      <data key="d6" />
    </node>
    <node id="智能机器">
      <data key="d0">智能机器</data>
      <data key="d1">artifact</data>
      <data key="d2">智能机器是以硅基材料为载体、运行算法并具备学习、适应与行动能力的系统。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973728</data>
      <data key="d6" />
    </node>
    <node id="人机共生">
      <data key="d0">人机共生</data>
      <data key="d1">concept</data>
      <data key="d2">人机共生是指人类与智能机器形成协作整体的关系，被视为智能演化轨迹的自然延伸。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973736</data>
      <data key="d6" />
    </node>
    <node id="热寂">
      <data key="d0">热寂</data>
      <data key="d1">concept</data>
      <data key="d2">热寂是宇宙熵增的最终结局，指所有能量均匀分布、不再有宏观运动与生命活动的死寂状态。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973736</data>
      <data key="d6" />
    </node>
    <node id="信息">
      <data key="d0">信息</data>
      <data key="d1">concept</data>
      <data key="d2">信息是生命、意识、技术、文化等系统在局部区域对抗混沌(熵增)的核心要素。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973729</data>
      <data key="d6" />
    </node>
    <node id="反熵增之河">
      <data key="d0">反熵增之河</data>
      <data key="d1">concept</data>
      <data key="d2">反熵增之河是一个比喻，指生命、人类与机器等智能形态共同构成的、持续对抗熵增以维系秩序的连续协作整体。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973729</data>
      <data key="d6" />
    </node>
    <node id="碳基智能体">
      <data key="d0">碳基智能体</data>
      <data key="d1">concept</data>
      <data key="d2">碳基智能体指以碳为基础的生命形式(如人类)，是典型的具身智能体，擅长在物理世界中行动、探索、感知和主动推理。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973729</data>
      <data key="d6" />
    </node>
    <node id="硅基智能体">
      <data key="d0">硅基智能体</data>
      <data key="d1">concept</data>
      <data key="d2">硅基智能体指以硅为基础的智能机器，是典型的计算智能体，擅长在信息空间中建模、推演、优化和感知学习。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973730</data>
      <data key="d6" />
    </node>
    <node id="复合智能系统">
      <data key="d0">复合智能系统</data>
      <data key="d1">concept</data>
      <data key="d2">复合智能系统是由人类(碳基)与机器(硅基)结合形成的协作整体，在对抗熵增方面的整体效率远超任何一方独立运行。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973730</data>
      <data key="d6" />
    </node>
    <node id="治理机制">
      <data key="d0">治理机制</data>
      <data key="d1">concept</data>
      <data key="d2">治理机制是人类为保持和优化与机器智能的互补性而需要建立的有效规则和框架。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973730</data>
      <data key="d6" />
    </node>
    <node id="递归式共进化">
      <data key="d0">递归式共进化</data>
      <data key="d1">concept</data>
      <data key="d2">递归式共进化描述了人类与智能机器在深度融合过程中形成自加速的正向反馈链，相互促进并推动整个智能系统向更高维组织形态跃迁的过程。&lt;SEP&gt;递归式共进化描述智能机器与人类能力之间相互促进、形成正向反馈链的进化模式，推动整个智能系统向更高维组织形态跃迁。</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973731</data>
      <data key="d6" />
    </node>
    <node id="SuperAdmin">
      <data key="d0">SuperAdmin</data>
      <data key="d1">person</data>
      <data key="d2">SuperAdmin is the editor responsible for reviewing the article.</data>
      <data key="d3">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973731</data>
      <data key="d6" />
    </node>
    <node id="郭毅可">
      <data key="d0">郭毅可</data>
      <data key="d1">person</data>
      <data key="d2">郭毅可是文章的作者，提出了人类智能与机器智能共生共融的观点，并基于“物理同源、数学同构”的底层逻辑进行阐述。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973732</data>
      <data key="d6" />
    </node>
    <node id="共生共融">
      <data key="d0">共生共融</data>
      <data key="d1">concept</data>
      <data key="d2">共生共融描述了人类智能与机器智能之间高度互补、深度融合，形成协同整体并递归式共进化的关系趋势。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973732</data>
      <data key="d6" />
    </node>
    <node id="物理同源">
      <data key="d0">物理同源</data>
      <data key="d1">concept</data>
      <data key="d2">物理同源指碳基大脑与硅基芯片在物理层面都遵循热力学定律，是精密的、通过吸收信息抵抗熵增的信息化系统。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973732</data>
      <data key="d6" />
    </node>
    <node id="数学同构">
      <data key="d0">数学同构</data>
      <data key="d1">concept</data>
      <data key="d2">数学同构指“贝叶斯大脑”与“自由能原理”为人类智能和机器智能构建了统一的认知框架，其核心工作机制都是通过持续学习与交互最小化预测误差。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973732</data>
      <data key="d6" />
    </node>
    <node id="李德毅">
      <data key="d0">李德毅</data>
      <data key="d1">person</data>
      <data key="d2">李德毅是院士，在《人工智能看哲学》一文中提出了人类智能与机器智能“物理上同源，数学上同构”的观点。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973734</data>
      <data key="d6" />
    </node>
    <node id="2025年世界人工智能大会">
      <data key="d0">2025年世界人工智能大会</data>
      <data key="d1">event</data>
      <data key="d2">2025年世界人工智能大会是一个会议活动，深度学习奠基者杰弗里·辛顿在会上发表了关于人类大脑与大语言模型理解方式相似的言论。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973734</data>
      <data key="d6" />
    </node>
    <node id="人工智能看哲学">
      <data key="d0">人工智能看哲学</data>
      <data key="d1">content</data>
      <data key="d2">《人工智能看哲学》是李德毅院士撰写的一篇文章，其中提出了人类智能与机器智能“物理上同源，数学上同构”的观点。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973734</data>
      <data key="d6" />
    </node>
    <node id="碳基大脑">
      <data key="d0">碳基大脑</data>
      <data key="d1">concept</data>
      <data key="d2">碳基大脑指人类智能的物理载体，是遵循热力学定律、通过吸收信息抵抗熵增的精密信息化系统。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973734</data>
      <data key="d6" />
    </node>
    <node id="硅基芯片">
      <data key="d0">硅基芯片</data>
      <data key="d1">concept</data>
      <data key="d2">硅基芯片指机器智能的物理载体，是遵循热力学定律、通过吸收信息抵抗熵增的精密信息化系统。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973734</data>
      <data key="d6" />
    </node>
    <node id="人机协同">
      <data key="d0">人机协同</data>
      <data key="d1">concept</data>
      <data key="d2">人机协同描述了当下人工智能在邮件润色、文稿生成、问题求解等场景中与人类共同处理任务的初级协作形态。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973735</data>
      <data key="d6" />
    </node>
    <node id="共同演化">
      <data key="d0">共同演化</data>
      <data key="d1">concept</data>
      <data key="d2">共同演化描述了在未来，人类自身的认知结构与智力水平将因其与智能体的持续对齐与协同过程而随之演进的关系。</data>
      <data key="d3">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973735</data>
      <data key="d6" />
    </node>
    <node id="神经元网络">
      <data key="d0">神经元网络</data>
      <data key="d1">concept</data>
      <data key="d2">大脑中由神经元连接形成的网络，其连接模式的改变是学习和记忆的物理基础。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973735</data>
      <data key="d6" />
    </node>
    <node id="突触">
      <data key="d0">突触</data>
      <data key="d1">concept</data>
      <data key="d2">神经元之间的连接结构，其强度和连接的可塑性是大脑学习、记忆与环境适应的生物学基础。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973736</data>
      <data key="d6" />
    </node>
    <node id="阿兰·图灵">
      <data key="d0">阿兰·图灵</data>
      <data key="d1">person</data>
      <data key="d2">认为复杂思维可拆解为机械步骤的开创者，提出了图灵机和图灵测试，影响了人工智能的发展方向。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973736</data>
      <data key="d6" />
    </node>
    <node id="图灵机">
      <data key="d0">图灵机</data>
      <data key="d1">concept</data>
      <data key="d2">阿兰·图灵在1936年论文中提出的假想机器，将思考过程抽象为可控状态转换，定义了计算的基本结构。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973737</data>
      <data key="d6" />
    </node>
    <node id="图灵测试">
      <data key="d0">图灵测试</data>
      <data key="d1">concept</data>
      <data key="d2">阿兰·图灵在1950年论文中提出的功能主义智能定义，通过自然语言交流判断机器是否具备智能。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973737</data>
      <data key="d6" />
    </node>
    <node id="诺伯特·维纳">
      <data key="d0">诺伯特·维纳</data>
      <data key="d1">person</data>
      <data key="d2">美国科学家，创立控制论，认为智能核心在于“目标→行动→反馈”的闭环结构，强调反馈与调节。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973738</data>
      <data key="d6" />
    </node>
    <node id="控制论">
      <data key="d0">控制论</data>
      <data key="d1">concept</data>
      <data key="d2">诺伯特·维纳在1948年提出的科学，将动物与机器的控制和通讯置于同一理论框架中。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973738</data>
      <data key="d6" />
    </node>
    <node id="克劳德·艾尔伍德·香农">
      <data key="d0">克劳德·艾尔伍德·香农</data>
      <data key="d1">person</data>
      <data key="d2">信息论的创立者，指出信息的本质在于消除不确定性，即降低熵的过程。&lt;SEP&gt;克劳德·艾尔伍德·香农是信息论的创始人，他在1938年发表了重要的硕士学位论文，并于1948年发表了《通信的一个数学理论》，为密码破译和数字通信理论做出了贡献。</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974403</data>
      <data key="d6" />
    </node>
    <node id="论可计算数及其在判定问题上的应用">
      <data key="d0">论可计算数及其在判定问题上的应用</data>
      <data key="d1">content</data>
      <data key="d2">A 1936 paper by Alan Turing in which he proposed the Turing Machine and formally defined computation.</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973741</data>
      <data key="d6" />
    </node>
    <node id="计算机器与智能">
      <data key="d0">计算机器与智能</data>
      <data key="d1">content</data>
      <data key="d2">A classic 1950 paper by Alan Turing where he proposed the Turing Test and discussed machine intelligence.</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973741</data>
      <data key="d6" />
    </node>
    <node id="控制论：或关于在动物和机器中控制和通讯的科学">
      <data key="d0">控制论：或关于在动物和机器中控制和通讯的科学</data>
      <data key="d1">content</data>
      <data key="d2">A 1948 book by Norbert Wiener that founded the field of cybernetics, unifying the study of control in animals and machines.</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973742</data>
      <data key="d6" />
    </node>
    <node id="人有人的用处：控制论与社会">
      <data key="d0">人有人的用处：控制论与社会</data>
      <data key="d1">content</data>
      <data key="d2">A subsequent book by Norbert Wiener that expanded on cybernetics, discussing its implications for society and the nature of life in systems.</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973742</data>
      <data key="d6" />
    </node>
    <node id="大模型时代">
      <data key="d0">大模型时代</data>
      <data key="d1">concept</data>
      <data key="d2">The era of large-scale AI models, where it is recognized that the Turing Test and language ability are insufficient to fully define intelligence.</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973742</data>
      <data key="d6" />
    </node>
    <node id="语言能力">
      <data key="d0">语言能力</data>
      <data key="d1">concept</data>
      <data key="d2">The ability to use natural language, which was once considered a core standard for measuring machine intelligence, especially under the influence of the Turing Test.</data>
      <data key="d3">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973742</data>
      <data key="d6" />
    </node>
    <node id="生物演化">
      <data key="d0">生物演化</data>
      <data key="d3">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d2">Biological evolution is the process that accumulated the anti-entropy increase capability over eons.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973775</data>
      <data key="d6" />
    </node>
    <node id="玻尔兹曼机">
      <data key="d0">玻尔兹曼机</data>
      <data key="d1">concept</data>
      <data key="d2">A type of stochastic recurrent neural network invented by Geoffrey Hinton.&lt;SEP&gt;玻尔兹曼机是一种适用于解决包含大量“弱”约束的约束满足问题的并行计算结构。&lt;SEP&gt;A type of neural network where hidden units can be interconnected, forming recurrent neural networks, which makes learning difficult.&lt;SEP&gt;玻尔兹曼机是一种受Hopfield网络能量最小化思想影响的后续神经网络模型。&lt;SEP&gt;玻尔兹曼机is the third category of neural network models in deep learning discussed in the document, with Restricted Boltzmann Machine (RBM) being a prominent example.</data>
      <data key="d3">chunk-d0e494da55d171b3a3a8b96678397514&lt;SEP&gt;chunk-29b81edcfc109c880298f79878843454&lt;SEP&gt;chunk-b2aa136f0a91bbc88ed87eed07a66512&lt;SEP&gt;chunk-673b334bee153545178b73f52b190891&lt;SEP&gt;chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974830</data>
      <data key="d6" />
    </node>
    <node id="深度神经网络">
      <data key="d0">深度神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">A type of machine learning algorithm, specifically a neural network with multiple layers.&lt;SEP&gt;A type of neural network with multiple layers, introduced in the context of AlexNet in 2012.</data>
      <data key="d3">chunk-d0e494da55d171b3a3a8b96678397514&lt;SEP&gt;chunk-ea8a6fc4ba2e7bba693b03aaff3df4db</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975149</data>
      <data key="d6" />
    </node>
    <node id="机器学习算法三">
      <data key="d0">机器学习算法三</data>
      <data key="d1">content</data>
      <data key="d2">Refers to the third part of a series on machine learning algorithms, specifically covering deep neural networks.</data>
      <data key="d3">chunk-d0e494da55d171b3a3a8b96678397514</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973812</data>
      <data key="d6" />
    </node>
    <node id="神经网络实践第三步">
      <data key="d0">神经网络实践第三步</data>
      <data key="d1">content</data>
      <data key="d2">Refers to the third step in the practice of neural networks, part of a tutorial or series.</data>
      <data key="d3">chunk-d0e494da55d171b3a3a8b96678397514</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973812</data>
      <data key="d6" />
    </node>
    <node id="Geoffrey Hinton">
      <data key="d0">Geoffrey Hinton</data>
      <data key="d1">person</data>
      <data key="d2">A researcher credited with the invention of the Boltzmann machine.</data>
      <data key="d3">chunk-d0e494da55d171b3a3a8b96678397514</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973813</data>
      <data key="d6" />
    </node>
    <node id="图神经网络">
      <data key="d0">图神经网络</data>
      <data key="d1">method</data>
      <data key="d2">本研究基于图神经网络开发了代谢反应标准吉布斯自由能预测工具。</data>
      <data key="d3">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973830</data>
      <data key="d6" />
    </node>
    <node id="代谢反应标准吉布斯自由能预测工具">
      <data key="d0">代谢反应标准吉布斯自由能预测工具</data>
      <data key="d1">artifact</data>
      <data key="d2">本研究开发了名为dGbyG的代谢反应标准吉布斯自由能预测工具。</data>
      <data key="d3">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973830</data>
      <data key="d6" />
    </node>
    <node id="dGbyG">
      <data key="d0">dGbyG</data>
      <data key="d1">artifact</data>
      <data key="d2">dGbyG是基于图神经网络开发的代谢反应标准吉布斯自由能预测工具。</data>
      <data key="d3">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973831</data>
      <data key="d6" />
    </node>
    <node id="验证集">
      <data key="d0">验证集</data>
      <data key="d1">data</data>
      <data key="d2">验证集用于评估预测工具的性能。</data>
      <data key="d3">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973832</data>
      <data key="d6" />
    </node>
    <node id="现有最优方法">
      <data key="d0">现有最优方法</data>
      <data key="d1">method</data>
      <data key="d2">现有最优方法在验证集上的预测误差中位数为5.33 kJ/mol。</data>
      <data key="d3">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973832</data>
      <data key="d6" />
    </node>
    <node id="克劳修斯">
      <data key="d0">克劳修斯</data>
      <data key="d1">person</data>
      <data key="d2">Rudolf Clausius is a physicist who defined entropy from macroscopic thermal phenomena such as heat transfer and work.&lt;SEP&gt;A German physicist who originally introduced the concept of entropy.&lt;SEP&gt;克劳修斯是引入熵概念并用于表述热力学第二定律的物理学家。</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924&lt;SEP&gt;chunk-6135ecccd835afdfdaba2f58578ed61e&lt;SEP&gt;chunk-1248b4cdb9c5b6a4f15c20d0991319ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973924</data>
      <data key="d6" />
    </node>
    <node id="玻尔兹曼">
      <data key="d0">玻尔兹曼</data>
      <data key="d1">person</data>
      <data key="d2">Boltzmann is a physicist associated with the statistical interpretation of entropy.&lt;SEP&gt;玻尔兹曼是提出熵的统计力学定义公式S = k * ln W的物理学家。&lt;SEP&gt;玻尔兹曼是物理学家，提出了熵的统计解释，公式为S=k*lnW。</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924&lt;SEP&gt;chunk-74f709ca5bbf7d60213a39cdce19a507&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975795</data>
      <data key="d6" />
    </node>
    <node id="Hopfield网络">
      <data key="d0">Hopfield网络</data>
      <data key="d1">concept</data>
      <data key="d2">The Hopfield network is a discrete feedback neural network (recurrent neural network) proposed by physicist John Hopfield in 1982.&lt;SEP&gt;Hopfield网络是一种神经网络模型，在1980年代神经网络复兴中起到重要作用，为神经网络的记忆机制和递归结构提供了基础。</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924&lt;SEP&gt;chunk-673b334bee153545178b73f52b190891</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974664</data>
      <data key="d6" />
    </node>
    <node id="John Hopfield">
      <data key="d0">John Hopfield</data>
      <data key="d1">person</data>
      <data key="d2">John Hopfield is a physicist who proposed the Hopfield network in 1982.</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973873</data>
      <data key="d6" />
    </node>
    <node id="宏观热现象">
      <data key="d0">宏观热现象</data>
      <data key="d1">concept</data>
      <data key="d2">Macroscopic thermal phenomena refer to observable heat-related events like heat transfer and work.</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973875</data>
      <data key="d6" />
    </node>
    <node id="热传递">
      <data key="d0">热传递</data>
      <data key="d1">concept</data>
      <data key="d2">Heat transfer is a process of energy movement due to temperature difference.</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973876</data>
      <data key="d6" />
    </node>
    <node id="做功">
      <data key="d0">做功</data>
      <data key="d1">concept</data>
      <data key="d2">Work, in thermodynamics, is the energy transfer associated with a force acting through a distance.</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973876</data>
      <data key="d6" />
    </node>
    <node id="离散型反馈神经网络">
      <data key="d0">离散型反馈神经网络</data>
      <data key="d1">method</data>
      <data key="d2">Discrete feedback neural network is a type of recurrent neural network.</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973876</data>
      <data key="d6" />
    </node>
    <node id="递归神经网络">
      <data key="d0">递归神经网络</data>
      <data key="d1">method</data>
      <data key="d2">Recurrent neural network is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence.</data>
      <data key="d3">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973877</data>
      <data key="d6" />
    </node>
    <node id="神经网络">
      <data key="d0">神经网络</data>
      <data key="d1">method</data>
      <data key="d2">神经网络是一种广泛应用于机器学习的计算模型。它通过将输入信号X映射到输出信号Y来执行诸如分类等任务，能够解决包括异或问题在内的复杂非线性关系。神经网络在概念上可以被抽象为一种通信模型，这使得信息论的概念，特别是交叉熵，能够被应用于模型的优化过程。此外，存在一些特殊构造的神经网络，例如深度玻尔兹曼机。在技术实现层面，神经网络的特定设计或训练方法有时可以用于节省计算资源，例如显存。</data>
      <data key="d3">chunk-6135ecccd835afdfdaba2f58578ed61e&lt;SEP&gt;chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973&lt;SEP&gt;chunk-93a18801c2737ad9536660fe9501c9d8&lt;SEP&gt;chunk-36562522576eae8192339d548d0a1406&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975932</data>
      <data key="d6" />
    </node>
    <node id="分类问题">
      <data key="d0">分类问题</data>
      <data key="d1">concept</data>
      <data key="d2">A type of problem in machine learning and statistics where the goal is to categorize data into predefined classes.&lt;SEP&gt;A type of problem in machine learning where the goal is to assign categories to data points.</data>
      <data key="d3">chunk-6135ecccd835afdfdaba2f58578ed61e&lt;SEP&gt;chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976252</data>
      <data key="d6" />
    </node>
    <node id="鲁道夫·克劳修斯">
      <data key="d0">鲁道夫·克劳修斯</data>
      <data key="d1">person</data>
      <data key="d2">德国物理学家，于1865年首次提出了熵的概念。&lt;SEP&gt;鲁道夫·克劳修斯是德国物理学家，最早提出了熵的概念。</data>
      <data key="d3">chunk-ed0ca1ab77e5b700d5a4eb0d861cccb4&lt;SEP&gt;chunk-31dfc0a8415a0647f471a1cab88d6e36</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973956</data>
      <data key="d6" />
    </node>
    <node id="大脑神经网络">
      <data key="d0">大脑神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">大脑中的神经网络结构，其学习过程被描述为建立有序连接以降低熵，不复习则导致连接退化。</data>
      <data key="d3">chunk-ed0ca1ab77e5b700d5a4eb0d861cccb4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973904</data>
      <data key="d6" />
    </node>
    <node id="ΔS = ΔQ/T">
      <data key="d0">ΔS = ΔQ/T</data>
      <data key="d1">concept</data>
      <data key="d2">ΔS = ΔQ/T是描述热力学系统中熵变与热量及温度关系的数学公式。</data>
      <data key="d3">chunk-1248b4cdb9c5b6a4f15c20d0991319ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973925</data>
      <data key="d6" />
    </node>
    <node id="统计物理">
      <data key="d0">统计物理</data>
      <data key="d1">concept</data>
      <data key="d2">统计物理是物理学的一个分支，熵是其核心概念之一。</data>
      <data key="d3">chunk-31dfc0a8415a0647f471a1cab88d6e36</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973948</data>
      <data key="d6" />
    </node>
    <node id="Entropy">
      <data key="d0">Entropy</data>
      <data key="d1">concept</data>
      <data key="d2">Entropy is a core concept in thermodynamics, statistical physics, and information theory, used to describe the degree of disorder or chaos in a system.&lt;SEP&gt;The English term for entropy, a measure of uncertainty or information content.</data>
      <data key="d3">chunk-31dfc0a8415a0647f471a1cab88d6e36&lt;SEP&gt;chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974281</data>
      <data key="d6" />
    </node>
    <node id="玻尔兹曼常数">
      <data key="d0">玻尔兹曼常数</data>
      <data key="d1">concept</data>
      <data key="d2">玻尔兹曼常数是一个物理常数，在熵的统计力学定义公式S = k * ln W中表示为k。</data>
      <data key="d3">chunk-74f709ca5bbf7d60213a39cdce19a507</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973969</data>
      <data key="d6" />
    </node>
    <node id="微观状态数">
      <data key="d0">微观状态数</data>
      <data key="d1">concept</data>
      <data key="d2">微观状态数是一个系统可能存在的微观状态总数，在熵的统计力学定义公式S = k * ln W中表示为W。</data>
      <data key="d3">chunk-74f709ca5bbf7d60213a39cdce19a507</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973971</data>
      <data key="d6" />
    </node>
    <node id="公式S=k*lnW">
      <data key="d0">公式S=k*lnW</data>
      <data key="d1">method</data>
      <data key="d2">公式S = k * ln W是熵的统计力学定义，由玻尔兹曼提出，将熵与系统的微观状态数联系起来。&lt;SEP&gt;这是玻尔兹曼提出的熵的统计力学公式，其中S是熵，k是玻尔兹曼常数，W是微观状态数。</data>
      <data key="d3">chunk-74f709ca5bbf7d60213a39cdce19a507&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975795</data>
      <data key="d6" />
    </node>
    <node id="自由熵">
      <data key="d0">自由熵</data>
      <data key="d1">concept</data>
      <data key="d2">自由熵是一个热力学概念，在文本中被描述为负值，并被当作随机变量考虑其统计分布。</data>
      <data key="d3">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973993</data>
      <data key="d6" />
    </node>
    <node id="传统玻尔兹曼测度">
      <data key="d0">传统玻尔兹曼测度</data>
      <data key="d1">concept</data>
      <data key="d2">传统玻尔兹曼测度是物理学中的一种统计力学方法，文本中暗示自由熵的负值可能源于此测度。</data>
      <data key="d3">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973993</data>
      <data key="d6" />
    </node>
    <node id="大偏差原理">
      <data key="d0">大偏差原理</data>
      <data key="d1">concept</data>
      <data key="d2">大偏差原理是概率论中的一个原理，用于描述罕见事件的概率衰减速率，在文本中用于描述自由熵的统计分布。</data>
      <data key="d3">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974002</data>
      <data key="d6" />
    </node>
    <node id="统计分布">
      <data key="d0">统计分布</data>
      <data key="d1">concept</data>
      <data key="d2">统计分布指的是随机变量取值的概率分布，在文本中是自由熵作为随机变量所服从的规律。</data>
      <data key="d3">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974002</data>
      <data key="d6" />
    </node>
    <node id="P(S)~e -Nr(S)">
      <data key="d0">P(S)~e -Nr(S)</data>
      <data key="d1">concept</data>
      <data key="d2">这是一个概率分布表达式，描述自由熵作为随机变量时，其概率分布服从大偏差原理的具体数学形式。</data>
      <data key="d3">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973994</data>
      <data key="d6" />
    </node>
    <node id="r(S)">
      <data key="d0">r(S)</data>
      <data key="d1">concept</data>
      <data key="d2">这是大偏差原理中的速率函数，用于描述概率衰减的速率。</data>
      <data key="d3">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768973994</data>
      <data key="d6" />
    </node>
    <node id="X">
      <data key="d0">X</data>
      <data key="d1">data</data>
      <data key="d2">X is an array with n samples and m features, used as input data in a machine learning method.&lt;SEP&gt;An input variable, likely representing a multi-dimensional array, to the softmax function.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda&lt;SEP&gt;chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975456</data>
      <data key="d6" />
    </node>
    <node id="mbatch_backprop">
      <data key="d0">mbatch_backprop</data>
      <data key="d1">method</data>
      <data key="d2">A method defined within a class that performs backpropagation on mini-batches of data, returning delta values for biases and weights.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974024</data>
      <data key="d6" />
    </node>
    <node id="delta_b">
      <data key="d0">delta_b</data>
      <data key="d1">data</data>
      <data key="d2">An array representing the gradient of the cost function with respect to the biases, calculated and averaged over samples during backpropagation.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974025</data>
      <data key="d6" />
    </node>
    <node id="delta_w">
      <data key="d0">delta_w</data>
      <data key="d1">data</data>
      <data key="d2">An array representing the gradient of the cost function with respect to the weights, calculated and averaged over samples during backpropagation.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974026</data>
      <data key="d6" />
    </node>
    <node id="quadratic_cost">
      <data key="d0">quadratic_cost</data>
      <data key="d1">method</data>
      <data key="d2">A method that calculates the Mean Squared Error (MSE) cost function for given input data X and target labels y.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974026</data>
      <data key="d6" />
    </node>
    <node id="MSE">
      <data key="d0">MSE</data>
      <data key="d1">concept</data>
      <data key="d2">Mean Squared Error, a common cost function used in machine learning to measure the average squared difference between estimated and actual values.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974026</data>
      <data key="d6" />
    </node>
    <node id="y">
      <data key="d0">y</data>
      <data key="d1">data</data>
      <data key="d2">y represents the target labels or output data used alongside input X in machine learning methods for training.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974026</data>
      <data key="d6" />
    </node>
    <node id="samples">
      <data key="d0">samples</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the number of data samples, used to average the calculated delta values (gradients) in the backpropagation method.</data>
      <data key="d3">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974026</data>
      <data key="d6" />
    </node>
    <node id="Zhang">
      <data key="d0">Zhang</data>
      <data key="d1">person</data>
      <data key="d2">Zhang is a researcher who proposed the dispersion transfer entropy algorithm in 2020.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974058</data>
      <data key="d6" />
    </node>
    <node id="离散传递熵">
      <data key="d0">离散传递熵</data>
      <data key="d1">concept</data>
      <data key="d2">离散传递熵is an algorithm proposed by Zhang et al. in 2020 for optimizing symbolic processes.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974058</data>
      <data key="d6" />
    </node>
    <node id="DTE算法">
      <data key="d0">DTE算法</data>
      <data key="d1">method</data>
      <data key="d2">DTE算法is the abbreviation for dispersion transfer entropy, an algorithm used for symbolic process optimization.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974059</data>
      <data key="d6" />
    </node>
    <node id="符号化过程">
      <data key="d0">符号化过程</data>
      <data key="d1">concept</data>
      <data key="d2">符号化过程is the process of converting data into symbols, which the DTE algorithm aims to optimize.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974060</data>
      <data key="d6" />
    </node>
    <node id="Ragwitz准则">
      <data key="d0">Ragwitz准则</data>
      <data key="d1">concept</data>
      <data key="d2">Ragwitz准则is a criterion used by the DTE algorithm to dynamically select parameters based on discrete patterns.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974060</data>
      <data key="d6" />
    </node>
    <node id="离散模式">
      <data key="d0">离散模式</data>
      <data key="d1">concept</data>
      <data key="d2">离散模式refers to the discrete patterns used in the DTE algorithm for dynamic parameter selection.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974060</data>
      <data key="d6" />
    </node>
    <node id="序列符号化过程">
      <data key="d0">序列符号化过程</data>
      <data key="d1">concept</data>
      <data key="d2">序列符号化过程is the process of symbolizing sequences, for which the DTE algorithm provides a solution.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974060</data>
      <data key="d6" />
    </node>
    <node id="Dispersion Transfer Entropy">
      <data key="d0">Dispersion Transfer Entropy</data>
      <data key="d1">concept</data>
      <data key="d2">Dispersion Transfer Entropy is an algorithm proposed in 2020 for optimizing symbolic processes.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974060</data>
      <data key="d6" />
    </node>
    <node id="Parameter Selection">
      <data key="d0">Parameter Selection</data>
      <data key="d1">concept</data>
      <data key="d2">Parameter Selection is a process dynamically performed by the DTE algorithm using discrete patterns based on the Ragwitz criterion.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974061</data>
      <data key="d6" />
    </node>
    <node id="2020">
      <data key="d0">2020</data>
      <data key="d1">event</data>
      <data key="d2">2020 is the year when Zhang et al. proposed the dispersion transfer entropy algorithm.</data>
      <data key="d3">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974061</data>
      <data key="d6" />
    </node>
    <node id="Simon Haykin">
      <data key="d0">Simon Haykin</data>
      <data key="d1">person</data>
      <data key="d2">Simon Haykin is the author of the book and has long been engaged in research on neural networks.</data>
      <data key="d3">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974083</data>
      <data key="d6" />
    </node>
    <node id="Shannon">
      <data key="d0">Shannon</data>
      <data key="d1">person</data>
      <data key="d2">Shannon is the founder of information theory, whose principles are discussed as tools for unsupervised learning.</data>
      <data key="d3">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974083</data>
      <data key="d6" />
    </node>
    <node id="Unsupervised Learning">
      <data key="d0">Unsupervised Learning</data>
      <data key="d1">concept</data>
      <data key="d2">Unsupervised Learning is a machine learning method, and principles from information theory are used to implement it.&lt;SEP&gt;Unsupervised learning is a machine learning paradigm where models learn patterns from unlabeled data.</data>
      <data key="d3">chunk-82dd7e184547eda32bd10d04c1cae982&lt;SEP&gt;chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974623</data>
      <data key="d6" />
    </node>
    <node id="Neural Networks">
      <data key="d0">Neural Networks</data>
      <data key="d1">concept</data>
      <data key="d2">Neural Networks are a research area that Simon Haykin has long been engaged in.</data>
      <data key="d3">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974084</data>
      <data key="d6" />
    </node>
    <node id="The Book">
      <data key="d0">The Book</data>
      <data key="d1">artifact</data>
      <data key="d2">The book is authored by Simon Haykin and contains chapters discussing neural networks and information theory.</data>
      <data key="d3">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974085</data>
      <data key="d6" />
    </node>
    <node id="Chapter 10">
      <data key="d0">Chapter 10</data>
      <data key="d1">content</data>
      <data key="d2">Chapter 10 of the book explores how principles from Shannon's information theory can be used as tools for unsupervised learning.</data>
      <data key="d3">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974085</data>
      <data key="d6" />
    </node>
    <node id="深度自适应神经网络">
      <data key="d0">深度自适应神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">深度自适应神经网络是一种动态神经网络，近年来引起了广泛关注。</data>
      <data key="d3">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974105</data>
      <data key="d6" />
    </node>
    <node id="动态神经网络">
      <data key="d0">动态神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">动态神经网络是一类神经网络，深度自适应神经网络是其代表。</data>
      <data key="d3">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974105</data>
      <data key="d6" />
    </node>
    <node id="香农">
      <data key="d0">香农</data>
      <data key="d1">person</data>
      <data key="d2">香农是信息论的创始人，提出了信息熵的概念。&lt;SEP&gt;香农是信息论的创始人，提出了信息熵的概念。</data>
      <data key="d3">chunk-0662825c74f8b5ee226b4f32d6eae491&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975793</data>
      <data key="d6" />
    </node>
    <node id="预测不确定性">
      <data key="d0">预测不确定性</data>
      <data key="d1">concept</data>
      <data key="d2">预测不确定性指网络对样本x的预测结果的不确定程度。</data>
      <data key="d3">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974106</data>
      <data key="d6" />
    </node>
    <node id="H(x)">
      <data key="d0">H(x)</data>
      <data key="d1">concept</data>
      <data key="d2">H(x)是熵的数学表示，用于量化网络关于样本x的预测不确定性。</data>
      <data key="d3">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974106</data>
      <data key="d6" />
    </node>
    <node id="样本x">
      <data key="d0">样本x</data>
      <data key="d1">data</data>
      <data key="d2">样本x是网络进行预测所针对的数据对象。</data>
      <data key="d3">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974106</data>
      <data key="d6" />
    </node>
    <node id="同一视角组">
      <data key="d0">同一视角组</data>
      <data key="d1">concept</data>
      <data key="d2">A group of multiple views that share network parameters with each other.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974140</data>
      <data key="d6" />
    </node>
    <node id="多视图">
      <data key="d0">多视图</data>
      <data key="d1">concept</data>
      <data key="d2">Multiple views, which can be under the same perspective group or different perspective groups.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974140</data>
      <data key="d6" />
    </node>
    <node id="网络参数">
      <data key="d0">网络参数</data>
      <data key="d1">concept</data>
      <data key="d2">Parameters of a network, shared within the same perspective group but differ across different perspective groups.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974141</data>
      <data key="d6" />
    </node>
    <node id="网络训练过程">
      <data key="d0">网络训练过程</data>
      <data key="d1">method</data>
      <data key="d2">A two-step network training process involving pre-training and fine-tuning.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974141</data>
      <data key="d6" />
    </node>
    <node id="图像数据集ImageNet">
      <data key="d0">图像数据集ImageNet</data>
      <data key="d1">data</data>
      <data key="d2">An image dataset named ImageNet used for pre-training the network.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974141</data>
      <data key="d6" />
    </node>
    <node id="预训练">
      <data key="d0">预训练</data>
      <data key="d1">method</data>
      <data key="d2">The first step of network training, which involves training the network on the ImageNet dataset.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974142</data>
      <data key="d6" />
    </node>
    <node id="步骤">
      <data key="d0">步骤</data>
      <data key="d1">method</data>
      <data key="d2">The second step of network training, which is based on the pre-training step.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974142</data>
      <data key="d6" />
    </node>
    <node id="不同视角组">
      <data key="d0">不同视角组</data>
      <data key="d1">concept</data>
      <data key="d2">Different perspective groups, each using distinct network parameters for their multiple views.</data>
      <data key="d3">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974142</data>
      <data key="d6" />
    </node>
    <node id="本发明">
      <data key="d0">本发明</data>
      <data key="d1">artifact</data>
      <data key="d2">This invention combines model output feature vectors and text data features, using Gini impurity and Shannon entropy to define functions that measure the likelihood of test cases being misclassified.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974170</data>
      <data key="d6" />
    </node>
    <node id="模型输出特征向量">
      <data key="d0">模型输出特征向量</data>
      <data key="d1">data</data>
      <data key="d2">Model output feature vectors are data representations used in the invention to analyze test cases.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974170</data>
      <data key="d6" />
    </node>
    <node id="文本数据">
      <data key="d0">文本数据</data>
      <data key="d1">data</data>
      <data key="d2">Text data is a type of data whose features are used in the invention for analysis.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974171</data>
      <data key="d6" />
    </node>
    <node id="基尼不纯度">
      <data key="d0">基尼不纯度</data>
      <data key="d1">concept</data>
      <data key="d2">Gini impurity is a function used in the invention to measure the likelihood of test cases being misclassified and to rank them.&lt;SEP&gt;A criterion for selecting the best feature to split on in a decision tree.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f&lt;SEP&gt;chunk-a79596200294b5109fdd0cf885110f83</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975818</data>
      <data key="d6" />
    </node>
    <node id="测试用例">
      <data key="d0">测试用例</data>
      <data key="d1">data</data>
      <data key="d2">Test cases are the subjects being analyzed and ranked by the functions defined in the invention.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974171</data>
      <data key="d6" />
    </node>
    <node id="错误分类可能性">
      <data key="d0">错误分类可能性</data>
      <data key="d1">concept</data>
      <data key="d2">The likelihood of misclassification is the property being measured by the functions defined using Gini impurity and Shannon entropy.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974171</data>
      <data key="d6" />
    </node>
    <node id="衡量测试用例被错误分类可能性大小的函数">
      <data key="d0">衡量测试用例被错误分类可能性大小的函数</data>
      <data key="d1">concept</data>
      <data key="d2">The invention defines functions that measure the likelihood of test cases being misclassified.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974172</data>
      <data key="d6" />
    </node>
    <node id="排序">
      <data key="d0">排序</data>
      <data key="d1">method</data>
      <data key="d2">The invention uses the defined functions to rank test cases.</data>
      <data key="d3">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974173</data>
      <data key="d6" />
    </node>
    <node id="麻省理工学院">
      <data key="d0">麻省理工学院</data>
      <data key="d1">organization</data>
      <data key="d2">A research institution whose team published a study in SCIENCE ADVANCES.</data>
      <data key="d3">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974195</data>
      <data key="d6" />
    </node>
    <node id="SCIENCE ADVANCES">
      <data key="d0">SCIENCE ADVANCES</data>
      <data key="d1">content</data>
      <data key="d2">A journal where the research team from MIT published their study.</data>
      <data key="d3">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974195</data>
      <data key="d6" />
    </node>
    <node id="乘法模拟频率变换光学神经网络">
      <data key="d0">乘法模拟频率变换光学神经网络</data>
      <data key="d1">artifact</data>
      <data key="d2">An innovative architecture named MAFT-ONN proposed in the research.</data>
      <data key="d3">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974196</data>
      <data key="d6" />
    </node>
    <node id="MAFT-ONN">
      <data key="d0">MAFT-ONN</data>
      <data key="d1">artifact</data>
      <data key="d2">The acronym for the innovative architecture "乘法模拟频率变换光学神经网络".</data>
      <data key="d3">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974196</data>
      <data key="d6" />
    </node>
    <node id="香农极限">
      <data key="d0">香农极限</data>
      <data key="d1">concept</data>
      <data key="d2">A theoretical limit in information theory that the research aims to surpass.</data>
      <data key="d3">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974196</data>
      <data key="d6" />
    </node>
    <node id="研究团队">
      <data key="d0">研究团队</data>
      <data key="d1">organization</data>
      <data key="d2">The research team from MIT that proposed the MAFT-ONN architecture.</data>
      <data key="d3">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974196</data>
      <data key="d6" />
    </node>
    <node id="创新架构">
      <data key="d0">创新架构</data>
      <data key="d1">concept</data>
      <data key="d2">The concept of an innovative architecture, exemplified by MAFT-ONN.</data>
      <data key="d3">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974197</data>
      <data key="d6" />
    </node>
    <node id="脉冲耦合神经网络">
      <data key="d0">脉冲耦合神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">脉冲耦合神经网络是一种不同于传统人工神经网络的新型神经网络，具有生物学背景。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974227</data>
      <data key="d6" />
    </node>
    <node id="并行点火模型">
      <data key="d0">并行点火模型</data>
      <data key="d1">concept</data>
      <data key="d2">并行点火模型是脉冲耦合神经网络的一种模型。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974227</data>
      <data key="d6" />
    </node>
    <node id="图像增强">
      <data key="d0">图像增强</data>
      <data key="d1">concept</data>
      <data key="d2">图像增强是脉冲耦合神经网络的一个应用领域。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974220</data>
      <data key="d6" />
    </node>
    <node id="最大香农熵">
      <data key="d0">最大香农熵</data>
      <data key="d1">concept</data>
      <data key="d2">最大香农熵是信息论中的一个核心概念。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974220</data>
      <data key="d6" />
    </node>
    <node id="图像分割">
      <data key="d0">图像分割</data>
      <data key="d1">concept</data>
      <data key="d2">图像分割是脉冲耦合神经网络的一个应用领域。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974220</data>
      <data key="d6" />
    </node>
    <node id="中图分类号">
      <data key="d0">中图分类号</data>
      <data key="d1">data</data>
      <data key="d2">中图分类号是用于对文献进行分类的代码。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974221</data>
      <data key="d6" />
    </node>
    <node id="PCNN">
      <data key="d0">PCNN</data>
      <data key="d1">concept</data>
      <data key="d2">PCNN是脉冲耦合神经网络的英文缩写。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974221</data>
      <data key="d6" />
    </node>
    <node id="传统人工神经网络">
      <data key="d0">传统人工神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">传统人工神经网络是与脉冲耦合神经网络不同的另一种神经网络类型。</data>
      <data key="d3">chunk-b3aee2cd221856b5ea7d30d3400aa8dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974221</data>
      <data key="d6" />
    </node>
    <node id="复杂环境">
      <data key="d0">复杂环境</data>
      <data key="d1">concept</data>
      <data key="d2">Complex environment refers to the challenging conditions under which network channel characteristics need to be characterized.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974249</data>
      <data key="d6" />
    </node>
    <node id="网络信道特性">
      <data key="d0">网络信道特性</data>
      <data key="d1">concept</data>
      <data key="d2">Network channel characteristics are the properties of communication channels that need to be represented.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974249</data>
      <data key="d6" />
    </node>
    <node id="舰船通信网络">
      <data key="d0">舰船通信网络</data>
      <data key="d1">organization</data>
      <data key="d2">Ship communication network is the specific type of network being studied.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974250</data>
      <data key="d6" />
    </node>
    <node id="信号动态变化特性">
      <data key="d0">信号动态变化特性</data>
      <data key="d1">concept</data>
      <data key="d2">Signal dynamic change characteristics refer to the time-varying properties of signals within the network.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974250</data>
      <data key="d6" />
    </node>
    <node id="坎贝尔定理">
      <data key="d0">坎贝尔定理</data>
      <data key="d1">concept</data>
      <data key="d2">Campbell's theorem is a theoretical principle used as a basis for the model construction.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974251</data>
      <data key="d6" />
    </node>
    <node id="节点">
      <data key="d0">节点</data>
      <data key="d1">concept</data>
      <data key="d2">Nodes are the fundamental units or points within the communication network.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974251</data>
      <data key="d6" />
    </node>
    <node id="泊松点过程">
      <data key="d0">泊松点过程</data>
      <data key="d1">method</data>
      <data key="d2">Poisson point process is a stochastic process used to model the distribution and interaction of nodes.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974251</data>
      <data key="d6" />
    </node>
    <node id="信道">
      <data key="d0">信道</data>
      <data key="d1">concept</data>
      <data key="d2">Channel refers to the communication pathway whose properties are being modeled.&lt;SEP&gt;信道是信息传递模型中的信息介质，如电话线，负责传递信息，但可能引入噪音影响信息准确性。&lt;SEP&gt;信道是通信系统中的一个组成部分，用于传输信息。</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974405</data>
      <data key="d6" />
    </node>
    <node id="表征能力">
      <data key="d0">表征能力</data>
      <data key="d1">concept</data>
      <data key="d2">Characterization capability refers to the ability to represent and describe the properties of network channels in complex environments.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974252</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-a5d66dff">
      <data key="d0">DOC_ID: chunk-a5d66dff</data>
      <data key="d1">data</data>
      <data key="d2">DOC_ID: chunk-a5d66dff is a unique document identifier for the text segment.</data>
      <data key="d3">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974252</data>
      <data key="d6" />
    </node>
    <node id="電機控制">
      <data key="d0">電機控制</data>
      <data key="d1">concept</data>
      <data key="d2">A concept related to the control of electric motors.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974279</data>
      <data key="d6" />
    </node>
    <node id="磁場導向控制">
      <data key="d0">磁場導向控制</data>
      <data key="d1">concept</data>
      <data key="d2">A control method, also known as Field-Oriented Control (FOC), for AC motors.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974279</data>
      <data key="d6" />
    </node>
    <node id="磁場導向">
      <data key="d0">磁場導向</data>
      <data key="d1">concept</data>
      <data key="d2">The principle of field orientation used in motor control.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974287</data>
      <data key="d6" />
    </node>
    <node id="FOC">
      <data key="d0">FOC</data>
      <data key="d1">method</data>
      <data key="d2">An abbreviation for Field-Oriented Control, a method for controlling AC motors.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974280</data>
      <data key="d6" />
    </node>
    <node id="交流電機">
      <data key="d0">交流電機</data>
      <data key="d1">artifact</data>
      <data key="d2">A type of electric motor that operates on alternating current.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974280</data>
      <data key="d6" />
    </node>
    <node id="交流電機控制回路設計">
      <data key="d0">交流電機控制回路設計</data>
      <data key="d1">concept</data>
      <data key="d2">The design of control circuits for AC motors.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974280</data>
      <data key="d6" />
    </node>
    <node id="磁场定向控制">
      <data key="d0">磁场定向控制</data>
      <data key="d1">concept</data>
      <data key="d2">The Chinese term for Field-Oriented Control (FOC).</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974280</data>
      <data key="d6" />
    </node>
    <node id="葉志鈞">
      <data key="d0">葉志鈞</data>
      <data key="d1">person</data>
      <data key="d2">A person associated with the topic, likely an author or contributor.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974280</data>
      <data key="d6" />
    </node>
    <node id="叶志钧">
      <data key="d0">叶志钧</data>
      <data key="d1">person</data>
      <data key="d2">The simplified Chinese name for the person葉志鈞.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974281</data>
      <data key="d6" />
    </node>
    <node id="ai">
      <data key="d0">ai</data>
      <data key="d1">concept</data>
      <data key="d2">An abbreviation for artificial intelligence, mentioned in the context.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974282</data>
      <data key="d6" />
    </node>
    <node id="交流電機FOC Sensorless">
      <data key="d0">交流電機FOC Sensorless</data>
      <data key="d1">method</data>
      <data key="d2">A specific method for sensorless Field-Oriented Control of AC motors.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974282</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-33b57564">
      <data key="d0">DOC_ID: chunk-33b57564</data>
      <data key="d1">data</data>
      <data key="d2">A document identifier for a specific chunk of information.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974282</data>
      <data key="d6" />
    </node>
    <node id="领域: 信息论">
      <data key="d0">领域: 信息论</data>
      <data key="d1">concept</data>
      <data key="d2">The domain or field of study is Information Theory.</data>
      <data key="d3">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974283</data>
      <data key="d6" />
    </node>
    <node id="通信模型">
      <data key="d0">通信模型</data>
      <data key="d1">concept</data>
      <data key="d2">通信模型是描述信号从输入到输出传输过程的框架，在本文中用于类比神经网络。&lt;SEP&gt;通信模型是信息论中描述信息从发送方到接收方传递过程的抽象框架，交叉熵可以用来衡量接收方接收到的信息相对于其预期的吃惊程度。</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974382</data>
      <data key="d6" />
    </node>
    <node id="分类任务">
      <data key="d0">分类任务</data>
      <data key="d1">concept</data>
      <data key="d2">分类任务是指将输入数据分配到预定义类别的过程，本文中以文本分类为例。&lt;SEP&gt;分类任务是机器学习中的一种任务，目标是将输入数据(如文本)划分到预定义的类别中，例如政治、经济、娱乐等。</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974385</data>
      <data key="d6" />
    </node>
    <node id="文本">
      <data key="d0">文本</data>
      <data key="d1">content</data>
      <data key="d2">文本是需要被分类的输入数据，在示例中是一篇待分类的文章。</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974385</data>
      <data key="d6" />
    </node>
    <node id="科技类">
      <data key="d0">科技类</data>
      <data key="d1">concept</data>
      <data key="d2">科技类是文本分类任务中的一个具体类别，在示例中被标记为真实类别。</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974387</data>
      <data key="d6" />
    </node>
    <node id="真实分布">
      <data key="d0">真实分布</data>
      <data key="d1">data</data>
      <data key="d2">真实分布是标注语料中给定的目标概率分布，在示例中由向量[0,0,0,0,1,0,0]表示。</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974389</data>
      <data key="d6" />
    </node>
    <node id="模型预测分布">
      <data key="d0">模型预测分布</data>
      <data key="d1">data</data>
      <data key="d2">模型预测分布是神经网络对输入数据预测出的概率分布，在示例中由向量[0.1,0.1,0.04,0.06,0.2,0.4,0.09,0.01]等表示。</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974390</data>
      <data key="d6" />
    </node>
    <node id="震惊程度">
      <data key="d0">震惊程度</data>
      <data key="d1">concept</data>
      <data key="d2">震惊程度是交叉熵的直观解释，表示接收到的真实分布出乎预料预先猜测的分布的程度。</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974390</data>
      <data key="d6" />
    </node>
    <node id="JioNLP">
      <data key="d0">JioNLP</data>
      <data key="d1">organization</data>
      <data key="d2">JioNLP is the entity publishing the article and soliciting reader feedback through sharing or tipping.</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974391</data>
      <data key="d6" />
    </node>
    <node id="JioNLP Article">
      <data key="d0">JioNLP Article</data>
      <data key="d1">content</data>
      <data key="d2">The JioNLP article explains the concept of cross-entropy and its application in neural networks.</data>
      <data key="d3">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974391</data>
      <data key="d6" />
    </node>
    <node id="小北">
      <data key="d0">小北</data>
      <data key="d1">person</data>
      <data key="d2">小北是一个买彩票的人，他经历了未中奖和两次中奖的事件，用以说明信息量的大小。&lt;SEP&gt;小北是一个购买彩票的人，在连续中奖两次后对彩票系统产生怀疑，后来发现彩票中心主任是他的父亲，因此其中奖概率被暗中提高。</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974391</data>
      <data key="d6" />
    </node>
    <node id="彩票系统">
      <data key="d0">彩票系统</data>
      <data key="d1">organization</data>
      <data key="d2">彩票系统是发行和管理彩票的机构，在故事中被小北怀疑存在问题，因为他连续中奖的概率极低。</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974392</data>
      <data key="d6" />
    </node>
    <node id="彩票中心主任">
      <data key="d0">彩票中心主任</data>
      <data key="d1">person</data>
      <data key="d2">彩票中心主任是小北的父亲，他利用职务之便，将小北的真实中奖概率从0.0001提高到0.3。</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974392</data>
      <data key="d6" />
    </node>
    <node id="信息量">
      <data key="d0">信息量</data>
      <data key="d1">concept</data>
      <data key="d2">信息量是信息论中的概念，衡量信息接收方对信息的直观震惊程度，与事件发生的概率成反比。&lt;SEP&gt;信息量是衡量一个事件发生所带来的信息多少的度量，通常用概率的负对数表示，概率越小的事件发生，其信息量越大。&lt;SEP&gt;Information quantity refers to the measure of information content; in this context, it is what the partition function of the network represents.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973&lt;SEP&gt;chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975336</data>
      <data key="d6" />
    </node>
    <node id="先验分布">
      <data key="d0">先验分布</data>
      <data key="d1">concept</data>
      <data key="d2">先验分布是信息接收方在观测数据之前，心中默认或预期的概率分布。&lt;SEP&gt;在观测到数据之前，对模型参数不确定性的概率描述。</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976202</data>
      <data key="d6" />
    </node>
    <node id="后验分布">
      <data key="d0">后验分布</data>
      <data key="d1">concept</data>
      <data key="d2">后验分布是信息接收方在观测到数据之后，所了解到的真实概率分布。</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974393</data>
      <data key="d6" />
    </node>
    <node id="H(X)">
      <data key="d0">H(X)</data>
      <data key="d1">concept</data>
      <data key="d2">H(X) is the formula representing cross-entropy, defined as the sum over events of the real probability p(x) times the logarithm of the reciprocal of the prior probability q(x).</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974395</data>
      <data key="d6" />
    </node>
    <node id="KL(p||q)">
      <data key="d0">KL(p||q)</data>
      <data key="d1">concept</data>
      <data key="d2">KL(p||q) is the formula for relative entropy (KL divergence), defined as the cross-entropy H(p, q) minus the entropy H(p).</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974395</data>
      <data key="d6" />
    </node>
    <node id="女孩">
      <data key="d0">女孩</data>
      <data key="d1">person</data>
      <data key="d2">女孩是举例中听男孩说话的人，她对关于四川气候的陈述会感到震惊。&lt;SEP&gt;女孩is a character used in the communication model analogy to explain cross-entropy, representing the information receiver whose level of surprise depends on her prior expectations.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974396</data>
      <data key="d6" />
    </node>
    <node id="男孩">
      <data key="d0">男孩</data>
      <data key="d1">person</data>
      <data key="d2">男孩是举例中说话的人，他陈述了关于四川气候的事件。&lt;SEP&gt;男孩is a character in the communication model analogy who confesses his love to the girl, acting as the information sender.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974396</data>
      <data key="d6" />
    </node>
    <node id="刘慈欣">
      <data key="d0">刘慈欣</data>
      <data key="d1">person</data>
      <data key="d2">刘慈欣is the author of "The Wandering Earth," a science fiction story referenced to illustrate a scenario where the common knowledge (sun rising from the east) is overturned.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974397</data>
      <data key="d6" />
    </node>
    <node id="流浪地球">
      <data key="d0">流浪地球</data>
      <data key="d1">content</data>
      <data key="d2">流浪地球(The Wandering Earth) is a science fiction story by Liu Cixin where the Earth's rotation is affected, causing the sun to rise from the west, used as an example of a surprising posterior distribution.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974397</data>
      <data key="d6" />
    </node>
    <node id="太阳从东边升起">
      <data key="d0">太阳从东边升起</data>
      <data key="d1">concept</data>
      <data key="d2">太阳从东边升起is presented as a 100% certain common knowledge event with zero information content, serving as the prior distribution in an example.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974397</data>
      <data key="d6" />
    </node>
    <node id="太阳从西边升起">
      <data key="d0">太阳从西边升起</data>
      <data key="d1">concept</data>
      <data key="d2">太阳从西边升起is the surprising real event in "The Wandering Earth" example, representing the posterior distribution that contradicts common prior belief.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974398</data>
      <data key="d6" />
    </node>
    <node id="政治">
      <data key="d0">政治</data>
      <data key="d1">concept</data>
      <data key="d2">政治(Politics) is one of the seven predefined categories (e.g., for text classification) mentioned in the context of neural network applications.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974399</data>
      <data key="d6" />
    </node>
    <node id="经济">
      <data key="d0">经济</data>
      <data key="d1">concept</data>
      <data key="d2">经济(Economics) is one of the seven predefined categories (e.g., for text classification) mentioned in the context of neural network applications.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974400</data>
      <data key="d6" />
    </node>
    <node id="娱乐">
      <data key="d0">娱乐</data>
      <data key="d1">concept</data>
      <data key="d2">娱乐(Entertainment) is one of the seven predefined categories (e.g., for text classification) mentioned in the context of neural network applications.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974400</data>
      <data key="d6" />
    </node>
    <node id="社会">
      <data key="d0">社会</data>
      <data key="d1">concept</data>
      <data key="d2">社会(Society) is one of the seven predefined categories (e.g., for text classification) mentioned in the context of neural network applications.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974400</data>
      <data key="d6" />
    </node>
    <node id="科技">
      <data key="d0">科技</data>
      <data key="d1">concept</data>
      <data key="d2">科技(Technology) is one of the seven predefined categories (e.g., for text classification) mentioned in the context of neural network applications.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974402</data>
      <data key="d6" />
    </node>
    <node id="历史">
      <data key="d0">历史</data>
      <data key="d1">concept</data>
      <data key="d2">历史(History) is one of the seven predefined categories (e.g., for text classification) mentioned in the context of neural network applications.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974402</data>
      <data key="d6" />
    </node>
    <node id="家庭">
      <data key="d0">家庭</data>
      <data key="d1">concept</data>
      <data key="d2">家庭(Family) is one of the seven predefined categories (e.g., for text classification) mentioned in the context of neural network applications.</data>
      <data key="d3">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974402</data>
      <data key="d6" />
    </node>
    <node id="A Symbolic Analysis of Relay and Switching Circuits">
      <data key="d0">A Symbolic Analysis of Relay and Switching Circuits</data>
      <data key="d1">content</data>
      <data key="d2">这是克劳德·香农在1938年发表的硕士学位论文，该论文使他获得了美国Alfred Noble协会美国工程师奖，并被权威人士高度评价。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974403</data>
      <data key="d6" />
    </node>
    <node id="通信的一个数学理论">
      <data key="d0">通信的一个数学理论</data>
      <data key="d1">content</data>
      <data key="d2">这是克劳德·香农在1948年发表的论文，被认为是信息论的开端。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974403</data>
      <data key="d6" />
    </node>
    <node id="信息传递模型">
      <data key="d0">信息传递模型</data>
      <data key="d1">concept</data>
      <data key="d2">信息传递模型描述了信息从发送方(信源)通过信道传递到接收方(信宿)的过程，涉及编码、噪音和传递准确性等问题。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974404</data>
      <data key="d6" />
    </node>
    <node id="信源">
      <data key="d0">信源</data>
      <data key="d1">concept</data>
      <data key="d2">信源是信息传递模型中的信息发送方，例如例子中向女孩传递信息的男孩。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974404</data>
      <data key="d6" />
    </node>
    <node id="信宿">
      <data key="d0">信宿</data>
      <data key="d1">concept</data>
      <data key="d2">信宿是信息传递模型中的信息接收方，例如例子中接收男孩信息的女孩。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974404</data>
      <data key="d6" />
    </node>
    <node id="编码">
      <data key="d0">编码</data>
      <data key="d1">concept</data>
      <data key="d2">编码是信息传递中对信息进行表达的方式，如使用不同的语言，它并非信息本身，而是一种表达形式。&lt;SEP&gt;编码是通信系统中的一个过程，用于将信息转换为适合传输的形式。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974405</data>
      <data key="d6" />
    </node>
    <node id="Alfred Noble协会美国工程师奖">
      <data key="d0">Alfred Noble协会美国工程师奖</data>
      <data key="d1">organization</data>
      <data key="d2">Alfred Noble协会美国工程师奖是一个奖项，授予了发表重要论文的克劳德·香农。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974405</data>
      <data key="d6" />
    </node>
    <node id="Transactions of the American Institute of Electrical Engineers">
      <data key="d0">Transactions of the American Institute of Electrical Engineers</data>
      <data key="d1">content</data>
      <data key="d2">Transactions of the American Institute of Electrical Engineers是克劳德·香农在1938年发表其论文《A Symbolic Analysis of Relay and Switching Circuits》的期刊。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974405</data>
      <data key="d6" />
    </node>
    <node id="自然语言处理">
      <data key="d0">自然语言处理</data>
      <data key="d1">concept</data>
      <data key="d2">自然语言处理是一个领域，信息论是其理论基础，离开信息论难以讨论清楚该领域。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974407</data>
      <data key="d6" />
    </node>
    <node id="数字通信理论">
      <data key="d0">数字通信理论</data>
      <data key="d1">concept</data>
      <data key="d2">数字通信理论是克劳德·香农的主要研究领域之一，与信息论密切相关。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974408</data>
      <data key="d6" />
    </node>
    <node id="密码学">
      <data key="d0">密码学</data>
      <data key="d1">concept</data>
      <data key="d2">密码学是克劳德·香农的主要研究领域之一，他在二战期间为密码破译做出了贡献。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974408</data>
      <data key="d6" />
    </node>
    <node id="二战">
      <data key="d0">二战</data>
      <data key="d1">event</data>
      <data key="d2">二战是一个历史事件，期间克劳德·香农为密码破译和保密通信做出了贡献。</data>
      <data key="d3">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974408</data>
      <data key="d6" />
    </node>
    <node id="太阳">
      <data key="d0">太阳</data>
      <data key="d1">naturalobject</data>
      <data key="d2">太阳是每天从东边升起的恒星，其升起是一个必然事件，概率为1，信息量为0。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974408</data>
      <data key="d6" />
    </node>
    <node id="四川">
      <data key="d0">四川</data>
      <data key="d1">location</data>
      <data key="d2">四川是一个地区，在例子中遭遇了有气象观测记录以来最干旱高温的夏天，这是一个低概率事件。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974409</data>
      <data key="d6" />
    </node>
    <node id="概率">
      <data key="d0">概率</data>
      <data key="d1">concept</data>
      <data key="d2">概率是衡量事件发生可能性的数值，范围在0到1之间，是计算信息量的基础。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974409</data>
      <data key="d6" />
    </node>
    <node id="彩票">
      <data key="d0">彩票</data>
      <data key="d1">artifact</data>
      <data key="d2">彩票是一种博彩工具，中奖概率极低，在例子中用于演示低概率事件带来的高信息量。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974410</data>
      <data key="d6" />
    </node>
    <node id="硬币">
      <data key="d0">硬币</data>
      <data key="d1">artifact</data>
      <data key="d2">硬币是用于投掷的物体，出现正面或反面的概率各为二分之一，用于说明信息量的加性性质。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974419</data>
      <data key="d6" />
    </node>
    <node id="日本恐怖片">
      <data key="d0">日本恐怖片</data>
      <data key="d1">content</data>
      <data key="d2">日本恐怖片是一种电影类型，在例子中用于比喻信息传递是消除不确定性的过程。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974420</data>
      <data key="d6" />
    </node>
    <node id="通信系统">
      <data key="d0">通信系统</data>
      <data key="d1">concept</data>
      <data key="d2">通信系统是包括信息发送方、接收方、信道和编码的场景，是理解信息论的背景框架。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974420</data>
      <data key="d6" />
    </node>
    <node id="彩票机构员工">
      <data key="d0">彩票机构员工</data>
      <data key="d1">person</data>
      <data key="d2">彩票机构员工是社会新闻中提到的中奖者，暗示彩票系统可能存在问题。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974420</data>
      <data key="d6" />
    </node>
    <node id="地球">
      <data key="d0">地球</data>
      <data key="d1">naturalobject</data>
      <data key="d2">地球是一个行星，在例子中被用作概率极低的参照物(“比地球爆炸的概率还低”)。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974422</data>
      <data key="d6" />
    </node>
    <node id="信息发送方">
      <data key="d0">信息发送方</data>
      <data key="d1">concept</data>
      <data key="d2">信息发送方是通信系统中发出信息的源头。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974422</data>
      <data key="d6" />
    </node>
    <node id="信息接收方">
      <data key="d0">信息接收方</data>
      <data key="d1">concept</data>
      <data key="d2">信息接收方是通信系统中接收信息的终点，其不确定性在信息传递中被消除。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974423</data>
      <data key="d6" />
    </node>
    <node id="高中">
      <data key="d0">高中</data>
      <data key="d1">concept</data>
      <data key="d2">高中是一个教育阶段，熵的概念在此阶段被引入学习。</data>
      <data key="d3">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974423</data>
      <data key="d6" />
    </node>
    <node id="文本信息">
      <data key="d0">文本信息</data>
      <data key="d1">content</data>
      <data key="d2">一串需要被传输的文本信息。</data>
      <data key="d3">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974459</data>
      <data key="d6" />
    </node>
    <node id="字母">
      <data key="d0">字母</data>
      <data key="d1">concept</data>
      <data key="d2">文本信息中的基本组成单位，其出现具有特定的概率。</data>
      <data key="d3">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974459</data>
      <data key="d6" />
    </node>
    <node id="出现概率">
      <data key="d0">出现概率</data>
      <data key="d1">concept</data>
      <data key="d2">字母在文本信息中出现的可能性，记为p(x)。</data>
      <data key="d3">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974460</data>
      <data key="d6" />
    </node>
    <node id="最佳编码长度">
      <data key="d0">最佳编码长度</data>
      <data key="d1">concept</data>
      <data key="d2">对于具有特定出现概率的字母，其最优的编码长度是log_2 p(x)。</data>
      <data key="d3">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974460</data>
      <data key="d6" />
    </node>
    <node id="平均编码长度">
      <data key="d0">平均编码长度</data>
      <data key="d1">concept</data>
      <data key="d2">整段文本信息中所有字母编码长度的期望值，计算公式为-∑ p(x) log_2 p(x)。</data>
      <data key="d3">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974460</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-b5d062ff">
      <data key="d0">DOC_ID: chunk-b5d062ff</data>
      <data key="d1">data</data>
      <data key="d2">文档的唯一标识符。</data>
      <data key="d3">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974461</data>
      <data key="d6" />
    </node>
    <node id="编码定理">
      <data key="d0">编码定理</data>
      <data key="d1">concept</data>
      <data key="d2">编码定理是信息论的核心理论，阐述了在通信信道中实现可靠传输的可能性。&lt;SEP&gt;编码定理是信息论中的核心定理之一，从数学角度看是最优编码的存在性定理。</data>
      <data key="d3">chunk-c78284e4671aee8befd9c6871d1db529&lt;SEP&gt;chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974514</data>
      <data key="d6" />
    </node>
    <node id="克劳德·香农">
      <data key="d0">克劳德·香农</data>
      <data key="d1">person</data>
      <data key="d2">克劳德·香农是信息论的奠基人，在1948年发表了《通信的数学理论》。</data>
      <data key="d3">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974497</data>
      <data key="d6" />
    </node>
    <node id="通信的数学理论">
      <data key="d0">通信的数学理论</data>
      <data key="d1">content</data>
      <data key="d2">《通信的数学理论》是克劳德·香农于1948年发表的论文，首次系统阐述了信息论。</data>
      <data key="d3">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974492</data>
      <data key="d6" />
    </node>
    <node id="信道容量">
      <data key="d0">信道容量</data>
      <data key="d1">concept</data>
      <data key="d2">信道容量是通信信道在理论上能够无错误传输信息的最大速率。</data>
      <data key="d3">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974492</data>
      <data key="d6" />
    </node>
    <node id="汉明码">
      <data key="d0">汉明码</data>
      <data key="d1">method</data>
      <data key="d2">汉明码是一种线性纠错码，用于检测和纠正数据传输中的错误。</data>
      <data key="d3">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974492</data>
      <data key="d6" />
    </node>
    <node id="卷积码">
      <data key="d0">卷积码</data>
      <data key="d1">method</data>
      <data key="d2">卷积码是一种纠错编码方法，其编码输出不仅与当前输入有关，还与之前的输入有关。</data>
      <data key="d3">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974492</data>
      <data key="d6" />
    </node>
    <node id="纠错码">
      <data key="d0">纠错码</data>
      <data key="d1">concept</data>
      <data key="d2">纠错码是一种用于在数据传输中检测和纠正错误的编码方法。</data>
      <data key="d3">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974493</data>
      <data key="d6" />
    </node>
    <node id="信道编码定理">
      <data key="d0">信道编码定理</data>
      <data key="d1">concept</data>
      <data key="d2">信道编码定理是信息论中的核心定理之一，从数学角度看是最优编码的存在性定理。</data>
      <data key="d3">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974514</data>
      <data key="d6" />
    </node>
    <node id="最优编码">
      <data key="d0">最优编码</data>
      <data key="d1">concept</data>
      <data key="d2">最优编码是编码定理和信道编码定理所证明其存在的一种理想编码方式。</data>
      <data key="d3">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974515</data>
      <data key="d6" />
    </node>
    <node id="数学观点">
      <data key="d0">数学观点</data>
      <data key="d1">concept</data>
      <data key="d2">数学观点将编码定理和信道编码定理视为最优编码的存在性定理。</data>
      <data key="d3">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974522</data>
      <data key="d6" />
    </node>
    <node id="工程观点">
      <data key="d0">工程观点</data>
      <data key="d1">concept</data>
      <data key="d2">工程观点认为编码定理和信道编码定理缺乏结构性，无法直接指导最优编码的具体实现。</data>
      <data key="d3">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974523</data>
      <data key="d6" />
    </node>
    <node id="Toderici G">
      <data key="d0">Toderici G</data>
      <data key="d1">person</data>
      <data key="d2">Toderici G is an author of a paper on full resolution image compression with recurrent neural networks.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974562</data>
      <data key="d6" />
    </node>
    <node id="Vincent D">
      <data key="d0">Vincent D</data>
      <data key="d1">person</data>
      <data key="d2">Vincent D is an author of a paper on full resolution image compression with recurrent neural networks.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974562</data>
      <data key="d6" />
    </node>
    <node id="Johnston N">
      <data key="d0">Johnston N</data>
      <data key="d1">person</data>
      <data key="d2">Johnston N is an author of a paper on full resolution image compression with recurrent neural networks.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974562</data>
      <data key="d6" />
    </node>
    <node id="Full Resolution Image Compression With Recurrent Neural Networks">
      <data key="d0">Full Resolution Image Compression With Recurrent Neural Networks</data>
      <data key="d1">content</data>
      <data key="d2">This is a paper presented at the IEEE Conference on Computer Vision and Pattern Recognition.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974563</data>
      <data key="d6" />
    </node>
    <node id="IEEE Conference on Computer Vision and Pattern Recognition">
      <data key="d0">IEEE Conference on Computer Vision and Pattern Recognition</data>
      <data key="d1">event</data>
      <data key="d2">This is a conference where the paper on full resolution image compression with recurrent neural networks was presented.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974563</data>
      <data key="d6" />
    </node>
    <node id="Successive Refinement Of Images With Deep Joint Source-Channel Coding">
      <data key="d0">Successive Refinement Of Images With Deep Joint Source-Channel Coding</data>
      <data key="d1">content</data>
      <data key="d2">This is a paper presented at the IEEE 20th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC).</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974563</data>
      <data key="d6" />
    </node>
    <node id="IEEE 20th International Workshop On Signal Processing Advances In Wireless Communications (SPAWC)">
      <data key="d0">IEEE 20th International Workshop On Signal Processing Advances In Wireless Communications (SPAWC)</data>
      <data key="d1">event</data>
      <data key="d2">This is a workshop where the paper on successive refinement of images with deep joint source-channel coding was presented.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974563</data>
      <data key="d6" />
    </node>
    <node id="Deep Joint Source-Channel Coding For Wireless Image Retrieval">
      <data key="d0">Deep Joint Source-Channel Coding For Wireless Image Retrieval</data>
      <data key="d1">content</data>
      <data key="d2">This is a paper presented at the ICASSP 2020 IEEE International Conference on Acoustics, Speech and Signal Processing.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974564</data>
      <data key="d6" />
    </node>
    <node id="ICASSP 2020 IEEE International Conference On Acoustics, Speech And Signal Processing (ICASSP)">
      <data key="d0">ICASSP 2020 IEEE International Conference On Acoustics, Speech And Signal Processing (ICASSP)</data>
      <data key="d1">event</data>
      <data key="d2">This is a conference where the paper on deep joint source-channel coding for wireless image retrieval was presented.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974564</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning For Joint Source-Channel Coding Of Text">
      <data key="d0">Deep Learning For Joint Source-Channel Coding Of Text</data>
      <data key="d1">content</data>
      <data key="d2">This is a paper presented at the 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974565</data>
      <data key="d6" />
    </node>
    <node id="2018 IEEE International Conference On Acoustics, Speech And Signal Processing (ICASSP)">
      <data key="d0">2018 IEEE International Conference On Acoustics, Speech And Signal Processing (ICASSP)</data>
      <data key="d1">event</data>
      <data key="d2">This is a conference where the paper on deep learning for joint source-channel coding of text was presented.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974565</data>
      <data key="d6" />
    </node>
    <node id="M To 1 Joint Source-Channel Coding Of Gaussian Sources Via Dichotomy Of The Input Space Based On Deep Learning">
      <data key="d0">M To 1 Joint Source-Channel Coding Of Gaussian Sources Via Dichotomy Of The Input Space Based On Deep Learning</data>
      <data key="d1">content</data>
      <data key="d2">This is a paper presented at the 2019 Data Compression Conference (DCC).</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974573</data>
      <data key="d6" />
    </node>
    <node id="2019 Data Compression Conference (DCC)">
      <data key="d0">2019 Data Compression Conference (DCC)</data>
      <data key="d1">event</data>
      <data key="d2">This is a conference where the paper on M to 1 joint source-channel coding of Gaussian sources was presented.</data>
      <data key="d3">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974573</data>
      <data key="d6" />
    </node>
    <node id="约束满足问题">
      <data key="d0">约束满足问题</data>
      <data key="d1">concept</data>
      <data key="d2">约束满足问题是一类包含约束条件的问题，玻尔兹曼机被设计用于解决此类问题。</data>
      <data key="d3">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974588</data>
      <data key="d6" />
    </node>
    <node id="弱约束">
      <data key="d0">弱约束</data>
      <data key="d1">concept</data>
      <data key="d2">弱约束是相对于“强”约束而言的约束条件，是玻尔兹曼机处理的问题中的一种约束类型。</data>
      <data key="d3">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974589</data>
      <data key="d6" />
    </node>
    <node id="强约束">
      <data key="d0">强约束</data>
      <data key="d1">concept</data>
      <data key="d2">强约束是约束满足问题中一种更严格或必须满足的约束条件，与“弱”约束相对。</data>
      <data key="d3">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974590</data>
      <data key="d6" />
    </node>
    <node id="并行计算结构">
      <data key="d0">并行计算结构</data>
      <data key="d1">concept</data>
      <data key="d2">并行计算结构是一种计算架构，在文中特指玻尔兹曼机所采用的结构。</data>
      <data key="d3">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974590</data>
      <data key="d6" />
    </node>
    <node id="人工神经网络">
      <data key="d0">人工神经网络</data>
      <data key="d1">method</data>
      <data key="d2">人工神经网络是一种并行计算结构，文中指出玻尔兹曼机就是这种结构。&lt;SEP&gt;Artificial neural network is the method used to establish the mapping relationship between mesoscopic damage and macroscopic stiffness of solid propellants.</data>
      <data key="d3">chunk-29b81edcfc109c880298f79878843454&lt;SEP&gt;chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975011</data>
      <data key="d6" />
    </node>
    <node id="Restricted Boltzmann Machines">
      <data key="d0">Restricted Boltzmann Machines</data>
      <data key="d1">concept</data>
      <data key="d2">Restricted Boltzmann Machines (RBMs) are a key model in unsupervised learning, primarily used for feature learning and data modeling.</data>
      <data key="d3">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974615</data>
      <data key="d6" />
    </node>
    <node id="Feature Learning">
      <data key="d0">Feature Learning</data>
      <data key="d1">concept</data>
      <data key="d2">Feature learning is the process where a model automatically discovers the representations needed for feature detection or classification from raw data.</data>
      <data key="d3">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974623</data>
      <data key="d6" />
    </node>
    <node id="Data Modeling">
      <data key="d0">Data Modeling</data>
      <data key="d1">concept</data>
      <data key="d2">Data modeling is the process of creating a data model for the data to be stored in a database.</data>
      <data key="d3">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974616</data>
      <data key="d6" />
    </node>
    <node id="Energy-Based Model">
      <data key="d0">Energy-Based Model</data>
      <data key="d1">concept</data>
      <data key="d2">Energy-based models are a class of probabilistic models that define a probability distribution through an energy function.</data>
      <data key="d3">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974616</data>
      <data key="d6" />
    </node>
    <node id="Stochastic Neural Network">
      <data key="d0">Stochastic Neural Network</data>
      <data key="d1">concept</data>
      <data key="d2">A stochastic neural network is a type of artificial neural network built by introducing random variations into the network.</data>
      <data key="d3">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974616</data>
      <data key="d6" />
    </node>
    <node id="深度玻尔兹曼机">
      <data key="d0">深度玻尔兹曼机</data>
      <data key="d1">concept</data>
      <data key="d2">深度玻尔兹曼机是一种以受限玻尔兹曼机为基础的深度学习模型，本质是一种特殊构造的神经网络。&lt;SEP&gt;深度玻尔兹曼机(Deep Boltzmann Machine, DBM) is an extension of the Restricted Boltzmann Machine (RBM) and is considered within the realm of deep learning.</data>
      <data key="d3">chunk-93a18801c2737ad9536660fe9501c9d8&lt;SEP&gt;chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974832</data>
      <data key="d6" />
    </node>
    <node id="受限玻尔兹曼机">
      <data key="d0">受限玻尔兹曼机</data>
      <data key="d1">concept</data>
      <data key="d2">受限玻尔兹曼机是一种深度学习模型，是深度玻尔兹曼机的基础组件。&lt;SEP&gt;一种用于学习概率分布的生成式随机人工神经网络，由可见单元和隐藏单元构成。&lt;SEP&gt;受限玻尔兹曼机(Restricted Boltzmann Machine, RBM) is a two-layer neural network model widely used in industry, such as in recommendation systems.</data>
      <data key="d3">chunk-93a18801c2737ad9536660fe9501c9d8&lt;SEP&gt;chunk-52188c2297ba9ea322f462b96137a3c3&lt;SEP&gt;chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974830</data>
      <data key="d6" />
    </node>
    <node id="深度学习模型">
      <data key="d0">深度学习模型</data>
      <data key="d1">concept</data>
      <data key="d2">深度学习模型是一种机器学习方法，深度玻尔兹曼机是其中的一种。</data>
      <data key="d3">chunk-93a18801c2737ad9536660fe9501c9d8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974643</data>
      <data key="d6" />
    </node>
    <node id="Restricted Boltzmann Machine">
      <data key="d0">Restricted Boltzmann Machine</data>
      <data key="d1">concept</data>
      <data key="d2">Restricted Boltzmann Machine is a type of deep learning model, abbreviated as RBM, and serves as the foundational component for Deep Boltzmann Machines.</data>
      <data key="d3">chunk-93a18801c2737ad9536660fe9501c9d8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974643</data>
      <data key="d6" />
    </node>
    <node id="隐藏单元">
      <data key="d0">隐藏单元</data>
      <data key="d1">概念</data>
      <data key="d2">Units within a Boltzmann machine that can be connected to each other.&lt;SEP&gt;受限玻尔兹曼机中代表数据潜在特征的一种神经元。</data>
      <data key="d3">chunk-b2aa136f0a91bbc88ed87eed07a66512&lt;SEP&gt;chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974740</data>
      <data key="d6" />
    </node>
    <node id="循环神经网络">
      <data key="d0">循环神经网络</data>
      <data key="d1">method</data>
      <data key="d2">A type of neural network architecture formed when hidden units are interconnected, making learning challenging.&lt;SEP&gt;An autoregressive generative model used in the proposed method.</data>
      <data key="d3">chunk-b2aa136f0a91bbc88ed87eed07a66512&lt;SEP&gt;chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975399</data>
      <data key="d6" />
    </node>
    <node id="层内连接">
      <data key="d0">层内连接</data>
      <data key="d1">concept</data>
      <data key="d2">Connections between units within the same layer; restricting these connections can facilitate training.</data>
      <data key="d3">chunk-b2aa136f0a91bbc88ed87eed07a66512</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974651</data>
      <data key="d6" />
    </node>
    <node id="能量最小化思想">
      <data key="d0">能量最小化思想</data>
      <data key="d1">concept</data>
      <data key="d2">能量最小化思想是Hopfield网络的核心思想之一，影响了后来的玻尔兹曼机等模型的发展。</data>
      <data key="d3">chunk-673b334bee153545178b73f52b190891</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974664</data>
      <data key="d6" />
    </node>
    <node id="HopField Network">
      <data key="d0">HopField Network</data>
      <data key="d1">concept</data>
      <data key="d2">A type of recurrent neural network with symmetric weights and no self-connections, where the network dynamics minimize an energy function.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974732</data>
      <data key="d6" />
    </node>
    <node id="Restricted Boltzmann Machine (Rbm)">
      <data key="d0">Restricted Boltzmann Machine (Rbm)</data>
      <data key="d1">method</data>
      <data key="d2">A type of generative stochastic artificial neural network used for learning probability distributions, consisting of visible and hidden units.&lt;SEP&gt;A probabilistic graphical model used for learning probability distributions, with optimization challenges due to large computational costs of probability distributions.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3&lt;SEP&gt;chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974821</data>
      <data key="d6" />
    </node>
    <node id="Neuron">
      <data key="d0">Neuron</data>
      <data key="d1">concept</data>
      <data key="d2">A basic computational unit in a neural network, characterized by an input, a weight, a threshold, and a state.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974733</data>
      <data key="d6" />
    </node>
    <node id="Weight">
      <data key="d0">Weight</data>
      <data key="d1">concept</data>
      <data key="d2">A parameter representing the strength of the connection between two neurons in a neural network.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974734</data>
      <data key="d6" />
    </node>
    <node id="Threshold">
      <data key="d0">Threshold</data>
      <data key="d1">concept</data>
      <data key="d2">A parameter for a neuron that determines the level of input required to change its state.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974734</data>
      <data key="d6" />
    </node>
    <node id="State">
      <data key="d0">State</data>
      <data key="d1">concept</data>
      <data key="d2">The activation value of a neuron at a given time, which can be discrete (e.g., 1 or -1).</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974734</data>
      <data key="d6" />
    </node>
    <node id="Energy Function">
      <data key="d0">Energy Function</data>
      <data key="d1">concept</data>
      <data key="d2">A function defined for a neural network, such as HopField, that decreases as the network updates, indicating convergence to a stable state.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974734</data>
      <data key="d6" />
    </node>
    <node id="Discrete HopField Network">
      <data key="d0">Discrete HopField Network</data>
      <data key="d1">concept</data>
      <data key="d2">A HopField network where the activation function is a sign function, resulting in binary neuron states.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974734</data>
      <data key="d6" />
    </node>
    <node id="Sgn Function">
      <data key="d0">Sgn Function</data>
      <data key="d1">method</data>
      <data key="d2">The sign function used as the activation function in discrete HopField networks to produce binary outputs.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974735</data>
      <data key="d6" />
    </node>
    <node id="Visible Unit">
      <data key="d0">Visible Unit</data>
      <data key="d1">concept</data>
      <data key="d2">A type of neuron in a Restricted Boltzmann Machine that represents the observable data.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974735</data>
      <data key="d6" />
    </node>
    <node id="Hidden Unit">
      <data key="d0">Hidden Unit</data>
      <data key="d1">concept</data>
      <data key="d2">A type of neuron in a Restricted Boltzmann Machine that represents latent features of the data.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974735</data>
      <data key="d6" />
    </node>
    <node id="HopField网络">
      <data key="d0">HopField网络</data>
      <data key="d1">概念</data>
      <data key="d2">一种具有对称权重且无自连接的递归神经网络，其网络动力学过程会最小化一个能量函数。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974743</data>
      <data key="d6" />
    </node>
    <node id="权重">
      <data key="d0">权重</data>
      <data key="d1">概念</data>
      <data key="d2">表示神经网络中两个神经元之间连接强度的参数。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974736</data>
      <data key="d6" />
    </node>
    <node id="阈值">
      <data key="d0">阈值</data>
      <data key="d1">concept</data>
      <data key="d2">神经元的参数，决定其状态改变所需的输入水平。&lt;SEP&gt;Threshold is a parameter used in the ID3 algorithm to determine whether to stop splitting and return a leaf node.</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3&lt;SEP&gt;chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975918</data>
      <data key="d6" />
    </node>
    <node id="状态">
      <data key="d0">状态</data>
      <data key="d1">概念</data>
      <data key="d2">神经元在给定时间的激活值，可以是离散的(例如1或-1)。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974738</data>
      <data key="d6" />
    </node>
    <node id="能量函数">
      <data key="d0">能量函数</data>
      <data key="d1">concept</data>
      <data key="d2">为神经网络(如HopField网络)定义的函数，随着网络更新而减小，表明网络收敛到稳定状态。&lt;SEP&gt;能量函数for an RBM, given state vectors $v$ and $h$, is defined as $E(v,h) = -a^Tv - b^Th - h^TWv$.&lt;SEP&gt;分数函数的一种，通常与系统的能量状态相关。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3&lt;SEP&gt;chunk-e378397631b5d452d5eb095ebbfde434&lt;SEP&gt;chunk-08c978d767db01aaeef63f40ea958f51</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975371</data>
      <data key="d6" />
    </node>
    <node id="离散型HopField网络">
      <data key="d0">离散型HopField网络</data>
      <data key="d1">概念</data>
      <data key="d2">一种激活函数为符号函数的HopField网络，其神经元状态为二进制。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974739</data>
      <data key="d6" />
    </node>
    <node id="符号函数">
      <data key="d0">符号函数</data>
      <data key="d1">方法</data>
      <data key="d2">在离散型HopField网络中用作激活函数的符号函数，用于产生二进制输出。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974740</data>
      <data key="d6" />
    </node>
    <node id="可见单元">
      <data key="d0">可见单元</data>
      <data key="d1">概念</data>
      <data key="d2">受限玻尔兹曼机中代表可观测数据的一种神经元。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974740</data>
      <data key="d6" />
    </node>
    <node id="递推式">
      <data key="d0">递推式</data>
      <data key="d1">方法</data>
      <data key="d2">描述HopField网络中神经元状态随时间更新的数学公式。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974740</data>
      <data key="d6" />
    </node>
    <node id="能量增量">
      <data key="d0">能量增量</data>
      <data key="d1">概念</data>
      <data key="d2">HopField网络中单个神经元状态变化引起的能量变化量，在状态变化时总为负值。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974740</data>
      <data key="d6" />
    </node>
    <node id="权重矩阵">
      <data key="d0">权重矩阵</data>
      <data key="d1">概念</data>
      <data key="d2">包含所有神经元间连接权重的矩阵，在HopField网络中具有对称性且对角线元素为零。</data>
      <data key="d3">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974748</data>
      <data key="d6" />
    </node>
    <node id="Gradient Descent">
      <data key="d0">Gradient Descent</data>
      <data key="d1">method</data>
      <data key="d2">A theoretical optimization method for RBM, but often impractical due to the computational expense of calculating the full probability distribution.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974821</data>
      <data key="d6" />
    </node>
    <node id="Markov Chain Monte Carlo (Mcmc)">
      <data key="d0">Markov Chain Monte Carlo (Mcmc)</data>
      <data key="d1">method</data>
      <data key="d2">A class of algorithms used to simulate and approximate complex probability distributions, mentioned as a basis for more practical RBM training methods.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974823</data>
      <data key="d6" />
    </node>
    <node id="Gibbs Sampling">
      <data key="d0">Gibbs Sampling</data>
      <data key="d1">method</data>
      <data key="d2">A specific MCMC algorithm used for sampling from multivariate probability distributions.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974823</data>
      <data key="d6" />
    </node>
    <node id="Contrastive Divergence">
      <data key="d0">Contrastive Divergence</data>
      <data key="d1">method</data>
      <data key="d2">A commonly used method for training RBMs, based on Gibbs sampling, which approximates the gradient to avoid full probability distribution calculation.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974824</data>
      <data key="d6" />
    </node>
    <node id="Collaborative Filtering">
      <data key="d0">Collaborative Filtering</data>
      <data key="d1">method</data>
      <data key="d2">An application area for Restricted Boltzmann Machines, as referenced in the literature.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974824</data>
      <data key="d6" />
    </node>
    <node id="Gradient Formula">
      <data key="d0">Gradient Formula</data>
      <data key="d1">concept</data>
      <data key="d2">Mathematical expressions for the gradients of parameters (a_i, W_ij, b_i) with respect to the negative log-likelihood in an RBM.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974824</data>
      <data key="d6" />
    </node>
    <node id="Parameter A">
      <data key="d0">Parameter A</data>
      <data key="d1">concept</data>
      <data key="d2">A parameter of the RBM model, whose gradient is derived and shown in the text.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974825</data>
      <data key="d6" />
    </node>
    <node id="Parameter W">
      <data key="d0">Parameter W</data>
      <data key="d1">concept</data>
      <data key="d2">A weight matrix parameter of the RBM model, whose gradient formula is provided.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974825</data>
      <data key="d6" />
    </node>
    <node id="Parameter B">
      <data key="d0">Parameter B</data>
      <data key="d1">concept</data>
      <data key="d2">A bias parameter of the RBM model, whose gradient formula is provided.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974825</data>
      <data key="d6" />
    </node>
    <node id="Visible Unit V">
      <data key="d0">Visible Unit V</data>
      <data key="d1">concept</data>
      <data key="d2">The observed variables in an RBM model.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974825</data>
      <data key="d6" />
    </node>
    <node id="Hidden Unit H">
      <data key="d0">Hidden Unit H</data>
      <data key="d1">concept</data>
      <data key="d2">The latent variables in an RBM model.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974833</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning">
      <data key="d0">Deep Learning</data>
      <data key="d1">method</data>
      <data key="d2">A book by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, cited as a reference.&lt;SEP&gt;Deep Learning is a fundamental concept in AI with applications in digital pathology analysis for tasks like detection, segmentation, classification, and grading.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74&lt;SEP&gt;chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975133</data>
      <data key="d6" />
    </node>
    <node id="A Practical Guide To Training Restricted Boltzmann Machines">
      <data key="d0">A Practical Guide To Training Restricted Boltzmann Machines</data>
      <data key="d1">content</data>
      <data key="d2">A reference guide for training RBMs, authored by G.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974833</data>
      <data key="d6" />
    </node>
    <node id="Restricted Boltzmann Machines For Collaborative Filtering">
      <data key="d0">Restricted Boltzmann Machines For Collaborative Filtering</data>
      <data key="d1">content</data>
      <data key="d2">A reference paper on applying RBMs to collaborative filtering, authored by G.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974826</data>
      <data key="d6" />
    </node>
    <node id="Ian Goodfellow">
      <data key="d0">Ian Goodfellow</data>
      <data key="d1">person</data>
      <data key="d2">An author of the referenced book "Deep Learning".</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974826</data>
      <data key="d6" />
    </node>
    <node id="Yoshua Bengio">
      <data key="d0">Yoshua Bengio</data>
      <data key="d1">person</data>
      <data key="d2">An author of the referenced book "Deep Learning".</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974826</data>
      <data key="d6" />
    </node>
    <node id="Aaron Courville">
      <data key="d0">Aaron Courville</data>
      <data key="d1">person</data>
      <data key="d2">An author of the referenced book "Deep Learning".</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974827</data>
      <data key="d6" />
    </node>
    <node id="G.">
      <data key="d0">G.</data>
      <data key="d1">person</data>
      <data key="d2">The author of the referenced practical guide and collaborative filtering paper on RBMs.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974827</data>
      <data key="d6" />
    </node>
    <node id="刘建平Pinard">
      <data key="d0">刘建平Pinard</data>
      <data key="d1">person</data>
      <data key="d2">The poster/author of the blog text containing the technical discussion on RBMs.&lt;SEP&gt;刘建平Pinard is the author of the document discussing neural network models in deep learning.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74&lt;SEP&gt;chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974827</data>
      <data key="d6" />
    </node>
    <node id="Negative Log-Likelihood">
      <data key="d0">Negative Log-Likelihood</data>
      <data key="d1">concept</data>
      <data key="d2">The function -ln(P(V)) whose gradient is being calculated with respect to the RBM parameters.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974827</data>
      <data key="d6" />
    </node>
    <node id="Sample Gradient">
      <data key="d0">Sample Gradient</data>
      <data key="d1">concept</data>
      <data key="d2">The gradient loss for an individual sample, which is approximated using methods like Contrastive Divergence instead of calculating the full gradient sum.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974827</data>
      <data key="d6" />
    </node>
    <node id="Blog Post">
      <data key="d0">Blog Post</data>
      <data key="d1">content</data>
      <data key="d2">A blog post authored by刘建平Pinard discussing RBM theory, training methods, and applications, posted on 2017-03-11.</data>
      <data key="d3">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974828</data>
      <data key="d6" />
    </node>
    <node id="深度学习">
      <data key="d0">深度学习</data>
      <data key="d1">concept</data>
      <data key="d2">深度学习is a field of machine learning that includes various neural network models such as DNN, CNN, RNN, LSTM, and Boltzmann Machines.&lt;SEP&gt;深度学习是机器学习中一种基于对数据进行特征学习的方法，通过组合低层特征学习到数据的高层特征表达，常用于图像处理与计算机视觉领域。&lt;SEP&gt;一种人工智能技术，在数字病理分析中用于细胞和组织检测、分割、癌症分类和分级。&lt;SEP&gt;深度学习是人工智能的一个子领域，交叉熵损失函数在其中被广泛使用。</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434&lt;SEP&gt;chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-b332af60e3fc8fedacf0ad7703f20c18&lt;SEP&gt;chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975615</data>
      <data key="d6" />
    </node>
    <node id="前向神经网络">
      <data key="d0">前向神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">前向神经网络is a category of neural network models in deep learning, including DNN and CNN, characterized by forward propagation of signals.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974828</data>
      <data key="d6" />
    </node>
    <node id="DNN">
      <data key="d0">DNN</data>
      <data key="d1">concept</data>
      <data key="d2">DNN (Deep Neural Network) is a type of feedforward neural network model used in deep learning.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974829</data>
      <data key="d6" />
    </node>
    <node id="CNN">
      <data key="d0">CNN</data>
      <data key="d1">concept</data>
      <data key="d2">CNN (Convolutional Neural Network) is a type of feedforward neural network model used in deep learning, particularly for image processing.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974829</data>
      <data key="d6" />
    </node>
    <node id="反馈神经网络">
      <data key="d0">反馈神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">反馈神经网络is a category of neural network models in deep learning, including RNN and LSTM, characterized by feedback connections.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974829</data>
      <data key="d6" />
    </node>
    <node id="RNN">
      <data key="d0">RNN</data>
      <data key="d1">concept</data>
      <data key="d2">RNN (Recurrent Neural Network) is a type of neural network with feedback connections, used for sequential data.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974829</data>
      <data key="d6" />
    </node>
    <node id="LSTM">
      <data key="d0">LSTM</data>
      <data key="d1">concept</data>
      <data key="d2">LSTM (Long Short-Term Memory) is a type of recurrent neural network model used in deep learning.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974830</data>
      <data key="d6" />
    </node>
    <node id="隐藏层">
      <data key="d0">隐藏层</data>
      <data key="d1">concept</data>
      <data key="d2">隐藏层is the upper layer of neurons in an RBM, represented by vector $h$, where neurons are independent of each other.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974832</data>
      <data key="d6" />
    </node>
    <node id="可见层">
      <data key="d0">可见层</data>
      <data key="d1">concept</data>
      <data key="d2">可见层is the lower layer of neurons in an RBM, represented by vector $v$, where neurons are independent of each other.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974833</data>
      <data key="d6" />
    </node>
    <node id="权重矩阵W">
      <data key="d0">权重矩阵W</data>
      <data key="d1">concept</data>
      <data key="d2">权重矩阵W is the matrix representing the connection weights between the hidden layer and visible layer in an RBM, with full connectivity between the two layers.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974834</data>
      <data key="d6" />
    </node>
    <node id="偏倚系数向量a">
      <data key="d0">偏倚系数向量a</data>
      <data key="d1">concept</data>
      <data key="d2">偏倚系数向量a is the bias coefficient vector for the visible layer neurons in an RBM.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974834</data>
      <data key="d6" />
    </node>
    <node id="偏倚系数向量b">
      <data key="d0">偏倚系数向量b</data>
      <data key="d1">concept</data>
      <data key="d2">偏倚系数向量b is the bias coefficient vector for the hidden layer neurons in an RBM.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974834</data>
      <data key="d6" />
    </node>
    <node id="概率分布P(v,h)">
      <data key="d0">概率分布P(v,h)</data>
      <data key="d1">concept</data>
      <data key="d2">概率分布P(v,h) is the probability distribution defining the state of an RBM given $v$ and $h$, expressed as $P(v,h) = \frac{1}{Z}e^{-E(v,h)}$.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974835</data>
      <data key="d6" />
    </node>
    <node id="归一化系数Z">
      <data key="d0">归一化系数Z</data>
      <data key="d1">concept</data>
      <data key="d2">归一化系数Z is the normalization constant in the probability distribution $P(v,h)$ for an RBM.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974835</data>
      <data key="d6" />
    </node>
    <node id="sigmoid激活函数">
      <data key="d0">sigmoid激活函数</data>
      <data key="d1">concept</data>
      <data key="d2">sigmoid激活函数is the activation function used in RBM for both the visible-to-hidden layer and hidden-to-visible layer transformations.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974835</data>
      <data key="d6" />
    </node>
    <node id="对数损失函数">
      <data key="d0">对数损失函数</data>
      <data key="d1">concept</data>
      <data key="d2">对数损失函数is the loss function used for training RBM models on a dataset of m samples, aiming to minimize $L(W,a,b) = -\sum\limits_{i=1}^{m}ln(P(V^{(i)}))$.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974836</data>
      <data key="d6" />
    </node>
    <node id="梯度计算">
      <data key="d0">梯度计算</data>
      <data key="d1">concept</data>
      <data key="d2">梯度计算refers to the process of calculating gradients, such as for parameter $a_i$, during the training of an RBM model to minimize the loss function.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974836</data>
      <data key="d6" />
    </node>
    <node id="推荐系统">
      <data key="d0">推荐系统</data>
      <data key="d1">concept</data>
      <data key="d2">推荐系统is an industrial application area where RBM models and their extensions are widely used.</data>
      <data key="d3">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974837</data>
      <data key="d6" />
    </node>
    <node id="M2DNE">
      <data key="d0">M2DNE</data>
      <data key="d1">method</data>
      <data key="d2">M2DNE is a novel temporal network embedding method proposed in the text.</data>
      <data key="d3">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974870</data>
      <data key="d6" />
    </node>
    <node id="时间网络">
      <data key="d0">时间网络</data>
      <data key="d1">concept</data>
      <data key="d2">Temporal networks are described as ubiquitous entities that evolve over time in terms of micro and macro dynamics.</data>
      <data key="d3">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974870</data>
      <data key="d6" />
    </node>
    <node id="微观动态">
      <data key="d0">微观动态</data>
      <data key="d1">concept</data>
      <data key="d2">Micro dynamics refer to the detailed processes that form the network structure.</data>
      <data key="d3">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974871</data>
      <data key="d6" />
    </node>
    <node id="宏观动态">
      <data key="d0">宏观动态</data>
      <data key="d1">concept</data>
      <data key="d2">Macro dynamics refer to the evolutionary patterns at the network scale.</data>
      <data key="d3">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974871</data>
      <data key="d6" />
    </node>
    <node id="网络结构">
      <data key="d0">网络结构</data>
      <data key="d1">concept</data>
      <data key="d2">Network structure is the configuration of connections within a network, whose formation is detailed by micro dynamics.</data>
      <data key="d3">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974871</data>
      <data key="d6" />
    </node>
    <node id="时间特性">
      <data key="d0">时间特性</data>
      <data key="d1">concept</data>
      <data key="d2">Temporal characteristics are the time-evolving properties of a network that the M2DNE method aims to capture.</data>
      <data key="d3">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974871</data>
      <data key="d6" />
    </node>
    <node id="Olaf Sporns">
      <data key="d0">Olaf Sporns</data>
      <data key="d1">person</data>
      <data key="d2">Olaf Sporns is a researcher at Indiana University who first proposed the concept of "Connectomics" in 2005.</data>
      <data key="d3">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974896</data>
      <data key="d6" />
    </node>
    <node id="Indiana University">
      <data key="d0">Indiana University</data>
      <data key="d1">organization</data>
      <data key="d2">Indiana University is an American university where Olaf Sporns conducted research.</data>
      <data key="d3">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974896</data>
      <data key="d6" />
    </node>
    <node id="Connectomics">
      <data key="d0">Connectomics</data>
      <data key="d1">concept</data>
      <data key="d2">Connectomics is a concept first proposed by Olaf Sporns in 2005, referring to a new discipline focused on studying neural network connections.</data>
      <data key="d3">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974896</data>
      <data key="d6" />
    </node>
    <node id="Neural Network Connections">
      <data key="d0">Neural Network Connections</data>
      <data key="d1">concept</data>
      <data key="d2">Neural network connections are the primary subject of study in the discipline of Connectomics.</data>
      <data key="d3">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974896</data>
      <data key="d6" />
    </node>
    <node id="Neural Functional Connectivity Map">
      <data key="d0">Neural Functional Connectivity Map</data>
      <data key="d1">concept</data>
      <data key="d2">The neural functional connectivity map is the neurological foundation for any behavior performed by an organism.</data>
      <data key="d3">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974896</data>
      <data key="d6" />
    </node>
    <node id="2005">
      <data key="d0">2005</data>
      <data key="d1">event</data>
      <data key="d2">The year 2005 is when Olaf Sporns first proposed the concept of Connectomics.</data>
      <data key="d3">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974896</data>
      <data key="d6" />
    </node>
    <node id="Organism">
      <data key="d0">Organism</data>
      <data key="d1">creature</data>
      <data key="d2">An organism is a biological entity whose behaviors are neurologically based on its neural functional connectivity map.</data>
      <data key="d3">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974897</data>
      <data key="d6" />
    </node>
    <node id="神经科学家">
      <data key="d0">神经科学家</data>
      <data key="d1">person</data>
      <data key="d2">神经科学家是追踪大脑区域之间连接的研究人员。</data>
      <data key="d3">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974928</data>
      <data key="d6" />
    </node>
    <node id="大脑区域">
      <data key="d0">大脑区域</data>
      <data key="d1">location</data>
      <data key="d2">大脑区域是大脑中特定的功能分区，神经科学家研究它们之间的连接。</data>
      <data key="d3">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974928</data>
      <data key="d6" />
    </node>
    <node id="生物电讯号">
      <data key="d0">生物电讯号</data>
      <data key="d1">concept</data>
      <data key="d2">生物电讯号是激活大脑细胞的电信号，在神经元之间传递。</data>
      <data key="d3">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974930</data>
      <data key="d6" />
    </node>
    <node id="连接网络">
      <data key="d0">连接网络</data>
      <data key="d1">concept</data>
      <data key="d2">连接网络是神经元被激活时形成的相互连接的结构。</data>
      <data key="d3">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974931</data>
      <data key="d6" />
    </node>
    <node id="神经回路">
      <data key="d0">神经回路</data>
      <data key="d1">concept</data>
      <data key="d2">神经回路是神经元相互连接并通过其传递电讯号的复杂路径。</data>
      <data key="d3">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974931</data>
      <data key="d6" />
    </node>
    <node id="860亿个">
      <data key="d0">860亿个</data>
      <data key="d1">data</data>
      <data key="d2">860亿个是一个具体的数量，描述了人脑中神经元的数量。</data>
      <data key="d3">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974938</data>
      <data key="d6" />
    </node>
    <node id="脑神经连结">
      <data key="d0">脑神经连结</data>
      <data key="d1">concept</data>
      <data key="d2">Brain neural connections are a subject of research discussed in papers.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974971</data>
      <data key="d6" />
    </node>
    <node id="脑网络造影技术">
      <data key="d0">脑网络造影技术</data>
      <data key="d1">method</data>
      <data key="d2">Brain network imaging technology is a method described in a series of papers.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974971</data>
      <data key="d6" />
    </node>
    <node id="临床磁共振仪">
      <data key="d0">临床磁共振仪</data>
      <data key="d1">artifact</data>
      <data key="d2">Clinical MRI scanner is the equipment used to obtain complex diffusion neural images and brain networks in a short time.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974973</data>
      <data key="d6" />
    </node>
    <node id="复杂弥散神经影像">
      <data key="d0">复杂弥散神经影像</data>
      <data key="d1">data</data>
      <data key="d2">Complex diffusion neural images are a type of data obtained using clinical MRI scanners.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974973</data>
      <data key="d6" />
    </node>
    <node id="脑神经网络">
      <data key="d0">脑神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">Brain neural network is a concept related to the imaging and data obtained.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974974</data>
      <data key="d6" />
    </node>
    <node id="树兰俊杰科学Talk第三十五期">
      <data key="d0">树兰俊杰科学Talk第三十五期</data>
      <data key="d1">event</data>
      <data key="d2">Shulan Junjie Science Talk, 35th Session, is the title of the conference with the theme "Brain and Neuroscience-Connections and Emergence at Macro, Meso, and Micro Scales".</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974974</data>
      <data key="d6" />
    </node>
    <node id="脑与神经科学">
      <data key="d0">脑与神经科学</data>
      <data key="d1">concept</data>
      <data key="d2">Brain and neuroscience is the overarching theme of the conference.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974974</data>
      <data key="d6" />
    </node>
    <node id="宏观尺度">
      <data key="d0">宏观尺度</data>
      <data key="d1">concept</data>
      <data key="d2">Macro scale is one of the scales (macro, meso, micro) discussed in the conference theme regarding connections and emergence.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974975</data>
      <data key="d6" />
    </node>
    <node id="介观尺度">
      <data key="d0">介观尺度</data>
      <data key="d1">concept</data>
      <data key="d2">Meso scale is one of the scales (macro, meso, micro) discussed in the conference theme regarding connections and emergence.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974975</data>
      <data key="d6" />
    </node>
    <node id="微观尺度">
      <data key="d0">微观尺度</data>
      <data key="d1">concept</data>
      <data key="d2">Micro scale is one of the scales (macro, meso, micro) discussed in the conference theme regarding connections and emergence.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974975</data>
      <data key="d6" />
    </node>
    <node id="连接">
      <data key="d0">连接</data>
      <data key="d1">concept</data>
      <data key="d2">Connection is a key concept discussed in the conference theme across different scales.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974976</data>
      <data key="d6" />
    </node>
    <node id="涌现">
      <data key="d0">涌现</data>
      <data key="d1">concept</data>
      <data key="d2">Emergence is a key concept discussed in the conference theme across different scales.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974976</data>
      <data key="d6" />
    </node>
    <node id="树兰俊杰科学Talk">
      <data key="d0">树兰俊杰科学Talk</data>
      <data key="d1">event</data>
      <data key="d2">Shulan Junjie Science Talk is the name of the recurring conference series, with the 35th session being the specific event.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974983</data>
      <data key="d6" />
    </node>
    <node id="2022/07/28">
      <data key="d0">2022/07/28</data>
      <data key="d1">event</data>
      <data key="d2">July 28, 2022, is the date on which the conference was scheduled to take place.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974976</data>
      <data key="d6" />
    </node>
    <node id="14:00-17:00">
      <data key="d0">14:00-17:00</data>
      <data key="d1">event</data>
      <data key="d2">14:00 to 17:00 is the scheduled time duration for the conference.</data>
      <data key="d3">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768974976</data>
      <data key="d6" />
    </node>
    <node id="张滔韬">
      <data key="d0">张滔韬</data>
      <data key="d1">person</data>
      <data key="d2">张滔韬is a researcher involved in the study of the mapping relationship between mesoscopic damage and macroscopic stiffness of solid propellants using artificial neural networks.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975009</data>
      <data key="d6" />
    </node>
    <node id="杨玉新">
      <data key="d0">杨玉新</data>
      <data key="d1">person</data>
      <data key="d2">杨玉新is a researcher involved in the study of the mapping relationship between mesoscopic damage and macroscopic stiffness of solid propellants using artificial neural networks.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975009</data>
      <data key="d6" />
    </node>
    <node id="固体推进剂">
      <data key="d0">固体推进剂</data>
      <data key="d1">artifact</data>
      <data key="d2">Solid propellant is the material under study, focusing on its mesoscopic damage and macroscopic stiffness.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975010</data>
      <data key="d6" />
    </node>
    <node id="细观损伤">
      <data key="d0">细观损伤</data>
      <data key="d1">concept</data>
      <data key="d2">Mesoscopic damage refers to the damage at the microstructural level of solid propellants.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975011</data>
      <data key="d6" />
    </node>
    <node id="宏观刚度">
      <data key="d0">宏观刚度</data>
      <data key="d1">concept</data>
      <data key="d2">Macroscopic stiffness refers to the stiffness at the overall material level of solid propellants.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975011</data>
      <data key="d6" />
    </node>
    <node id="映射关系">
      <data key="d0">映射关系</data>
      <data key="d1">concept</data>
      <data key="d2">Mapping relationship describes the connection between mesoscopic damage and macroscopic stiffness in solid propellants.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975011</data>
      <data key="d6" />
    </node>
    <node id="单轴拉伸">
      <data key="d0">单轴拉伸</data>
      <data key="d1">method</data>
      <data key="d2">Uniaxial tension is a deformation condition used to test the predictive capability for macroscopic stiffness.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975011</data>
      <data key="d6" />
    </node>
    <node id="等双轴拉伸">
      <data key="d0">等双轴拉伸</data>
      <data key="d1">method</data>
      <data key="d2">Equibiaxial tension is a deformation condition used to test the predictive capability for macroscopic stiffness.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975012</data>
      <data key="d6" />
    </node>
    <node id="纯剪切">
      <data key="d0">纯剪切</data>
      <data key="d1">method</data>
      <data key="d2">Pure shear is a deformation condition used to test the predictive capability for macroscopic stiffness.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975012</data>
      <data key="d6" />
    </node>
    <node id="宏观刚度预报能力">
      <data key="d0">宏观刚度预报能力</data>
      <data key="d1">concept</data>
      <data key="d2">Macroscopic stiffness predictive capability refers to the ability to forecast stiffness under different deformation conditions.</data>
      <data key="d3">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975012</data>
      <data key="d6" />
    </node>
    <node id="Pathological Analysis">
      <data key="d0">Pathological Analysis</data>
      <data key="d1">concept</data>
      <data key="d2">Pathological analysis is the process of examining tissues and cells for disease diagnosis, which is evolving from qualitative to quantitative methods.&lt;SEP&gt;A diagnostic and prognostic procedure usually performed by pathologists, which can be time-consuming and labor-intensive.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5&lt;SEP&gt;chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975129</data>
      <data key="d6" />
    </node>
    <node id="AI Technology">
      <data key="d0">AI Technology</data>
      <data key="d1">concept</data>
      <data key="d2">AI Technology, especially deep neural networks, has greatly promoted the progress of pathological diagnosis, making it more intellectualized, accurate, and repeatable.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975129</data>
      <data key="d6" />
    </node>
    <node id="Deep Neural Network">
      <data key="d0">Deep Neural Network</data>
      <data key="d1">method</data>
      <data key="d2">Deep Neural Network is a type of AI technology that is a key driver in advancing pathological diagnosis.&lt;SEP&gt;A neural network with many layers, such as the AlexNet proposed by Krizhevsky.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5&lt;SEP&gt;chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975130</data>
      <data key="d6" />
    </node>
    <node id="Pathological Diagnosis">
      <data key="d0">Pathological Diagnosis</data>
      <data key="d1">concept</data>
      <data key="d2">Pathological Diagnosis is the process of identifying diseases from tissue samples, which has been improved by AI technology to be more intellectualized, accurate, and repeatable.&lt;SEP&gt;A medical process performed by pathologists examining pathological slides, which is time-consuming and labor-intensive.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5&lt;SEP&gt;chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975132</data>
      <data key="d6" />
    </node>
    <node id="Digital Pathology">
      <data key="d0">Digital Pathology</data>
      <data key="d1">concept</data>
      <data key="d2">Digital Pathology involves the analysis of digitized pathological images and is a field where deep learning is applied.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975133</data>
      <data key="d6" />
    </node>
    <node id="Cell And Tissue Detection And Segmentation">
      <data key="d0">Cell And Tissue Detection And Segmentation</data>
      <data key="d1">method</data>
      <data key="d2">Cell and Tissue Detection and Segmentation is an application of deep learning in digital pathology for identifying and outlining biological structures.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975133</data>
      <data key="d6" />
    </node>
    <node id="Cancer Classification And Grading">
      <data key="d0">Cancer Classification And Grading</data>
      <data key="d1">method</data>
      <data key="d2">Cancer Classification and Grading is an application of deep learning in digital pathology for categorizing and assessing the severity of cancers.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975134</data>
      <data key="d6" />
    </node>
    <node id="Quantitative Analysis">
      <data key="d0">Quantitative Analysis</data>
      <data key="d1">method</data>
      <data key="d2">Quantitative Analysis is a method in pathological analysis that involves numerical measurement, representing a progression from qualitative analysis.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975134</data>
      <data key="d6" />
    </node>
    <node id="Pathological Slice">
      <data key="d0">Pathological Slice</data>
      <data key="d1">artifact</data>
      <data key="d2">A pathological slice is the gold standard for pathological diagnosis and is widely used in clinical and scientific research.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975134</data>
      <data key="d6" />
    </node>
    <node id="Pathologist">
      <data key="d0">Pathologist</data>
      <data key="d1">person</data>
      <data key="d2">A professional who performs pathological analysis and prognosis.&lt;SEP&gt;A pathologist is a doctor who performs pathological diagnosis by examining pathological slices.&lt;SEP&gt;A medical professional who performs diagnosis and prognostic assessment by examining pathological slides.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5&lt;SEP&gt;chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975135</data>
      <data key="d6" />
    </node>
    <node id="Digital Pathology Analysis">
      <data key="d0">Digital Pathology Analysis</data>
      <data key="d1">concept</data>
      <data key="d2">Digital Pathology Analysis refers to the analysis of digital pathology, which is the subject of this paper's overview regarding deep learning applications.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975135</data>
      <data key="d6" />
    </node>
    <node id="This Paper">
      <data key="d0">This Paper</data>
      <data key="d1">content</data>
      <data key="d2">This paper describes the basic concept of deep learning and its application in digital pathology analysis, providing an overview and discussing future prospects.</data>
      <data key="d3">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975135</data>
      <data key="d6" />
    </node>
    <node id="闫雯">
      <data key="d0">闫雯</data>
      <data key="d1">person</data>
      <data key="d2">闫雯是文章的作者之一，文章标题为“深度学习在数字病理中的应用”。&lt;SEP&gt;作者之一，来自北京航空航天大学生物与医学工程系。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975136</data>
      <data key="d6" />
    </node>
    <node id="汤烨">
      <data key="d0">汤烨</data>
      <data key="d1">person</data>
      <data key="d2">作者之一，来自北京航空航天大学生物与医学工程系。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975136</data>
      <data key="d6" />
    </node>
    <node id="张益肇">
      <data key="d0">张益肇</data>
      <data key="d1">person</data>
      <data key="d2">作者之一，来自微软亚洲研究院。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975144</data>
      <data key="d6" />
    </node>
    <node id="来茂德">
      <data key="d0">来茂德</data>
      <data key="d1">person</data>
      <data key="d2">作者之一，来自浙江大学医学院基础医学院。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975136</data>
      <data key="d6" />
    </node>
    <node id="许燕">
      <data key="d0">许燕</data>
      <data key="d1">person</data>
      <data key="d2">通信作者，来自北京航空航天大学生物与医学工程系和软件开发环境国家重点实验室。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975136</data>
      <data key="d6" />
    </node>
    <node id="北京航空航天大学">
      <data key="d0">北京航空航天大学</data>
      <data key="d1">organization</data>
      <data key="d2">一所大学，其生物与医学工程系、软件开发环境国家重点实验室和深圳北航新兴产业技术研究院参与了本研究。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975137</data>
      <data key="d6" />
    </node>
    <node id="生物医学工程高精尖创新中心">
      <data key="d0">生物医学工程高精尖创新中心</data>
      <data key="d1">organization</data>
      <data key="d2">一个研究中心，与北京航空航天大学相关。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975137</data>
      <data key="d6" />
    </node>
    <node id="微软亚洲研究院">
      <data key="d0">微软亚洲研究院</data>
      <data key="d1">organization</data>
      <data key="d2">一个研究机构，作者张益肇所属单位。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975137</data>
      <data key="d6" />
    </node>
    <node id="浙江大学医学院">
      <data key="d0">浙江大学医学院</data>
      <data key="d1">organization</data>
      <data key="d2">一所医学院，作者来茂德所属单位。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975137</data>
      <data key="d6" />
    </node>
    <node id="国家自然科学基金">
      <data key="d0">国家自然科学基金</data>
      <data key="d1">organization</data>
      <data key="d2">一个资助机构，为本研究提供了资金支持(项目号81771910)。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975137</data>
      <data key="d6" />
    </node>
    <node id="深圳科创委">
      <data key="d0">深圳科创委</data>
      <data key="d1">organization</data>
      <data key="d2">一个地方科技委员会，为本研究提供了技术攻关项目资金(项目号shenfagai2016627)。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975138</data>
      <data key="d6" />
    </node>
    <node id="北京市自然科学基金">
      <data key="d0">北京市自然科学基金</data>
      <data key="d1">organization</data>
      <data key="d2">一个地方资助机构，为本研究提供了资金支持(项目号4152033)。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975138</data>
      <data key="d6" />
    </node>
    <node id="国家科学技术重大专项">
      <data key="d0">国家科学技术重大专项</data>
      <data key="d1">organization</data>
      <data key="d2">一个国家级的重大科技项目，为本研究提供了资金支持(项目号2017yfc0110903)。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975138</data>
      <data key="d6" />
    </node>
    <node id="软件开发环境国家重点实验室">
      <data key="d0">软件开发环境国家重点实验室</data>
      <data key="d1">organization</data>
      <data key="d2">一个位于北京航空航天大学的国家重点实验室，为本研究提供了中央高校基础研究基金(项目号sklsde-2017zx-08)。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975139</data>
      <data key="d6" />
    </node>
    <node id="111项目">
      <data key="d0">111项目</data>
      <data key="d1">organization</data>
      <data key="d2">一个中国的人才引进和培养项目，为本研究提供了资金支持(项目号b13003)。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975139</data>
      <data key="d6" />
    </node>
    <node id="数字病理">
      <data key="d0">数字病理</data>
      <data key="d1">concept</data>
      <data key="d2">数字病理是病理学的一个分支，涉及将病理切片数字化，以方便保存、传输和分析，被认为是病理学发展的重要转折点。&lt;SEP&gt;一个医学领域，涉及病理切片的数字化和分析。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975139</data>
      <data key="d6" />
    </node>
    <node id="病理切片">
      <data key="d0">病理切片</data>
      <data key="d1">artifact</data>
      <data key="d2">病理切片是病理诊断的金标准，通过组织染色和显微相机数字化后形成数字病理切片，用于临床诊断和科研。&lt;SEP&gt;用于癌症诊断的临床样本，是诊断的金标准。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975140</data>
      <data key="d6" />
    </node>
    <node id="人工智能">
      <data key="d0">人工智能</data>
      <data key="d1">concept</data>
      <data key="d2">一个技术领域，包括深度学习，用于推动病理分析从定性向定量转变。&lt;SEP&gt;人工智能是交叉熵损失函数应用的一个主要领域。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975614</data>
      <data key="d6" />
    </node>
    <node id="定量分析">
      <data key="d0">定量分析</data>
      <data key="d1">method</data>
      <data key="d2">定量分析是指依据统计数据建立数学模型，计算与病变相关的各项量化指标(如有丝分裂数目)，以提供更客观的诊断结果。&lt;SEP&gt;一种分析方法，在数字病理中使诊断更加准确和客观。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975141</data>
      <data key="d6" />
    </node>
    <node id="癌症诊断">
      <data key="d0">癌症诊断</data>
      <data key="d1">concept</data>
      <data key="d2">一个医学过程，病理切片是其金标准。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975149</data>
      <data key="d6" />
    </node>
    <node id="细胞检测">
      <data key="d0">细胞检测</data>
      <data key="d1">method</data>
      <data key="d2">深度学习在数字病理中的一个应用，用于识别细胞。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975141</data>
      <data key="d6" />
    </node>
    <node id="组织分割">
      <data key="d0">组织分割</data>
      <data key="d1">method</data>
      <data key="d2">深度学习在数字病理中的一个应用，用于分割组织区域。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975141</data>
      <data key="d6" />
    </node>
    <node id="癌症分类">
      <data key="d0">癌症分类</data>
      <data key="d1">method</data>
      <data key="d2">深度学习在数字病理中的一个应用，在组织层面上对癌症进行分类。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975142</data>
      <data key="d6" />
    </node>
    <node id="癌症分级">
      <data key="d0">癌症分级</data>
      <data key="d1">method</data>
      <data key="d2">深度学习在数字病理中的一个应用，在组织层面上对癌症进行分级。</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975142</data>
      <data key="d6" />
    </node>
    <node id="中国生物医学工程学报">
      <data key="d0">中国生物医学工程学报</data>
      <data key="d1">organization</data>
      <data key="d2">A Chinese academic journal where the article "Deep Learning in Digital Pathology" was published in Volume 37, Issue 1, February 2018.</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975142</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning in Digital Pathology">
      <data key="d0">Deep Learning in Digital Pathology</data>
      <data key="d1">content</data>
      <data key="d2">The title of the academic article or review paper that discusses the application of deep learning in digital pathology analysis.</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975143</data>
      <data key="d6" />
    </node>
    <node id="Prognostic Assessment">
      <data key="d0">Prognostic Assessment</data>
      <data key="d1">concept</data>
      <data key="d2">An evaluation of the likely course and outcome of a disease, part of the pathologist's work based on slide examination.</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975143</data>
      <data key="d6" />
    </node>
    <node id="Qualitative Analysis">
      <data key="d0">Qualitative Analysis</data>
      <data key="d1">method</data>
      <data key="d2">The traditional form of pathological analysis, which is being transformed towards quantitative analysis with AI.</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975143</data>
      <data key="d6" />
    </node>
    <node id="全片数字化图像">
      <data key="d0">全片数字化图像</data>
      <data key="d1">data</data>
      <data key="d2">全片数字化图像(WSI)是一种数字病理切片技术，于1999年出现，使病理切片的保存和传输更加方便安全。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975145</data>
      <data key="d6" />
    </node>
    <node id="定性分析">
      <data key="d0">定性分析</data>
      <data key="d1">method</data>
      <data key="d2">定性分析是对切片性质特点的概括，没有形成量化指标，其结果不可复现且受主观因素影响较大。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975145</data>
      <data key="d6" />
    </node>
    <node id="传统机器学习算法">
      <data key="d0">传统机器学习算法</data>
      <data key="d1">method</data>
      <data key="d2">传统机器学习算法依赖于人工设计特征表达(如形状、纹理)，需要专业知识且难以涵盖图像的全面特征。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975146</data>
      <data key="d6" />
    </node>
    <node id="卷积神经网络">
      <data key="d0">卷积神经网络</data>
      <data key="d1">method</data>
      <data key="d2">卷积神经网络是深度学习常用的网络结构，由卷积层、池化层和ReLU函数等构成，用于图像处理与计算机视觉。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975146</data>
      <data key="d6" />
    </node>
    <node id="病理医生">
      <data key="d0">病理医生</data>
      <data key="d1">person</data>
      <data key="d2">病理医生通过对病理切片进行镜检来完成病理诊断和预后评估，但传统过程费时费力，现逐渐借助定量分析。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975146</data>
      <data key="d6" />
    </node>
    <node id="人工智能技术">
      <data key="d0">人工智能技术</data>
      <data key="d1">concept</data>
      <data key="d2">人工智能技术走进病理分析领域，推动病理分析从传统的定性分析向定量分析过渡。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975147</data>
      <data key="d6" />
    </node>
    <node id="卷积">
      <data key="d0">卷积</data>
      <data key="d1">method</data>
      <data key="d2">卷积是深度学习中的一种技术，用于从数据中提取特征。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975147</data>
      <data key="d6" />
    </node>
    <node id="池化">
      <data key="d0">池化</data>
      <data key="d1">method</data>
      <data key="d2">池化是深度学习中的一种技术，用于降低数据的维度。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975147</data>
      <data key="d6" />
    </node>
    <node id="Dropout">
      <data key="d0">Dropout</data>
      <data key="d1">method</data>
      <data key="d2">Dropout是深度学习中的一种技术，用于防止模型过拟合。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975148</data>
      <data key="d6" />
    </node>
    <node id="ReLU函数">
      <data key="d0">ReLU函数</data>
      <data key="d1">method</data>
      <data key="d2">ReLU函数是深度学习中的一种激活函数，用于引入非线性。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975148</data>
      <data key="d6" />
    </node>
    <node id="GPU">
      <data key="d0">GPU</data>
      <data key="d1">artifact</data>
      <data key="d2">GPU是用于训练深度学习网络的硬件设备。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975148</data>
      <data key="d6" />
    </node>
    <node id="有丝分裂数目">
      <data key="d0">有丝分裂数目</data>
      <data key="d1">data</data>
      <data key="d2">有丝分裂数目是病理定量分析中的一个量化指标，用于评估病变。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975148</data>
      <data key="d6" />
    </node>
    <node id="肿瘤的实质与间质的比例">
      <data key="d0">肿瘤的实质与间质的比例</data>
      <data key="d1">data</data>
      <data key="d2">肿瘤的实质与间质的比例是病理定量分析中的一个量化指标。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975149</data>
      <data key="d6" />
    </node>
    <node id="黏液湖和癌细胞的比例">
      <data key="d0">黏液湖和癌细胞的比例</data>
      <data key="d1">data</data>
      <data key="d2">黏液湖和癌细胞的比例是病理定量分析中的一个量化指标。</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975149</data>
      <data key="d6" />
    </node>
    <node id="Krizhevsky">
      <data key="d0">Krizhevsky</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who proposed the deep convolutional network AlexNet in 2012.&lt;SEP&gt;The person who proposed the AlexNet deep convolutional network in 2012.</data>
      <data key="d3">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db&lt;SEP&gt;chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975149</data>
      <data key="d6" />
    </node>
    <node id="AlexNet">
      <data key="d0">AlexNet</data>
      <data key="d1">artifact</data>
      <data key="d2">A deep convolutional network proposed by Krizhevsky in 2012, which achieved image classification on the ImageNet dataset and reduced the error rate to 17.0%.&lt;SEP&gt;A deep convolutional network proposed by Krizhevsky in 2012 that achieved significant results on the ImageNet dataset.</data>
      <data key="d3">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db&lt;SEP&gt;chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975150</data>
      <data key="d6" />
    </node>
    <node id="ImageNet">
      <data key="d0">ImageNet</data>
      <data key="d1">dataset</data>
      <data key="d2">A dataset used for image classification tasks, on which AlexNet achieved a 17.0% error rate.&lt;SEP&gt;A large-scale dataset used for tasks like image classification.</data>
      <data key="d3">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db&lt;SEP&gt;chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975150</data>
      <data key="d6" />
    </node>
    <node id="最大池化层">
      <data key="d0">最大池化层</data>
      <data key="d1">method</data>
      <data key="d2">A pooling layer in neural networks that uses a window (e.g., 2x2) to take the maximum value from the feature map within that window to compose the feature map for the next layer.</data>
      <data key="d3">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975151</data>
      <data key="d6" />
    </node>
    <node id="Zisserman">
      <data key="d0">Zisserman</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who proposed a new deep convolutional network architecture based on AlexNet.</data>
      <data key="d3">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975151</data>
      <data key="d6" />
    </node>
    <node id="图2">
      <data key="d0">图2</data>
      <data key="d1">artifact</data>
      <data key="d2">A figure illustrating the structure or operation of the max-pooling layer with a sample window size of 2x2.&lt;SEP&gt;图2展示了水分子的结构及其微观堆积结构。</data>
      <data key="d3">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db&lt;SEP&gt;chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975212</data>
      <data key="d6" />
    </node>
    <node id="State Key Laboratory Of Software Development Environment">
      <data key="d0">State Key Laboratory Of Software Development Environment</data>
      <data key="d1">organization</data>
      <data key="d2">A state key laboratory located at Beihang University, focusing on software development environment research.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975159</data>
      <data key="d6" />
    </node>
    <node id="Key Laboratory Of Biomechanics And Mechanobiology">
      <data key="d0">Key Laboratory Of Biomechanics And Mechanobiology</data>
      <data key="d1">organization</data>
      <data key="d2">A key laboratory under the Ministry of Education, focusing on biomechanics and mechanobiology research.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975151</data>
      <data key="d6" />
    </node>
    <node id="Beihang University">
      <data key="d0">Beihang University</data>
      <data key="d1">organization</data>
      <data key="d2">A university with a research institute in Shenzhen and affiliations with several laboratories.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975151</data>
      <data key="d6" />
    </node>
    <node id="Beijing Advanced Innovation Center For Biomedical Engineering">
      <data key="d0">Beijing Advanced Innovation Center For Biomedical Engineering</data>
      <data key="d1">organization</data>
      <data key="d2">An innovation center in Beijing focused on biomedical engineering.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975152</data>
      <data key="d6" />
    </node>
    <node id="Microsoft Research">
      <data key="d0">Microsoft Research</data>
      <data key="d1">organization</data>
      <data key="d2">A research division of Microsoft located in Beijing, China.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975152</data>
      <data key="d6" />
    </node>
    <node id="Department Of Pathology, School Of Medicine, Zhejiang University">
      <data key="d0">Department Of Pathology, School Of Medicine, Zhejiang University</data>
      <data key="d1">organization</data>
      <data key="d2">An academic department within Zhejiang University's School of Medicine, located in Hangzhou, China.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975152</data>
      <data key="d6" />
    </node>
    <node id="Pathology">
      <data key="d0">Pathology</data>
      <data key="d1">concept</data>
      <data key="d2">Regarded as the gold standard for cancer diagnosis in clinical settings.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975152</data>
      <data key="d6" />
    </node>
    <node id="Cancer">
      <data key="d0">Cancer</data>
      <data key="d1">concept</data>
      <data key="d2">A disease for which pathology is the primary diagnostic standard.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975153</data>
      <data key="d6" />
    </node>
    <node id="Whole Slide Pathology">
      <data key="d0">Whole Slide Pathology</data>
      <data key="d1">method</data>
      <data key="d2">A developing field in pathology that involves the analysis of whole slide images.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975153</data>
      <data key="d6" />
    </node>
    <node id="Artificial Intelligence">
      <data key="d0">Artificial Intelligence</data>
      <data key="d1">concept</data>
      <data key="d2">A technology that may promote pathological analysis, potentially shifting it from qualitative analysis.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084&lt;SEP&gt;chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975153</data>
      <data key="d6" />
    </node>
    <node id="Ministry Of Education">
      <data key="d0">Ministry Of Education</data>
      <data key="d1">organization</data>
      <data key="d2">A government ministry overseeing education and research in China, affiliated with the Key Laboratory of Biomechanics and Mechanobiology.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975153</data>
      <data key="d6" />
    </node>
    <node id="Shenzhen">
      <data key="d0">Shenzhen</data>
      <data key="d1">location</data>
      <data key="d2">A city in China where Beihang University has a research institute.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975154</data>
      <data key="d6" />
    </node>
    <node id="Beijing">
      <data key="d0">Beijing</data>
      <data key="d1">location</data>
      <data key="d2">A city in China hosting the Beijing Advanced Innovation Center for Biomedical Engineering and Microsoft Research.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975154</data>
      <data key="d6" />
    </node>
    <node id="Hangzhou">
      <data key="d0">Hangzhou</data>
      <data key="d1">location</data>
      <data key="d2">A city in China where the Department of Pathology, School of Medicine, Zhejiang University is located.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975154</data>
      <data key="d6" />
    </node>
    <node id="Prognosis">
      <data key="d0">Prognosis</data>
      <data key="d1">concept</data>
      <data key="d2">A part of the pathological process, performed by pathologists, which can be time-consuming and labor-intensive.</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975154</data>
      <data key="d6" />
    </node>
    <node id="Convolutional Neural Network">
      <data key="d0">Convolutional Neural Network</data>
      <data key="d1">concept</data>
      <data key="d2">A type of neural network that uses convolutional layers, pooling layers, and fully connected layers, designed to process image data directly and is invariant to translation, scaling, and other deformations.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975155</data>
      <data key="d6" />
    </node>
    <node id="Convolutional Layer">
      <data key="d0">Convolutional Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A layer in a CNN that applies convolution operations using shared weights and local receptive fields to learn feature maps.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975155</data>
      <data key="d6" />
    </node>
    <node id="Pooling Layer">
      <data key="d0">Pooling Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A layer in a CNN that performs down-sampling (e.g., max-pooling, average-pooling) on feature maps to reduce parameters and prevent overfitting.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975156</data>
      <data key="d6" />
    </node>
    <node id="Fully Connected Layer">
      <data key="d0">Fully Connected Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A layer in a neural network where each neuron is connected to every neuron in the previous layer.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975156</data>
      <data key="d6" />
    </node>
    <node id="Weight Sharing">
      <data key="d0">Weight Sharing</data>
      <data key="d1">concept</data>
      <data key="d2">A concept in CNNs where hidden neurons share the same weights and biases when connected to their local receptive fields, reducing the number of parameters.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975156</data>
      <data key="d6" />
    </node>
    <node id="Local Receptive Field">
      <data key="d0">Local Receptive Field</data>
      <data key="d1">concept</data>
      <data key="d2">The specific region of the input that a hidden neuron in a convolutional layer is connected to.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975156</data>
      <data key="d6" />
    </node>
    <node id="Activation Function">
      <data key="d0">Activation Function</data>
      <data key="d1">concept</data>
      <data key="d2">A function (e.g., ReLU) applied to a neuron's output to introduce non-linearity into the network.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975156</data>
      <data key="d6" />
    </node>
    <node id="ReLU Function">
      <data key="d0">ReLU Function</data>
      <data key="d1">concept</data>
      <data key="d2">A common activation function defined as f(x)=max(0,x), known for alleviating the vanishing gradient problem and speeding up computation.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975156</data>
      <data key="d6" />
    </node>
    <node id="Cost Function">
      <data key="d0">Cost Function</data>
      <data key="d1">concept</data>
      <data key="d2">A function (e.g., mean squared error) that quantifies the difference between the network's output and the desired output, used to guide training.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975157</data>
      <data key="d6" />
    </node>
    <node id="Backpropagation Algorithm">
      <data key="d0">Backpropagation Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">An algorithm proposed by Rumelhart in 1986 for efficiently computing gradients to minimize the cost function during neural network training.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975157</data>
      <data key="d6" />
    </node>
    <node id="Max-Pooling">
      <data key="d0">Max-Pooling</data>
      <data key="d1">method</data>
      <data key="d2">A type of pooling operation that extracts the maximum value from a window of a feature map.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975159</data>
      <data key="d6" />
    </node>
    <node id="Average-Pooling">
      <data key="d0">Average-Pooling</data>
      <data key="d1">method</data>
      <data key="d2">A type of pooling operation that computes the average value from a window of a feature map.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975159</data>
      <data key="d6" />
    </node>
    <node id="Rumelhart">
      <data key="d0">Rumelhart</data>
      <data key="d1">person</data>
      <data key="d2">The person who proposed the backpropagation algorithm in 1986.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975160</data>
      <data key="d6" />
    </node>
    <node id="Traditional Recognition Algorithm">
      <data key="d0">Traditional Recognition Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">Traditional recognition algorithms that require complex manual feature design, which CNNs avoid.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975160</data>
      <data key="d6" />
    </node>
    <node id="Feature Map">
      <data key="d0">Feature Map</data>
      <data key="d1">concept</data>
      <data key="d2">A learned representation of input data, such as an image, produced by a hidden neuron in a convolutional layer.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975161</data>
      <data key="d6" />
    </node>
    <node id="Vanishing Gradient Problem">
      <data key="d0">Vanishing Gradient Problem</data>
      <data key="d1">concept</data>
      <data key="d2">A problem in training deep neural networks where gradients become extremely small, which the ReLU function helps alleviate.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975161</data>
      <data key="d6" />
    </node>
    <node id="Overfitting">
      <data key="d0">Overfitting</data>
      <data key="d1">concept</data>
      <data key="d2">A modeling error where a model learns the detail and noise in the training data to the extent that it negatively impacts performance on new data.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975161</data>
      <data key="d6" />
    </node>
    <node id="Image Classification">
      <data key="d0">Image Classification</data>
      <data key="d1">concept</data>
      <data key="d2">A computer vision task where an image is assigned a label from a fixed set of categories.</data>
      <data key="d3">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975161</data>
      <data key="d6" />
    </node>
    <node id="深度学习在数字病理中的应用">
      <data key="d0">深度学习在数字病理中的应用</data>
      <data key="d3">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d2">国家自然科学基金(项目号81771910)为这项关于深度学习在数字病理中应用的研究提供了资金支持。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975167</data>
      <data key="d6" />
    </node>
    <node id="病理分析">
      <data key="d0">病理分析</data>
      <data key="d3">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d2">人工智能技术进入病理分析领域，推动了该领域从定性分析向定量分析的过渡和发展。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975175</data>
      <data key="d6" />
    </node>
    <node id="Research Institute Of Beihang University">
      <data key="d0">Research Institute Of Beihang University</data>
      <data key="d3">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d2">The Research Institute of Beihang University is located in Shenzhen.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975181</data>
      <data key="d6" />
    </node>
    <node id="水分子">
      <data key="d0">水分子</data>
      <data key="d1">naturalobject</data>
      <data key="d2">水分子是由两个氢原子和一个氧原子组成的H2O分子，其化学键夹角约为105度。</data>
      <data key="d3">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975209</data>
      <data key="d6" />
    </node>
    <node id="氢">
      <data key="d0">氢</data>
      <data key="d1">naturalobject</data>
      <data key="d2">氢是水分子中的组成元素之一，化学符号为H。</data>
      <data key="d3">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975209</data>
      <data key="d6" />
    </node>
    <node id="氧">
      <data key="d0">氧</data>
      <data key="d1">naturalobject</data>
      <data key="d2">氧是水分子中的组成元素之一，化学符号为O。</data>
      <data key="d3">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975210</data>
      <data key="d6" />
    </node>
    <node id="微观堆积结构">
      <data key="d0">微观堆积结构</data>
      <data key="d1">concept</data>
      <data key="d2">水的微观堆积结构是水分子在空间中的排列方式，决定了水的特殊物理化学性质。</data>
      <data key="d3">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975211</data>
      <data key="d6" />
    </node>
    <node id="物理化学性质">
      <data key="d0">物理化学性质</data>
      <data key="d1">concept</data>
      <data key="d2">水的物理化学性质，如密度、比热容等，源于其独特的微观结构。</data>
      <data key="d3">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975211</data>
      <data key="d6" />
    </node>
    <node id="H2O">
      <data key="d0">H2O</data>
      <data key="d1">concept</data>
      <data key="d2">H2O是水分子的化学式，表示其由两个氢原子和一个氧原子组成。</data>
      <data key="d3">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975212</data>
      <data key="d6" />
    </node>
    <node id="Allen Mouse Brain Common Coordinate Framework">
      <data key="d0">Allen Mouse Brain Common Coordinate Framework</data>
      <data key="d1">artifact</data>
      <data key="d2">A 3D reference atlas for the mouse brain, described in a 2020 Cell paper by Wang Q X et al.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975272</data>
      <data key="d6" />
    </node>
    <node id="Wang Q X">
      <data key="d0">Wang Q X</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on the Allen Mouse Brain Common Coordinate Framework.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975272</data>
      <data key="d6" />
    </node>
    <node id="Ding S L">
      <data key="d0">Ding S L</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on the Allen Mouse Brain Common Coordinate Framework.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975273</data>
      <data key="d6" />
    </node>
    <node id="Li Y">
      <data key="d0">Li Y</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on the Allen Mouse Brain Common Coordinate Framework.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975274</data>
      <data key="d6" />
    </node>
    <node id="Cell">
      <data key="d0">Cell</data>
      <data key="d1">content</data>
      <data key="d2">The scientific journal where the paper on the Allen Mouse Brain Common Coordinate Framework was published.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975274</data>
      <data key="d6" />
    </node>
    <node id="The Logic Of Single-Cell Projections From Visual Cortex">
      <data key="d0">The Logic Of Single-Cell Projections From Visual Cortex</data>
      <data key="d1">content</data>
      <data key="d2">A research paper published in Nature in 2018 by Han Y Y et al.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975274</data>
      <data key="d6" />
    </node>
    <node id="Han Y Y">
      <data key="d0">Han Y Y</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on the logic of single-cell projections from visual cortex.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975274</data>
      <data key="d6" />
    </node>
    <node id="Kebschull J M">
      <data key="d0">Kebschull J M</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on the logic of single-cell projections from visual cortex.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975275</data>
      <data key="d6" />
    </node>
    <node id="Campbell R A A">
      <data key="d0">Campbell R A A</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on the logic of single-cell projections from visual cortex.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975275</data>
      <data key="d6" />
    </node>
    <node id="Nature">
      <data key="d0">Nature</data>
      <data key="d1">content</data>
      <data key="d2">The scientific journal where the paper on single-cell projections and the paper on brain-to-text communication were published.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975275</data>
      <data key="d6" />
    </node>
    <node id="Hippocampal Contribution To Ordinal Psychological Time In The Human Brain">
      <data key="d0">Hippocampal Contribution To Ordinal Psychological Time In The Human Brain</data>
      <data key="d1">content</data>
      <data key="d2">A research paper published in the Journal of Cognitive Neuroscience in 2020 by Gauthier B et al.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975275</data>
      <data key="d6" />
    </node>
    <node id="Gauthier B">
      <data key="d0">Gauthier B</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on hippocampal contribution to ordinal psychological time.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975276</data>
      <data key="d6" />
    </node>
    <node id="Prabhu P">
      <data key="d0">Prabhu P</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on hippocampal contribution to ordinal psychological time.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975276</data>
      <data key="d6" />
    </node>
    <node id="Kotegar K A">
      <data key="d0">Kotegar K A</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on hippocampal contribution to ordinal psychological time.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975276</data>
      <data key="d6" />
    </node>
    <node id="Journal Of Cognitive Neuroscience">
      <data key="d0">Journal Of Cognitive Neuroscience</data>
      <data key="d1">content</data>
      <data key="d2">The scientific journal where the paper on hippocampal contribution to ordinal psychological time was published.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975276</data>
      <data key="d6" />
    </node>
    <node id="High-Performance Brain-To-Text Communication Via Handwriting">
      <data key="d0">High-Performance Brain-To-Text Communication Via Handwriting</data>
      <data key="d1">content</data>
      <data key="d2">A research paper published in Nature in 2021 by Willett F R et al.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975284</data>
      <data key="d6" />
    </node>
    <node id="Willett F R">
      <data key="d0">Willett F R</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on high-performance brain-to-text communication via handwriting.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975284</data>
      <data key="d6" />
    </node>
    <node id="Avansino D T">
      <data key="d0">Avansino D T</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on high-performance brain-to-text communication via handwriting.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975277</data>
      <data key="d6" />
    </node>
    <node id="Hochberg L R">
      <data key="d0">Hochberg L R</data>
      <data key="d1">person</data>
      <data key="d2">An author of the paper on high-performance brain-to-text communication via handwriting.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975277</data>
      <data key="d6" />
    </node>
    <node id="Statistical Mechanics">
      <data key="d0">Statistical Mechanics</data>
      <data key="d1">concept</data>
      <data key="d2">The domain or field of study mentioned in the document metadata.&lt;SEP&gt;Statistical Mechanics is the domain or field of study mentioned in the document metadata.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c&lt;SEP&gt;chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975511</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-2017a15e">
      <data key="d0">DOC_ID: chunk-2017a15e</data>
      <data key="d1">data</data>
      <data key="d2">The unique identifier for the document chunk being processed.</data>
      <data key="d3">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975277</data>
      <data key="d6" />
    </node>
    <node id="网络">
      <data key="d0">网络</data>
      <data key="d1">concept</data>
      <data key="d2">The network's output layer partition function is discussed in relation to the input data.&lt;SEP&gt;A network is a structure composed of nodes and edges, used here as a model in statistical mechanics.</data>
      <data key="d3">chunk-bc6cd88a44423ac7bc4a08969a8b99f8&lt;SEP&gt;chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975334</data>
      <data key="d6" />
    </node>
    <node id="输出层配分函数">
      <data key="d0">输出层配分函数</data>
      <data key="d1">concept</data>
      <data key="d2">The output layer partition function of the network is stated to be equal to the partition function of the input data.</data>
      <data key="d3">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975306</data>
      <data key="d6" />
    </node>
    <node id="输入数据">
      <data key="d0">输入数据</data>
      <data key="d1">data</data>
      <data key="d2">The input data is described as a one-dimensional Ising model.&lt;SEP&gt;The actual data fed into a neural network model for training or prediction.</data>
      <data key="d3">chunk-bc6cd88a44423ac7bc4a08969a8b99f8&lt;SEP&gt;chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975573</data>
      <data key="d6" />
    </node>
    <node id="一维伊辛模型">
      <data key="d0">一维伊辛模型</data>
      <data key="d1">concept</data>
      <data key="d2">A one-dimensional Ising model is the specific type of input data mentioned.</data>
      <data key="d3">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975309</data>
      <data key="d6" />
    </node>
    <node id="配分函数">
      <data key="d0">配分函数</data>
      <data key="d1">concept</data>
      <data key="d2">The partition function is a central concept, noted to remain constant during the training process from time t=0 to t=∞.&lt;SEP&gt;The partition function is a fundamental quantity in statistical mechanics that sums over all possible states of a system; here, it quantifies the amount of information retained on all original nodes of a network.&lt;SEP&gt;配分函数是统计力学中的一个核心概念，用于计算系统的热力学性质。&lt;SEP&gt;分数函数的一种，通常用于描述系统的统计分布。&lt;SEP&gt;一个依赖于模型参数的函数，在计算无向模型的概率时起到归一化作用。&lt;SEP&gt;A function in statistical mechanics that sums over all possible states of a system, used to calculate thermodynamic properties.</data>
      <data key="d3">chunk-bc6cd88a44423ac7bc4a08969a8b99f8&lt;SEP&gt;chunk-7d7618b6fffb013ab6c5a2ca3a3fea50&lt;SEP&gt;chunk-36562522576eae8192339d548d0a1406&lt;SEP&gt;chunk-08c978d767db01aaeef63f40ea958f51&lt;SEP&gt;chunk-f5c5908d5644515cf8bcda82498e6671&lt;SEP&gt;chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975451</data>
      <data key="d6" />
    </node>
    <node id="训练过程">
      <data key="d0">训练过程</data>
      <data key="d1">method</data>
      <data key="d2">The training process is described, during which the partition function's value remains unchanged as time t varies from 0 to ∞.</data>
      <data key="d3">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975310</data>
      <data key="d6" />
    </node>
    <node id="f(x1w. (t). 1j. +x2w. (t).">
      <data key="d0">f(x1w. (t). 1j. +x2w. (t).</data>
      <data key="d1">data</data>
      <data key="d2">A mathematical expression representing a function or parameter in the training process.</data>
      <data key="d3">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975310</data>
      <data key="d6" />
    </node>
    <node id="特征值">
      <data key="d0">特征值</data>
      <data key="d1">concept</data>
      <data key="d2">An eigenvalue is a special scalar associated with a linear transformation; here, it refers to the eigenvalues of a matrix L related to the network.</data>
      <data key="d3">chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975335</data>
      <data key="d6" />
    </node>
    <node id="空手道俱乐部网络">
      <data key="d0">空手道俱乐部网络</data>
      <data key="d1">artifact</data>
      <data key="d2">The Karate Club network is a classic social network dataset used in network science to study community structure.</data>
      <data key="d3">chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975336</data>
      <data key="d6" />
    </node>
    <node id="L">
      <data key="d0">L</data>
      <data key="d1">concept</data>
      <data key="d2">L is a matrix associated with the network, whose eigenvalues are used in the calculation of the partition function.</data>
      <data key="d3">chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975336</data>
      <data key="d6" />
    </node>
    <node id="Batchsize">
      <data key="d0">Batchsize</data>
      <data key="d1">concept</data>
      <data key="d2">Batchsize是神经网络训练中的一个参数，降低它可以节省显存。</data>
      <data key="d3">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975356</data>
      <data key="d6" />
    </node>
    <node id="显存">
      <data key="d0">显存</data>
      <data key="d1">concept</data>
      <data key="d2">显存是计算机显卡的内存，降低Batchsize可以节省大量显存。</data>
      <data key="d3">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975358</data>
      <data key="d6" />
    </node>
    <node id="计算开销">
      <data key="d0">计算开销</data>
      <data key="d1">concept</data>
      <data key="d2">计算开销指的是执行计算任务所需的资源成本。</data>
      <data key="d3">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975358</data>
      <data key="d6" />
    </node>
    <node id="通信">
      <data key="d0">通信</data>
      <data key="d1">concept</data>
      <data key="d2">通信指的是数据传输过程，其成本往往比计算更高。</data>
      <data key="d3">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975359</data>
      <data key="d6" />
    </node>
    <node id="存储">
      <data key="d0">存储</data>
      <data key="d1">concept</data>
      <data key="d2">存储指的是数据保存，其成本往往比计算更高。</data>
      <data key="d3">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975359</data>
      <data key="d6" />
    </node>
    <node id="基于分数的生成模型">
      <data key="d0">基于分数的生成模型</data>
      <data key="d1">concept</data>
      <data key="d2">一种通过定义分数函数来描述数据分布的生成模型。</data>
      <data key="d3">chunk-08c978d767db01aaeef63f40ea958f51</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975370</data>
      <data key="d6" />
    </node>
    <node id="分数函数">
      <data key="d0">分数函数</data>
      <data key="d1">concept</data>
      <data key="d2">用于描述数据分布的函数，在基于分数的生成模型中定义。</data>
      <data key="d3">chunk-08c978d767db01aaeef63f40ea958f51</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975370</data>
      <data key="d6" />
    </node>
    <node id="动力配分函数">
      <data key="d0">动力配分函数</data>
      <data key="d1">concept</data>
      <data key="d2">A concept in statistical mechanics, representing a function used for efficient calculation.</data>
      <data key="d3">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975391</data>
      <data key="d6" />
    </node>
    <node id="PixelCNN">
      <data key="d0">PixelCNN</data>
      <data key="d1">method</data>
      <data key="d2">An autoregressive generative model used in the proposed method.</data>
      <data key="d3">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975399</data>
      <data key="d6" />
    </node>
    <node id="Transformer">
      <data key="d0">Transformer</data>
      <data key="d1">method</data>
      <data key="d2">An autoregressive generative model used in the proposed method.</data>
      <data key="d3">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975394</data>
      <data key="d6" />
    </node>
    <node id="自回归生成模型">
      <data key="d0">自回归生成模型</data>
      <data key="d1">method</data>
      <data key="d2">A category of models, including RNNs, PixelCNN, and Transformer, used in the proposed method.</data>
      <data key="d3">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975394</data>
      <data key="d6" />
    </node>
    <node id="创新方法">
      <data key="d0">创新方法</data>
      <data key="d3">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d2">The innovative method is applied for the efficient calculation of the dynamic partition function.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975396</data>
      <data key="d6" />
    </node>
    <node id="最大似然学习">
      <data key="d0">最大似然学习</data>
      <data key="d1">method</data>
      <data key="d2">一种用于估计模型参数的方法，在无向模型中学习参数时特别困难。</data>
      <data key="d3">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975417</data>
      <data key="d6" />
    </node>
    <node id="无向模型">
      <data key="d0">无向模型</data>
      <data key="d1">concept</data>
      <data key="d2">一种概率图模型，其配分函数依赖于模型参数。</data>
      <data key="d3">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975417</data>
      <data key="d6" />
    </node>
    <node id="对数似然">
      <data key="d0">对数似然</data>
      <data key="d1">concept</data>
      <data key="d2">模型参数的对数似然函数，其梯度包含配分函数梯度的贡献。</data>
      <data key="d3">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975419</data>
      <data key="d6" />
    </node>
    <node id="参数">
      <data key="d0">参数</data>
      <data key="d1">concept</data>
      <data key="d2">模型中的可调整变量，配分函数和对数似然都依赖于这些参数。</data>
      <data key="d3">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975419</data>
      <data key="d6" />
    </node>
    <node id="∇θlog˜p(x;θ)">
      <data key="d0">∇θlog˜p(x;θ)</data>
      <data key="d1">concept</data>
      <data key="d2">未归一化对数概率相对于参数的梯度。</data>
      <data key="d3">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975419</data>
      <data key="d6" />
    </node>
    <node id="∇θlogZ(θ)">
      <data key="d0">∇θlogZ(θ)</data>
      <data key="d1">concept</data>
      <data key="d2">配分函数的对数相对于参数的梯度。</data>
      <data key="d3">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975420</data>
      <data key="d6" />
    </node>
    <node id="分母">
      <data key="d0">分母</data>
      <data key="d1">concept</data>
      <data key="d2">The denominator in a mathematical expression, often used for normalization.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975449</data>
      <data key="d6" />
    </node>
    <node id="归一化常数">
      <data key="d0">归一化常数</data>
      <data key="d1">concept</data>
      <data key="d2">A constant used to normalize a probability distribution or other mathematical function.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975449</data>
      <data key="d6" />
    </node>
    <node id="对数-配分函数">
      <data key="d0">对数-配分函数</data>
      <data key="d1">concept</data>
      <data key="d2">The logarithm of the partition function, used in statistical mechanics.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975451</data>
      <data key="d6" />
    </node>
    <node id="统计物理学">
      <data key="d0">统计物理学</data>
      <data key="d1">concept</data>
      <data key="d2">A branch of physics that applies statistical methods to understand the behavior of physical systems with many particles.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975451</data>
      <data key="d6" />
    </node>
    <node id="粒子群">
      <data key="d0">粒子群</data>
      <data key="d1">concept</data>
      <data key="d2">An ensemble or collection of particles in a physical system.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975453</data>
      <data key="d6" />
    </node>
    <node id="方程">
      <data key="d0">方程</data>
      <data key="d1">concept</data>
      <data key="d2">A mathematical statement that expresses the equality of two expressions.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975455</data>
      <data key="d6" />
    </node>
    <node id="NDArray">
      <data key="d0">NDArray</data>
      <data key="d1">data</data>
      <data key="d2">A data structure representing a multi-dimensional array, often used in scientific computing.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975456</data>
      <data key="d6" />
    </node>
    <node id="softmax">
      <data key="d0">softmax</data>
      <data key="d1">method</data>
      <data key="d2">A mathematical function that converts a vector of numbers into a probability distribution.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975456</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID">
      <data key="d0">DOC_ID</data>
      <data key="d1">data</data>
      <data key="d2">A document identifier, specifically "chunk-b9060847".</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975456</data>
      <data key="d6" />
    </node>
    <node id="领域">
      <data key="d0">领域</data>
      <data key="d1">concept</data>
      <data key="d2">A field or domain of study, in this context specified as "统计力学".</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975456</data>
      <data key="d6" />
    </node>
    <node id="public">
      <data key="d0">public</data>
      <data key="d1">concept</data>
      <data key="d2">A keyword in programming denoting public accessibility of a method or class.</data>
      <data key="d3">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975457</data>
      <data key="d6" />
    </node>
    <node id="Rev. D">
      <data key="d0">Rev. D</data>
      <data key="d1">content</data>
      <data key="d2">Rev. D is a journal or publication referenced in the context of statistical mechanics research.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975506</data>
      <data key="d6" />
    </node>
    <node id="Yu J F">
      <data key="d0">Yu J F</data>
      <data key="d1">person</data>
      <data key="d2">Yu J F is an author of a research paper published in Rev. B in 2016.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975506</data>
      <data key="d6" />
    </node>
    <node id="Xie Z Y">
      <data key="d0">Xie Z Y</data>
      <data key="d1">person</data>
      <data key="d2">Xie Z Y is an author of multiple research papers published in Rev. B in 2016 and 2017.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975507</data>
      <data key="d6" />
    </node>
    <node id="Meurice Y">
      <data key="d0">Meurice Y</data>
      <data key="d1">person</data>
      <data key="d2">Meurice Y is an author of a research paper published in Rev. B in 2016.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975508</data>
      <data key="d6" />
    </node>
    <node id="Rev. B">
      <data key="d0">Rev. B</data>
      <data key="d1">content</data>
      <data key="d2">Rev. B is a journal or publication referenced multiple times for research papers in statistical mechanics.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975508</data>
      <data key="d6" />
    </node>
    <node id="Liu W Y">
      <data key="d0">Liu W Y</data>
      <data key="d1">person</data>
      <data key="d2">Liu W Y is an author of multiple research papers published in Rev. B in 2012 and 2017.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975508</data>
      <data key="d6" />
    </node>
    <node id="Dong S">
      <data key="d0">Dong S</data>
      <data key="d1">person</data>
      <data key="d2">Dong S is an author of a research paper published in Rev. B in 2012.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975508</data>
      <data key="d6" />
    </node>
    <node id="Wang C">
      <data key="d0">Wang C</data>
      <data key="d1">person</data>
      <data key="d2">Wang C is an author of research papers published in Rev. B in 2012 and 2018.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975509</data>
      <data key="d6" />
    </node>
    <node id="Liao H J">
      <data key="d0">Liao H J</data>
      <data key="d1">person</data>
      <data key="d2">Liao H J is an author of multiple research papers published in Rev. B in 2017.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975509</data>
      <data key="d6" />
    </node>
    <node id="Huang R Z">
      <data key="d0">Huang R Z</data>
      <data key="d1">person</data>
      <data key="d2">Huang R Z is an author of a research paper published in Rev. B in 2017.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975509</data>
      <data key="d6" />
    </node>
    <node id="Chen J">
      <data key="d0">Chen J</data>
      <data key="d1">person</data>
      <data key="d2">Chen J is an author of a research paper published in Rev. B in 2017.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975509</data>
      <data key="d6" />
    </node>
    <node id="Han Y J">
      <data key="d0">Han Y J</data>
      <data key="d1">person</data>
      <data key="d2">Han Y J is an author of research papers published in Rev. B in 2017 and 2018.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975510</data>
      <data key="d6" />
    </node>
    <node id="Dong S J">
      <data key="d0">Dong S J</data>
      <data key="d1">person</data>
      <data key="d2">Dong S J is an author of research papers published in Rev. B in 2017 and 2018.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975510</data>
      <data key="d6" />
    </node>
    <node id="Liang X">
      <data key="d0">Liang X</data>
      <data key="d1">person</data>
      <data key="d2">Liang X is an author of a research paper published in Rev. B in 2020.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975510</data>
      <data key="d6" />
    </node>
    <node id="Lin P Z">
      <data key="d0">Lin P Z</data>
      <data key="d1">person</data>
      <data key="d2">Lin P Z is an author of a research paper published in Rev. B in 2020.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975510</data>
      <data key="d6" />
    </node>
    <node id="Liu J G">
      <data key="d0">Liu J G</data>
      <data key="d1">person</data>
      <data key="d2">Liu J G is an author of a research paper published in Rev. B in 2017.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975510</data>
      <data key="d6" />
    </node>
    <node id="Wang L">
      <data key="d0">Wang L</data>
      <data key="d1">person</data>
      <data key="d2">Wang L is an author of a research paper published in Rev. B in 2017.</data>
      <data key="d3">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975510</data>
      <data key="d6" />
    </node>
    <node id="期望输出">
      <data key="d0">期望输出</data>
      <data key="d1">concept</data>
      <data key="d2">期望输出是机器学习模型训练中希望得到的理想概率分布，通常由真实标签或目标分布表示。</data>
      <data key="d3">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975538</data>
      <data key="d6" />
    </node>
    <node id="实际输出">
      <data key="d0">实际输出</data>
      <data key="d1">concept</data>
      <data key="d2">实际输出是机器学习模型根据输入数据计算出的预测概率分布。</data>
      <data key="d3">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975540</data>
      <data key="d6" />
    </node>
    <node id="H(p,q)">
      <data key="d0">H(p,q)</data>
      <data key="d1">concept</data>
      <data key="d2">H(p,q) is the mathematical notation representing the cross-entropy function between probability distribution p and probability distribution q.</data>
      <data key="d3">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975541</data>
      <data key="d6" />
    </node>
    <node id="神经网络训练">
      <data key="d0">神经网络训练</data>
      <data key="d1">method</data>
      <data key="d2">A process in machine learning where neural networks are optimized using input data.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975573</data>
      <data key="d6" />
    </node>
    <node id="类别概率分布">
      <data key="d0">类别概率分布</data>
      <data key="d1">concept</data>
      <data key="d2">The probability distribution of categories, either from the actual data or model predictions.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975574</data>
      <data key="d6" />
    </node>
    <node id="模型预测">
      <data key="d0">模型预测</data>
      <data key="d1">concept</data>
      <data key="d2">The output probability distribution of categories generated by a neural network model.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975576</data>
      <data key="d6" />
    </node>
    <node id="误差">
      <data key="d0">误差</data>
      <data key="d1">concept</data>
      <data key="d2">The difference or loss between the actual and predicted category probability distributions.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975576</data>
      <data key="d6" />
    </node>
    <node id="损失">
      <data key="d0">损失</data>
      <data key="d1">concept</data>
      <data key="d2">Synonymous with error, representing the discrepancy to be minimized during training.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975584</data>
      <data key="d6" />
    </node>
    <node id="输出端">
      <data key="d0">输出端</data>
      <data key="d1">concept</data>
      <data key="d2">The final layer of a neural network where predictions are made.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975577</data>
      <data key="d6" />
    </node>
    <node id="输入端">
      <data key="d0">输入端</data>
      <data key="d1">concept</data>
      <data key="d2">The initial layer of a neural network where data is fed in.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975577</data>
      <data key="d6" />
    </node>
    <node id="模型参数">
      <data key="d0">模型参数</data>
      <data key="d1">data</data>
      <data key="d2">The internal weights and biases of a neural network that are adjusted during training.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975578</data>
      <data key="d6" />
    </node>
    <node id="交叉熵计算">
      <data key="d0">交叉熵计算</data>
      <data key="d1">method</data>
      <data key="d2">The process of calculating loss using the cross-entropy method.</data>
      <data key="d3">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975578</data>
      <data key="d6" />
    </node>
    <node id="交叉熵损失函数">
      <data key="d0">交叉熵损失函数</data>
      <data key="d1">concept</data>
      <data key="d2">交叉熵损失函数是人工智能领域，特别是深度学习中，用于衡量模型预测结果与实际标签之间差异的重要工具。</data>
      <data key="d3">chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975613</data>
      <data key="d6" />
    </node>
    <node id="Cross Entropy Loss">
      <data key="d0">Cross Entropy Loss</data>
      <data key="d1">concept</data>
      <data key="d2">Cross Entropy Loss is an important tool in the field of artificial intelligence, especially in deep learning, used to measure the difference between model predictions and actual labels.</data>
      <data key="d3">chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975617</data>
      <data key="d6" />
    </node>
    <node id="人工智能模型">
      <data key="d0">人工智能模型</data>
      <data key="d1">concept</data>
      <data key="d2">人工智能模型是产生预测输出的系统，其准确性通过损失函数进行评估。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975690</data>
      <data key="d6" />
    </node>
    <node id="均方误差">
      <data key="d0">均方误差</data>
      <data key="d1">concept</data>
      <data key="d2">均方误差是一种损失函数，通常是回归算法的默认函数，计算预测值和真实值之间平方差的平均值。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975690</data>
      <data key="d6" />
    </node>
    <node id="平均绝对误差">
      <data key="d0">平均绝对误差</data>
      <data key="d1">concept</data>
      <data key="d2">平均绝对误差是一种损失函数，用于衡量预测值和实际值之间的平均绝对差，对异常值更具鲁棒性。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975692</data>
      <data key="d6" />
    </node>
    <node id="Huber损失">
      <data key="d0">Huber损失</data>
      <data key="d1">concept</data>
      <data key="d2">Huber损失是一种平滑L1损失，旨在平衡MAE和MSE的优势，包含一个可调整的超参数δ作为过渡点。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975692</data>
      <data key="d6" />
    </node>
    <node id="分类交叉熵损失">
      <data key="d0">分类交叉熵损失</data>
      <data key="d1">concept</data>
      <data key="d2">分类交叉熵损失是一种应用于多类分类的损失函数，模型以概率分布的形式输出预测。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975693</data>
      <data key="d6" />
    </node>
    <node id="铰链损失">
      <data key="d0">铰链损失</data>
      <data key="d1">concept</data>
      <data key="d2">铰链损失是一种用于分类算法的损失函数，将真实标签映射到{-1, 1}，并基于分类器输出计算损失。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975693</data>
      <data key="d6" />
    </node>
    <node id="IBM Granite">
      <data key="d0">IBM Granite</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM Granite是一个开放式、性能优异、值得信赖的AI模型系列，专门为企业量身定制，用于扩展AI应用程序。&lt;SEP&gt;A series of open, high-performance, trusted AI models tailored for enterprises, optimized for scaling AI applications.</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976039</data>
      <data key="d6" />
    </node>
    <node id="L2损失">
      <data key="d0">L2损失</data>
      <data key="d1">concept</data>
      <data key="d2">L2损失是均方误差的另一种名称，也称为二次损失。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975696</data>
      <data key="d6" />
    </node>
    <node id="二次损失">
      <data key="d0">二次损失</data>
      <data key="d1">concept</data>
      <data key="d2">二次损失是均方误差的另一种名称，也称为L2损失。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975696</data>
      <data key="d6" />
    </node>
    <node id="L1损失">
      <data key="d0">L1损失</data>
      <data key="d1">concept</data>
      <data key="d2">L1损失是平均绝对误差的另一种名称。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975697</data>
      <data key="d6" />
    </node>
    <node id="平滑L1损失">
      <data key="d0">平滑L1损失</data>
      <data key="d1">concept</data>
      <data key="d2">平滑L1损失是Huber损失的另一种名称。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975698</data>
      <data key="d6" />
    </node>
    <node id="超参数δ">
      <data key="d0">超参数δ</data>
      <data key="d1">concept</data>
      <data key="d2">超参数δ是Huber损失函数中的一个可调整参数，充当从二次行为到线性行为的过渡点。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975698</data>
      <data key="d6" />
    </node>
    <node id="IBM">
      <data key="d0">IBM</data>
      <data key="d1">organization</data>
      <data key="d2">IBM是一家科技公司，提供AI模型系列如IBM Granite，并发布相关指南和调查报告。&lt;SEP&gt;A technology company mentioned in the context of its privacy statement, AI models (IBM Granite), and AI development platform (IBM watsonx.ai).</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976038</data>
      <data key="d6" />
    </node>
    <node id="Think时事通讯">
      <data key="d0">Think时事通讯</data>
      <data key="d1">content</data>
      <data key="d2">Think时事通讯是IBM提供的每周通讯，提供关于最重要且最有趣的AI新闻的精选洞察分析。&lt;SEP&gt;A weekly newsletter from IBM providing curated insights and analysis on important and interesting AI news.</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976039</data>
      <data key="d6" />
    </node>
    <node id="IBM隐私声明">
      <data key="d0">IBM隐私声明</data>
      <data key="d1">content</data>
      <data key="d2">IBM隐私声明是订阅Think时事通讯时需要参阅的声明。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975698</data>
      <data key="d6" />
    </node>
    <node id="指南">
      <data key="d0">指南</data>
      <data key="d1">content</data>
      <data key="d2">指南是IBM发布的关于在AI新时代树立信任、从容自信蓬勃发展的指导性内容。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975699</data>
      <data key="d6" />
    </node>
    <node id="调查报告">
      <data key="d0">调查报告</data>
      <data key="d1">data</data>
      <data key="d2">调查报告是IBM对2000家组织进行的调查，旨在了解他们的AI计划以发现有效和无效的方法。</data>
      <data key="d3">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975699</data>
      <data key="d6" />
    </node>
    <node id="AI Applications">
      <data key="d0">AI Applications</data>
      <data key="d1">artifact</data>
      <data key="d2">AI applications are tailored and optimized for enterprises to help expand their AI capabilities.&lt;SEP&gt;AI applications can be built using a small subset of data in a very short time.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976042</data>
      <data key="d6" />
    </node>
    <node id="Language">
      <data key="d0">Language</data>
      <data key="d1">concept</data>
      <data key="d2">Language is one of the areas where AI applications can be optimized.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975699</data>
      <data key="d6" />
    </node>
    <node id="Code">
      <data key="d0">Code</data>
      <data key="d1">concept</data>
      <data key="d2">Code is one of the areas where AI applications can be optimized.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975700</data>
      <data key="d6" />
    </node>
    <node id="Time Series">
      <data key="d0">Time Series</data>
      <data key="d1">concept</data>
      <data key="d2">Time series is one of the areas where AI applications can be optimized.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975700</data>
      <data key="d6" />
    </node>
    <node id="Guardrail Options">
      <data key="d0">Guardrail Options</data>
      <data key="d1">concept</data>
      <data key="d2">Guardrail options are one of the areas where AI applications can be optimized.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975700</data>
      <data key="d6" />
    </node>
    <node id="Guide">
      <data key="d0">Guide</data>
      <data key="d1">content</data>
      <data key="d2">A guide aimed at building trust and thriving confidently in the new AI era.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975700</data>
      <data key="d6" />
    </node>
    <node id="Survey">
      <data key="d0">Survey</data>
      <data key="d1">event</data>
      <data key="d2">A survey of 2,000 organizations to understand their AI plans and identify effective and ineffective methods.&lt;SEP&gt;A survey was conducted involving 2,000 organizations to understand their AI plans and identify effective and ineffective methods.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976047</data>
      <data key="d6" />
    </node>
    <node id="IBM Watsonx.Ai">
      <data key="d0">IBM Watsonx.Ai</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM watsonx.ai is a next-generation enterprise-grade development platform for AI builders.&lt;SEP&gt;IBM Watsonx.Ai is a new generation enterprise-level development platform for AI builders, used to train, validate, tune, and deploy generative AI, foundation models, and machine learning capabilities.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976041</data>
      <data key="d6" />
    </node>
    <node id="Generative AI">
      <data key="d0">Generative AI</data>
      <data key="d1">concept</data>
      <data key="d2">Generative AI is a type of AI functionality that can be trained, validated, tuned, and deployed on the IBM watsonx.ai platform.&lt;SEP&gt;Generative AI is a type of artificial intelligence capability that can be trained and deployed using the IBM Watsonx.Ai platform.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976048</data>
      <data key="d6" />
    </node>
    <node id="Foundation Models">
      <data key="d0">Foundation Models</data>
      <data key="d1">concept</data>
      <data key="d2">Foundation models are a type of AI model that can be trained, validated, tuned, and deployed on the IBM watsonx.ai platform.&lt;SEP&gt;Foundation models are large-scale AI models that can be trained and deployed using the IBM Watsonx.Ai platform.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976055</data>
      <data key="d6" />
    </node>
    <node id="Machine Learning">
      <data key="d0">Machine Learning</data>
      <data key="d1">concept</data>
      <data key="d2">Machine learning is a type of AI functionality that can be trained, validated, tuned, and deployed on the IBM watsonx.ai platform.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975702</data>
      <data key="d6" />
    </node>
    <node id="AI Development Lifecycle">
      <data key="d0">AI Development Lifecycle</data>
      <data key="d1">concept</data>
      <data key="d2">The AI development lifecycle encompasses all stages from training to deployment, accessible through a unified platform.&lt;SEP&gt;The AI development lifecycle encompasses all stages from initial training to final deployment of AI solutions.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976042</data>
      <data key="d6" />
    </node>
    <node id="User-Friendly Interface">
      <data key="d0">User-Friendly Interface</data>
      <data key="d1">artifact</data>
      <data key="d2">A user-friendly interface is part of the IBM watsonx.ai platform for building AI solutions.&lt;SEP&gt;A user-friendly interface is part of the platform that facilitates the creation of powerful AI solutions.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976050</data>
      <data key="d6" />
    </node>
    <node id="Workflow">
      <data key="d0">Workflow</data>
      <data key="d1">concept</data>
      <data key="d2">Workflow tools are part of the IBM watsonx.ai platform for building AI solutions.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975702</data>
      <data key="d6" />
    </node>
    <node id="Industry-Standard APIs">
      <data key="d0">Industry-Standard APIs</data>
      <data key="d1">artifact</data>
      <data key="d2">Industry-standard APIs are accessible on the IBM watsonx.ai platform for building AI solutions.&lt;SEP&gt;Industry-standard APIs are accessible through the platform for developing AI solutions.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976044</data>
      <data key="d6" />
    </node>
    <node id="SDKs">
      <data key="d0">SDKs</data>
      <data key="d1">artifact</data>
      <data key="d2">SDKs are accessible on the IBM watsonx.ai platform for building AI solutions.&lt;SEP&gt;SDKs (Software Development Kits) are accessible through the platform for developing AI solutions.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976044</data>
      <data key="d6" />
    </node>
    <node id="AI Plans">
      <data key="d0">AI Plans</data>
      <data key="d1">concept</data>
      <data key="d2">AI plans are the strategic initiatives of organizations, as studied in a survey of 2,000 organizations to identify effective and ineffective methods.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975703</data>
      <data key="d6" />
    </node>
    <node id="Key Workflows">
      <data key="d0">Key Workflows</data>
      <data key="d1">concept</data>
      <data key="d2">Key workflows are operational processes that can be reshaped through the integration of AI to maximize experience, real-time decision-making, and business value.&lt;SEP&gt;Key workflows are business processes targeted for transformation through the application of AI.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976045</data>
      <data key="d6" />
    </node>
    <node id="Operations">
      <data key="d0">Operations</data>
      <data key="d1">concept</data>
      <data key="d2">Operations are business functions that can be reshaped through the integration of AI to maximize experience, real-time decision-making, and business value.&lt;SEP&gt;Operations refer to the core business functions that can be reshaped by AI.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976045</data>
      <data key="d6" />
    </node>
    <node id="Experience">
      <data key="d0">Experience</data>
      <data key="d1">concept</data>
      <data key="d2">Experience is a business outcome that can be maximized by reshaping key workflows and operations with AI.&lt;SEP&gt;Experience is one of the areas, along with decision-making and business value, that AI aims to maximize.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976046</data>
      <data key="d6" />
    </node>
    <node id="Real-Time Decision-Making">
      <data key="d0">Real-Time Decision-Making</data>
      <data key="d1">concept</data>
      <data key="d2">Real-time decision-making is a business outcome that can be maximized by reshaping key workflows and operations with AI.&lt;SEP&gt;Real-time decision-making is a capability that AI can enhance to improve business outcomes.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976046</data>
      <data key="d6" />
    </node>
    <node id="Business Value">
      <data key="d0">Business Value</data>
      <data key="d1">concept</data>
      <data key="d2">Business value is a commercial outcome that can be maximized by reshaping key workflows and operations with AI.&lt;SEP&gt;Business value is a key metric that organizations seek to maximize through the application of AI.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976046</data>
      <data key="d6" />
    </node>
    <node id="Powerful AI Solutions">
      <data key="d0">Powerful AI Solutions</data>
      <data key="d1">concept</data>
      <data key="d2">Powerful AI solutions are the end products that can be generated using the IBM watsonx.ai platform's features.</data>
      <data key="d3">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975705</data>
      <data key="d6" />
    </node>
    <node id="信息增益决策树">
      <data key="d0">信息增益决策树</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning method that uses information gain as the criterion for splitting nodes during decision tree construction.</data>
      <data key="d3">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975742</data>
      <data key="d6" />
    </node>
    <node id="Ent(D)">
      <data key="d0">Ent(D)</data>
      <data key="d1">concept</data>
      <data key="d2">The entropy of a dataset D, representing its overall impurity or uncertainty.</data>
      <data key="d3">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975743</data>
      <data key="d6" />
    </node>
    <node id="18年期末">
      <data key="d0">18年期末</data>
      <data key="d1">event</data>
      <data key="d2">Refers to a final exam from the year 2018, used as a reference or example for a similar problem.</data>
      <data key="d3">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975746</data>
      <data key="d6" />
    </node>
    <node id="表格">
      <data key="d0">表格</data>
      <data key="d1">data</data>
      <data key="d2">A table of data provided for calculating the first branch selection in an information gain decision tree problem.</data>
      <data key="d3">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975746</data>
      <data key="d6" />
    </node>
    <node id="第一个选择分支">
      <data key="d0">第一个选择分支</data>
      <data key="d1">concept</data>
      <data key="d2">The first attribute or feature selected for splitting the root node in an information gain decision tree.</data>
      <data key="d3">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975747</data>
      <data key="d6" />
    </node>
    <node id="决策树">
      <data key="d0">决策树</data>
      <data key="d1">concept</data>
      <data key="d2">决策树是一种机器学习模型，信息增益用于评估特征对其的贡献。&lt;SEP&gt;A model based on a tree structure used for decision-making, applicable to classification and regression tasks.&lt;SEP&gt;决策树是一种用于分类和回归的机器学习模型，其构建涉及特征选择、生成和剪枝。&lt;SEP&gt;决策树是一种基本的分类和回归方法，呈树形结构，表示基于特征对实例进行分类的过程，可以认为是if-then规则的集合或定义在特征空间和类空间上的条件概率分布。&lt;SEP&gt;A machine learning model that uses a tree-like structure to make decisions, employing a divide-and-conquer strategy and greedy search to find optimal split points.&lt;SEP&gt;Decision tree is a predictive modeling approach used in machine learning for classification and regression, discussed in the lecture.</data>
      <data key="d3">chunk-62fad8ab846c9df991d8fe50bdf2edf6&lt;SEP&gt;chunk-a79596200294b5109fdd0cf885110f83&lt;SEP&gt;chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c&lt;SEP&gt;chunk-b787493679d2ca259f397315e308f4b1&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976190</data>
      <data key="d6" />
    </node>
    <node id="公式">
      <data key="d0">公式</data>
      <data key="d1">method</data>
      <data key="d2">信息增益可以通过一个特定的公式进行计算。</data>
      <data key="d3">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975788</data>
      <data key="d6" />
    </node>
    <node id="耗散结构">
      <data key="d0">耗散结构</data>
      <data key="d1">concept</data>
      <data key="d2">耗散结构是一种在非平衡条件下通过能量耗散维持的有序结构。</data>
      <data key="d3">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975790</data>
      <data key="d6" />
    </node>
    <node id="薛定谔">
      <data key="d0">薛定谔</data>
      <data key="d1">person</data>
      <data key="d2">薛定谔是物理学家，在其著作《生命是什么》中讨论了熵与生命的关系。</data>
      <data key="d3">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975793</data>
      <data key="d6" />
    </node>
    <node id="生命是什么">
      <data key="d0">生命是什么</data>
      <data key="d1">content</data>
      <data key="d2">这是薛定谔的著作，探讨了物理学与生物学，特别是熵在生命系统中的作用。</data>
      <data key="d3">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975796</data>
      <data key="d6" />
    </node>
    <node id="分类">
      <data key="d0">分类</data>
      <data key="d1">concept</data>
      <data key="d2">A type of task in machine learning.&lt;SEP&gt;分类是决策树的主要应用之一，表示基于特征对实例进行分类的过程。</data>
      <data key="d3">chunk-a79596200294b5109fdd0cf885110f83&lt;SEP&gt;chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975925</data>
      <data key="d6" />
    </node>
    <node id="回归">
      <data key="d0">回归</data>
      <data key="d1">concept</data>
      <data key="d2">A type of task in machine learning.&lt;SEP&gt;回归是决策树的主要应用之一，是一种预测连续值的方法。</data>
      <data key="d3">chunk-a79596200294b5109fdd0cf885110f83&lt;SEP&gt;chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975925</data>
      <data key="d6" />
    </node>
    <node id="ID3">
      <data key="d0">ID3</data>
      <data key="d1">method</data>
      <data key="d2">ID3是一种决策树生成算法。&lt;SEP&gt;ID3是一种决策树学习算法，使用信息增益作为特征选择的标准，容易偏向于取值较多的特征。&lt;SEP&gt;An algorithm for building decision trees, short for "Iterative Dichotomiser 3," proposed by Ross Quinlan, using entropy and information gain.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976034</data>
      <data key="d6" />
    </node>
    <node id="C4.5">
      <data key="d0">C4.5</data>
      <data key="d1">method</data>
      <data key="d2">C4.5是一种决策树生成算法。&lt;SEP&gt;C4.5是一种决策树学习算法，引入了信息增益比作为特征选择的标准，以减少信息增益容易选择特征值多的特征的问题。&lt;SEP&gt;A later iteration of the ID3 algorithm, also proposed by Ross Quinlan, which can use information gain or gain ratio.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976036</data>
      <data key="d6" />
    </node>
    <node id="CART">
      <data key="d0">CART</data>
      <data key="d1">method</data>
      <data key="d2">CART是一种决策树生成算法。&lt;SEP&gt;CART是一种决策树学习算法，使用基尼系数作为特征选择的标准，基尼系数代表了模型的不纯度，基尼系数越小则不纯度越低。&lt;SEP&gt;An algorithm for building decision trees, short for "Classification and Regression Trees," proposed by Leo Breiman, often using the Gini index.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976037</data>
      <data key="d6" />
    </node>
    <node id="信息增益比">
      <data key="d0">信息增益比</data>
      <data key="d1">concept</data>
      <data key="d2">信息增益比是信息增益和特征熵的比值，是C4.5算法中引入的特征选择标准，用于解决信息增益偏向取值较多特征的问题。</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975920</data>
      <data key="d6" />
    </node>
    <node id="基尼系数">
      <data key="d0">基尼系数</data>
      <data key="d1">concept</data>
      <data key="d2">基尼系数代表了模型的不纯度，基尼系数越小则不纯度越低，特征越好，是CART分类树算法使用的特征选择标准。&lt;SEP&gt;基尼系数是CART算法中用于度量数据集纯度的指标，当基尼系数小于阈值ε_1时，停止递归。&lt;SEP&gt;A measure used in the CART algorithm to determine the ideal attribute for splitting; it measures how often a randomly chosen attribute would be incorrectly classified.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-b787493679d2ca259f397315e308f4b1&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976038</data>
      <data key="d6" />
    </node>
    <node id="特征选择">
      <data key="d0">特征选择</data>
      <data key="d1">concept</data>
      <data key="d2">特征选择是决策树学习的一个步骤，在于选取对训练数据具有分类能力的特征，基本方法包括信息增益、信息增益比和基尼系数。&lt;SEP&gt;Feature selection is the process of selecting a subset of relevant features for model construction, covered in the lecture.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976192</data>
      <data key="d6" />
    </node>
    <node id="决策树的生成">
      <data key="d0">决策树的生成</data>
      <data key="d1">concept</data>
      <data key="d2">决策树的生成是决策树学习的一个步骤，涉及根据训练数据和损失函数最小化原则建立决策树模型。</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975915</data>
      <data key="d6" />
    </node>
    <node id="决策树的剪枝">
      <data key="d0">决策树的剪枝</data>
      <data key="d1">concept</data>
      <data key="d2">决策树的剪枝是决策树学习的一个步骤，用于优化和简化生成的决策树模型。</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975915</data>
      <data key="d6" />
    </node>
    <node id="训练数据">
      <data key="d0">训练数据</data>
      <data key="d1">data</data>
      <data key="d2">训练数据是用于学习并建立决策树模型的数据集。</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975915</data>
      <data key="d6" />
    </node>
    <node id="训练集">
      <data key="d0">训练集</data>
      <data key="d1">data</data>
      <data key="d2">Training set is the input dataset used by decision tree algorithms like ID3 for learning.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975918</data>
      <data key="d6" />
    </node>
    <node id="特征集">
      <data key="d0">特征集</data>
      <data key="d1">data</data>
      <data key="d2">Feature set is the collection of attributes or features available for the decision tree algorithm to use during learning.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975919</data>
      <data key="d6" />
    </node>
    <node id="单节点树">
      <data key="d0">单节点树</data>
      <data key="d1">artifact</data>
      <data key="d2">单节点树是决策树的一种退化形式，当不满足划分条件时生成，其类别标记为样本中实例数最多的输出类别。&lt;SEP&gt;Single-node tree is a leaf node returned by the ID3 algorithm when a stopping condition (like all samples belonging to the same class or no features left) is met.</data>
      <data key="d3">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975919</data>
      <data key="d6" />
    </node>
    <node id="经验熵">
      <data key="d0">经验熵</data>
      <data key="d1">concept</data>
      <data key="d2">经验熵用于衡量一个叶结点中分类结果的混乱程度，值越大表示分类结果越混乱，分类效果越差。&lt;SEP&gt;经验熵用于度量叶结点中分类结果的混乱程度，经验熵越大表示分类结果越混乱，其计算公式基于叶结点中各类别样本的比例。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c&lt;SEP&gt;chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975919</data>
      <data key="d6" />
    </node>
    <node id="剪枝">
      <data key="d0">剪枝</data>
      <data key="d1">method</data>
      <data key="d2">剪枝是一种通过移除决策树的部分子树来简化模型、避免过拟合的技术。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975920</data>
      <data key="d6" />
    </node>
    <node id="NP难问题">
      <data key="d0">NP难问题</data>
      <data key="d1">concept</data>
      <data key="d2">寻找最优决策树是一个NP难问题，通常通过启发式方法解决，可能陷入局部最优。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975921</data>
      <data key="d6" />
    </node>
    <node id="集成学习">
      <data key="d0">集成学习</data>
      <data key="d1">method</data>
      <data key="d2">集成学习是一种可以改善决策树性能的方法。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975922</data>
      <data key="d6" />
    </node>
    <node id="叶结点">
      <data key="d0">叶结点</data>
      <data key="d1">concept</data>
      <data key="d2">叶结点是决策树中的终端节点，其经验熵用于衡量该节点分类结果的混乱程度。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975922</data>
      <data key="d6" />
    </node>
    <node id="子树">
      <data key="d0">子树</data>
      <data key="d1">concept</data>
      <data key="d2">子树是以某个节点为根的决策树分支，剪枝操作会移除子树而只保留根节点。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975922</data>
      <data key="d6" />
    </node>
    <node id="剪枝系数">
      <data key="d0">剪枝系数</data>
      <data key="d1">concept</data>
      <data key="d2">剪枝系数(α)是一个用于平衡决策树复杂度和分类效果的参数，通过计算节点剪枝前后的损失函数变化得到。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975923</data>
      <data key="d6" />
    </node>
    <node id="过拟合">
      <data key="d0">过拟合</data>
      <data key="d1">concept</data>
      <data key="d2">过拟合是指模型对训练数据分类很准确，但对未知测试数据分类准确性下降的现象，通常由于模型过于复杂导致。&lt;SEP&gt;过拟合是模型过于复杂而过度拟合训练数据，导致泛化能力下降的现象，剪枝可以用于避免过拟合。&lt;SEP&gt;A modeling error where a model is too complex and learns the noise in the training data, reducing its generalizability.</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c&lt;SEP&gt;chunk-b787493679d2ca259f397315e308f4b1&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976040</data>
      <data key="d6" />
    </node>
    <node id="启发式方法">
      <data key="d0">启发式方法</data>
      <data key="d1">method</data>
      <data key="d2">启发式方法是一种用于近似解决NP难问题(如寻找最优决策树)的策略，可能陷入局部最优。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975924</data>
      <data key="d6" />
    </node>
    <node id="异或">
      <data key="d0">异或</data>
      <data key="d1">concept</data>
      <data key="d2">异或是一种逻辑关系，决策树难以学习此类复杂关系，通常需要神经网络等方法来解决。</data>
      <data key="d3">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975924</data>
      <data key="d6" />
    </node>
    <node id="10212">
      <data key="d0">10212</data>
      <data key="d1">data</data>
      <data key="d2">10212 is a numerical identifier, likely a document or comment ID.</data>
      <data key="d3">chunk-53ac52739a03e942236087bac0208db0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975926</data>
      <data key="d6" />
    </node>
    <node id="阈值ε">
      <data key="d0">阈值ε</data>
      <data key="d1">concept</data>
      <data key="d2">阈值ε是决策树生成算法中的一个预设参数，用于判断信息增益是否足够进行节点划分。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975926</data>
      <data key="d6" />
    </node>
    <node id="特征A_g">
      <data key="d0">特征A_g</data>
      <data key="d1">concept</data>
      <data key="d2">特征A_g是决策树算法中计算出的具有最大信息增益的特征，用于对数据集进行划分。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975926</data>
      <data key="d6" />
    </node>
    <node id="C4.5算法">
      <data key="d0">C4.5算法</data>
      <data key="d1">method</data>
      <data key="d2">C4.5算法是一种决策树生成算法，它采用信息增益率作为特征选择标准，并使用PEP剪枝法进行剪枝。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975926</data>
      <data key="d6" />
    </node>
    <node id="CART算法">
      <data key="d0">CART算法</data>
      <data key="d1">method</data>
      <data key="d2">CART算法是一种决策树生成算法，它使用基尼系数作为特征选择标准，并采用CCP剪枝法进行剪枝。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975926</data>
      <data key="d6" />
    </node>
    <node id="阈值ε_1">
      <data key="d0">阈值ε_1</data>
      <data key="d1">concept</data>
      <data key="d2">阈值ε_1是CART算法中用于判断基尼系数是否足够小的预设参数，以决定是否停止节点划分。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975927</data>
      <data key="d6" />
    </node>
    <node id="阈值ε_2">
      <data key="d0">阈值ε_2</data>
      <data key="d1">concept</data>
      <data key="d2">阈值ε_2是CART算法中用于判断样本个数是否过少的预设参数，如果样本数小于此值则停止递归。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975927</data>
      <data key="d6" />
    </node>
    <node id="预剪枝">
      <data key="d0">预剪枝</data>
      <data key="d1">method</data>
      <data key="d2">预剪枝是在决策树构建过程中提前终止树的生长以避免产生过多节点的剪枝方法，但实用性不强。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975935</data>
      <data key="d6" />
    </node>
    <node id="后剪枝">
      <data key="d0">后剪枝</data>
      <data key="d1">method</data>
      <data key="d2">后剪枝是在决策树构建完成后，用叶子节点替代置信度不达标的节点子树的剪枝方法，包括CCP、REP、PEP、MEP等方法。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975928</data>
      <data key="d6" />
    </node>
    <node id="CCP剪枝法">
      <data key="d0">CCP剪枝法</data>
      <data key="d1">method</data>
      <data key="d2">CCP(代价复杂度剪枝)是一种后剪枝方法，由完全树开始逐步剪枝得到子树序列，并在验证集上选择损失函数最小的树。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975928</data>
      <data key="d6" />
    </node>
    <node id="PEP剪枝法">
      <data key="d0">PEP剪枝法</data>
      <data key="d1">method</data>
      <data key="d2">PEP(悲观错误剪枝)是一种自上而下的后剪枝方法，由Quinlan提出，C4.5算法采用此法，根据剪枝前后的错误率判定是否修剪子树。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975928</data>
      <data key="d6" />
    </node>
    <node id="训练集D">
      <data key="d0">训练集D</data>
      <data key="d1">data</data>
      <data key="d2">训练集D是决策树算法的输入数据，用于生成决策树模型。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975928</data>
      <data key="d6" />
    </node>
    <node id="样本输出D">
      <data key="d0">样本输出D</data>
      <data key="d1">data</data>
      <data key="d2">样本输出D是训练数据中的目标类别变量，在决策树生成过程中会根据特征取值被划分成不同类别D_i。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975929</data>
      <data key="d6" />
    </node>
    <node id="特征值A_gi">
      <data key="d0">特征值A_gi</data>
      <data key="d1">data</data>
      <data key="d2">特征值A_gi是特征A_g的具体取值，用于将样本输出D划分成不同的子类别D_i，并生成对应的子节点。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975929</data>
      <data key="d6" />
    </node>
    <node id="子树T_i">
      <data key="d0">子树T_i</data>
      <data key="d1">concept</data>
      <data key="d2">子树T_i是通过递归调用决策树生成算法，针对子节点数据集D_i和特征集A-{A_g}所生成的决策子树。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975929</data>
      <data key="d6" />
    </node>
    <node id="最优特征A">
      <data key="d0">最优特征A</data>
      <data key="d1">concept</data>
      <data key="d2">最优特征A是在CART算法中，根据基尼系数计算选出的、能够最有效划分数据集的特征。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975930</data>
      <data key="d6" />
    </node>
    <node id="最优特征值a">
      <data key="d0">最优特征值a</data>
      <data key="d1">data</data>
      <data key="d2">最优特征值a是与最优特征A对应的具体取值，用于将数据集D划分成两部分D1和D2。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975930</data>
      <data key="d6" />
    </node>
    <node id="数据集D1">
      <data key="d0">数据集D1</data>
      <data key="d1">data</data>
      <data key="d2">数据集D1是根据最优特征A和特征值a，从原始数据集D中划分出来的一个子集，对应决策树的一个左节点。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975930</data>
      <data key="d6" />
    </node>
    <node id="数据集D2">
      <data key="d0">数据集D2</data>
      <data key="d1">data</data>
      <data key="d2">数据集D2是根据最优特征A和特征值a，从原始数据集D中划分出来的另一个子集，对应决策树的一个右节点。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975930</data>
      <data key="d6" />
    </node>
    <node id="完全树T_0">
      <data key="d0">完全树T_0</data>
      <data key="d1">concept</data>
      <data key="d2">完全树T_0是CCP剪枝算法开始的初始状态，即未经剪枝的完整决策树。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975931</data>
      <data key="d6" />
    </node>
    <node id="树T">
      <data key="d0">树T</data>
      <data key="d1">concept</data>
      <data key="d2">树T是CCP剪枝算法中讨论的决策树对象，其叶结点个数用|T_leaf|表示，并用于计算经验熵等指标。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975931</data>
      <data key="d6" />
    </node>
    <node id="叶结点t">
      <data key="d0">叶结点t</data>
      <data key="d1">concept</data>
      <data key="d2">叶结点t是决策树T的终端节点，包含N_t个样本点，其中N_tk个属于k类，其分类混乱程度用经验熵H_t(T)度量。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975932</data>
      <data key="d6" />
    </node>
    <node id="参数α">
      <data key="d0">参数α</data>
      <data key="d1">concept</data>
      <data key="d2">参数α是CCP剪枝算法中用于平衡树复杂度和拟合程度的非负超参数。</data>
      <data key="d3">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768975940</data>
      <data key="d6" />
    </node>
    <node id="分而治之">
      <data key="d0">分而治之</data>
      <data key="d1">method</data>
      <data key="d2">A strategy used in decision tree learning to recursively split data.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976030</data>
      <data key="d6" />
    </node>
    <node id="贪心搜索">
      <data key="d0">贪心搜索</data>
      <data key="d1">method</data>
      <data key="d2">An algorithmic approach used to identify the best split point in a decision tree.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976030</data>
      <data key="d6" />
    </node>
    <node id="类标签">
      <data key="d0">类标签</data>
      <data key="d1">concept</data>
      <data key="d2">The target classification category to which data points are assigned in a decision tree.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976032</data>
      <data key="d6" />
    </node>
    <node id="纯净叶节点">
      <data key="d0">纯净叶节点</data>
      <data key="d1">concept</data>
      <data key="d2">A leaf node in a decision tree where all data points belong to a single class.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976032</data>
      <data key="d6" />
    </node>
    <node id="数据碎片">
      <data key="d0">数据碎片</data>
      <data key="d1">concept</data>
      <data key="d2">A situation in large decision trees where too few data points are assigned to a specific subtree, often leading to overfitting.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976032</data>
      <data key="d6" />
    </node>
    <node id="奥卡姆剃刀">
      <data key="d0">奥卡姆剃刀</data>
      <data key="d1">concept</data>
      <data key="d2">A principle of parsimony stating that simpler explanations are generally better; applied to decision trees by favoring smaller trees.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976040</data>
      <data key="d6" />
    </node>
    <node id="修剪">
      <data key="d0">修剪</data>
      <data key="d1">method</data>
      <data key="d2">A process in decision tree learning to remove branches split on less important features to reduce complexity and prevent overfitting.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976033</data>
      <data key="d6" />
    </node>
    <node id="交叉验证">
      <data key="d0">交叉验证</data>
      <data key="d1">method</data>
      <data key="d2">A process used to evaluate the fit of a machine learning model, such as a decision tree.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976034</data>
      <data key="d6" />
    </node>
    <node id="Hunt算法">
      <data key="d0">Hunt算法</data>
      <data key="d1">method</data>
      <data key="d2">An algorithm developed in the 1960s for modeling human learning in psychology, forming the basis for many mainstream decision tree algorithms.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976034</data>
      <data key="d6" />
    </node>
    <node id="Ross Quinlan">
      <data key="d0">Ross Quinlan</data>
      <data key="d1">person</data>
      <data key="d2">The proposer of the ID3 and C4.5 decision tree algorithms.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976034</data>
      <data key="d6" />
    </node>
    <node id="增益比">
      <data key="d0">增益比</data>
      <data key="d1">concept</data>
      <data key="d2">A metric used in the C4.5 algorithm to evaluate splits in a decision tree.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976035</data>
      <data key="d6" />
    </node>
    <node id="Leo Breiman">
      <data key="d0">Leo Breiman</data>
      <data key="d1">person</data>
      <data key="d2">The proposer of the CART (Classification and Regression Trees) algorithm.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976037</data>
      <data key="d6" />
    </node>
    <node id="IBM watsonx.ai">
      <data key="d0">IBM watsonx.ai</data>
      <data key="d1">artifact</data>
      <data key="d2">A next-generation enterprise studio for AI builders to train, validate, tune, and deploy generative AI, foundation models, and machine learning capabilities.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976039</data>
      <data key="d6" />
    </node>
    <node id="2024年AI实际应用">
      <data key="d0">2024年AI实际应用</data>
      <data key="d1">content</data>
      <data key="d2">A data-rich report based on a survey of 2,000 companies' AI initiatives, providing a comprehensive profile of AI leaders and expert commentary.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976040</data>
      <data key="d6" />
    </node>
    <node id="生成式AI">
      <data key="d0">生成式AI</data>
      <data key="d1">concept</data>
      <data key="d2">A type of artificial intelligence that can generate new content, mentioned in the context of improving customer service and machine learning capabilities.</data>
      <data key="d3">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976040</data>
      <data key="d6" />
    </node>
    <node id="Workflows">
      <data key="d0">Workflows</data>
      <data key="d1">method</data>
      <data key="d2">Workflows are tools provided by the platform to assist in the AI development process.</data>
      <data key="d3">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976050</data>
      <data key="d6" />
    </node>
    <node id="AI Solutions">
      <data key="d0">AI Solutions</data>
      <data key="d1">artifact</data>
      <data key="d2">AI solutions are powerful outcomes generated using the platform's tools and resources.</data>
      <data key="d3">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976044</data>
      <data key="d6" />
    </node>
    <node id="2,000 Organizations">
      <data key="d0">2,000 Organizations</data>
      <data key="d1">organization</data>
      <data key="d2">2,000 organizations were surveyed to gather insights into their AI strategies and implementation approaches.</data>
      <data key="d3">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976046</data>
      <data key="d6" />
    </node>
    <node id="Machine Learning Capabilities">
      <data key="d0">Machine Learning Capabilities</data>
      <data key="d1">concept</data>
      <data key="d2">Machine learning capabilities refer to the AI functions that can be developed and deployed using the IBM Watsonx.Ai platform.</data>
      <data key="d3">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976055</data>
      <data key="d6" />
    </node>
    <node id="Nov 12, 2025">
      <data key="d0">Nov 12, 2025</data>
      <data key="d1">data</data>
      <data key="d2">The expiration date of the security certificate issued to www.showmeai.tech.</data>
      <data key="d3">chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976097</data>
      <data key="d6" />
    </node>
    <node id="Jan 13, 2026">
      <data key="d0">Jan 13, 2026</data>
      <data key="d1">data</data>
      <data key="d2">The current system date when the certificate expiration warning was encountered.</data>
      <data key="d3">chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976097</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-d191d067">
      <data key="d0">DOC_ID: chunk-d191d067</data>
      <data key="d1">data</data>
      <data key="d2">A document identifier for the text chunk being processed.</data>
      <data key="d3">chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976098</data>
      <data key="d6" />
    </node>
    <node id="Bayes分类">
      <data key="d0">Bayes分类</data>
      <data key="d1">method</data>
      <data key="d2">一种基于贝叶斯定理的分类方法，旨在最小化分类错误的期望代价。&lt;SEP&gt;Bayes classification is a statistical method for classification based on Bayes' theorem, discussed in the lecture.</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976185</data>
      <data key="d6" />
    </node>
    <node id="代价函数">
      <data key="d0">代价函数</data>
      <data key="d1">concept</data>
      <data key="d2">用于衡量分类器性能的函数，定义为将样本错误分类的期望代价。&lt;SEP&gt;Cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some "cost" associated with the event, mentioned in the context of Bayes classification.</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976185</data>
      <data key="d6" />
    </node>
    <node id="贝叶斯最优分类器">
      <data key="d0">贝叶斯最优分类器</data>
      <data key="d1">concept</data>
      <data key="d2">一种分类器，其目标是找到使期望代价最小的决策函数。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976179</data>
      <data key="d6" />
    </node>
    <node id="Bayes公式">
      <data key="d0">Bayes公式</data>
      <data key="d1">concept</data>
      <data key="d2">将条件概率P(x|y)与联合概率P(x, y)和边缘概率P(y)联系起来的公式，形式为P(x|y) = P(x, y) / P(y)。&lt;SEP&gt;Bayes' formula or theorem is a fundamental probability rule used in Bayes classification.</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976180</data>
      <data key="d6" />
    </node>
    <node id="判别式模型">
      <data key="d0">判别式模型</data>
      <data key="d1">method</data>
      <data key="d2">直接根据后验概率P(c|x)决定样本点x的归类结果的模型。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976180</data>
      <data key="d6" />
    </node>
    <node id="生成式模型">
      <data key="d0">生成式模型</data>
      <data key="d1">method</data>
      <data key="d2">一种从数据生成过程角度进行建模的统计模型，当先验分布为均匀分布时，其最大似然估计等价于最小二乘法。&lt;SEP&gt;通过联合概率P(x, c)或似然P(x|c)和先验P(c)来建模，并用于分类的模型。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c&lt;SEP&gt;chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976181</data>
      <data key="d6" />
    </node>
    <node id="线性回归">
      <data key="d0">线性回归</data>
      <data key="d1">method</data>
      <data key="d2">一种建模变量间线性关系的方法，样本点形式为(x_i, y_i)，其中y_i = a^T x_i + ϵ_i。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976181</data>
      <data key="d6" />
    </node>
    <node id="朴素贝叶斯分类器">
      <data key="d0">朴素贝叶斯分类器</data>
      <data key="d1">method</data>
      <data key="d2">一种生成式分类模型，假设特征在给定类别下条件独立，以简化计算。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976181</data>
      <data key="d6" />
    </node>
    <node id="Y">
      <data key="d0">Y</data>
      <data key="d1">data</data>
      <data key="d2">Y表示样本的类别集合，定义为Y = {c1, c2, ..., cN}。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976182</data>
      <data key="d6" />
    </node>
    <node id="λi,j">
      <data key="d0">λi,j</data>
      <data key="d1">concept</data>
      <data key="d2">λi,j是将一个属于类别ci的样本点错误分类为类别cj的代价。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976182</data>
      <data key="d6" />
    </node>
    <node id="R(ci|x)">
      <data key="d0">R(ci|x)</data>
      <data key="d1">concept</data>
      <data key="d2">R(ci|x)是给定样本点x时，将其分类为ci的期望代价，定义为 Σ_{j=1}^N P(cj|x)λi,j。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976182</data>
      <data key="d6" />
    </node>
    <node id="h">
      <data key="d0">h</data>
      <data key="d1">concept</data>
      <data key="d2">h是一个分类器函数，将输入空间X映射到类别集合Y，即h: X → Y。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976190</data>
      <data key="d6" />
    </node>
    <node id="R(h)">
      <data key="d0">R(h)</data>
      <data key="d1">concept</data>
      <data key="d2">R(h)是分类器h的期望代价，定义为E_X[R(h(X)|X)]。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976190</data>
      <data key="d6" />
    </node>
    <node id="h*">
      <data key="d0">h*</data>
      <data key="d1">concept</data>
      <data key="d2">h*是贝叶斯最优分类器，是使期望代价R(h)最小的分类器，即h* = argmin_h R(h)。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976183</data>
      <data key="d6" />
    </node>
    <node id="P(x|y)">
      <data key="d0">P(x|y)</data>
      <data key="d1">concept</data>
      <data key="d2">P(x|y)是在给定y的条件下x发生的条件概率。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976183</data>
      <data key="d6" />
    </node>
    <node id="P(x, y)">
      <data key="d0">P(x, y)</data>
      <data key="d1">concept</data>
      <data key="d2">P(x, y)是x和y的联合概率。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976183</data>
      <data key="d6" />
    </node>
    <node id="P(y)">
      <data key="d0">P(y)</data>
      <data key="d1">concept</data>
      <data key="d2">P(y)是y的边缘概率。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976183</data>
      <data key="d6" />
    </node>
    <node id="P(y|x)">
      <data key="d0">P(y|x)</data>
      <data key="d1">concept</data>
      <data key="d2">P(y|x)是在给定x的条件下y发生的条件概率。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976184</data>
      <data key="d6" />
    </node>
    <node id="P(c|x)">
      <data key="d0">P(c|x)</data>
      <data key="d1">concept</data>
      <data key="d2">P(c|x)是判别式模型中，给定样本点x时，其属于类别c的后验概率。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976184</data>
      <data key="d6" />
    </node>
    <node id="P(x|c)">
      <data key="d0">P(x|c)</data>
      <data key="d1">concept</data>
      <data key="d2">P(x|c)是生成式模型中，在类别c中采样到样本点x的似然概率。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976185</data>
      <data key="d6" />
    </node>
    <node id="P(c)">
      <data key="d0">P(c)</data>
      <data key="d1">concept</data>
      <data key="d2">P(c)是类别c的先验概率。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976185</data>
      <data key="d6" />
    </node>
    <node id="噪音ϵi">
      <data key="d0">噪音ϵi</data>
      <data key="d1">concept</data>
      <data key="d2">在线性回归模型中，噪音 ϵi是观测值yi与预测值a^T xi之间的差值，即 ϵi = y_i - a^T x_i。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976187</data>
      <data key="d6" />
    </node>
    <node id="似然函数Li">
      <data key="d0">似然函数Li</data>
      <data key="d1">concept</data>
      <data key="d2">对于线性回归中的单个样本点xi，其似然函数Li定义为exp(-(y_i - a^T x_i)^2 / (2σ^2))。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976187</data>
      <data key="d6" />
    </node>
    <node id="lnL">
      <data key="d0">lnL</data>
      <data key="d1">concept</data>
      <data key="d2">lnL是似然函数L的自然对数，用于方便地求解参数的最大似然估计。</data>
      <data key="d3">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976188</data>
      <data key="d6" />
    </node>
    <node id="第九讲： Bayes分类、熵、决策树、特征选择">
      <data key="d0">第九讲： Bayes分类、熵、决策树、特征选择</data>
      <data key="d1">content</data>
      <data key="d2">This is the title and content of a lecture or course material covering topics including Bayes classification, entropy, decision trees, and feature selection.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976188</data>
      <data key="d6" />
    </node>
    <node id="徐玥珠">
      <data key="d0">徐玥珠</data>
      <data key="d1">person</data>
      <data key="d2">Xu Yue Zhu is a person associated with the lecture material, likely an author or presenter.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976188</data>
      <data key="d6" />
    </node>
    <node id="张锦岳">
      <data key="d0">张锦岳</data>
      <data key="d1">person</data>
      <data key="d2">Zhang Jin Yue is a person associated with the lecture material, likely an author or presenter.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976188</data>
      <data key="d6" />
    </node>
    <node id="最大熵原则">
      <data key="d0">最大熵原则</data>
      <data key="d1">concept</data>
      <data key="d2">Maximum entropy principle is a guideline for choosing probability distributions, mentioned in the lecture.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976192</data>
      <data key="d6" />
    </node>
    <node id="ID3决策树">
      <data key="d0">ID3决策树</data>
      <data key="d1">method</data>
      <data key="d2">ID3 decision tree is a specific algorithm for constructing decision trees, mentioned in the lecture.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976193</data>
      <data key="d6" />
    </node>
    <node id="C4.5决策树">
      <data key="d0">C4.5决策树</data>
      <data key="d1">method</data>
      <data key="d2">C4.5 decision tree is an algorithm for generating decision trees, an extension of ID3, mentioned in the lecture.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976193</data>
      <data key="d6" />
    </node>
    <node id="其他决策树">
      <data key="d0">其他决策树</data>
      <data key="d1">concept</data>
      <data key="d2">Other decision trees refer to additional or alternative decision tree algorithms beyond ID3 and C4.5.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976193</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-f65fc231">
      <data key="d0">DOC_ID: chunk-f65fc231</data>
      <data key="d1">data</data>
      <data key="d2">This is a document identifier for a specific chunk of content.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976194</data>
      <data key="d6" />
    </node>
    <node id="2020年6月24日">
      <data key="d0">2020年6月24日</data>
      <data key="d1">event</data>
      <data key="d2">This is the date of the lecture or when the material was created.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976194</data>
      <data key="d6" />
    </node>
    <node id="目录">
      <data key="d0">目录</data>
      <data key="d1">content</data>
      <data key="d2">This refers to the table of contents of the lecture material, outlining its structure.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976195</data>
      <data key="d6" />
    </node>
    <node id="0.1 Bayes分类">
      <data key="d0">0.1 Bayes分类</data>
      <data key="d1">content</data>
      <data key="d2">This is a section heading within the lecture material, specifically introducing Bayes classification.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976195</data>
      <data key="d6" />
    </node>
    <node id="0.1.1代价函数">
      <data key="d0">0.1.1代价函数</data>
      <data key="d1">content</data>
      <data key="d2">This is a subsection heading within the lecture material, discussing the cost function in the context of Bayes classification.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976195</data>
      <data key="d6" />
    </node>
    <node id="定义">
      <data key="d0">定义</data>
      <data key="d1">content</data>
      <data key="d2">This indicates a part of the content where a definition is provided, specifically for the cost function.</data>
      <data key="d3">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976196</data>
      <data key="d6" />
    </node>
    <node id="最小二乘法">
      <data key="d0">最小二乘法</data>
      <data key="d1">method</data>
      <data key="d2">一种参数估计方法，通过最小化预测值与观测值之差的平方和来寻找数据的最佳函数匹配。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976196</data>
      <data key="d6" />
    </node>
    <node id="骰子">
      <data key="d0">骰子</data>
      <data key="d1">artifact</data>
      <data key="d2">一种用于产生随机数的多面体玩具，在示例中用于说明概率分布和期望。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976197</data>
      <data key="d6" />
    </node>
    <node id="期望">
      <data key="d0">期望</data>
      <data key="d1">concept</data>
      <data key="d2">随机变量所有可能取值的概率加权平均。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976198</data>
      <data key="d6" />
    </node>
    <node id="排列组合">
      <data key="d0">排列组合</data>
      <data key="d1">concept</data>
      <data key="d2">数学中研究给定条件下对象的不同排列或组合方式数量的分支。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976199</data>
      <data key="d6" />
    </node>
    <node id="似然函数">
      <data key="d0">似然函数</data>
      <data key="d1">concept</data>
      <data key="d2">用于参数估计的函数，表示给定参数下观测到当前数据的概率。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976200</data>
      <data key="d6" />
    </node>
    <node id="自然对数">
      <data key="d0">自然对数</data>
      <data key="d1">concept</data>
      <data key="d2">以常数e为底的对数，常用于简化数学运算，如求似然函数的最大值。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976202</data>
      <data key="d6" />
    </node>
    <node id="事件域">
      <data key="d0">事件域</data>
      <data key="d1">concept</data>
      <data key="d2">一个随机试验所有可能结果的集合。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976203</data>
      <data key="d6" />
    </node>
    <node id="排列组合数目">
      <data key="d0">排列组合数目</data>
      <data key="d1">concept</data>
      <data key="d2">从一组对象中选取特定数量对象的不同方式的数量。</data>
      <data key="d3">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976203</data>
      <data key="d6" />
    </node>
    <node id="概率模型">
      <data key="d0">概率模型</data>
      <data key="d1">concept</data>
      <data key="d2">概率模型是一种用于描述随机现象或数据的数学模型，最大熵模型是构建此类模型的一种方法。</data>
      <data key="d3">chunk-2dd1a13b5c662bd9e747f8aa4b9d3361</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976230</data>
      <data key="d6" />
    </node>
    <node id="约束条件">
      <data key="d0">约束条件</data>
      <data key="d1">concept</data>
      <data key="d2">约束条件是构建最大熵模型时必须满足的一组已知条件或限制，模型在满足这些条件下选择分布。</data>
      <data key="d3">chunk-2dd1a13b5c662bd9e747f8aa4b9d3361</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976230</data>
      <data key="d6" />
    </node>
    <node id="深度学习算法">
      <data key="d0">深度学习算法</data>
      <data key="d1">method</data>
      <data key="d2">A class of machine learning algorithms, particularly popular for their strong performance in classification.</data>
      <data key="d3">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976261</data>
      <data key="d6" />
    </node>
    <node id="多层神经网络">
      <data key="d0">多层神经网络</data>
      <data key="d1">method</data>
      <data key="d2">A type of neural network architecture with multiple layers, known for its powerful fitting capability.</data>
      <data key="d3">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976254</data>
      <data key="d6" />
    </node>
    <node id="拟合能力">
      <data key="d0">拟合能力</data>
      <data key="d1">concept</data>
      <data key="d2">The ability of a model to approximate complex patterns in data.</data>
      <data key="d3">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976254</data>
      <data key="d6" />
    </node>
    <node id="性能">
      <data key="d0">性能</data>
      <data key="d1">concept</data>
      <data key="d2">The effectiveness and efficiency of a model in performing its intended task.</data>
      <data key="d3">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1768976254</data>
      <data key="d6" />
    </node>
    <edge source="熵" target="信息论">
      <data key="d7">2.0</data>
      <data key="d8">熵是信息论中的一个核心概念，用于量化信息。&lt;SEP&gt;熵是信息论领域的核心概念，用于描述系统的无序程度。</data>
      <data key="d9">学科基础,定义,核心概念</data>
      <data key="d10">chunk-9e4905d7255ffcf74cb7aad95daffceb&lt;SEP&gt;chunk-31dfc0a8415a0647f471a1cab88d6e36</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973950</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="信息熵">
      <data key="d7">3.0</data>
      <data key="d8">信息熵是熵的另一个名称，两者指代同一概念。&lt;SEP&gt;信息熵即熵，是信息论中用于度量不确定性的核心概念。&lt;SEP&gt;信息熵的概念来源于热力学的熵，因为信息对于接收方而言总是在增加。</data>
      <data key="d9">别名,同义,命名,核心度量,概念来源,概念等同</data>
      <data key="d10">chunk-9e4905d7255ffcf74cb7aad95daffceb&lt;SEP&gt;chunk-0662825c74f8b5ee226b4f32d6eae491&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974434</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="信源熵">
      <data key="d7">1.0</data>
      <data key="d8">信源熵是熵的另一个名称，两者指代同一概念。</data>
      <data key="d9">别名,同义</data>
      <data key="d10">chunk-9e4905d7255ffcf74cb7aad95daffceb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972808</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="平均自信息量">
      <data key="d7">1.0</data>
      <data key="d8">平均自信息量是熵的另一个名称，两者指代同一概念。</data>
      <data key="d9">别名,同义</data>
      <data key="d10">chunk-9e4905d7255ffcf74cb7aad95daffceb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972808</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="比特">
      <data key="d7">1.0</data>
      <data key="d8">比特是熵的常用度量单位。</data>
      <data key="d9">单位,度量</data>
      <data key="d10">chunk-9e4905d7255ffcf74cb7aad95daffceb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972809</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="交叉熵">
      <data key="d7">1.0</data>
      <data key="d8">Cross-entropy is an extension of entropy that compares a true distribution against a model distribution, using the same logarithmic measure of information.</data>
      <data key="d9">information theory,probability distributions</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972929</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="相对熵">
      <data key="d7">2.0</data>
      <data key="d8">Relative entropy quantifies the divergence of a probability distribution from another distribution, building upon the concept of entropy.&lt;SEP&gt;KL divergence can be expressed using entropy; specifically, D_KL(p||q) = H(p, q) - H(p), where H(p) is the entropy of distribution p.</data>
      <data key="d9">component,divergence,information measure,mathematical relation</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973150</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="联合熵">
      <data key="d7">1.0</data>
      <data key="d8">Joint entropy generalizes the concept of entropy to measure the combined uncertainty of two or more random variables.</data>
      <data key="d9">information theory,multivariate uncertainty</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972929</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="条件熵">
      <data key="d7">1.0</data>
      <data key="d8">Conditional entropy is derived from entropy and measures the uncertainty of one variable given knowledge of another.</data>
      <data key="d9">conditional uncertainty,information theory</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972930</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="互信息">
      <data key="d7">1.0</data>
      <data key="d8">Mutual information is a fundamental concept derived from entropy that measures the shared information between two variables.</data>
      <data key="d9">dependency,information theory</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972930</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="概率分布">
      <data key="d7">1.0</data>
      <data key="d8">Entropy is defined as a function of a probability distribution, measuring the average uncertainty or information content inherent in that distribution.</data>
      <data key="d9">information measure,uncertainty</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972931</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="最大熵原理">
      <data key="d7">3.0</data>
      <data key="d8">最大熵原理的核心思想是选择熵最大的分布。&lt;SEP&gt;最大熵原理将熵作为选择最合理概率分布的准则。&lt;SEP&gt;最大熵原理是在已知约束下，选择使熵最大化的概率分布。</data>
      <data key="d9">不确定性,优化原则,优化目标,最合理分布,核心概念,概率推断</data>
      <data key="d10">chunk-d4b315e54e592e86c3a5acfef7099954&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6&lt;SEP&gt;chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976215</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="统计均衡理论">
      <data key="d7">1.0</data>
      <data key="d8">The market allocates agents to offer sets to maximize the entropy of the market transaction distribution.</data>
      <data key="d9">dispersion,optimization criterion</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973460</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="最大似然Logit模型">
      <data key="d7">1.0</data>
      <data key="d8">The maximum likelihood Logit model is the maximum entropy model for all unordered discrete choice problems.</data>
      <data key="d9">discrete choice,model equivalence</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973461</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="自由能原理">
      <data key="d7">1.0</data>
      <data key="d8">自由能原理的核心是生命体通过最小化自由能来对抗宇宙的无序化趋势(熵增)。</data>
      <data key="d9">对抗关系,物理基础</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973766</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="生命">
      <data key="d7">2.0</data>
      <data key="d8">生命的本质是抵抗熵增、维持有序的“逆行者”，通过摄取负熵来对抗热力学第二定律所描述的熵增趋势。&lt;SEP&gt;生命体在一个熵增的宇宙中必须不断吸收和处理信息以抵御熵增，维持自身结构。</data>
      <data key="d9">存在前提,对抗关系,本质定义</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973763</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="热力学第二定律">
      <data key="d7">3.0</data>
      <data key="d8">热力学第二定律的核心内容是描述孤立系统中熵(无序度)只会不断增加的趋势。&lt;SEP&gt;热力学第二定律的数学表述主要借助熵的概念来完成。&lt;SEP&gt;热力学第二定律描述了孤立系统中熵总是增加的规律。</data>
      <data key="d9">定律描述,数学表述,核心概念,物理定律,系统演化</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a&lt;SEP&gt;chunk-1248b4cdb9c5b6a4f15c20d0991319ae&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975799</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="克劳修斯">
      <data key="d7">3.0</data>
      <data key="d8">Rudolf Clausius defined the concept of entropy from macroscopic thermal phenomena.&lt;SEP&gt;克劳修斯是引入熵这一物理概念的德国物理学家。&lt;SEP&gt;克劳修斯是引入熵这一概念的物理学家。</data>
      <data key="d9">definition,thermodynamics,定义,引入,概念引入,物理学贡献</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924&lt;SEP&gt;chunk-6135ecccd835afdfdaba2f58578ed61e&lt;SEP&gt;chunk-1248b4cdb9c5b6a4f15c20d0991319ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973928</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="鲁道夫·克劳修斯">
      <data key="d7">2.0</data>
      <data key="d8">鲁道夫·克劳修斯于1865年首次提出了熵的概念。&lt;SEP&gt;德国物理学家鲁道夫·克劳修斯最早提出了熵的概念。</data>
      <data key="d9">历史渊源,定义,提出,概念提出</data>
      <data key="d10">chunk-ed0ca1ab77e5b700d5a4eb0d861cccb4&lt;SEP&gt;chunk-31dfc0a8415a0647f471a1cab88d6e36</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973951</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="大脑神经网络">
      <data key="d7">1.0</data>
      <data key="d8">大脑神经网络在学习时建立有序连接，这一过程被描述为降低熵。</data>
      <data key="d9">学习过程,有序化</data>
      <data key="d10">chunk-ed0ca1ab77e5b700d5a4eb0d861cccb4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973908</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="热力学系统">
      <data key="d7">1.0</data>
      <data key="d8">熵用于描述热力学系统中无序度的变化，其增减由公式 ΔS = ΔQ/T计算。</data>
      <data key="d9">增减,描述</data>
      <data key="d10">chunk-1248b4cdb9c5b6a4f15c20d0991319ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973936</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="热力学">
      <data key="d7">1.0</data>
      <data key="d8">熵是热力学领域的核心概念，用于描述系统的无序程度。</data>
      <data key="d9">学科基础,核心概念</data>
      <data key="d10">chunk-31dfc0a8415a0647f471a1cab88d6e36</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973950</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="统计物理">
      <data key="d7">1.0</data>
      <data key="d8">熵是统计物理领域的核心概念，用于描述系统的无序程度。</data>
      <data key="d9">学科基础,核心概念</data>
      <data key="d10">chunk-31dfc0a8415a0647f471a1cab88d6e36</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973950</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="公式S=k*lnW">
      <data key="d7">1.0</data>
      <data key="d8">熵由公式S = k * ln W定义，该公式是熵的统计力学表达式。</data>
      <data key="d9">定义,数学表达</data>
      <data key="d10">chunk-74f709ca5bbf7d60213a39cdce19a507</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973973</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="预测不确定性">
      <data key="d7">1.0</data>
      <data key="d8">网络关于样本x的预测不确定性可以用熵H(x)来量化和表示。</data>
      <data key="d9">度量关系,量化表示</data>
      <data key="d10">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974120</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="样本x">
      <data key="d7">1.0</data>
      <data key="d8">熵H(x)是用于量化网络关于样本x的预测不确定性的函数。</data>
      <data key="d9">函数关系,量化表示</data>
      <data key="d10">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974121</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="高中">
      <data key="d7">1.0</data>
      <data key="d8">熵作为一个热力学概念，是在高中阶段被引入学习的。</data>
      <data key="d9">学习阶段,概念引入</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974438</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="平均编码长度">
      <data key="d7">1.0</data>
      <data key="d8">以2为底的平均编码长度就是信息熵。</data>
      <data key="d9">定义,等价于</data>
      <data key="d10">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974466</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="交叉熵损失函数">
      <data key="d7">1.0</data>
      <data key="d8">熵是信息论中的基础概念，是构成交叉熵损失函数理论来源的一部分。</data>
      <data key="d9">构成要素,理论基础</data>
      <data key="d10">chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975621</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="Ent(D)">
      <data key="d7">1.0</data>
      <data key="d8">Ent(D) is the specific notation for the entropy value of a given dataset D.</data>
      <data key="d9">dataset impurity,mathematical representation</data>
      <data key="d10">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975749</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="信息增益">
      <data key="d7">1.0</data>
      <data key="d8">Information gain is calculated based on the reduction in entropy (impurity) before and after a dataset split.</data>
      <data key="d9">calculation basis,impurity reduction</data>
      <data key="d10">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975750</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="香农">
      <data key="d7">1.0</data>
      <data key="d8">香农在信息论中提出了信息熵的概念。</data>
      <data key="d9">信息论,概念提出</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975797</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="薛定谔">
      <data key="d7">1.0</data>
      <data key="d8">薛定谔在其著作《生命是什么》中探讨了熵与生命系统的关系。</data>
      <data key="d9">物理学与生物学,理论探讨</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975797</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="玻尔兹曼">
      <data key="d7">1.0</data>
      <data key="d8">玻尔兹曼为熵提供了统计解释，并提出了公式S=k*lnW。</data>
      <data key="d9">公式定义,统计力学</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975799</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="耗散结构">
      <data key="d7">1.0</data>
      <data key="d8">耗散结构理论解释了在开放系统中，熵产生可以驱动形成有序结构。</data>
      <data key="d9">有序维持,非平衡系统</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975800</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="ID3">
      <data key="d7">1.0</data>
      <data key="d8">The ID3 algorithm uses entropy as a key metric to evaluate candidate splits.</data>
      <data key="d9">evaluation metric,split criterion</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976054</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="第九讲： Bayes分类、熵、决策树、特征选择">
      <data key="d7">1.0</data>
      <data key="d8">The lecture covers the topic of entropy.</data>
      <data key="d9">educational content,topic coverage</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976209</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="最大熵原则">
      <data key="d7">1.0</data>
      <data key="d8">The maximum entropy principle is a key principle related to the concept of entropy.</data>
      <data key="d9">application,principle</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976210</data>
      <data key="d13" />
    </edge>
    <edge source="熵" target="不确定性">
      <data key="d7">1.0</data>
      <data key="d8">Entropy is a measure of uncertainty.</data>
      <data key="d9">measurement,quantification</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976211</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="交叉熵">
      <data key="d7">3.0</data>
      <data key="d8">Cross-entropy is calculated using two probability distributions, representing the expected coding length when one distribution is used to model another.&lt;SEP&gt;交叉熵的计算需要两个概率分布：真实的概率分布(后验分布)和预期的概率分布(先验分布)。&lt;SEP&gt;交叉熵用于度量两个概率分布(期望输出与实际输出)之间的距离。</data>
      <data key="d9">coding cost,model evaluation,度量,核心要素,计算基础,距离</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49&lt;SEP&gt;chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975549</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="相对熵">
      <data key="d7">1.0</data>
      <data key="d8">Relative entropy measures the divergence between two probability distributions, quantifying how one distribution differs from another.</data>
      <data key="d9">distribution comparison,divergence</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972933</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="KL散度">
      <data key="d7">1.0</data>
      <data key="d8">KL散度被用作目标函数来衡量概率分布之间的差异。</data>
      <data key="d9">差异度量,目标函数</data>
      <data key="d10">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973179</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="Wasserstein距离">
      <data key="d7">1.0</data>
      <data key="d8">Wasserstein距离是一种真正的度量，用于衡量概率分布之间的差异。</data>
      <data key="d9">差异度量,真正度量</data>
      <data key="d10">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973181</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="Bhattacharyya距离">
      <data key="d7">1.0</data>
      <data key="d8">Bhattacharyya距离是一种真正的度量，用于衡量概率分布之间的差异。</data>
      <data key="d9">差异度量,真正度量</data>
      <data key="d10">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973182</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="最大熵模型">
      <data key="d7">1.0</data>
      <data key="d8">在文本分类中，最大熵模型用于计算每个类别的概率分布。</data>
      <data key="d9">原理,计算</data>
      <data key="d10">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973291</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="Softmax">
      <data key="d7">1.0</data>
      <data key="d8">Softmax函数的核心功能是将数值向量转换为一个概率分布。</data>
      <data key="d9">映射,生成</data>
      <data key="d10">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973292</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="期望输出">
      <data key="d7">1.0</data>
      <data key="d8">期望输出被定义为概率分布p，是模型训练的目标分布。</data>
      <data key="d9">定义,表示</data>
      <data key="d10">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975542</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="实际输出">
      <data key="d7">1.0</data>
      <data key="d8">实际输出被定义为概率分布q，是模型产生的预测分布。</data>
      <data key="d9">定义,表示</data>
      <data key="d10">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975542</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="分类交叉熵损失">
      <data key="d7">1.0</data>
      <data key="d8">分类交叉熵损失应用于多类分类，模型以概率分布的形式输出预测。</data>
      <data key="d9">应用,输出形式</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975712</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布" target="骰子">
      <data key="d7">1.0</data>
      <data key="d8">骰子每次投掷的结果由一个特定的概率分布来描述。</data>
      <data key="d9">不确定性,结果描述</data>
      <data key="d10">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976217</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="博弈论">
      <data key="d7">1.0</data>
      <data key="d8">Information theory reasoning links game theory to empirical evidence.</data>
      <data key="d9">empirical evidence,theoretical linkage</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973458</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="克劳德·艾尔伍德·香农">
      <data key="d7">2.0</data>
      <data key="d8">克劳德·艾尔伍德·香农创立了信息论，阐述了信息消除不确定性的本质。&lt;SEP&gt;克劳德·香农是信息论的创始人，他通过发表《通信的一个数学理论》开创了这一领域。</data>
      <data key="d9">信息本质,创立,理论创立,贡献</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577&lt;SEP&gt;chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974425</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="智能">
      <data key="d7">1.0</data>
      <data key="d8">信息论为理解智能提供了统一视角，即智能是吸收信息以对抗熵增(消除不确定性)的能力。</data>
      <data key="d9">对抗熵增,理论基础</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973795</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="交叉熵">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵的概念源于信息论，用于量化两个概率分布之间的差异。</data>
      <data key="d9">度量,理论基础</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974425</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="信息传递模型">
      <data key="d7">1.0</data>
      <data key="d8">信息论为理解信息传递模型提供了理论基础，该模型抽象描述了通信过程。</data>
      <data key="d9">基础,应用</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974428</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="信息熵">
      <data key="d7">1.0</data>
      <data key="d8">信息熵是信息论中的一个核心概念，用于量化信息量。</data>
      <data key="d9">包含,量化</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="机器学习">
      <data key="d7">1.0</data>
      <data key="d8">信息论是机器学习领域的基础内容。</data>
      <data key="d9">基础,应用</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974431</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="自然语言处理">
      <data key="d7">1.0</data>
      <data key="d8">信息论是自然语言处理领域的理论基础，为其提供铺垫。</data>
      <data key="d9">基础,应用</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974432</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="神经网络">
      <data key="d7">2.0</data>
      <data key="d8">信息论的概念，如信息熵，在神经网络模型中同样适用。&lt;SEP&gt;信息论可以应用于神经网络等领域，神经网络模型可以被抽象看作一种通信系统。</data>
      <data key="d9">应用,抽象,概念适用</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974433</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="信息">
      <data key="d7">1.0</data>
      <data key="d8">信息论中的“信息”指能够说什么，其传递是一个消除不确定性的过程。</data>
      <data key="d9">消除不确定性</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974435</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="通信系统">
      <data key="d7">1.0</data>
      <data key="d8">理解信息论的概念需要脑补出一个包括发送方、接收方、信道和编码的通信系统场景。</data>
      <data key="d9">应用场景,框架</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974436</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="编码定理">
      <data key="d7">1.0</data>
      <data key="d8">编码定理是信息论领域的核心理论，构成了该学科的基础。</data>
      <data key="d9">基础,核心理论</data>
      <data key="d10">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974493</data>
      <data key="d13" />
    </edge>
    <edge source="信息论" target="交叉熵损失函数">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵损失函数的概念源于信息论中的熵和相对熵。</data>
      <data key="d9">基础概念,理论起源</data>
      <data key="d10">chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975621</data>
      <data key="d13" />
    </edge>
    <edge source="信息熵" target="KL散度">
      <data key="d7">1.0</data>
      <data key="d8">KL divergence directly assesses the difference between cross-entropy and information entropy.</data>
      <data key="d9">difference assessment,formula component</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973032</data>
      <data key="d13" />
    </edge>
    <edge source="信息熵" target="香农">
      <data key="d7">1.0</data>
      <data key="d8">香农创立了信息论并定义了信息熵的概念。</data>
      <data key="d9">概念定义,理论创立</data>
      <data key="d10">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974120</data>
      <data key="d13" />
    </edge>
    <edge source="信息熵" target="Entropy">
      <data key="d7">1.0</data>
      <data key="d8">信息熵is the Chinese translation of the English concept Entropy.</data>
      <data key="d9">synonym,translation</data>
      <data key="d10">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974283</data>
      <data key="d13" />
    </edge>
    <edge source="信息熵" target="随机变量">
      <data key="d7">2.0</data>
      <data key="d8">信息熵与随机变量相关联，用于衡量该变量所代表事件的信息量。&lt;SEP&gt;信息熵是根据随机变量的概率分布计算得出的，用于度量其平均不确定性。</data>
      <data key="d9">关联,度量不确定性,衡量,计算公式</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238&lt;SEP&gt;chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974431</data>
      <data key="d13" />
    </edge>
    <edge source="EMCNN" target="Node Influence">
      <data key="d7">1.0</data>
      <data key="d8">EMCNN is a method proposed to predict node influence, showing high correlation with real infection counts, indicating accurate identification of spreading influence.</data>
      <data key="d9">accuracy,prediction</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972867</data>
      <data key="d13" />
    </edge>
    <edge source="SIR Model" target="Correlation Experiment">
      <data key="d7">1.0</data>
      <data key="d8">The correlation experiment uses the SIR model to generate real influence data for validating algorithm predictions.</data>
      <data key="d9">evaluation,validation</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972867</data>
      <data key="d13" />
    </edge>
    <edge source="SIR Model" target="Node Influence">
      <data key="d7">1.0</data>
      <data key="d8">The SIR model is used to simulate infection spread and generate the real, ground-truth influence values for nodes.</data>
      <data key="d9">ground truth,simulation</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972868</data>
      <data key="d13" />
    </edge>
    <edge source="SIR Model" target="Infection Count">
      <data key="d7">1.0</data>
      <data key="d8">The SIR model simulation generates the infection count data, which serves as the ground truth for node influence.</data>
      <data key="d9">generation,output</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972869</data>
      <data key="d13" />
    </edge>
    <edge source="Degree" target="Node Influence">
      <data key="d7">1.0</data>
      <data key="d8">Degree is a traditional method for measuring node influence, but shows weak correlation with actual influence in highly clustered networks.</data>
      <data key="d9">limitation,measurement</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972869</data>
      <data key="d13" />
    </edge>
    <edge source="Degree" target="Community Structure">
      <data key="d7">1.0</data>
      <data key="d8">High community structure in networks limits the correlation between a node's degree and its global influence, affecting the accuracy of the Degree metric.</data>
      <data key="d9">correlation,limitation</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972870</data>
      <data key="d13" />
    </edge>
    <edge source="H-index" target="Node Influence">
      <data key="d7">1.0</data>
      <data key="d8">H-index is a traditional metric for measuring influence, but shows weak correlation with actual spread influence in the experiments.</data>
      <data key="d9">limitation,measurement</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972870</data>
      <data key="d13" />
    </edge>
    <edge source="PageRank" target="Node Influence">
      <data key="d7">1.0</data>
      <data key="d8">PageRank is an algorithm for ranking node influence, but it performs poorly in identifying high-influence nodes in strongly clustered networks due to bias.</data>
      <data key="d9">bias,ranking</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972870</data>
      <data key="d13" />
    </edge>
    <edge source="InfGCN" target="Node Influence">
      <data key="d7">1.0</data>
      <data key="d8">InfGCN is a deep learning method for predicting node influence, but it performed poorly due to insufficient fusion of network structure information.</data>
      <data key="d9">insufficiency,prediction</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972870</data>
      <data key="d13" />
    </edge>
    <edge source="Node Influence" target="Node Importance Ranking">
      <data key="d7">1.0</data>
      <data key="d8">Node influence is the property used as the basis for creating a node importance ranking.</data>
      <data key="d9">basis,ordering</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972871</data>
      <data key="d13" />
    </edge>
    <edge source="Network" target="Correlation Experiment">
      <data key="d7">1.0</data>
      <data key="d8">The correlation experiment is conducted across nine different networks to analyze algorithm performance.</data>
      <data key="d9">analysis,testing</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972868</data>
      <data key="d13" />
    </edge>
    <edge source="Correlation Experiment" target="Infection Probability">
      <data key="d7">1.0</data>
      <data key="d8">The correlation experiment sets specific infection probabilities (β values) for each of the nine networks when running the SIR model.</data>
      <data key="d9">parameter setting,simulation setup</data>
      <data key="d10">chunk-638c79cbb743dead1aa6af99fd6d0fcb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972869</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="相对熵">
      <data key="d7">3.0</data>
      <data key="d8">Relative entropy can be expressed as the difference between cross-entropy and entropy, linking these two measures.&lt;SEP&gt;KL divergence can be expressed using cross-entropy; specifically, D_KL(p||q) = H(p, q) - H(p), where H(p, q) is the cross-entropy.&lt;SEP&gt;相对熵(KL散度)由交叉熵引申而来，是交叉熵与信息熵的差值，表示相对的吃惊程度。</data>
      <data key="d9">component,divergence,information theory,mathematical relation,数学关联,概念引申</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437&lt;SEP&gt;chunk-0c9d3f43376e35055643ae46b0d5a233&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974432</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="KL散度">
      <data key="d7">1.0</data>
      <data key="d8">KL divergence directly assesses the difference between cross-entropy and information entropy.</data>
      <data key="d9">difference assessment,formula component</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973029</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="神经网络">
      <data key="d7">2.0</data>
      <data key="d8">交叉熵被用作神经网络的损失函数，以衡量模型预测分布与真实分布之间的差异。&lt;SEP&gt;在机器学习中，交叉熵常被用作神经网络的损失函数，以衡量模型预测分布与真实分布之间的差异。</data>
      <data key="d9">优化,优化指标,损失函数,理论应用</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974424</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="损失函数">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵是神经网络中广泛使用的损失函数，用于优化模型。</data>
      <data key="d9">应用,衡量标准</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974426</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="震惊程度">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵的值被解释为一种震惊程度，表示真实分布与预期分布的偏离程度。</data>
      <data key="d9">概念描述,直观解释</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974426</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="JioNLP Article">
      <data key="d7">1.0</data>
      <data key="d8">The JioNLP article explains the concept of cross-entropy.</data>
      <data key="d9">explanation,publication</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974427</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="小北">
      <data key="d7">1.0</data>
      <data key="d8">小北购买彩票的经历被用作解释交叉熵概念的直观例子，他因真实中奖概率与预期不同而感到吃惊，这种吃惊程度就是交叉熵。</data>
      <data key="d9">个人经历,概念应用</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974427</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="信息量">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵的计算依赖于信息量的概念，它是对真实概率分布下信息量的期望。</data>
      <data key="d9">数学定义,概念关联</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974428</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="先验分布">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵衡量的是用“自以为的”先验分布去观测世界时产生的吃惊程度。</data>
      <data key="d9">对比参照,预期基准</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="后验分布">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵衡量的是后验分布(真实发生的情况)与先验分布(预期情况)之间的差异所带来的信息量。</data>
      <data key="d9">对比目标,真实参照</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974431</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="通信模型">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵的概念可以放在通信模型中理解，表示信息接收方接收到的信息相对于其预期的吃惊程度。</data>
      <data key="d9">场景类比,理论应用</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974431</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="H(X)">
      <data key="d7">1.0</data>
      <data key="d8">H(X) is the mathematical formula provided in the text to define and calculate cross-entropy.</data>
      <data key="d9">公式定义,数学表达</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974424</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="女孩">
      <data key="d7">1.0</data>
      <data key="d8">The girl's level of surprise upon receiving the boy's confession is used as an analogy to explain the concept of cross-entropy.</data>
      <data key="d9">概念例证,角色类比</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974425</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="太阳从东边升起">
      <data key="d7">1.0</data>
      <data key="d8">"The sun rises from the east" is used as an example of a prior distribution with zero surprise, which is a baseline for calculating cross-entropy when it is contradicted.</data>
      <data key="d9">先验分布,概念例证</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974426</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="太阳从西边升起">
      <data key="d7">1.0</data>
      <data key="d8">"The sun rises from the west" in the story is the surprising posterior distribution, and the cross-entropy measures the shock when this information is received against the prior belief.</data>
      <data key="d9">后验分布,概念例证</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974429</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="期望输出">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵将期望输出作为衡量实际输出准确性的目标或基准。</data>
      <data key="d9">目标,衡量</data>
      <data key="d10">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975542</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="实际输出">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵衡量模型的实际输出(预测概率分布)与期望输出之间的接近程度。</data>
      <data key="d9">衡量,预测</data>
      <data key="d10">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975543</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="机器学习">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵是机器学习领域中的一个核心概念，常用于模型训练中的损失函数。</data>
      <data key="d9">核心概念,领域应用</data>
      <data key="d10">chunk-c83ff92607271cc36071ca55ac4a8385</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975543</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="误差">
      <data key="d7">1.0</data>
      <data key="d8">Cross-entropy is a method used to calculate the error or loss between distributions.</data>
      <data key="d9">calculation,measurement</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975592</data>
      <data key="d13" />
    </edge>
    <edge source="交叉熵" target="交叉熵计算">
      <data key="d7">1.0</data>
      <data key="d8">Cross-entropy is implemented through the specific process of cross-entropy calculation.</data>
      <data key="d9">implementation,process</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975593</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="KL散度">
      <data key="d7">2.0</data>
      <data key="d8">Relative entropy is also known as KL divergence (Kullback–Leibler divergence); they refer to the same concept.&lt;SEP&gt;相对熵和KL散度是同一个概念的不同名称，都用于衡量两个概率分布之间的差异。</data>
      <data key="d9">synonym,terminology,术语等同,概念同一</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233&lt;SEP&gt;chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974428</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="信息散度">
      <data key="d7">1.0</data>
      <data key="d8">Relative entropy is also known as information divergence; they are synonymous terms.</data>
      <data key="d9">synonym,terminology</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973148</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="信息增益">
      <data key="d7">1.0</data>
      <data key="d8">Relative entropy is also referred to as information gain in certain contexts, such as measuring belief updates in Bayesian inference.</data>
      <data key="d9">application,synonym</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973148</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="概率分布P">
      <data key="d7">1.0</data>
      <data key="d8">Relative entropy measures the difference from probability distribution P, which typically represents the true data distribution.</data>
      <data key="d9">comparison,measurement</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973149</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="概率分布Q">
      <data key="d7">1.0</data>
      <data key="d8">Relative entropy measures the difference to probability distribution Q, which typically represents a model or approximate distribution.</data>
      <data key="d9">comparison,measurement</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973149</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="贝叶斯推理">
      <data key="d7">1.0</data>
      <data key="d8">In Bayesian inference, KL divergence D_KL(p||q) is used to measure the information gain when updating beliefs from prior q to posterior p.</data>
      <data key="d9">application,measurement</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973152</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="变分自编码器">
      <data key="d7">1.0</data>
      <data key="d8">The variational autoencoder uses KL divergence as a component of its objective function for training.</data>
      <data key="d9">objective function,utilization</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973154</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="Kullback">
      <data key="d7">1.0</data>
      <data key="d8">Kullback, along with Leibler, is associated with the proposal and naming of relative entropy (KL divergence) in 1951.</data>
      <data key="d9">naming,proposal</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973155</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="Leibler">
      <data key="d7">1.0</data>
      <data key="d8">Leibler, along with Kullback, is associated with the proposal and naming of relative entropy (KL divergence) in 1951.</data>
      <data key="d9">naming,proposal</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973156</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="D_KL(p||q)">
      <data key="d7">1.0</data>
      <data key="d8">Relative entropy is mathematically represented as D_KL(p||q), measuring divergence from q to p.</data>
      <data key="d9">mathematical notation,representation</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973157</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="D_KL(Q||P)">
      <data key="d7">1.0</data>
      <data key="d8">Relative entropy is also represented as D_KL(Q||P), illustrating its asymmetric property.</data>
      <data key="d9">asymmetry,mathematical notation</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973158</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="KL(p||q)">
      <data key="d7">1.0</data>
      <data key="d8">KL(p||q) is the mathematical formula provided in the text to define and calculate relative entropy (KL divergence).</data>
      <data key="d9">公式定义,数学表达</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974429</data>
      <data key="d13" />
    </edge>
    <edge source="相对熵" target="交叉熵损失函数">
      <data key="d7">1.0</data>
      <data key="d8">相对熵是信息论中的概念，是构成交叉熵损失函数理论来源的一部分。</data>
      <data key="d9">构成要素,理论来源</data>
      <data key="d10">chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975622</data>
      <data key="d13" />
    </edge>
    <edge source="联合熵" target="条件熵">
      <data key="d7">1.0</data>
      <data key="d8">Joint entropy can be decomposed into the sum of conditional entropy and the entropy of the other variable, showing their mathematical relationship.</data>
      <data key="d9">decomposition,information theory</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972930</data>
      <data key="d13" />
    </edge>
    <edge source="联合熵" target="随机变量">
      <data key="d7">1.0</data>
      <data key="d8">Joint entropy measures the combined uncertainty of two random variables, X and Y.</data>
      <data key="d9">information theory,multivariate analysis</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972931</data>
      <data key="d13" />
    </edge>
    <edge source="联合熵" target="互信息">
      <data key="d7">1.0</data>
      <data key="d8">Mutual information can be expressed in terms of joint entropy and the individual entropies of the variables.</data>
      <data key="d9">information theory,shared information</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972932</data>
      <data key="d13" />
    </edge>
    <edge source="联合熵" target="最大熵原理马尔可夫问题">
      <data key="d7">1.0</data>
      <data key="d8">The joint entropy of P and W is maximized under constraints in the generalized maximum entropy Markov problem.</data>
      <data key="d9">entropy maximization,optimization target</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973469</data>
      <data key="d13" />
    </edge>
    <edge source="条件熵" target="随机变量">
      <data key="d7">1.0</data>
      <data key="d8">Conditional entropy measures the uncertainty of one random variable given the knowledge of another random variable.</data>
      <data key="d9">conditional probability,information theory</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972932</data>
      <data key="d13" />
    </edge>
    <edge source="条件熵" target="互信息">
      <data key="d7">1.0</data>
      <data key="d8">Mutual information can also be expressed as the reduction in uncertainty (entropy) of one variable given knowledge of another, linking it to conditional entropy.</data>
      <data key="d9">conditional information,information theory</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972933</data>
      <data key="d13" />
    </edge>
    <edge source="互信息" target="随机变量">
      <data key="d7">1.0</data>
      <data key="d8">Mutual information quantifies the amount of information shared between two random variables.</data>
      <data key="d9">dependency,shared information</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972933</data>
      <data key="d13" />
    </edge>
    <edge source="对数似然比" target="编码长度">
      <data key="d7">1.0</data>
      <data key="d8">The log-likelihood ratio directly describes the difference in coding length for a symbol between two coding schemes.</data>
      <data key="d9">coding theory,information measure</data>
      <data key="d10">chunk-b0156872199d42b66461b7109077a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972932</data>
      <data key="d13" />
    </edge>
    <edge source="www.showmeai.tech" target="Security Certificate">
      <data key="d7">2.0</data>
      <data key="d8">The website www.showmeai.tech is supposed to be verified by a security certificate, but the certificate has expired.&lt;SEP&gt;The website www.showmeai.tech possesses a security certificate to authenticate its identity.</data>
      <data key="d9">ownership,security,verification</data>
      <data key="d10">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976099</data>
      <data key="d13" />
    </edge>
    <edge source="www.showmeai.tech" target="Attackers">
      <data key="d7">1.0</data>
      <data key="d8">Attackers might try to steal information from users visiting the website www.showmeai.tech due to its insecure connection.</data>
      <data key="d9">exploitation,threat</data>
      <data key="d10">chunk-03892a1548c3ca50ed164db6a524dac7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972965</data>
      <data key="d13" />
    </edge>
    <edge source="TrustAsia DV TLS RSA CA 2025" target="Security Certificate">
      <data key="d7">2.0</data>
      <data key="d8">The organization TrustAsia DV TLS RSA CA 2025 issued the security certificate for the website.&lt;SEP&gt;The Certificate Authority TrustAsia DV TLS RSA CA 2025 issued the security certificate for the website.</data>
      <data key="d9">authority,issuance</data>
      <data key="d10">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976099</data>
      <data key="d13" />
    </edge>
    <edge source="Security Certificate" target="ERR_CERT_DATE_INVALID">
      <data key="d7">2.0</data>
      <data key="d8">The error ERR_CERT_DATE_INVALID is triggered because the security certificate's validity date has passed.&lt;SEP&gt;The expiration of the security certificate triggers the ERR_CERT_DATE_INVALID browser error.</data>
      <data key="d9">error,expiration,validation</data>
      <data key="d10">chunk-03892a1548c3ca50ed164db6a524dac7&lt;SEP&gt;chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976100</data>
      <data key="d13" />
    </edge>
    <edge source="Security Certificate" target="PEM Encoded Chain">
      <data key="d7">1.0</data>
      <data key="d8">The security certificate's data is encoded and presented as a PEM encoded chain.</data>
      <data key="d9">data representation,encoding</data>
      <data key="d10">chunk-03892a1548c3ca50ed164db6a524dac7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972966</data>
      <data key="d13" />
    </edge>
    <edge source="Security Certificate" target="Nov 12, 2025">
      <data key="d7">1.0</data>
      <data key="d8">The security certificate was set to expire on November 12, 2025.</data>
      <data key="d9">attribute,expiration date</data>
      <data key="d10">chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976100</data>
      <data key="d13" />
    </edge>
    <edge source="ERR_CERT_DATE_INVALID" target="System Clock">
      <data key="d7">1.0</data>
      <data key="d8">The error may be caused by an incorrect system clock date, which should be corrected.</data>
      <data key="d9">error cause,system configuration</data>
      <data key="d10">chunk-03892a1548c3ca50ed164db6a524dac7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972966</data>
      <data key="d13" />
    </edge>
    <edge source="ERR_CERT_DATE_INVALID" target="Jan 13, 2026">
      <data key="d7">1.0</data>
      <data key="d8">The error occurs because the current date, January 13, 2026, is after the certificate's expiration date.</data>
      <data key="d9">date comparison,error cause</data>
      <data key="d10">chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976100</data>
      <data key="d13" />
    </edge>
    <edge source="Attackers" target="Information">
      <data key="d7">1.0</data>
      <data key="d8">Attackers aim to steal sensitive information like passwords and credit cards from users.</data>
      <data key="d9">target,theft</data>
      <data key="d10">chunk-03892a1548c3ca50ed164db6a524dac7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768972966</data>
      <data key="d13" />
    </edge>
    <edge source="老饼" target="矩阵LU分解">
      <data key="d7">1.0</data>
      <data key="d8">老饼authored introductory articles explaining the matrix LU decomposition method.</data>
      <data key="d9">authoring,explanation</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973028</data>
      <data key="d13" />
    </edge>
    <edge source="老饼" target="老饼讲解-机器学习">
      <data key="d7">1.0</data>
      <data key="d8">老饼is the creator or contributor to the "老饼讲解-机器学习" content series/website.</data>
      <data key="d9">affiliation,content creation</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973029</data>
      <data key="d13" />
    </edge>
    <edge source="矩阵LU分解" target="Doolittle分解">
      <data key="d7">1.0</data>
      <data key="d8">Doolittle decomposition is a specific type of LU matrix decomposition.</data>
      <data key="d9">decomposition type,method variant</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973029</data>
      <data key="d13" />
    </edge>
    <edge source="矩阵LU分解" target="Crout分解">
      <data key="d7">1.0</data>
      <data key="d8">Crout decomposition is a specific type of LU matrix decomposition.</data>
      <data key="d9">decomposition type,method variant</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973032</data>
      <data key="d13" />
    </edge>
    <edge source="矩阵LU分解" target="Cholesky分解">
      <data key="d7">1.0</data>
      <data key="d8">Cholesky decomposition is a specific type of LU matrix decomposition.</data>
      <data key="d9">decomposition type,method variant</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973041</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="分布">
      <data key="d7">1.0</data>
      <data key="d8">KL divergence is used to calculate the distance or difference between two probability distributions.</data>
      <data key="d9">distance calculation,measurement</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973028</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="Kullback-Leibler Divergence">
      <data key="d7">1.0</data>
      <data key="d8">KL散度is the Chinese term for Kullback-Leibler Divergence.</data>
      <data key="d9">terminology,translation</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973041</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="Distribution Q(X)">
      <data key="d7">1.0</data>
      <data key="d8">KL散度measures the difference between the cognitive distribution Q(X) and the true distribution.</data>
      <data key="d9">comparison,measurement</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973041</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="Distribution P(X)">
      <data key="d7">1.0</data>
      <data key="d8">KL散度measures the difference between the cognitive distribution and the true distribution P(X).</data>
      <data key="d9">comparison,measurement</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973042</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="KL Divergence Formula">
      <data key="d7">1.0</data>
      <data key="d8">KL散度is defined and calculated by the KL Divergence Formula.</data>
      <data key="d9">calculation,definition</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973042</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="分布P">
      <data key="d7">1.0</data>
      <data key="d8">KL散度用于度量基于分布Q的编码对来自分布P的样本进行编码所需的额外成本。</data>
      <data key="d9">度量,编码</data>
      <data key="d10">chunk-e7d56d1a1382da4ef9c8e90e4d8fd39f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973050</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="分布Q">
      <data key="d7">1.0</data>
      <data key="d8">KL散度用于度量使用基于分布Q的编码来编码样本所需的额外比特数。</data>
      <data key="d9">度量,编码</data>
      <data key="d10">chunk-e7d56d1a1382da4ef9c8e90e4d8fd39f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973050</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="Kullback–Leibler Divergence">
      <data key="d7">1.0</data>
      <data key="d8">KL散度is the abbreviated Chinese term for Kullback–Leibler divergence.</data>
      <data key="d9">abbreviation,full name</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973151</data>
      <data key="d13" />
    </edge>
    <edge source="KL散度" target="KLD">
      <data key="d7">1.0</data>
      <data key="d8">KL散度is also abbreviated as KLD.</data>
      <data key="d9">abbreviation,acronym</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973152</data>
      <data key="d13" />
    </edge>
    <edge source="分布" target="字母">
      <data key="d7">1.0</data>
      <data key="d8">所有字母的出现概率共同构成了一个概率分布。</data>
      <data key="d9">描述,遵循</data>
      <data key="d10">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974466</data>
      <data key="d13" />
    </edge>
    <edge source="老饼讲解-机器学习" target="www.bbbdata.com">
      <data key="d7">1.0</data>
      <data key="d8">The content "老饼讲解-机器学习" is hosted at the website www.bbbdata.com.</data>
      <data key="d9">hosting,website address</data>
      <data key="d10">chunk-bcb9e2b1f343c904193b0f647416ae0e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973032</data>
      <data key="d13" />
    </edge>
    <edge source="分布Q" target="基于Q的编码">
      <data key="d7">1.0</data>
      <data key="d8">分布Q是构建基于Q的编码方法所依据的理论分布。</data>
      <data key="d9">理论依据,编码基础</data>
      <data key="d10">chunk-e7d56d1a1382da4ef9c8e90e4d8fd39f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973050</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="信息增益决策树">
      <data key="d7">1.0</data>
      <data key="d8">Information gain is the core criterion used by the information gain decision tree algorithm to determine how to split nodes.</data>
      <data key="d9">algorithm criterion,node splitting</data>
      <data key="d10">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975749</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="决策树">
      <data key="d7">2.0</data>
      <data key="d8">信息增益是用于度量特征对于决策树贡献的度量标准。&lt;SEP&gt;When implementing a decision tree by hand, selecting the best split feature involves criteria like information gain.</data>
      <data key="d9">feature selection,model implementation,度量标准,贡献评估</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6&lt;SEP&gt;chunk-a79596200294b5109fdd0cf885110f83</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975822</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="特征">
      <data key="d7">1.0</data>
      <data key="d8">信息增益用于度量特征的重要性。</data>
      <data key="d9">特征选择,重要性度量</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975797</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="公式">
      <data key="d7">1.0</data>
      <data key="d8">信息增益可以通过一个特定的公式进行计算。</data>
      <data key="d9">数学定义,计算方法</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975798</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="信息增益比">
      <data key="d7">1.0</data>
      <data key="d8">信息增益比是在信息增益基础上发展而来的改进标准，旨在减少对取值较多特征的偏向。</data>
      <data key="d9">evolution,improvement</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975933</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="基尼系数">
      <data key="d7">1.0</data>
      <data key="d8">基尼系数是作为信息增益(和信息增益比)的替代品出现的，用于避免基于熵模型的对数运算。</data>
      <data key="d9">alternative,comparison</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975934</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="ID3">
      <data key="d7">2.0</data>
      <data key="d8">ID3算法使用信息增益作为其核心特征选择的标准。&lt;SEP&gt;The ID3 algorithm uses information gain as a metric to evaluate candidate splits.</data>
      <data key="d9">core concept,evaluation metric,feature selection,split criterion</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976056</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="特征A_g">
      <data key="d7">1.0</data>
      <data key="d8">信息增益被用作度量标准来选择最优划分特征A_g。</data>
      <data key="d9">度量标准,特征选择</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975940</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="阈值ε">
      <data key="d7">1.0</data>
      <data key="d8">阈值ε被用作判断信息增益是否足够大的停止条件，若信息增益小于ε则停止划分。</data>
      <data key="d9">停止条件,参数判断</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975941</data>
      <data key="d13" />
    </edge>
    <edge source="信息增益" target="C4.5">
      <data key="d7">1.0</data>
      <data key="d8">The C4.5 algorithm can use information gain to evaluate splits.</data>
      <data key="d9">evaluation metric,split criterion</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976058</data>
      <data key="d13" />
    </edge>
    <edge source="变分自编码器" target="Diederik P. Kingma">
      <data key="d7">1.0</data>
      <data key="d8">Diederik P. Kingma, along with Max Welling, proposed the variational autoencoder in 2013.</data>
      <data key="d9">development,proposal</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973155</data>
      <data key="d13" />
    </edge>
    <edge source="变分自编码器" target="Max Welling">
      <data key="d7">1.0</data>
      <data key="d8">Max Welling, along with Diederik P. Kingma, proposed the variational autoencoder in 2013.</data>
      <data key="d9">development,proposal</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973156</data>
      <data key="d13" />
    </edge>
    <edge source="Focal-KLD" target="Shuai Wang">
      <data key="d7">1.0</data>
      <data key="d8">Shuai Wang and colleagues developed Focal-KLD, a modified version of KL divergence, in 2018.</data>
      <data key="d9">development,modification</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973149</data>
      <data key="d13" />
    </edge>
    <edge source="Focal-KLD" target="单通道多说话人识别框架">
      <data key="d7">1.0</data>
      <data key="d8">Focal-KLD was applied to a neural network-based single-channel multi-speaker recognition framework as an improvement proposed by Shuai Wang et al.</data>
      <data key="d9">application,improvement</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973150</data>
      <data key="d13" />
    </edge>
    <edge source="Focal-KLD" target="Hard Samples">
      <data key="d7">1.0</data>
      <data key="d8">Focal-KLD modifies the standard KL divergence to give more weight to hard samples during model training.</data>
      <data key="d9">training focus,weighting</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973155</data>
      <data key="d13" />
    </edge>
    <edge source="Shuai Wang" target="92.47% Correct Rate">
      <data key="d7">1.0</data>
      <data key="d8">Shuai Wang and colleagues achieved a 92.47% correct rate for two-speaker recognition with their improved system.</data>
      <data key="d9">achievement,experimental result</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973156</data>
      <data key="d13" />
    </edge>
    <edge source="Shuai Wang" target="55.83% Correct Rate">
      <data key="d7">1.0</data>
      <data key="d8">Shuai Wang and colleagues achieved a 55.83% correct rate for three-speaker recognition with their improved system.</data>
      <data key="d9">achievement,experimental result</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973157</data>
      <data key="d13" />
    </edge>
    <edge source="单通道多说话人识别框架" target="Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">The single-channel multi-speaker recognition framework is based on a neural network architecture.</data>
      <data key="d9">foundation,implementation</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973155</data>
      <data key="d13" />
    </edge>
    <edge source="单通道多说话人识别框架" target="Baseline System">
      <data key="d7">1.0</data>
      <data key="d8">The improved single-channel multi-speaker recognition framework was compared against a baseline system.</data>
      <data key="d9">comparison,performance benchmark</data>
      <data key="d10">chunk-0c9d3f43376e35055643ae46b0d5a233</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973156</data>
      <data key="d13" />
    </edge>
    <edge source="目标函数" target="比较学习">
      <data key="d7">1.0</data>
      <data key="d8">目标函数在比较学习方法中被使用。</data>
      <data key="d9">功能组件,方法应用</data>
      <data key="d10">chunk-726d03cb1277ab1c0a32f929ee13c3fc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973179</data>
      <data key="d13" />
    </edge>
    <edge source="目标函数" target="网络熵">
      <data key="d7">1.0</data>
      <data key="d8">网络熵被用作需要最大化的目标函数。</data>
      <data key="d9">优化目标</data>
      <data key="d10">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973223</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="最大熵原理">
      <data key="d7">1.0</data>
      <data key="d8">最大熵模型是基于最大熵原理构建的。</data>
      <data key="d9">模型构建,理论基础</data>
      <data key="d10">chunk-d4b315e54e592e86c3a5acfef7099954</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973198</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="对数线性分类模型">
      <data key="d7">1.0</data>
      <data key="d8">最大熵模型是一种具体的对数线性分类模型。</data>
      <data key="d9">分类,算法类型</data>
      <data key="d10">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973247</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="逻辑回归">
      <data key="d7">1.0</data>
      <data key="d8">最大熵模型和逻辑回归在算法类型上类似，都属于对数线性分类模型。</data>
      <data key="d9">相似性,算法对比</data>
      <data key="d10">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973248</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="损失函数">
      <data key="d7">1.0</data>
      <data key="d8">最大熵模型在优化过程中会使用损失函数来调整模型参数。</data>
      <data key="d9">优化,算法组件</data>
      <data key="d10">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973249</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="特征函数">
      <data key="d7">1.0</data>
      <data key="d8">最大熵模型使用特征函数来处理提取的特征。</data>
      <data key="d9">数学工具,模型组件</data>
      <data key="d10">chunk-8985837bff3264915ed561ec4d80111b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973263</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="特征">
      <data key="d7">1.0</data>
      <data key="d8">最大熵模型的主要工作在于(人工)提取特征，特征是该模型的输入和处理对象。</data>
      <data key="d9">数据处理,模型输入</data>
      <data key="d10">chunk-8985837bff3264915ed561ec4d80111b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973264</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="文本分类">
      <data key="d7">1.0</data>
      <data key="d8">最大熵模型被应用于文本分类任务中。</data>
      <data key="d9">应用,模型</data>
      <data key="d10">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973290</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="分类问题">
      <data key="d7">1.0</data>
      <data key="d8">Maximum entropy models were historically used for classification problems.</data>
      <data key="d9">application,historical usage</data>
      <data key="d10">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976255</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵模型" target="深度学习算法">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning algorithms have largely replaced maximum entropy models for classification due to superior performance.</data>
      <data key="d9">comparison,replacement</data>
      <data key="d10">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976256</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="均匀分布">
      <data key="d7">1.0</data>
      <data key="d8">在没有任何约束的情况下，最大熵原理选择均匀分布作为最佳模型。</data>
      <data key="d9">应用示例,无约束情况</data>
      <data key="d10">chunk-d4b315e54e592e86c3a5acfef7099954</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973198</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="Scharfenaker">
      <data key="d7">1.0</data>
      <data key="d8">Scharfenaker and Foley adopted the maximum entropy principle to develop a statistical equilibrium of quantal response.</data>
      <data key="d9">application,model development</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973459</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="Foley">
      <data key="d7">1.0</data>
      <data key="d8">Scharfenaker and Foley adopted the maximum entropy principle to develop a statistical equilibrium of quantal response.</data>
      <data key="d9">application,model development</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973460</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="最大熵原理马尔可夫问题">
      <data key="d7">1.0</data>
      <data key="d8">The maximum entropy principle opens a path for modeling conditional Markov processes in complex systems with evolving data.</data>
      <data key="d9">complex systems modeling,generalization</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973463</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="经济学">
      <data key="d7">1.0</data>
      <data key="d8">The maximum entropy principle is frequently applied in economics to solve problems like matrix balancing and infer economic distributions.</data>
      <data key="d9">application,theoretical tool</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973469</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="METE (生态学最大熵原理)">
      <data key="d7">1.0</data>
      <data key="d8">METE is a specific ecological theory built upon the general framework of the maximum entropy principle.</data>
      <data key="d9">specialization,theoretical foundation</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973471</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="Golan">
      <data key="d7">1.0</data>
      <data key="d8">Golan applied the maximum entropy principle to develop a stochastic theory for the distribution of firm sizes in an economy.</data>
      <data key="d9">application,theory development</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973472</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="矩阵平衡问题">
      <data key="d7">1.0</data>
      <data key="d8">The maximum entropy principle provides a method for solving matrix balancing problems under linear and normalization constraints.</data>
      <data key="d9">application,solution method</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973473</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="马尔科夫例子">
      <data key="d7">1.0</data>
      <data key="d8">The Markov example is presented as a generalization of the simple maximum entropy model used for matrix balancing.</data>
      <data key="d9">generalization,model extension</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973481</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理" target="广义的最大熵原理马尔可夫问题">
      <data key="d7">1.0</data>
      <data key="d8">The generalized maximum entropy principle Markov problem shares the same dimensionality (number of constraints and Lagrange multipliers) as the maximum entropy principle.</data>
      <data key="d9">dimensionality,generalization</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973482</data>
      <data key="d13" />
    </edge>
    <edge source="均匀分布" target="先验分布">
      <data key="d7">1.0</data>
      <data key="d8">当先验分布为均匀分布时，最大后验估计退化为最大似然估计。</data>
      <data key="d9">特定条件,简化</data>
      <data key="d10">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976217</data>
      <data key="d13" />
    </edge>
    <edge source="概率约束" target="模型">
      <data key="d7">1.0</data>
      <data key="d8">模型构建中包含了概率约束。</data>
      <data key="d9">约束条件</data>
      <data key="d10">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973223</data>
      <data key="d13" />
    </edge>
    <edge source="成本约束" target="模型">
      <data key="d7">1.0</data>
      <data key="d8">模型构建中包含了成本约束。</data>
      <data key="d9">约束条件</data>
      <data key="d10">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973223</data>
      <data key="d13" />
    </edge>
    <edge source="空间约束" target="模型">
      <data key="d7">1.0</data>
      <data key="d8">模型构建中包含了空间约束。</data>
      <data key="d9">约束条件</data>
      <data key="d10">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973224</data>
      <data key="d13" />
    </edge>
    <edge source="模型" target="物种">
      <data key="d7">1.0</data>
      <data key="d8">模型在各种物种中进行了拟合验证。</data>
      <data key="d9">应用验证</data>
      <data key="d10">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973224</data>
      <data key="d13" />
    </edge>
    <edge source="模型" target="解">
      <data key="d7">1.0</data>
      <data key="d8">模型有一个唯一的解。</data>
      <data key="d9">唯一性,模型属性</data>
      <data key="d10">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973224</data>
      <data key="d13" />
    </edge>
    <edge source="模型" target="拟合效果">
      <data key="d7">1.0</data>
      <data key="d8">模型在各种物种中表现出相当好的拟合效果。</data>
      <data key="d9">性能评估,模型验证</data>
      <data key="d10">chunk-e4d6318364157e6228ebc39c8c646b45</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973224</data>
      <data key="d13" />
    </edge>
    <edge source="模型" target="Bayes分类">
      <data key="d7">1.0</data>
      <data key="d8">A model is the implementation or representation form of Bayes classification.</data>
      <data key="d9">implementation,representation</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976209</data>
      <data key="d13" />
    </edge>
    <edge source="逻辑回归" target="对数线性分类模型">
      <data key="d7">1.0</data>
      <data key="d8">逻辑回归是一种具体的对数线性分类模型。</data>
      <data key="d9">分类,算法类型</data>
      <data key="d10">chunk-f34ecacf5f99ee02bae6647b8bd65153</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973249</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="神经网络">
      <data key="d7">1.0</data>
      <data key="d8">在用于分类问题的神经网络训练中，损失函数得到了广泛应用，用于评估和优化模型。</data>
      <data key="d9">性能评估,训练工具</data>
      <data key="d10">chunk-6135ecccd835afdfdaba2f58578ed61e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973894</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="人工智能模型">
      <data key="d7">1.0</data>
      <data key="d8">损失函数用于追踪和量化人工智能模型输出的错误程度。</data>
      <data key="d9">评估,量化</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975708</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="均方误差">
      <data key="d7">1.0</data>
      <data key="d8">均方误差是损失函数的一种特定类型，通常用作回归算法的默认函数。</data>
      <data key="d9">回归,类型</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975709</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="平均绝对误差">
      <data key="d7">1.0</data>
      <data key="d8">平均绝对误差是损失函数的一种类型，以其对异常值的鲁棒性为特点。</data>
      <data key="d9">类型,鲁棒性</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975711</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="分类交叉熵损失">
      <data key="d7">1.0</data>
      <data key="d8">分类交叉熵损失是损失函数的一种类型，专门应用于多类分类问题。</data>
      <data key="d9">分类,类型</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975711</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="铰链损失">
      <data key="d7">1.0</data>
      <data key="d8">铰链损失是损失函数的一种类型，用于特定的分类算法。</data>
      <data key="d9">分类,类型</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975720</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="经验熵">
      <data key="d7">1.0</data>
      <data key="d8">损失函数是叶结点经验熵的期望，经验熵是计算损失函数的基础组成部分。</data>
      <data key="d9">组成部分,计算依据</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975936</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="剪枝">
      <data key="d7">1.0</data>
      <data key="d8">剪枝过程通过比较剪枝前后的损失函数值来决定是否进行剪枝，以优化模型。</data>
      <data key="d9">优化目标,评估标准</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975937</data>
      <data key="d13" />
    </edge>
    <edge source="Softmax" target="多分类问题">
      <data key="d7">1.0</data>
      <data key="d8">Softmax函数常用于解决多分类问题。</data>
      <data key="d9">函数,应用</data>
      <data key="d10">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973290</data>
      <data key="d13" />
    </edge>
    <edge source="Softmax" target="输出层">
      <data key="d7">1.0</data>
      <data key="d8">Softmax函数作用于神经网络的输出层，将其连续值转换为概率。</data>
      <data key="d9">组件,转换</data>
      <data key="d10">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973291</data>
      <data key="d13" />
    </edge>
    <edge source="Softmax函数" target="连续值">
      <data key="d7">1.0</data>
      <data key="d8">Softmax函数将输出层的连续值作为输入进行转换。</data>
      <data key="d9">转换,输入</data>
      <data key="d10">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973290</data>
      <data key="d13" />
    </edge>
    <edge source="Softmax函数" target="类别">
      <data key="d7">1.0</data>
      <data key="d8">Softmax函数为每个类别计算一个概率值。</data>
      <data key="d9">分配,计算</data>
      <data key="d10">chunk-23713b5f1cb0ee19178382510009449e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973291</data>
      <data key="d13" />
    </edge>
    <edge source="类别" target="分类任务">
      <data key="d7">1.0</data>
      <data key="d8">分类任务的目标是将输入数据分配到预定义的类别中。</data>
      <data key="d9">定义,目标输出</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974424</data>
      <data key="d13" />
    </edge>
    <edge source="随机理论" target="参考文献[16]">
      <data key="d7">1.0</data>
      <data key="d8">References [16] and [75] extend the random theory to a general equilibrium model of a complex economy.</data>
      <data key="d9">economic modeling,theory extension</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973458</data>
      <data key="d13" />
    </edge>
    <edge source="随机理论" target="参考文献[75]">
      <data key="d7">1.0</data>
      <data key="d8">References [16] and [75] extend the random theory to a general equilibrium model of a complex economy.</data>
      <data key="d9">economic modeling,theory extension</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973458</data>
      <data key="d13" />
    </edge>
    <edge source="参考文献[16]" target="复杂经济体">
      <data key="d7">1.0</data>
      <data key="d8">Reference [16] extends the theory to a general equilibrium model of a complex economy.</data>
      <data key="d9">economic theory,model application</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973462</data>
      <data key="d13" />
    </edge>
    <edge source="参考文献[75]" target="复杂经济体">
      <data key="d7">1.0</data>
      <data key="d8">Reference [75] extends the theory to a general equilibrium model of a complex economy.</data>
      <data key="d9">economic theory,model application</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973463</data>
      <data key="d13" />
    </edge>
    <edge source="Foley" target="统计均衡理论">
      <data key="d7">1.0</data>
      <data key="d8">Foley developed the statistical equilibrium theory of markets.</data>
      <data key="d9">market analysis,theory development</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973458</data>
      <data key="d13" />
    </edge>
    <edge source="Foley" target="市场的统计均衡理论">
      <data key="d7">1.0</data>
      <data key="d8">Foley developed a statistical equilibrium theory of markets, contributing to economic theory using statistical and maximum entropy concepts.</data>
      <data key="d9">development,theoretical contribution</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973472</data>
      <data key="d13" />
    </edge>
    <edge source="Foley" target="报价集">
      <data key="d7">1.0</data>
      <data key="d8">Foley's statistical equilibrium theory of markets begins with the analysis of sets of offers from market participants.</data>
      <data key="d9">analysis foundation,market theory</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973475</data>
      <data key="d13" />
    </edge>
    <edge source="统计均衡理论" target="报价集">
      <data key="d7">1.0</data>
      <data key="d8">Market analysis in the statistical equilibrium theory begins with the set of offers from market agents.</data>
      <data key="d9">foundational concept,market mechanism</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973458</data>
      <data key="d13" />
    </edge>
    <edge source="统计均衡理论" target="市场">
      <data key="d7">1.0</data>
      <data key="d8">The statistical equilibrium theory describes how the market allocates agents to maximize entropy.</data>
      <data key="d9">allocation mechanism,theoretical framework</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973462</data>
      <data key="d13" />
    </edge>
    <edge source="报价集" target="市场主体">
      <data key="d7">1.0</data>
      <data key="d8">Market agents have sets of offers that are conditioned on their information, technology, endowments, and preferences.</data>
      <data key="d9">conditional offers,possession</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973462</data>
      <data key="d13" />
    </edge>
    <edge source="McKelvey" target="随机最优反应均衡">
      <data key="d7">1.0</data>
      <data key="d8">McKelvey and Palfrey adopted a statistical approach to establish the quantal response equilibrium (QRE) in a game theory setting.</data>
      <data key="d9">game theory,model development</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973458</data>
      <data key="d13" />
    </edge>
    <edge source="McKelvey" target="数量选择模型">
      <data key="d7">1.0</data>
      <data key="d8">McKelvey and Palfrey used a quantal choice model in their game theory setting.</data>
      <data key="d9">game theory,method adoption</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973471</data>
      <data key="d13" />
    </edge>
    <edge source="Palfrey" target="随机最优反应均衡">
      <data key="d7">1.0</data>
      <data key="d8">McKelvey and Palfrey adopted a statistical approach to establish the quantal response equilibrium (QRE) in a game theory setting.</data>
      <data key="d9">game theory,model development</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973459</data>
      <data key="d13" />
    </edge>
    <edge source="Palfrey" target="数量选择模型">
      <data key="d7">1.0</data>
      <data key="d8">McKelvey and Palfrey used a quantal choice model in their game theory setting.</data>
      <data key="d9">game theory,method adoption</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973465</data>
      <data key="d13" />
    </edge>
    <edge source="随机最优反应均衡" target="量子响应均衡">
      <data key="d7">1.0</data>
      <data key="d8">The random optimal response equilibrium is also known as the Quantal Response Equilibrium (QRE).</data>
      <data key="d9">alternative name,concept equivalence</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973460</data>
      <data key="d13" />
    </edge>
    <edge source="随机最优反应均衡" target="Logit均衡">
      <data key="d7">1.0</data>
      <data key="d8">A specific parameter class of quantal response functions produces a Logit equilibrium.</data>
      <data key="d9">parameter class,specific instance</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973462</data>
      <data key="d13" />
    </edge>
    <edge source="随机最优反应均衡" target="误差结构">
      <data key="d7">1.0</data>
      <data key="d8">The Quantal Response Equilibrium is a fixed point of a process given a specific error structure.</data>
      <data key="d9">dependence,model assumption</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973463</data>
      <data key="d13" />
    </edge>
    <edge source="随机最优反应均衡" target="反应函数">
      <data key="d7">1.0</data>
      <data key="d8">The QRE process results in probabilistic reaction functions.</data>
      <data key="d9">probabilistic output,result</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973466</data>
      <data key="d13" />
    </edge>
    <edge source="非平衡热力学系统" target="生态学">
      <data key="d7">1.0</data>
      <data key="d8">Like disturbed ecosystems and transitioning economies, non-equilibrium thermodynamic systems are examples where changing state variables lead to prediction failures.</data>
      <data key="d9">prediction failure,shared characteristic</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973464</data>
      <data key="d13" />
    </edge>
    <edge source="马尔可夫过程" target="条件概率">
      <data key="d7">1.0</data>
      <data key="d8">Conditional probability rules are used to compute system states in Markov processes.</data>
      <data key="d9">computational tool,state transition</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973460</data>
      <data key="d13" />
    </edge>
    <edge source="马尔可夫过程" target="物种的种群增长">
      <data key="d7">1.0</data>
      <data key="d8">Markov processes are used to model dynamic processes such as population growth of species.</data>
      <data key="d9">application,dynamic modeling</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973464</data>
      <data key="d13" />
    </edge>
    <edge source="马尔可夫过程" target="金融市场">
      <data key="d7">1.0</data>
      <data key="d8">Markov processes are used to model dynamic processes such as the progression of securities in financial markets.</data>
      <data key="d9">application,dynamic modeling</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973467</data>
      <data key="d13" />
    </edge>
    <edge source="马尔可夫过程" target="等级组织">
      <data key="d7">1.0</data>
      <data key="d8">Markov processes are used to model dynamic processes such as promotions in hierarchical organizations.</data>
      <data key="d9">application,dynamic modeling</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973469</data>
      <data key="d13" />
    </edge>
    <edge source="条件概率" target="外生变量">
      <data key="d7">1.0</data>
      <data key="d8">Transitions in Markov processes can be conditioned on exogenous variables to infer causal effects.</data>
      <data key="d9">causal inference,conditioning factor</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973466</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理马尔可夫问题" target="香农熵">
      <data key="d7">1.0</data>
      <data key="d8">In the maximum entropy inference problem, Shannon entropy needs to be defined for the probability distributions P and W.</data>
      <data key="d9">definition requirement,probability distributions</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973460</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理马尔可夫问题" target="拉格朗日乘子">
      <data key="d7">1.0</data>
      <data key="d8">Lagrange multipliers are inferred simultaneously with transition probabilities and uncertainty during the optimization of the generalized maximum entropy Markov problem.</data>
      <data key="d9">optimization parameter,simultaneous inference</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973462</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理马尔可夫问题" target="观察到的信息Y和X">
      <data key="d7">1.0</data>
      <data key="d8">The generalized maximum entropy Markov problem aims to infer transition probabilities and uncertainty given observed information Y and X.</data>
      <data key="d9">inference basis,input data</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973467</data>
      <data key="d13" />
    </edge>
    <edge source="最大熵原理马尔可夫问题" target="过渡概率">
      <data key="d7">1.0</data>
      <data key="d8">Transition probabilities (P) are one of the outputs inferred in the optimization of the maximum entropy Markov problem.</data>
      <data key="d9">inferred parameter,output</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973470</data>
      <data key="d13" />
    </edge>
    <edge source="香农熵" target="测试用例">
      <data key="d7">1.0</data>
      <data key="d8">The function based on Shannon entropy measures the misclassification likelihood of test cases and ranks them.</data>
      <data key="d9">measurement,ranking</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974173</data>
      <data key="d13" />
    </edge>
    <edge source="香农熵" target="本发明">
      <data key="d7">1.0</data>
      <data key="d8">The invention defines and applies a function based on Shannon entropy.</data>
      <data key="d9">application,definition</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974176</data>
      <data key="d13" />
    </edge>
    <edge source="DynaMETE" target="广义的最大熵原理马尔可夫问题">
      <data key="d7">1.0</data>
      <data key="d8">The generalized method discussed can be simplified to DynaMETE under conditions of no uncertainty and a system in a steady state.</data>
      <data key="d9">condition,simplification</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973483</data>
      <data key="d13" />
    </edge>
    <edge source="MET E" target="广义的最大熵原理马尔可夫问题">
      <data key="d7">1.0</data>
      <data key="d8">The generalized method discussed can be simplified to MET E under conditions of no uncertainty and a system in a steady state.</data>
      <data key="d9">condition,simplification</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973484</data>
      <data key="d13" />
    </edge>
    <edge source="不确定性" target="概率分布W">
      <data key="d7">1.0</data>
      <data key="d8">Uncertainty is treated as a random variable with a probability distribution W.</data>
      <data key="d9">random variable,representation</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973467</data>
      <data key="d13" />
    </edge>
    <edge source="不确定性" target="广义方法">
      <data key="d7">1.0</data>
      <data key="d8">The generalized method simplifies to classical principles under the condition of no uncertainty.</data>
      <data key="d9">simplification condition</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973484</data>
      <data key="d13" />
    </edge>
    <edge source="不确定性" target="MaxCal">
      <data key="d7">1.0</data>
      <data key="d8">MaxCal converges to the same result as other methods when there is no uncertainty.</data>
      <data key="d9">convergence condition</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973486</data>
      <data key="d13" />
    </edge>
    <edge source="过渡概率" target="因果解释">
      <data key="d7">1.0</data>
      <data key="d8">Each exogenous variable has a direct causal interpretation regarding its impact on the inferred transition probabilities.</data>
      <data key="d9">interpretation,variable impact</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973469</data>
      <data key="d13" />
    </edge>
    <edge source="因果解释" target="连续外生变量">
      <data key="d7">1.0</data>
      <data key="d8">Causal effects can be calculated for continuous exogenous variables.</data>
      <data key="d9">calculation applicability,variable type</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973470</data>
      <data key="d13" />
    </edge>
    <edge source="因果解释" target="离散外生变量">
      <data key="d7">1.0</data>
      <data key="d8">Causal effects can be calculated for discrete exogenous variables.</data>
      <data key="d9">calculation applicability,variable type</data>
      <data key="d10">chunk-1aee14dcece6506b2fb182a424fefbd5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973471</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="生态结构函数">
      <data key="d7">1.0</data>
      <data key="d8">The ecological structure function is a core probability distribution derived within the METE framework to describe species and individual attributes.</data>
      <data key="d9">core component,prediction</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973472</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="空间分布">
      <data key="d7">1.0</data>
      <data key="d8">The spatial distribution is a core probability distribution in METE that predicts how individuals of a species are aggregated in space.</data>
      <data key="d9">core component,prediction</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973481</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="状态变量">
      <data key="d7">1.0</data>
      <data key="d8">METE's probability distributions are conditioned on state variables like area, species count, and total metabolism, which define the ecological system.</data>
      <data key="d9">conditioning,system definition</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973474</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="物种丰度">
      <data key="d7">1.0</data>
      <data key="d8">METE predicts the distribution of species abundance as one of its testable ecological outcomes.</data>
      <data key="d9">ecological pattern,prediction</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973475</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="个体代谢率">
      <data key="d7">1.0</data>
      <data key="d8">METE predicts the distribution of individual metabolic rates as one of its testable ecological outcomes.</data>
      <data key="d9">ecological pattern,prediction</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973476</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="种内空间聚集度">
      <data key="d7">1.0</data>
      <data key="d8">METE predicts the degree of spatial aggregation of individuals within a species.</data>
      <data key="d9">ecological pattern,prediction</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973477</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="物种多样性">
      <data key="d7">1.0</data>
      <data key="d8">METE predicts how species diversity depends on the sampling area.</data>
      <data key="d9">ecological pattern,prediction</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973479</data>
      <data key="d13" />
    </edge>
    <edge source="METE (生态学最大熵原理)" target="状态方程">
      <data key="d7">1.0</data>
      <data key="d8">METE yields equations of state that relate biomass, metabolic rate, abundance, and species diversity.</data>
      <data key="d9">prediction,theoretical relationship</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973482</data>
      <data key="d13" />
    </edge>
    <edge source="生态结构函数" target="空间分布">
      <data key="d7">1.0</data>
      <data key="d8">Together, the ecological structure function and the spatial distribution form the basis for generating testable ecological predictions within METE.</data>
      <data key="d9">complementary distributions,ecological prediction</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973473</data>
      <data key="d13" />
    </edge>
    <edge source="生态结构函数" target="代谢比例定律">
      <data key="d7">1.0</data>
      <data key="d8">The metabolic scaling law is an assumption used to infer metabolic rates for the ecological structure function when direct measurement is not possible.</data>
      <data key="d9">assumption,inference</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973474</data>
      <data key="d13" />
    </edge>
    <edge source="Jaynes" target="统计力学">
      <data key="d7">1.0</data>
      <data key="d8">Jaynes derived statistical mechanics using the maximum entropy principle, which enabled many subsequent applications in various fields.</data>
      <data key="d9">derivation,foundational work</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973471</data>
      <data key="d13" />
    </edge>
    <edge source="Golan" target="企业规模分布">
      <data key="d7">1.0</data>
      <data key="d8">Golan used the maximum entropy principle to derive a multivariate stochastic theory for the distribution of firm sizes.</data>
      <data key="d9">derivation,theory development</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973474</data>
      <data key="d13" />
    </edge>
    <edge source="Golan" target="主体生产">
      <data key="d7">1.0</data>
      <data key="d8">Golan's theory is a statistical model of agent production subject to resource and technological constraints.</data>
      <data key="d9">constraint,modeling</data>
      <data key="d10">chunk-ea0643cdcdc8c7cc8b817ff03ae21ed4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973475</data>
      <data key="d13" />
    </edge>
    <edge source="Information Theory" target="Complexity Science">
      <data key="d7">1.0</data>
      <data key="d8">Information theory serves as a foundational framework for the field of complexity science.</data>
      <data key="d9">application,foundation</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973475</data>
      <data key="d13" />
    </edge>
    <edge source="Information Theory" target="Maximum Entropy Principle">
      <data key="d7">1.0</data>
      <data key="d8">The Maximum Entropy Principle is a key inference method derived from and applied within information theory.</data>
      <data key="d9">application,derivation</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973476</data>
      <data key="d13" />
    </edge>
    <edge source="Information Theory" target="Shannon">
      <data key="d7">1.0</data>
      <data key="d8">Shannon is the founder of information theory, which is based on his principles.</data>
      <data key="d9">foundation,principles</data>
      <data key="d10">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974086</data>
      <data key="d13" />
    </edge>
    <edge source="Information Theory" target="Unsupervised Learning">
      <data key="d7">1.0</data>
      <data key="d8">Principles from Shannon's information theory are used as tools to implement unsupervised learning.</data>
      <data key="d9">application,tool</data>
      <data key="d10">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974087</data>
      <data key="d13" />
    </edge>
    <edge source="Modeling" target="Inference">
      <data key="d7">1.0</data>
      <data key="d8">Modeling and inference are both central concepts to scientific inquiry, especially for complex systems.</data>
      <data key="d9">central concepts,scientific process</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973476</data>
      <data key="d13" />
    </edge>
    <edge source="Maximum Entropy Principle" target="Edwin Thompson Jaynes">
      <data key="d7">1.0</data>
      <data key="d8">Edwin Thompson Jaynes formalized and generalized the Maximum Entropy Principle based on Shannon's work.</data>
      <data key="d9">formalization,generalization</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973478</data>
      <data key="d13" />
    </edge>
    <edge source="Maximum Entropy Principle" target="John Skilling">
      <data key="d7">1.0</data>
      <data key="d8">John Skilling proposed applying the Maximum Entropy Principle to predict the behavior of incompletely characterized systems.</data>
      <data key="d9">application,proposal</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973481</data>
      <data key="d13" />
    </edge>
    <edge source="Maximum Entropy Principle" target="Shannon Entropy">
      <data key="d7">1.0</data>
      <data key="d8">The Maximum Entropy Principle involves maximizing the Shannon entropy under given constraints.</data>
      <data key="d9">objective function,optimization</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973491</data>
      <data key="d13" />
    </edge>
    <edge source="Maximum Entropy Principle" target="Uniform Distribution">
      <data key="d7">1.0</data>
      <data key="d8">The Maximum Entropy solution is proven to be closest to the uniform distribution, representing an unbiased inference.</data>
      <data key="d9">approximation,unbiased result</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973484</data>
      <data key="d13" />
    </edge>
    <edge source="Jakob Bernoulli" target="Principle Of Insufficient Reason">
      <data key="d7">1.0</data>
      <data key="d8">Jakob Bernoulli formulated the Principle of Insufficient Reason, a foundational concept for probabilistic reasoning.</data>
      <data key="d9">formulation,foundational work</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973476</data>
      <data key="d13" />
    </edge>
    <edge source="Jakob Bernoulli" target="Probability Theory">
      <data key="d7">1.0</data>
      <data key="d8">Jakob Bernoulli is considered a founder of probability theory.</data>
      <data key="d9">contribution,foundation</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973478</data>
      <data key="d13" />
    </edge>
    <edge source="Principle Of Insufficient Reason" target="Pierre-Simon Laplace">
      <data key="d7">1.0</data>
      <data key="d8">The Principle of Insufficient Reason is also attributed to Pierre-Simon Laplace, who further developed the concept.</data>
      <data key="d9">attribution,development</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973477</data>
      <data key="d13" />
    </edge>
    <edge source="Pierre-Simon Laplace" target="Statistical Inference">
      <data key="d7">1.0</data>
      <data key="d8">Pierre-Simon Laplace laid the foundation for statistical and probabilistic inference.</data>
      <data key="d9">contribution,foundation</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973480</data>
      <data key="d13" />
    </edge>
    <edge source="Claude Shannon" target="Information Entropy">
      <data key="d7">1.0</data>
      <data key="d8">Claude Shannon formulated the concept of information entropy, which is foundational to information theory.</data>
      <data key="d9">formulation,foundational concept</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973478</data>
      <data key="d13" />
    </edge>
    <edge source="Information Entropy" target="Edwin Thompson Jaynes">
      <data key="d7">1.0</data>
      <data key="d8">Edwin Thompson Jaynes applied Shannon's information entropy as a key tool for unbiased inference.</data>
      <data key="d9">application,inference tool</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973481</data>
      <data key="d13" />
    </edge>
    <edge source="Probability Distribution" target="Restricted Boltzmann Machine (Rbm)">
      <data key="d7">1.0</data>
      <data key="d8">The objective of an RBM is to learn a probability distribution, but calculating it is computationally expensive due to its exponential number of states.</data>
      <data key="d9">computational challenge,model objective</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974839</data>
      <data key="d13" />
    </edge>
    <edge source="Probability Distribution" target="Gradient Descent">
      <data key="d7">1.0</data>
      <data key="d8">Using gradient descent directly is impractical for RBMs because it requires calculating the full probability distribution, which is computationally expensive.</data>
      <data key="d9">computational limitation,impracticality</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974842</data>
      <data key="d13" />
    </edge>
    <edge source="Leontief Input-Output Model" target="Social Accounting Matrix">
      <data key="d7">1.0</data>
      <data key="d8">A Social Accounting Matrix is an extension of the Leontief Input-Output model, adding accounts for factor payments and final demand.</data>
      <data key="d9">economic accounting,extension</data>
      <data key="d10">chunk-faa76b2118855e8e73676c027eae5ca1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973481</data>
      <data key="d13" />
    </edge>
    <edge source="广义的最大熵原理马尔可夫问题" target="经典的最大熵原理">
      <data key="d7">1.0</data>
      <data key="d8">The generalized method discussed can be simplified to the classical maximum entropy principle under conditions of no uncertainty and a system in a steady state.</data>
      <data key="d9">condition,simplification</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973485</data>
      <data key="d13" />
    </edge>
    <edge source="广义的最大熵原理马尔可夫问题" target="MaxCal">
      <data key="d7">1.0</data>
      <data key="d8">The generalized method discussed can be simplified to MaxCal under conditions of no uncertainty and a system in a steady state.</data>
      <data key="d9">condition,simplification</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973486</data>
      <data key="d13" />
    </edge>
    <edge source="MaxCal" target="马尔科夫框架">
      <data key="d7">1.0</data>
      <data key="d8">MaxCal is a special case of the Markovian framework proposed.</data>
      <data key="d9">inclusion,special case</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973486</data>
      <data key="d13" />
    </edge>
    <edge source="MaxCal" target="模糊性">
      <data key="d7">1.0</data>
      <data key="d8">MaxCal converges to the same result as other methods when there is no fuzziness.</data>
      <data key="d9">convergence condition</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973486</data>
      <data key="d13" />
    </edge>
    <edge source="MaxCal" target="路径">
      <data key="d7">1.0</data>
      <data key="d8">MaxCal converges to the same result when paths are not constrained by other factors.</data>
      <data key="d9">constraint,convergence</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973487</data>
      <data key="d13" />
    </edge>
    <edge source="MaxCal" target="外部因素">
      <data key="d7">1.0</data>
      <data key="d8">MaxCal converges to the same result when paths are not constrained by external factors.</data>
      <data key="d9">constraint,convergence</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973487</data>
      <data key="d13" />
    </edge>
    <edge source="MaxCal" target="复杂数据">
      <data key="d7">1.0</data>
      <data key="d8">MaxCal converges to the same result when paths are not constrained by complex data.</data>
      <data key="d9">constraint,convergence</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973487</data>
      <data key="d13" />
    </edge>
    <edge source="广义方法" target="模型复杂性">
      <data key="d7">1.0</data>
      <data key="d8">The generalized method solves more complex problems without increasing model complexity.</data>
      <data key="d9">efficiency,problem-solving</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973483</data>
      <data key="d13" />
    </edge>
    <edge source="广义方法" target="稳定状态">
      <data key="d7">1.0</data>
      <data key="d8">The generalized method simplifies to classical principles under the condition of the system being in a steady state.</data>
      <data key="d9">simplification condition</data>
      <data key="d10">chunk-40c170209efa5da46edeea817792b434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973485</data>
      <data key="d13" />
    </edge>
    <edge source="热力学信息神经网络" target="归纳偏差">
      <data key="d7">1.0</data>
      <data key="d8">热力学信息神经网络采用归纳偏差来构建，以强制执行热力学定律。</data>
      <data key="d9">强制执行,构建</data>
      <data key="d10">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973509</data>
      <data key="d13" />
    </edge>
    <edge source="热力学信息神经网络" target="热力学第一定律">
      <data key="d7">1.0</data>
      <data key="d8">热力学信息神经网络执行热力学第一定律的强制执行。</data>
      <data key="d9">应用,强制执行</data>
      <data key="d10">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973509</data>
      <data key="d13" />
    </edge>
    <edge source="热力学信息神经网络" target="热力学第二定律">
      <data key="d7">1.0</data>
      <data key="d8">热力学信息神经网络执行热力学第二定律的强制执行。</data>
      <data key="d9">应用,强制执行</data>
      <data key="d10">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973510</data>
      <data key="d13" />
    </edge>
    <edge source="热力学信息神经网络" target="黑盒子网络">
      <data key="d7">1.0</data>
      <data key="d8">与未经过信息的黑盒子网络相比，热力学信息神经网络提供了出色的结果。</data>
      <data key="d9">优势,性能对比</data>
      <data key="d10">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973510</data>
      <data key="d13" />
    </edge>
    <edge source="归纳偏差" target="Metriplectic演化">
      <data key="d7">1.0</data>
      <data key="d8">为构建这些归纳偏差，假定了系统的metriplectic演化。</data>
      <data key="d9">假定,构建基础</data>
      <data key="d10">chunk-39fe5cddbd852d7e5e0202a65cc33f68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973509</data>
      <data key="d13" />
    </edge>
    <edge source="热力学第二定律" target="热力学">
      <data key="d7">1.0</data>
      <data key="d8">热力学第二定律是热力学的三条基本定律之一。</data>
      <data key="d9">基本定律,组成部分</data>
      <data key="d10">chunk-aedc5bd9c6d5647339e7b59deea0f006</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973521</data>
      <data key="d13" />
    </edge>
    <edge source="物理学" target="热力学">
      <data key="d7">1.0</data>
      <data key="d8">Thermodynamics is a branch of physics.</data>
      <data key="d9">branch,scientific discipline</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973877</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="人类智能">
      <data key="d7">3.0</data>
      <data key="d8">The text states that machine intelligence and human intelligence share a physical and functional homology, with the same core goal of forming an anti-entropy system.&lt;SEP&gt;人类智能在具身探索与推理决策上的优势，与机器智能在高速建模与数据处理上的专长，形成高度互补而非竞争的关系，二者走向共生共融。&lt;SEP&gt;Human intelligence and machine intelligence are compared and found to share a common core mechanism.</data>
      <data key="d9">commonality,comparison,homology,shared goal,互补关系,共生共融</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973743</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="连接主义">
      <data key="d7">1.0</data>
      <data key="d8">The connectionist school of thought, which emphasizes the homology between human and machine intelligence, is key to the success of modern AI.</data>
      <data key="d9">success factor,theoretical foundation</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973744</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="郭毅可">
      <data key="d7">1.0</data>
      <data key="d8">郭毅可作为文章作者，系统阐述了机器智能的本质及其与人类智能的关系。</data>
      <data key="d9">核心概念,观点阐述</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973781</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="物理同源">
      <data key="d7">1.0</data>
      <data key="d8">机器智能(硅基芯片)在物理层面与人类智能同源，都是遵循热力学定律、通过吸收信息抵抗熵增的精密信息化系统。</data>
      <data key="d9">属性描述,理论基础</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973784</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="数学同构">
      <data key="d7">1.0</data>
      <data key="d8">机器智能的认知框架可以用“自由能原理”和贝叶斯推理来描述，这与人类智能的数学框架同构。</data>
      <data key="d9">理论基础,认知框架</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973791</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="自由能原理">
      <data key="d7">1.0</data>
      <data key="d8">“自由能原理”是描述机器智能(及广义智能系统)认知和工作机制的理论框架，其核心是通过最小化自由能(预测误差)来适应环境。</data>
      <data key="d9">工作机制,理论框架</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973784</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="递归式共进化">
      <data key="d7">1.0</data>
      <data key="d8">机器智能在与人类智能的深度融合中，将通过“递归式共进化”形成正向反馈链，推动整个智能系统向更高维形态跃迁。</data>
      <data key="d9">未来趋势,演进过程</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973785</data>
      <data key="d13" />
    </edge>
    <edge source="机器智能" target="硅基芯片">
      <data key="d7">1.0</data>
      <data key="d8">硅基芯片是机器智能的物理基础和实现载体。</data>
      <data key="d9">实现基础,物理载体</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973786</data>
      <data key="d13" />
    </edge>
    <edge source="人类智能" target="郭毅可">
      <data key="d7">1.0</data>
      <data key="d8">郭毅可作为文章作者，系统阐述了人类智能的本质及其与机器智能的关系。</data>
      <data key="d9">核心概念,观点阐述</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973781</data>
      <data key="d13" />
    </edge>
    <edge source="人类智能" target="物理同源">
      <data key="d7">1.0</data>
      <data key="d8">人类智能(碳基大脑)在物理层面与机器智能同源，都是遵循热力学定律、通过吸收信息抵抗熵增的精密信息化系统。</data>
      <data key="d9">属性描述,理论基础</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973781</data>
      <data key="d13" />
    </edge>
    <edge source="人类智能" target="数学同构">
      <data key="d7">1.0</data>
      <data key="d8">人类智能的认知框架可以用“贝叶斯大脑”和“自由能原理”来描述，这与机器智能的数学框架同构。</data>
      <data key="d9">理论基础,认知框架</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973784</data>
      <data key="d13" />
    </edge>
    <edge source="人类智能" target="杰弗里·辛顿">
      <data key="d7">1.0</data>
      <data key="d8">杰弗里·辛顿指出，人类大脑和大语言模型对语言的理解方式几乎是同一种方式，揭示了人类智能与机器智能在机制上的相似性。</data>
      <data key="d9">机制类比,研究结论</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973785</data>
      <data key="d13" />
    </edge>
    <edge source="人类智能" target="贝叶斯大脑">
      <data key="d7">1.0</data>
      <data key="d8">“贝叶斯大脑”是描述人类智能认知和工作机制的理论框架，其核心是通过贝叶斯推理最小化预测误差。</data>
      <data key="d9">工作机制,理论框架</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973787</data>
      <data key="d13" />
    </edge>
    <edge source="人类智能" target="递归式共进化">
      <data key="d7">1.0</data>
      <data key="d8">人类智能在与机器智能的深度融合中，将通过“递归式共进化”形成正向反馈链，推动自身认知结构和思维方式的演进。</data>
      <data key="d9">未来趋势,演进过程</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973789</data>
      <data key="d13" />
    </edge>
    <edge source="人类智能" target="碳基大脑">
      <data key="d7">1.0</data>
      <data key="d8">碳基大脑是人类智能的物理基础和实现载体。</data>
      <data key="d9">实现基础,物理载体</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973789</data>
      <data key="d13" />
    </edge>
    <edge source="连接主义" target="现代神经网络">
      <data key="d7">1.0</data>
      <data key="d8">连接主义强调智能的物理同源性，是现代神经网络得以成功和发展的关键思想基础。</data>
      <data key="d9">工程实践,思想基础</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973790</data>
      <data key="d13" />
    </edge>
    <edge source="现代神经网络" target="赫布学习定律">
      <data key="d7">2.0</data>
      <data key="d8">Modern neural networks are described as the engineering crystallization of Hebb's learning law.&lt;SEP&gt;Modern neural networks are considered an engineering crystallization of Hebbian learning principles.</data>
      <data key="d9">implementation,theoretical basis,工程结晶,理论基础</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973743</data>
      <data key="d13" />
    </edge>
    <edge source="现代神经网络" target="图灵">
      <data key="d7">2.0</data>
      <data key="d8">现代神经网络是图灵思想的工程化结晶，实现了将思维过程机械化计算的理念。&lt;SEP&gt;Modern neural networks are described as the engineering crystallization of Turing's ideas.</data>
      <data key="d9">implementation,theoretical basis,工程化,思想结晶</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973745</data>
      <data key="d13" />
    </edge>
    <edge source="现代神经网络" target="维纳">
      <data key="d7">1.0</data>
      <data key="d8">现代神经网络体现了维纳所强调的通过反馈进行学习和调节的智能机制。</data>
      <data key="d9">反馈调节,机制体现</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973794</data>
      <data key="d13" />
    </edge>
    <edge source="赫布学习定律" target="唐纳德·赫布">
      <data key="d7">1.0</data>
      <data key="d8">Donald Hebb formulated the Hebbian Learning rule, which describes how synaptic connections are strengthened when neurons fire together.</data>
      <data key="d9">formulation,theory</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973754</data>
      <data key="d13" />
    </edge>
    <edge source="赫布学习定律" target="突触可塑性">
      <data key="d7">1.0</data>
      <data key="d8">The Hebbian Learning rule reveals the mechanism of synaptic plasticity, where synaptic connections are dynamically altered based on neural activity.</data>
      <data key="d9">foundation,mechanism</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973755</data>
      <data key="d13" />
    </edge>
    <edge source="赫布学习定律" target="神经元">
      <data key="d7">1.0</data>
      <data key="d8">Neurons operate according to the Hebbian Learning rule, where their connections are strengthened through co-activation.</data>
      <data key="d9">application,functional principle</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973757</data>
      <data key="d13" />
    </edge>
    <edge source="赫布学习定律" target="记忆">
      <data key="d7">1.0</data>
      <data key="d8">The Hebbian Learning rule provides the mechanism by which experiences and learning physically alter synaptic connections, forming the basis of memory.</data>
      <data key="d9">mechanism,physical basis</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973757</data>
      <data key="d13" />
    </edge>
    <edge source="反馈回路" target="机器学习">
      <data key="d7">1.0</data>
      <data key="d8">Wiener's concept of "feedback loops" is embodied in machine learning as optimization mechanisms.</data>
      <data key="d9">conceptualization,embodiment</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973743</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="梯度下降">
      <data key="d7">1.0</data>
      <data key="d8">Gradient descent is an optimization mechanism used within the field of machine learning.</data>
      <data key="d9">optimization,utilization</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973745</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="反向传播">
      <data key="d7">1.0</data>
      <data key="d8">Backpropagation is an optimization mechanism used within the field of machine learning.</data>
      <data key="d9">optimization,utilization</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973747</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="决策树">
      <data key="d7">1.0</data>
      <data key="d8">Decision tree is a specific model and method within the broader field of machine learning.</data>
      <data key="d9">model type,subfield</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976061</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="DOC_ID: chunk-d191d067">
      <data key="d7">1.0</data>
      <data key="d8">The document identified by the ID is categorized under the domain of machine learning.</data>
      <data key="d9">document classification,domain</data>
      <data key="d10">chunk-074ae094f32d31b781b0e74bdeb88703</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976099</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="第九讲： Bayes分类、熵、决策树、特征选择">
      <data key="d7">1.0</data>
      <data key="d8">The lecture content belongs to the field of machine learning.</data>
      <data key="d9">domain,field of study</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976212</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降" target="均方误差">
      <data key="d7">1.0</data>
      <data key="d8">均方误差损失函数因其易于通过梯度下降方法进行优化而具有优势。</data>
      <data key="d9">优化,计算</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975711</data>
      <data key="d13" />
    </edge>
    <edge source="人脑" target="莱尔·华特森">
      <data key="d7">1.0</data>
      <data key="d8">Lyall Watson made an observation about the complexity of the human brain and our limited ability to understand it.</data>
      <data key="d9">complexity,observation</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973744</data>
      <data key="d13" />
    </edge>
    <edge source="人脑" target="反问题">
      <data key="d7">1.0</data>
      <data key="d8">The brain's task of inferring the external world from sensory signals is described as solving an inverse problem.</data>
      <data key="d9">inference task,solves</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973745</data>
      <data key="d13" />
    </edge>
    <edge source="人脑" target="神经元">
      <data key="d7">1.0</data>
      <data key="d8">人脑内包含约860亿个神经元。</data>
      <data key="d9">包含,构成</data>
      <data key="d10">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974933</data>
      <data key="d13" />
    </edge>
    <edge source="数学模型" target="信号动态变化特性">
      <data key="d7">1.0</data>
      <data key="d8">The mathematical model is designed to describe the dynamic change characteristics of the signals.</data>
      <data key="d9">description,modeling</data>
      <data key="d10">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974252</data>
      <data key="d13" />
    </edge>
    <edge source="数学模型" target="坎贝尔定理">
      <data key="d7">1.0</data>
      <data key="d8">The mathematical model is constructed based on Campbell's theorem.</data>
      <data key="d9">construction,theoretical basis</data>
      <data key="d10">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974253</data>
      <data key="d13" />
    </edge>
    <edge source="数学模型" target="舰船通信网络">
      <data key="d7">1.0</data>
      <data key="d8">The mathematical model is applied to analyze the ship communication network.</data>
      <data key="d9">analysis,application</data>
      <data key="d10">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974254</data>
      <data key="d13" />
    </edge>
    <edge source="数学模型" target="网络信道特性">
      <data key="d7">1.0</data>
      <data key="d8">The mathematical model is designed to enhance the characterization capability of network channel properties.</data>
      <data key="d9">characterization,enhancement</data>
      <data key="d10">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974254</data>
      <data key="d13" />
    </edge>
    <edge source="高层级皮层" target="低层级感觉区">
      <data key="d7">1.0</data>
      <data key="d8">High-level cortical areas generate predictions, while low-level sensory areas calculate prediction errors and provide feedback.</data>
      <data key="d9">error feedback,prediction</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973745</data>
      <data key="d13" />
    </edge>
    <edge source="高层级皮层" target="前额叶">
      <data key="d7">1.0</data>
      <data key="d8">The prefrontal cortex is given as an example of a high-level cortical area.</data>
      <data key="d9">example,part of</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973747</data>
      <data key="d13" />
    </edge>
    <edge source="低层级感觉区" target="视觉皮层">
      <data key="d7">1.0</data>
      <data key="d8">The visual cortex is given as an example of a low-level sensory area.</data>
      <data key="d9">example,part of</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973747</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯理论" target="贝叶斯定理">
      <data key="d7">1.0</data>
      <data key="d8">Bayesian theory is based on the elegant mathematical formula known as Bayes' theorem.</data>
      <data key="d9">based on,core formula</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973746</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="先验">
      <data key="d7">1.0</data>
      <data key="d8">Bayes' theorem defines "prior" as one of its three core intuitive concepts.</data>
      <data key="d9">core concept,defines</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973747</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="似然">
      <data key="d7">1.0</data>
      <data key="d8">Bayes' theorem defines "likelihood" as one of its three core intuitive concepts.</data>
      <data key="d9">core concept,defines</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973748</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="后验">
      <data key="d7">1.0</data>
      <data key="d8">Bayes' theorem defines "posterior" as one of its three core intuitive concepts.</data>
      <data key="d9">core concept,defines</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973748</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="贝叶斯大脑">
      <data key="d7">1.0</data>
      <data key="d8">The Bayesian Brain hypothesis applies Bayes' theorem to the process of perception.</data>
      <data key="d9">application,hypothesis</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973756</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="自由能原理">
      <data key="d7">2.0</data>
      <data key="d8">The Free Energy Principle explains that the brain must work based on Bayesian logic due to the physical nature of life itself.&lt;SEP&gt;自由能原理从生命的物理观出发，推导出大脑必须遵循贝叶斯逻辑的必然性。</data>
      <data key="d9">necessitates,physical basis,数学基础,理论推导</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973749</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="归纳推理">
      <data key="d7">1.0</data>
      <data key="d8">Bayes' theorem extends human reasoning from simple judgments to inductive reasoning capable of handling uncertainty.</data>
      <data key="d9">enables,reasoning expansion</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973753</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="溯因推理">
      <data key="d7">1.0</data>
      <data key="d8">Bayes' theorem extends human reasoning from simple judgments to abductive reasoning capable of handling uncertainty.</data>
      <data key="d9">enables,reasoning expansion</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973754</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="大脑">
      <data key="d7">1.0</data>
      <data key="d8">大脑基于贝叶斯定理进行工作，以最小化预测误差的方式进行推理和学习。</data>
      <data key="d9">推理逻辑,认知方式</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973759</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯定理" target="语言模型">
      <data key="d7">1.0</data>
      <data key="d8">语言模型的训练过程在功能上模拟了贝叶斯定理中“用新证据更新旧信念”的更新机制。</data>
      <data key="d9">功能模拟,机制相似</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973762</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯大脑" target="认知科学">
      <data key="d7">1.0</data>
      <data key="d8">The Bayesian Brain hypothesis explains the core paradox in cognitive science about perceiving a stable world without direct access to reality.</data>
      <data key="d9">core paradox,explains</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973749</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯大脑" target="自由能原理">
      <data key="d7">1.0</data>
      <data key="d8">The Bayesian brain establishes a unified cognitive framework, which is connected via the free energy principle to the physical mechanism of life.</data>
      <data key="d9">connection,unification</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973770</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯大脑" target="物理同源、数学同构">
      <data key="d7">1.0</data>
      <data key="d8">The Bayesian brain framework establishes the foundation for the deep meaning of "physical homology and mathematical isomorphism" between intelligences.</data>
      <data key="d9">deep meaning,foundation</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973774</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="卡尔·弗里斯顿">
      <data key="d7">2.0</data>
      <data key="d8">Karl Friston is the British neuroscientist associated with the Free Energy Principle.&lt;SEP&gt;卡尔·弗里斯顿作为英国神经科学家，提出了自由能原理。</data>
      <data key="d9">associated with,development,理论提出,科学贡献</data>
      <data key="d10">chunk-3a748b94de215b941d68d078dd68dd6d&lt;SEP&gt;chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973753</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="大脑">
      <data key="d7">1.0</data>
      <data key="d8">大脑遵循自由能原理，通过最小化自由能来维持自身结构并抵抗熵增。</data>
      <data key="d9">生存策略,遵循原则</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973758</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="世界模型">
      <data key="d7">1.0</data>
      <data key="d8">在自由能原理框架下，认知系统不追求完美的世界模型，而是在解释力与简洁性间寻找平衡。</data>
      <data key="d9">理论框架,认知目标</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973760</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="智能">
      <data key="d7">1.0</data>
      <data key="d8">智能的核心机制被理解为不断“减少自由能”的过程。</data>
      <data key="d9">定义基础,核心机制</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973761</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="生命">
      <data key="d7">1.0</data>
      <data key="d8">生命体的物理特性(对抗宇宙无序化)决定了其必须遵循自由能原理以维持存续。</data>
      <data key="d9">物理基础,生存必然</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973761</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="学习">
      <data key="d7">1.0</data>
      <data key="d8">在自由能原理框架下，学习是系统为最小化自由能而改变内部认知模型的路径。</data>
      <data key="d9">实现路径,认知更新</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973763</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="记忆">
      <data key="d7">1.0</data>
      <data key="d8">记忆作为用新证据修正旧模型的过程，是自由能最小化在认知层面的体现。</data>
      <data key="d9">模型修正,认知过程</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973767</data>
      <data key="d13" />
    </edge>
    <edge source="自由能原理" target="熵增">
      <data key="d7">1.0</data>
      <data key="d8">The free energy principle connects cognitive frameworks to the physical mechanism of life resisting entropy increase.</data>
      <data key="d9">connection,resistance</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973771</data>
      <data key="d13" />
    </edge>
    <edge source="埃尔温·薛定谔" target="生命是什么？">
      <data key="d7">2.0</data>
      <data key="d8">Erwin Schrödinger authored the book "What is Life?" which laid the conceptual foundation for understanding life as feeding on negative entropy.&lt;SEP&gt;物理学家埃尔温·薛定谔撰写了著作《生命是什么？》，并在其中提出了关于生命与负熵的核心观点。</data>
      <data key="d9">authorship,conceptual foundation,理论载体,著作撰写</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973748</data>
      <data key="d13" />
    </edge>
    <edge source="埃尔温·薛定谔" target="负熵">
      <data key="d7">2.0</data>
      <data key="d8">Erwin Schrödinger proposed the concept that life feeds on "negative entropy" to maintain order.&lt;SEP&gt;物理学家埃尔温·薛定谔在其著作《生命是什么？》中提出了“生命以负熵为食”的洞见。</data>
      <data key="d9">definition,proposal,概念提出,理论贡献</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973756</data>
      <data key="d13" />
    </edge>
    <edge source="埃尔温·薛定谔" target="非周期性晶体">
      <data key="d7">1.0</data>
      <data key="d8">Erwin Schrödinger predicted that the programs for maintaining order are stored in an "aperiodic crystal," a structure with high information encoding capability.</data>
      <data key="d9">information storage,prediction</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973749</data>
      <data key="d13" />
    </edge>
    <edge source="负熵" target="生命">
      <data key="d7">2.0</data>
      <data key="d8">根据薛定谔的洞见，生命体以“负熵”为食，通过从外界摄取负熵来维持自身的秩序和结构。&lt;SEP&gt;Life feeds on "negative entropy," which is the fundamental principle for maintaining its ordered structure.</data>
      <data key="d9">fundamental principle,sustenance,摄取关系,生存机制</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a&lt;SEP&gt;chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973755</data>
      <data key="d13" />
    </edge>
    <edge source="詹姆斯·沃森" target="DNA双螺旋结构">
      <data key="d7">1.0</data>
      <data key="d8">James Watson, together with Francis Crick, discovered and elucidated the double-helix structure of DNA.</data>
      <data key="d9">discovery,elucidation</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973750</data>
      <data key="d13" />
    </edge>
    <edge source="詹姆斯·沃森" target="弗朗西斯·克里克">
      <data key="d7">1.0</data>
      <data key="d8">James Watson and Francis Crick collaborated to discover the structure of DNA.</data>
      <data key="d9">collaboration,scientific discovery</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973754</data>
      <data key="d13" />
    </edge>
    <edge source="詹姆斯·沃森" target="自然">
      <data key="d7">1.0</data>
      <data key="d8">James Watson, along with Francis Crick, published their discovery of the DNA double helix in the journal "Nature."</data>
      <data key="d9">dissemination,publication</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973754</data>
      <data key="d13" />
    </edge>
    <edge source="弗朗西斯·克里克" target="DNA双螺旋结构">
      <data key="d7">1.0</data>
      <data key="d8">Francis Crick, together with James Watson, discovered and elucidated the double-helix structure of DNA.</data>
      <data key="d9">discovery,elucidation</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973754</data>
      <data key="d13" />
    </edge>
    <edge source="弗朗西斯·克里克" target="自然">
      <data key="d7">1.0</data>
      <data key="d8">Francis Crick, along with James Watson, published their discovery of the DNA double helix in the journal "Nature."</data>
      <data key="d9">dissemination,publication</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973755</data>
      <data key="d13" />
    </edge>
    <edge source="弗朗西斯·克里克" target="中心法则">
      <data key="d7">1.0</data>
      <data key="d8">Francis Crick proposed the "central dogma" to explain how life produces proteins according to the DNA program.</data>
      <data key="d9">explanation,proposal</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973757</data>
      <data key="d13" />
    </edge>
    <edge source="DNA双螺旋结构" target="中心法则">
      <data key="d7">1.0</data>
      <data key="d8">The DNA double-helix structure provides the informational basis for life, which is functionally extended by the central dogma explaining protein production.</data>
      <data key="d9">functional extension,information basis</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973757</data>
      <data key="d13" />
    </edge>
    <edge source="DNA双螺旋结构" target="生命">
      <data key="d7">1.0</data>
      <data key="d8">The DNA double-helix structure explains the informational essence of life, with the arrangement of ATCG bases constituting its genetic code.</data>
      <data key="d9">genetic basis,information essence</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973766</data>
      <data key="d13" />
    </edge>
    <edge source="中心法则" target="蛋白质">
      <data key="d7">1.0</data>
      <data key="d8">The central dogma explains how life produces various proteins according to the DNA program.</data>
      <data key="d9">functional explanation,production mechanism</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973766</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="智能">
      <data key="d7">1.0</data>
      <data key="d8">Neurons are the physical carriers of intelligence, and their coordinated work leads to the emergence of intelligent functions.</data>
      <data key="d9">emergence,physical carrier</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973757</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="思想实验">
      <data key="d7">1.0</data>
      <data key="d8">The thought experiment involves the gradual replacement of biological neurons.</data>
      <data key="d9">involvement,replacement</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973772</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="碳基神经元">
      <data key="d7">1.0</data>
      <data key="d8">Neurons are specified as being carbon-based, the biological material in question.</data>
      <data key="d9">material,specification</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973774</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="HopField网络">
      <data key="d7">1.0</data>
      <data key="d8">HopField网络由多个相互作用的神经元组成。</data>
      <data key="d9">网络架构,计算单元</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974742</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="权重">
      <data key="d7">1.0</data>
      <data key="d8">神经元之间的连接由调节信号强度的权重来表征。</data>
      <data key="d9">信号传递,连接参数</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974745</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="阈值">
      <data key="d7">1.0</data>
      <data key="d8">每个神经元都有一个阈值，该阈值影响其状态是否根据加权输入而改变。</data>
      <data key="d9">激活参数,状态改变</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974745</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="状态">
      <data key="d7">1.0</data>
      <data key="d8">神经元的状态是其在特定时间的输出值，该值根据网络动力学而变化。</data>
      <data key="d9">时间动态,激活值</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974746</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="神经科学家">
      <data key="d7">1.0</data>
      <data key="d8">神经科学家着眼于神经元来研究大脑连接。</data>
      <data key="d9">关注,研究</data>
      <data key="d10">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974932</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="生物电讯号">
      <data key="d7">1.0</data>
      <data key="d8">神经元被生物电讯号激活，并传递这些讯号。</data>
      <data key="d9">传递,激活</data>
      <data key="d10">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974932</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="连接网络">
      <data key="d7">1.0</data>
      <data key="d8">神经元相互连接，形成激活时的连接网络。</data>
      <data key="d9">形成,构成</data>
      <data key="d10">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974932</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="神经回路">
      <data key="d7">1.0</data>
      <data key="d8">神经元相互连接，通过神经回路传递电讯号。</data>
      <data key="d9">传递,构成</data>
      <data key="d10">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974932</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质" target="细胞">
      <data key="d7">1.0</data>
      <data key="d8">Protein interactions form cellular activities, which follow the principle of negative entropy.</data>
      <data key="d9">activity formation,interaction</data>
      <data key="d10">chunk-e1923dd5beb8906f6b5c75a359732d8a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973757</data>
      <data key="d13" />
    </edge>
    <edge source="智能" target="预测误差">
      <data key="d7">1.0</data>
      <data key="d8">智能系统通过最小化预测误差来减少自由能。</data>
      <data key="d9">最小化目标,驱动因素</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973761</data>
      <data key="d13" />
    </edge>
    <edge source="智能" target="主动推断">
      <data key="d7">1.0</data>
      <data key="d8">主动推断是智能系统为最小化自由能而采取的行动路径，即改变世界以配合预测。</data>
      <data key="d9">实现方式,行为路径</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973763</data>
      <data key="d13" />
    </edge>
    <edge source="智能" target="控制论">
      <data key="d7">1.0</data>
      <data key="d8">控制论指出智能的核心在于具备“目标→行动→反馈”的闭环结构，强调反馈是智能的调节机制。</data>
      <data key="d9">反馈调节,核心机制</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973790</data>
      <data key="d13" />
    </edge>
    <edge source="智能" target="图灵测试">
      <data key="d7">1.0</data>
      <data key="d8">图灵测试曾被视为衡量机器智能的核心标准，关注机器在行为上能否表现得像在思考。</data>
      <data key="d9">行为表现,衡量标准</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973792</data>
      <data key="d13" />
    </edge>
    <edge source="记忆" target="神经元网络">
      <data key="d7">1.0</data>
      <data key="d8">记忆的本质是神经元网络的连接模式，存储于大脑的物理结构中。</data>
      <data key="d9">存储机制,物理基础</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973787</data>
      <data key="d13" />
    </edge>
    <edge source="大脑" target="预测误差">
      <data key="d7">1.0</data>
      <data key="d8">大脑通过最小化预测误差(自由能)来维持稳定并适应环境。</data>
      <data key="d9">最小化目标,核心机制</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973760</data>
      <data key="d13" />
    </edge>
    <edge source="大脑" target="大语言模型">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型与人类大脑在认知方式和优化逻辑上功能相似，都遵循最小化自由能的原则。</data>
      <data key="d9">功能相似,智能机制</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973761</data>
      <data key="d13" />
    </edge>
    <edge source="大脑" target="突触">
      <data key="d7">1.0</data>
      <data key="d8">大脑通过突触层面的动态可塑性进行学习、记忆和适应环境。</data>
      <data key="d9">学习机制,生物基础</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973788</data>
      <data key="d13" />
    </edge>
    <edge source="认知模型" target="感知数据">
      <data key="d7">1.0</data>
      <data key="d8">自由能被视为认知模型(预测)与感知数据(现实)之间的差距。</data>
      <data key="d9">对比关系,误差来源</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973766</data>
      <data key="d13" />
    </edge>
    <edge source="预测误差" target="现有最优方法">
      <data key="d7">1.0</data>
      <data key="d8">现有最优方法在验证集上的预测误差中位数为5.33 kJ/mol。</data>
      <data key="d9">对比参照,性能基准</data>
      <data key="d10">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973834</data>
      <data key="d13" />
    </edge>
    <edge source="预测误差" target="dGbyG">
      <data key="d7">1.0</data>
      <data key="d8">dGbyG工具将验证集预测误差的中位数减小到4.11 kJ/mol。</data>
      <data key="d9">性能改进,精度提升</data>
      <data key="d10">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973841</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="下一个词元预测">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型通过“下一个词元预测”任务来最小化预测误差，模拟贝叶斯更新。</data>
      <data key="d9">核心机制,训练任务</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973760</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="训练语料">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型依赖海量静态的训练语料作为外部证据，通过算法进行被动训练和优化以最小化预测误差。</data>
      <data key="d9">优化依据,数据依赖</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973762</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="图1">
      <data key="d7">1.0</data>
      <data key="d8">图1直观呈现了以语言模型作为智能体大脑，驱动其产生行为并遵循最小化自由能机制的过程。</data>
      <data key="d9">可视化呈现,过程说明</data>
      <data key="d10">chunk-eec0721be9c4be236261d47be592d37a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973764</data>
      <data key="d13" />
    </edge>
    <edge source="主动推断" target="自由能框架">
      <data key="d7">1.0</data>
      <data key="d8">Active inference is the behavioral mechanism within the free energy framework for reducing prediction errors.</data>
      <data key="d9">mechanism,theoretical basis</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973768</data>
      <data key="d13" />
    </edge>
    <edge source="主动推断" target="智能体">
      <data key="d7">1.0</data>
      <data key="d8">Intelligent agents are being endowed with active inference capabilities.</data>
      <data key="d9">capability,endowment</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973776</data>
      <data key="d13" />
    </edge>
    <edge source="图1" target="空手道俱乐部网络">
      <data key="d7">1.0</data>
      <data key="d8">Figure 1 visually presents the partition function calculated for the Karate Club network.</data>
      <data key="d9">data presentation,visualization</data>
      <data key="d10">chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975337</data>
      <data key="d13" />
    </edge>
    <edge source="爱思想" target="aisixiang.com">
      <data key="d7">1.0</data>
      <data key="d8">爱思想is the organization that operates the website with the domain aisixiang.com.</data>
      <data key="d9">domain,website</data>
      <data key="d10">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973763</data>
      <data key="d13" />
    </edge>
    <edge source="爱思想" target="ixiang.com/data/170628.html">
      <data key="d7">1.0</data>
      <data key="d8">The webpage ixiang.com/data/170628.html is hosted on the爱思想website.</data>
      <data key="d9">content location,hosting</data>
      <data key="d10">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973768</data>
      <data key="d13" />
    </edge>
    <edge source="爱思想" target="SuperAdmin">
      <data key="d7">1.0</data>
      <data key="d8">SuperAdmin served as the editor for the article published on the爱思想website.</data>
      <data key="d9">content management,editorial role</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973786</data>
      <data key="d13" />
    </edge>
    <edge source="杨涛" target="人工智能驱动的术语国际传播：模式变革与实践路径">
      <data key="d7">1.0</data>
      <data key="d8">杨涛is an author of the article "人工智能驱动的术语国际传播：模式变革与实践路径".</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973771</data>
      <data key="d13" />
    </edge>
    <edge source="王辉" target="人工智能驱动的术语国际传播：模式变革与实践路径">
      <data key="d7">1.0</data>
      <data key="d8">王辉is an author of the article "人工智能驱动的术语国际传播：模式变革与实践路径".</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973768</data>
      <data key="d13" />
    </edge>
    <edge source="周智婉" target="人工智能驱动的术语国际传播：模式变革与实践路径">
      <data key="d7">1.0</data>
      <data key="d8">周智婉is an author of the article "人工智能驱动的术语国际传播：模式变革与实践路径".</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-0826cf20559726ef1bbfbd76138a113d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973769</data>
      <data key="d13" />
    </edge>
    <edge source="新证据" target="旧模型">
      <data key="d7">1.0</data>
      <data key="d8">New evidence is used to correct and update old models.</data>
      <data key="d9">correction,updating</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973768</data>
      <data key="d13" />
    </edge>
    <edge source="自由能框架" target="具身智能">
      <data key="d7">1.0</data>
      <data key="d8">The free energy framework serves as a highly condensed theoretical explanation for embodied intelligence.</data>
      <data key="d9">explanation,theoretical framework</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973776</data>
      <data key="d13" />
    </edge>
    <edge source="自由能框架" target="自由能">
      <data key="d7">1.0</data>
      <data key="d8">The free energy framework centers on the concept of free energy, with minimization as its core goal.</data>
      <data key="d9">central concept,minimization goal</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973772</data>
      <data key="d13" />
    </edge>
    <edge source="认知" target="行动">
      <data key="d7">1.0</data>
      <data key="d8">Cognition and action are unified as two sides of the same coin within the free energy framework, both serving to minimize free energy.</data>
      <data key="d9">dual aspects,unification</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973768</data>
      <data key="d13" />
    </edge>
    <edge source="认知" target="自由能最小化">
      <data key="d7">1.0</data>
      <data key="d8">Cognition contributes to the process of free energy minimization by updating internal models.</data>
      <data key="d9">contribution,process</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973769</data>
      <data key="d13" />
    </edge>
    <edge source="行动" target="自由能最小化">
      <data key="d7">1.0</data>
      <data key="d8">Action contributes to the process of free energy minimization by changing the external world.</data>
      <data key="d9">contribution,process</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973771</data>
      <data key="d13" />
    </edge>
    <edge source="智能体" target="好奇心">
      <data key="d7">1.0</data>
      <data key="d8">Curiosity is an intrinsic drive and necessity for intelligent agents to enhance survival and optimize models in uncertain worlds.</data>
      <data key="d9">intrinsic drive,necessity</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973771</data>
      <data key="d13" />
    </edge>
    <edge source="利用" target="探索">
      <data key="d7">1.0</data>
      <data key="d8">Exploitation and exploration are two strategies between which an intelligent agent with active inference capabilities continuously weighs.</data>
      <data key="d9">strategy,trade-off</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973769</data>
      <data key="d13" />
    </edge>
    <edge source="利用" target="强化学习">
      <data key="d7">1.0</data>
      <data key="d8">The exploitation strategy reflects the logic of reinforcement learning.</data>
      <data key="d9">logic,reflection</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973772</data>
      <data key="d13" />
    </edge>
    <edge source="探索" target="好奇心">
      <data key="d7">1.0</data>
      <data key="d8">Exploration reflects advanced cognitive functions such as curiosity and hypothesis generation.</data>
      <data key="d9">cognitive function,reflection</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973771</data>
      <data key="d13" />
    </edge>
    <edge source="探索" target="假设生成">
      <data key="d7">1.0</data>
      <data key="d8">The exploration strategy reflects advanced cognitive functions like hypothesis generation.</data>
      <data key="d9">cognitive function,reflection</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973773</data>
      <data key="d13" />
    </edge>
    <edge source="探索" target="欣赏">
      <data key="d7">1.0</data>
      <data key="d8">The exploration strategy reflects advanced cognitive functions like appreciation.</data>
      <data key="d9">cognitive function,reflection</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973775</data>
      <data key="d13" />
    </edge>
    <edge source="熵增" target="智能的第一性原理">
      <data key="d7">2.0</data>
      <data key="d8">The first principle of intelligence defines it as a system's ability to use information to maintain order and resist entropy increase.&lt;SEP&gt;智能的第一性原理从科学和哲学层面，将智能理解为信息抵抗熵增(宇宙基本趋势)的组织方式。</data>
      <data key="d9">definition,resistance,宏观视角,理论对抗</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741&lt;SEP&gt;chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973773</data>
      <data key="d13" />
    </edge>
    <edge source="熵增" target="信息">
      <data key="d7">1.0</data>
      <data key="d8">生命、意识、技术、文化等系统利用信息在局部区域对抗熵增带来的混沌，形成短暂的逆流。</data>
      <data key="d9">对抗混沌,局部逆流</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973777</data>
      <data key="d13" />
    </edge>
    <edge source="杰弗里·辛顿" target="思想实验">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton proposed a thought experiment to explore the material basis of intelligence and consciousness.</data>
      <data key="d9">exploration,proposal</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973771</data>
      <data key="d13" />
    </edge>
    <edge source="杰弗里·辛顿" target="2025年世界人工智能大会">
      <data key="d7">1.0</data>
      <data key="d8">深度学习奠基者杰弗里·辛顿在2025年世界人工智能大会上发言，指出了人类大脑与大语言模型理解方式的相似性。</data>
      <data key="d9">会议发言,观点发表</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973784</data>
      <data key="d13" />
    </edge>
    <edge source="杰弗里·辛顿" target="玻尔兹曼机">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton is credited with inventing the Boltzmann machine.</data>
      <data key="d9">contribution,invention</data>
      <data key="d10">chunk-d0e494da55d171b3a3a8b96678397514</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973813</data>
      <data key="d13" />
    </edge>
    <edge source="思想实验" target="电子元件">
      <data key="d7">1.0</data>
      <data key="d8">The thought experiment involves substituting biological neurons with electronic components.</data>
      <data key="d9">involvement,substitution</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973774</data>
      <data key="d13" />
    </edge>
    <edge source="思想实验" target="意识">
      <data key="d7">1.0</data>
      <data key="d8">The thought experiment explores the question of whether consciousness would persist in a non-biological brain.</data>
      <data key="d9">exploration,question</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973775</data>
      <data key="d13" />
    </edge>
    <edge source="电子元件" target="碳基神经元">
      <data key="d7">1.0</data>
      <data key="d8">Electronic components are contrasted with and proposed as substitutes for carbon-based neurons.</data>
      <data key="d9">contrast,substitution</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973776</data>
      <data key="d13" />
    </edge>
    <edge source="智能的第一性原理" target="结构化组织方式">
      <data key="d7">1.0</data>
      <data key="d8">The first principle of intelligence states that it depends on a structured organizational method, not specific materials.</data>
      <data key="d9">dependence,principle</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973775</data>
      <data key="d13" />
    </edge>
    <edge source="语言" target="文字">
      <data key="d7">1.0</data>
      <data key="d8">Humans created language to organize thought, and later created writing as a tool for expressing cognition and forming ideas.</data>
      <data key="d9">creation,tool evolution</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973772</data>
      <data key="d13" />
    </edge>
    <edge source="文字" target="思想">
      <data key="d7">1.0</data>
      <data key="d8">Writing serves as a tool for the formation and expression of thought.</data>
      <data key="d9">formation,tool</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973776</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="创新方法">
      <data key="d7">1.0</data>
      <data key="d8">The innovative method combines reinforcement learning techniques.</data>
      <data key="d9">combines,methodology</data>
      <data key="d10">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975397</data>
      <data key="d13" />
    </edge>
    <edge source="反熵增能力" target="生物演化">
      <data key="d7">1.0</data>
      <data key="d8">Biological evolution is the process that accumulated the anti-entropy increase capability over eons.</data>
      <data key="d9">accumulation,process</data>
      <data key="d10">chunk-477b045a573ebc356439c0b836643741</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973776</data>
      <data key="d13" />
    </edge>
    <edge source="反熵增能力" target="人类">
      <data key="d7">1.0</data>
      <data key="d8">人类通过创造语言、文字和教育，首次实现了反熵增能力的外化与迁移，区别于其他生物。</data>
      <data key="d9">演化突破,能力外化</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973777</data>
      <data key="d13" />
    </edge>
    <edge source="人类" target="智能机器">
      <data key="d7">3.0</data>
      <data key="d8">人类与智能机器之间形成“递归式共进化”模式：人类创造更强AI → AI提升人类认知 → 认知升级的人类创造更高阶AI，构成自加速的正向反馈链。&lt;SEP&gt;人类与智能机器的共生关系是智能演化轨迹的自然延伸，构成一个连续的协作整体。&lt;SEP&gt;人类与机器是同一条“反熵增之河”中前后接力、共同维系秩序的不同节点。</data>
      <data key="d9">共生关系,协作节点,反熵增之河,正向反馈,演化延伸,递归式共进化</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973782</data>
      <data key="d13" />
    </edge>
    <edge source="人类" target="治理机制">
      <data key="d7">1.0</data>
      <data key="d8">人类有能力通过建立有效的治理机制，来保持和优化与机器智能的天然互补性，使“共生”成为演化最优解。</data>
      <data key="d9">优化互补,建立框架</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973783</data>
      <data key="d13" />
    </edge>
    <edge source="智能机制" target="算法">
      <data key="d7">1.0</data>
      <data key="d8">人类将生物智能机制抽象为可以复制的算法，使其能够脱离生物载体。</data>
      <data key="d9">形式转化,抽象与复制</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973777</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="硅基材料">
      <data key="d7">1.0</data>
      <data key="d8">算法以硅基材料为载体，构成了智能机器的物理基础。</data>
      <data key="d9">物理实现,载体承载</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973778</data>
      <data key="d13" />
    </edge>
    <edge source="硅基材料" target="智能机器">
      <data key="d7">1.0</data>
      <data key="d8">以硅基材料为载体运行的算法构成了具备学习、适应与行动能力的智能机器。</data>
      <data key="d9">构成基础,系统形成</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973781</data>
      <data key="d13" />
    </edge>
    <edge source="碳基智能体" target="硅基智能体">
      <data key="d7">2.0</data>
      <data key="d8">碳基智能体与硅基智能体结合形成的复合智能系统，在对抗熵增(最小化自由能)方面的整体效率远超任何一方独立运行。&lt;SEP&gt;碳基智能体(人类)擅长高效决策和物理探索，硅基智能体(机器)擅长快速建模和信息处理，两者高度互补。</data>
      <data key="d9">不对称互补,复合智能系统,效率协同,效率提升</data>
      <data key="d10">chunk-890027492eed3ffaa84135ada616a525</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973778</data>
      <data key="d13" />
    </edge>
    <edge source="递归式共进化" target="共同演化">
      <data key="d7">1.0</data>
      <data key="d8">“共同演化”描述了人类与智能体协同进化的关系，是“递归式共进化”这一更广泛正向反馈过程的一部分。</data>
      <data key="d9">概念关联,演进关系</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973787</data>
      <data key="d13" />
    </edge>
    <edge source="共生共融" target="人机协同">
      <data key="d7">1.0</data>
      <data key="d8">当下的人机协同应用是走向人类智能与机器智能深度融合、共生共融的初级形态。</data>
      <data key="d9">初级形态,演进阶段</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973787</data>
      <data key="d13" />
    </edge>
    <edge source="物理同源" target="李德毅">
      <data key="d7">1.0</data>
      <data key="d8">李德毅院士在《人工智能看哲学》一文中提出了人类智能与机器智能“物理上同源”的观点。</data>
      <data key="d9">核心观点,理论提出</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973783</data>
      <data key="d13" />
    </edge>
    <edge source="数学同构" target="李德毅">
      <data key="d7">1.0</data>
      <data key="d8">李德毅院士在《人工智能看哲学》一文中提出了人类智能与机器智能“数学上同构”的观点。</data>
      <data key="d9">核心观点,理论提出</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973785</data>
      <data key="d13" />
    </edge>
    <edge source="李德毅" target="人工智能看哲学">
      <data key="d7">1.0</data>
      <data key="d8">李德毅院士撰写了文章《人工智能看哲学》，并在其中提出了“物理同源、数学同构”的核心观点。</data>
      <data key="d9">文章撰写,观点发表</data>
      <data key="d10">chunk-728fd00b31adc6c169bac4b11f4d064a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973786</data>
      <data key="d13" />
    </edge>
    <edge source="神经元网络" target="突触">
      <data key="d7">1.0</data>
      <data key="d8">神经元网络由突触连接构成，突触的可塑性(强弱和增减)是网络学习和适应的基础。</data>
      <data key="d9">可塑性,组成结构</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973789</data>
      <data key="d13" />
    </edge>
    <edge source="阿兰·图灵" target="图灵机">
      <data key="d7">1.0</data>
      <data key="d8">阿兰·图灵提出了图灵机，将人类思考过程形式化，定义了计算和智能机器的基本结构。</data>
      <data key="d9">形式化定义,理论提出</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973788</data>
      <data key="d13" />
    </edge>
    <edge source="阿兰·图灵" target="图灵测试">
      <data key="d7">1.0</data>
      <data key="d8">阿兰·图灵提出了图灵测试，从行为表现(尤其是语言能力)来功能性地定义机器智能。</data>
      <data key="d9">功能主义,智能定义</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973789</data>
      <data key="d13" />
    </edge>
    <edge source="阿兰·图灵" target="论可计算数及其在判定问题上的应用">
      <data key="d7">1.0</data>
      <data key="d8">Alan Turing authored the paper "On Computable Numbers, with an Application to the Entscheidungsproblem," where he introduced the Turing Machine.</data>
      <data key="d9">理论提出,著作发表</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973791</data>
      <data key="d13" />
    </edge>
    <edge source="阿兰·图灵" target="计算机器与智能">
      <data key="d7">1.0</data>
      <data key="d8">Alan Turing authored the paper "Computing Machinery and Intelligence," where he proposed the Turing Test.</data>
      <data key="d9">理论提出,著作发表</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973794</data>
      <data key="d13" />
    </edge>
    <edge source="图灵测试" target="大模型时代">
      <data key="d7">1.0</data>
      <data key="d8">In the era of large models, it is recognized that the Turing Test is insufficient to fully characterize intelligence.</data>
      <data key="d9">时代反思,标准局限</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973795</data>
      <data key="d13" />
    </edge>
    <edge source="图灵测试" target="语言能力">
      <data key="d7">1.0</data>
      <data key="d8">The Turing Test made language ability a core standard for measuring machine intelligence.</data>
      <data key="d9">核心要素,衡量标准</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973796</data>
      <data key="d13" />
    </edge>
    <edge source="诺伯特·维纳" target="控制论">
      <data key="d7">1.0</data>
      <data key="d8">诺伯特·维纳创立了控制论，为动物和机器的控制与通讯提供了统一的理论框架。</data>
      <data key="d9">理论创立,统一框架</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973796</data>
      <data key="d13" />
    </edge>
    <edge source="诺伯特·维纳" target="控制论：或关于在动物和机器中控制和通讯的科学">
      <data key="d7">1.0</data>
      <data key="d8">Norbert Wiener authored the book "Cybernetics: or Control and Communication in the Animal and the Machine," which founded the field of cybernetics.</data>
      <data key="d9">理论创立,著作发表</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973792</data>
      <data key="d13" />
    </edge>
    <edge source="诺伯特·维纳" target="人有人的用处：控制论与社会">
      <data key="d7">1.0</data>
      <data key="d8">Norbert Wiener authored the book "The Human Use of Human Beings: Cybernetics and Society," which expanded on the ideas of cybernetics.</data>
      <data key="d9">理论扩展,著作发表</data>
      <data key="d10">chunk-54a0d4972c29a80d85d0bae2eef78577</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973795</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·艾尔伍德·香农" target="A Symbolic Analysis of Relay and Switching Circuits">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农撰写并发表了这篇重要的硕士学位论文。</data>
      <data key="d9">发表,撰写</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974428</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·艾尔伍德·香农" target="通信的一个数学理论">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农撰写并发表了这篇标志信息论开端的论文。</data>
      <data key="d9">发表,撰写</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974429</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·艾尔伍德·香农" target="Alfred Noble协会美国工程师奖">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农因其论文《A Symbolic Analysis of Relay and Switching Circuits》被授予Alfred Noble协会美国工程师奖。</data>
      <data key="d9">获奖,认可</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·艾尔伍德·香农" target="数字通信理论">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农的主要研究集中于数字通信理论。</data>
      <data key="d9">研究,贡献</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974432</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·艾尔伍德·香农" target="密码学">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农的主要研究集中于密码学，并在二战期间为此领域做出贡献。</data>
      <data key="d9">研究,贡献</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974433</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·艾尔伍德·香农" target="二战">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农在二战期间为密码破译和保密通信做出了贡献。</data>
      <data key="d9">参与,贡献</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974434</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼机" target="Geoffrey Hinton">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton is credited with inventing the Boltzmann machine.</data>
      <data key="d9">contribution,invention</data>
      <data key="d10">chunk-d0e494da55d171b3a3a8b96678397514</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973814</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼机" target="约束满足问题">
      <data key="d7">1.0</data>
      <data key="d8">玻尔兹曼机被设计用于解决包含大量“弱”约束的约束满足问题。</data>
      <data key="d9">应用,解决</data>
      <data key="d10">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974591</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼机" target="并行计算结构">
      <data key="d7">1.0</data>
      <data key="d8">玻尔兹曼机本身就是一种并行计算结构。</data>
      <data key="d9">实现,等同</data>
      <data key="d10">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974591</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼机" target="隐藏单元">
      <data key="d7">1.0</data>
      <data key="d8">Boltzmann machines contain hidden units as part of their structure.</data>
      <data key="d9">component,network architecture</data>
      <data key="d10">chunk-b2aa136f0a91bbc88ed87eed07a66512</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974652</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼机" target="能量最小化思想">
      <data key="d7">1.0</data>
      <data key="d8">Hopfield网络的能量最小化思想影响了后来玻尔兹曼机等模型的发展。</data>
      <data key="d9">思想影响,模型发展</data>
      <data key="d10">chunk-673b334bee153545178b73f52b190891</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974666</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼机" target="受限玻尔兹曼机">
      <data key="d7">1.0</data>
      <data key="d8">The Boltzmann machine category includes the Restricted Boltzmann Machine (RBM), which is the most widely used model in practical applications like recommendation systems.</data>
      <data key="d9">includes,practical application</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974844</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼机" target="深度学习">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning encompasses the category of Boltzmann machine neural network models.</data>
      <data key="d9">categorization,includes</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974846</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="最大池化层">
      <data key="d7">1.0</data>
      <data key="d8">The max-pooling layer is a component and a common operation used within deep neural network architectures.</data>
      <data key="d9">component,operation</data>
      <data key="d10">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975178</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="Zisserman">
      <data key="d7">1.0</data>
      <data key="d8">Zisserman proposed a new deep convolutional network architecture based on the foundation of AlexNet, contributing to the advancement of deep neural networks.</data>
      <data key="d9">advancement,proposal</data>
      <data key="d10">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975180</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="AlexNet">
      <data key="d7">1.0</data>
      <data key="d8">AlexNet is an instance and a significant advancement in the field of deep neural networks.</data>
      <data key="d9">advancement,instance</data>
      <data key="d10">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975189</data>
      <data key="d13" />
    </edge>
    <edge source="图神经网络" target="dGbyG">
      <data key="d7">1.0</data>
      <data key="d8">dGbyG预测工具是基于图神经网络开发的。</data>
      <data key="d9">开发基础,技术实现</data>
      <data key="d10">chunk-cc989a9fb47a8cd36db8fe7fb353106b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973834</data>
      <data key="d13" />
    </edge>
    <edge source="克劳修斯" target="宏观热现象">
      <data key="d7">1.0</data>
      <data key="d8">Rudolf Clausius defined entropy based on observations of macroscopic thermal phenomena.</data>
      <data key="d9">definition basis,observation</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973879</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼" target="公式S=k*lnW">
      <data key="d7">2.0</data>
      <data key="d8">玻尔兹曼提出了熵的统计力学定义公式S = k * ln W。&lt;SEP&gt;玻尔兹曼提出了熵的统计力学公式S=k*lnW。</data>
      <data key="d9">公式提出,关联,提出,理论贡献</data>
      <data key="d10">chunk-74f709ca5bbf7d60213a39cdce19a507&lt;SEP&gt;chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975798</data>
      <data key="d13" />
    </edge>
    <edge source="Hopfield网络" target="John Hopfield">
      <data key="d7">1.0</data>
      <data key="d8">Physicist John Hopfield proposed the Hopfield network in 1982.</data>
      <data key="d9">invention,neural networks</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973877</data>
      <data key="d13" />
    </edge>
    <edge source="Hopfield网络" target="离散型反馈神经网络">
      <data key="d7">1.0</data>
      <data key="d8">The Hopfield network is a type of discrete feedback neural network.</data>
      <data key="d9">classification,is a type of</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973878</data>
      <data key="d13" />
    </edge>
    <edge source="Hopfield网络" target="递归神经网络">
      <data key="d7">1.0</data>
      <data key="d8">The Hopfield network is a type of recurrent neural network.</data>
      <data key="d9">classification,is a type of</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973879</data>
      <data key="d13" />
    </edge>
    <edge source="Hopfield网络" target="能量最小化思想">
      <data key="d7">1.0</data>
      <data key="d8">能量最小化思想是Hopfield网络的核心思想之一，构成了其理论基础。</data>
      <data key="d9">核心思想,模型基础</data>
      <data key="d10">chunk-673b334bee153545178b73f52b190891</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974666</data>
      <data key="d13" />
    </edge>
    <edge source="宏观热现象" target="热传递">
      <data key="d7">1.0</data>
      <data key="d8">Macroscopic thermal phenomena include processes such as heat transfer.</data>
      <data key="d9">example,includes</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973877</data>
      <data key="d13" />
    </edge>
    <edge source="宏观热现象" target="做功">
      <data key="d7">1.0</data>
      <data key="d8">Macroscopic thermal phenomena include processes such as work.</data>
      <data key="d9">example,includes</data>
      <data key="d10">chunk-76741d601c3b02adb5beb29cf0c31924</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973878</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="分类问题">
      <data key="d7">1.0</data>
      <data key="d8">神经网络被应用于解决分类问题的训练中。</data>
      <data key="d9">应用领域,机器学习</data>
      <data key="d10">chunk-6135ecccd835afdfdaba2f58578ed61e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973893</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="通信模型">
      <data key="d7">1.0</data>
      <data key="d8">神经网络可以被看作一个通信模型，其中输入信号X被映射为输出信号Y。</data>
      <data key="d9">框架,类比</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974424</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="JioNLP Article">
      <data key="d7">1.0</data>
      <data key="d8">The JioNLP article explains the application of cross-entropy in neural networks.</data>
      <data key="d9">application,explanation</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974427</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="分类任务">
      <data key="d7">1.0</data>
      <data key="d8">神经网络常用于执行分类任务，例如对文本进行多类别分类。</data>
      <data key="d9">任务类型,模型应用</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974428</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="深度玻尔兹曼机">
      <data key="d7">1.0</data>
      <data key="d8">深度玻尔兹曼机被描述为一种特殊构造的神经网络。</data>
      <data key="d9">属于,类别</data>
      <data key="d10">chunk-93a18801c2737ad9536660fe9501c9d8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974637</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="Batchsize">
      <data key="d7">1.0</data>
      <data key="d8">在神经网络训练中，调整Batchsize是一个关键的参数设置，直接影响资源消耗。</data>
      <data key="d9">参数调整,资源管理</data>
      <data key="d10">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975360</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="决策树">
      <data key="d7">1.0</data>
      <data key="d8">对于决策树难以学习的复杂关系(如异或)，神经网络可以作为替代的分类方法。</data>
      <data key="d9">方法比较,替代方案</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975942</data>
      <data key="d13" />
    </edge>
    <edge source="分类问题" target="深度学习算法">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning algorithms are now the prevalent method for solving classification problems.</data>
      <data key="d9">application,modern solution</data>
      <data key="d10">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976256</data>
      <data key="d13" />
    </edge>
    <edge source="玻尔兹曼常数" target="公式S=k*lnW">
      <data key="d7">1.0</data>
      <data key="d8">公式S = k * ln W中包含玻尔兹曼常数k作为关键参数。</data>
      <data key="d9">包含,物理常数</data>
      <data key="d10">chunk-74f709ca5bbf7d60213a39cdce19a507</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973973</data>
      <data key="d13" />
    </edge>
    <edge source="微观状态数" target="公式S=k*lnW">
      <data key="d7">1.0</data>
      <data key="d8">公式S = k * ln W将熵与系统的微观状态数W相关联，表明熵是状态数的对数度量。</data>
      <data key="d9">关联,系统状态</data>
      <data key="d10">chunk-74f709ca5bbf7d60213a39cdce19a507</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973973</data>
      <data key="d13" />
    </edge>
    <edge source="自由熵" target="传统玻尔兹曼测度">
      <data key="d7">1.0</data>
      <data key="d8">自由熵的负值特性被认为是传统玻尔兹曼测度可能产生的结果。</data>
      <data key="d9">理论来源,统计力学</data>
      <data key="d10">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973995</data>
      <data key="d13" />
    </edge>
    <edge source="自由熵" target="大偏差原理">
      <data key="d7">1.0</data>
      <data key="d8">自由熵作为随机变量，其统计分布被认为服从大偏差原理。</data>
      <data key="d9">概率描述,统计原理</data>
      <data key="d10">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973996</data>
      <data key="d13" />
    </edge>
    <edge source="大偏差原理" target="P(S)~e -Nr(S)">
      <data key="d7">1.0</data>
      <data key="d8">大偏差原理的具体数学表达式是P(S)~e -Nr(S)，用于量化自由熵的统计分布。</data>
      <data key="d9">数学表达,概率分布</data>
      <data key="d10">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973996</data>
      <data key="d13" />
    </edge>
    <edge source="P(S)~e -Nr(S)" target="r(S)">
      <data key="d7">1.0</data>
      <data key="d8">在表达式P(S)~e -Nr(S)中，r(S)是定义概率衰减速率的函数。</data>
      <data key="d9">函数定义,速率函数</data>
      <data key="d10">chunk-a27259397f49437041a5c155ca0adfa1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768973996</data>
      <data key="d13" />
    </edge>
    <edge source="X" target="mbatch_backprop">
      <data key="d7">1.0</data>
      <data key="d8">The mbatch_backprop method takes the array X as input data for performing backpropagation.</data>
      <data key="d9">data processing,input</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974027</data>
      <data key="d13" />
    </edge>
    <edge source="X" target="quadratic_cost">
      <data key="d7">1.0</data>
      <data key="d8">The quadratic_cost method uses the array X as input to compute the Mean Squared Error cost.</data>
      <data key="d9">cost evaluation,input</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974029</data>
      <data key="d13" />
    </edge>
    <edge source="mbatch_backprop" target="delta_b">
      <data key="d7">1.0</data>
      <data key="d8">The mbatch_backprop method calculates and returns the delta_b array, which contains bias gradients.</data>
      <data key="d9">gradient calculation,output</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974028</data>
      <data key="d13" />
    </edge>
    <edge source="mbatch_backprop" target="delta_w">
      <data key="d7">1.0</data>
      <data key="d8">The mbatch_backprop method calculates and returns the delta_w array, which contains weight gradients.</data>
      <data key="d9">gradient calculation,output</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974029</data>
      <data key="d13" />
    </edge>
    <edge source="mbatch_backprop" target="y">
      <data key="d7">1.0</data>
      <data key="d8">The mbatch_backprop method takes the target labels y as input alongside the features X for backpropagation.</data>
      <data key="d9">input,target data</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974030</data>
      <data key="d13" />
    </edge>
    <edge source="mbatch_backprop" target="samples">
      <data key="d7">1.0</data>
      <data key="d8">The mbatch_backprop method uses the number of samples to average (divide by) the calculated delta_b and delta_w gradients.</data>
      <data key="d9">averaging,normalization</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974031</data>
      <data key="d13" />
    </edge>
    <edge source="quadratic_cost" target="MSE">
      <data key="d7">1.0</data>
      <data key="d8">The quadratic_cost method implements the MSE (Mean Squared Error) cost function.</data>
      <data key="d9">cost function,implementation</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974027</data>
      <data key="d13" />
    </edge>
    <edge source="quadratic_cost" target="y">
      <data key="d7">1.0</data>
      <data key="d8">The quadratic_cost method uses the target labels y as input alongside X to compute the cost.</data>
      <data key="d9">input,target data</data>
      <data key="d10">chunk-2a2578aca1988c90b1a9c10b69b57cda</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974028</data>
      <data key="d13" />
    </edge>
    <edge source="Zhang" target="离散传递熵">
      <data key="d7">1.0</data>
      <data key="d8">Zhang proposed the dispersion transfer entropy algorithm in 2020.</data>
      <data key="d9">algorithm development,proposal</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974062</data>
      <data key="d13" />
    </edge>
    <edge source="Zhang" target="2020">
      <data key="d7">1.0</data>
      <data key="d8">Zhang proposed the dispersion transfer entropy algorithm in the year 2020.</data>
      <data key="d9">proposal,temporal context</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974063</data>
      <data key="d13" />
    </edge>
    <edge source="离散传递熵" target="DTE算法">
      <data key="d7">1.0</data>
      <data key="d8">离散传递熵is abbreviated as DTE算法.</data>
      <data key="d9">abbreviation,algorithm identity</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974063</data>
      <data key="d13" />
    </edge>
    <edge source="DTE算法" target="符号化过程">
      <data key="d7">1.0</data>
      <data key="d8">The DTE algorithm is used to optimize the symbolic process.</data>
      <data key="d9">application,optimization</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974063</data>
      <data key="d13" />
    </edge>
    <edge source="DTE算法" target="Ragwitz准则">
      <data key="d7">1.0</data>
      <data key="d8">The DTE algorithm uses the Ragwitz criterion for dynamic parameter selection.</data>
      <data key="d9">criterion usage,parameter selection</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974063</data>
      <data key="d13" />
    </edge>
    <edge source="DTE算法" target="序列符号化过程">
      <data key="d7">1.0</data>
      <data key="d8">The DTE algorithm solves issues in the sequence symbolization process.</data>
      <data key="d9">problem-solving,process improvement</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974064</data>
      <data key="d13" />
    </edge>
    <edge source="Ragwitz准则" target="离散模式">
      <data key="d7">1.0</data>
      <data key="d8">The Ragwitz criterion uses discrete patterns to dynamically select parameters.</data>
      <data key="d9">dynamic adjustment,pattern-based selection</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974062</data>
      <data key="d13" />
    </edge>
    <edge source="Dispersion Transfer Entropy" target="Parameter Selection">
      <data key="d7">1.0</data>
      <data key="d8">The Dispersion Transfer Entropy algorithm performs dynamic parameter selection to optimize the symbolic process.</data>
      <data key="d9">algorithm mechanism,dynamic optimization</data>
      <data key="d10">chunk-3e9c56763968dc5abd8ddc1332aa273c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974062</data>
      <data key="d13" />
    </edge>
    <edge source="Simon Haykin" target="Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">Simon Haykin has long been engaged in research on neural networks and has authored textbooks on the subject.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974086</data>
      <data key="d13" />
    </edge>
    <edge source="Simon Haykin" target="The Book">
      <data key="d7">1.0</data>
      <data key="d8">Simon Haykin is the author of the book.</data>
      <data key="d9">authorship,content</data>
      <data key="d10">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974087</data>
      <data key="d13" />
    </edge>
    <edge source="Unsupervised Learning" target="Restricted Boltzmann Machines">
      <data key="d7">1.0</data>
      <data key="d8">Restricted Boltzmann Machines are a key model used within the field of unsupervised learning.</data>
      <data key="d9">application,model type</data>
      <data key="d10">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974617</data>
      <data key="d13" />
    </edge>
    <edge source="The Book" target="Chapter 10">
      <data key="d7">1.0</data>
      <data key="d8">The book contains Chapter 10, which discusses the application of information theory to unsupervised learning.</data>
      <data key="d9">contains,discusses</data>
      <data key="d10">chunk-82dd7e184547eda32bd10d04c1cae982</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974086</data>
      <data key="d13" />
    </edge>
    <edge source="深度自适应神经网络" target="动态神经网络">
      <data key="d7">1.0</data>
      <data key="d8">深度自适应神经网络是动态神经网络的一个代表性类别。</data>
      <data key="d9">代表性,类别归属</data>
      <data key="d10">chunk-0662825c74f8b5ee226b4f32d6eae491</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974120</data>
      <data key="d13" />
    </edge>
    <edge source="同一视角组" target="多视图">
      <data key="d7">1.0</data>
      <data key="d8">Multiple views under the same perspective group share network parameters.</data>
      <data key="d9">grouping,parameter sharing</data>
      <data key="d10">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974142</data>
      <data key="d13" />
    </edge>
    <edge source="多视图" target="网络参数">
      <data key="d7">1.0</data>
      <data key="d8">Multiple views utilize network parameters, which differ between views from different perspective groups.</data>
      <data key="d9">differentiation,utilization</data>
      <data key="d10">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974143</data>
      <data key="d13" />
    </edge>
    <edge source="网络训练过程" target="预训练">
      <data key="d7">1.0</data>
      <data key="d8">The network training process includes a pre-training step as its first phase.</data>
      <data key="d9">initialization,process step</data>
      <data key="d10">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974142</data>
      <data key="d13" />
    </edge>
    <edge source="网络训练过程" target="步骤">
      <data key="d7">1.0</data>
      <data key="d8">The network training process includes a second step that builds upon the pre-training.</data>
      <data key="d9">continuation,process step</data>
      <data key="d10">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974143</data>
      <data key="d13" />
    </edge>
    <edge source="图像数据集ImageNet" target="预训练">
      <data key="d7">1.0</data>
      <data key="d8">The pre-training step is performed using the ImageNet image dataset.</data>
      <data key="d9">foundation,training data</data>
      <data key="d10">chunk-f10f1d00e42dd5c9205033fe49f4f520</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974143</data>
      <data key="d13" />
    </edge>
    <edge source="本发明" target="模型输出特征向量">
      <data key="d7">1.0</data>
      <data key="d8">The invention utilizes and combines model output feature vectors in its methodology.</data>
      <data key="d9">combination,utilization</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974173</data>
      <data key="d13" />
    </edge>
    <edge source="本发明" target="文本数据">
      <data key="d7">1.0</data>
      <data key="d8">The invention utilizes and combines text data features in its methodology.</data>
      <data key="d9">combination,utilization</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974174</data>
      <data key="d13" />
    </edge>
    <edge source="本发明" target="基尼不纯度">
      <data key="d7">1.0</data>
      <data key="d8">The invention defines and applies a function based on Gini impurity.</data>
      <data key="d9">application,definition</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974175</data>
      <data key="d13" />
    </edge>
    <edge source="本发明" target="衡量测试用例被错误分类可能性大小的函数">
      <data key="d7">1.0</data>
      <data key="d8">The invention defines functions that measure the likelihood of test cases being misclassified.</data>
      <data key="d9">creation,definition</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974177</data>
      <data key="d13" />
    </edge>
    <edge source="基尼不纯度" target="测试用例">
      <data key="d7">1.0</data>
      <data key="d8">The function based on Gini impurity measures the misclassification likelihood of test cases and ranks them.</data>
      <data key="d9">measurement,ranking</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974176</data>
      <data key="d13" />
    </edge>
    <edge source="基尼不纯度" target="决策树">
      <data key="d7">1.0</data>
      <data key="d8">When implementing a decision tree by hand, selecting the best split feature involves criteria like Gini impurity.</data>
      <data key="d9">feature selection,model implementation</data>
      <data key="d10">chunk-a79596200294b5109fdd0cf885110f83</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975822</data>
      <data key="d13" />
    </edge>
    <edge source="测试用例" target="衡量测试用例被错误分类可能性大小的函数">
      <data key="d7">1.0</data>
      <data key="d8">The functions measure the likelihood of test cases being misclassified.</data>
      <data key="d9">evaluation,measurement</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974174</data>
      <data key="d13" />
    </edge>
    <edge source="测试用例" target="排序">
      <data key="d7">1.0</data>
      <data key="d8">The invention uses the defined functions to rank the test cases.</data>
      <data key="d9">organization,prioritization</data>
      <data key="d10">chunk-dc26f10df4bfd7aac2de935884b8ad3f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974175</data>
      <data key="d13" />
    </edge>
    <edge source="麻省理工学院" target="SCIENCE ADVANCES">
      <data key="d7">1.0</data>
      <data key="d8">The research team from MIT published their study in the journal SCIENCE ADVANCES.</data>
      <data key="d9">publication,research dissemination</data>
      <data key="d10">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974198</data>
      <data key="d13" />
    </edge>
    <edge source="麻省理工学院" target="乘法模拟频率变换光学神经网络">
      <data key="d7">1.0</data>
      <data key="d8">The research team from MIT proposed the innovative architecture named MAFT-ONN.</data>
      <data key="d9">innovation,research development</data>
      <data key="d10">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974198</data>
      <data key="d13" />
    </edge>
    <edge source="乘法模拟频率变换光学神经网络" target="MAFT-ONN">
      <data key="d7">1.0</data>
      <data key="d8">MAFT-ONN is the acronym for the architecture named "乘法模拟频率变换光学神经网络".</data>
      <data key="d9">acronym,naming</data>
      <data key="d10">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974198</data>
      <data key="d13" />
    </edge>
    <edge source="乘法模拟频率变换光学神经网络" target="香农极限">
      <data key="d7">1.0</data>
      <data key="d8">The MAFT-ONN architecture is proposed as an innovation that aims to surpass the Shannon limit.</data>
      <data key="d9">innovation,theoretical breakthrough</data>
      <data key="d10">chunk-c236f82f4d1c6b66d541fbb6f8076051</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974199</data>
      <data key="d13" />
    </edge>
    <edge source="舰船通信网络" target="节点">
      <data key="d7">1.0</data>
      <data key="d8">Nodes are the constituent elements that make up the ship communication network.</data>
      <data key="d9">composition,structure</data>
      <data key="d10">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974253</data>
      <data key="d13" />
    </edge>
    <edge source="节点" target="泊松点过程">
      <data key="d7">1.0</data>
      <data key="d8">The Poisson point process is used to model the distribution and relationships between nodes.</data>
      <data key="d9">distribution,stochastic modeling</data>
      <data key="d10">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974252</data>
      <data key="d13" />
    </edge>
    <edge source="泊松点过程" target="信道">
      <data key="d7">1.0</data>
      <data key="d8">The Poisson point process is used to construct the model of the communication channel.</data>
      <data key="d9">construction,modeling</data>
      <data key="d10">chunk-8c2cb0873e78699bf2531a59b921954f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974253</data>
      <data key="d13" />
    </edge>
    <edge source="信道" target="信息传递模型">
      <data key="d7">1.0</data>
      <data key="d8">信息传递模型包含信道作为信息传递的介质。</data>
      <data key="d9">包含,定义</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974432</data>
      <data key="d13" />
    </edge>
    <edge source="信道" target="通信系统">
      <data key="d7">1.0</data>
      <data key="d8">信道是通信系统的一个关键组成部分，负责信息的传输。</data>
      <data key="d9">信息传输,组成部分</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974437</data>
      <data key="d13" />
    </edge>
    <edge source="磁場導向控制" target="FOC">
      <data key="d7">1.0</data>
      <data key="d8">磁場導向控制is the Chinese term for the method abbreviated as FOC.</data>
      <data key="d9">abbreviation,synonym</data>
      <data key="d10">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974283</data>
      <data key="d13" />
    </edge>
    <edge source="磁場導向控制" target="磁场定向控制">
      <data key="d7">1.0</data>
      <data key="d8">磁场定向控制is the simplified Chinese translation of the traditional Chinese term磁場導向控制.</data>
      <data key="d9">synonym,translation</data>
      <data key="d10">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974285</data>
      <data key="d13" />
    </edge>
    <edge source="葉志鈞" target="叶志钧">
      <data key="d7">1.0</data>
      <data key="d8">葉志鈞and叶志钧are traditional and simplified Chinese variants of the same person's name.</data>
      <data key="d9">name variant,translation</data>
      <data key="d10">chunk-33949af9012de6222abbb5ee9e909273</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974283</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="文本">
      <data key="d7">1.0</data>
      <data key="d8">分类任务以文本作为输入数据进行处理，示例中是对一篇文章进行分类。</data>
      <data key="d9">处理对象,应用场景</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974424</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="政治">
      <data key="d7">1.0</data>
      <data key="d8">Politics is listed as one of the target categories for the text classification task mentioned.</data>
      <data key="d9">任务定义,类别包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974431</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="经济">
      <data key="d7">1.0</data>
      <data key="d8">Economics is listed as one of the target categories for the text classification task mentioned.</data>
      <data key="d9">任务定义,类别包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974432</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="娱乐">
      <data key="d7">1.0</data>
      <data key="d8">Entertainment is listed as one of the target categories for the text classification task mentioned.</data>
      <data key="d9">任务定义,类别包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974424</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="社会">
      <data key="d7">1.0</data>
      <data key="d8">Society is listed as one of the target categories for the text classification task mentioned.</data>
      <data key="d9">任务定义,类别包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974425</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="科技">
      <data key="d7">1.0</data>
      <data key="d8">Technology is listed as one of the target categories for the text classification task mentioned.</data>
      <data key="d9">任务定义,类别包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974426</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="历史">
      <data key="d7">1.0</data>
      <data key="d8">History is listed as one of the target categories for the text classification task mentioned.</data>
      <data key="d9">任务定义,类别包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974429</data>
      <data key="d13" />
    </edge>
    <edge source="分类任务" target="家庭">
      <data key="d7">1.0</data>
      <data key="d8">Family is listed as one of the target categories for the text classification task mentioned.</data>
      <data key="d9">任务定义,类别包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="真实分布" target="模型预测分布">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵用于衡量真实分布与模型预测分布之间的差异。</data>
      <data key="d9">对比,差异度量</data>
      <data key="d10">chunk-56a41b95a520be32c97da3124e41c828</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974424</data>
      <data key="d13" />
    </edge>
    <edge source="小北" target="彩票系统">
      <data key="d7">1.0</data>
      <data key="d8">小北作为彩票购买者，在连续中奖后对彩票系统的公平性产生了怀疑。</data>
      <data key="d9">产生怀疑,用户互动</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974425</data>
      <data key="d13" />
    </edge>
    <edge source="小北" target="彩票中心主任">
      <data key="d7">1.0</data>
      <data key="d8">彩票中心主任是小北的父亲，他利用职权为小北设定了更高的中奖概率。</data>
      <data key="d9">家庭关系,特殊待遇</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974426</data>
      <data key="d13" />
    </edge>
    <edge source="小北" target="彩票">
      <data key="d7">1.0</data>
      <data key="d8">小北购买彩票，经历了未中奖和两次中奖的事件。</data>
      <data key="d9">中奖事件,购买</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974434</data>
      <data key="d13" />
    </edge>
    <edge source="小北" target="信息量">
      <data key="d7">1.0</data>
      <data key="d8">小北对未中奖不惊讶(信息量低)，对中奖非常震惊(信息量高)，体现了信息量衡量震惊程度。</data>
      <data key="d9">接收信息,震惊程度</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974436</data>
      <data key="d13" />
    </edge>
    <edge source="小北" target="地球">
      <data key="d7">1.0</data>
      <data key="d8">小北认为连续两次中奖的概率比地球爆炸的概率还低，因此感到极其惊讶。</data>
      <data key="d9">惊讶程度,概率比较</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974437</data>
      <data key="d13" />
    </edge>
    <edge source="信息量" target="太阳">
      <data key="d7">1.0</data>
      <data key="d8">太阳从东边升起是必然事件，其概率为1，因此该事件的信息量为0。</data>
      <data key="d9">信息量为零,必然事件</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974432</data>
      <data key="d13" />
    </edge>
    <edge source="信息量" target="四川">
      <data key="d7">1.0</data>
      <data key="d8">四川遭遇极端高温干旱是一个低概率事件，因此描述该事件的话语信息量非常大。</data>
      <data key="d9">低概率事件,高信息量</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974433</data>
      <data key="d13" />
    </edge>
    <edge source="信息量" target="概率">
      <data key="d7">1.0</data>
      <data key="d8">信息量的大小与事件发生的概率成反比，概率越小，信息量越大。</data>
      <data key="d9">反比关系,度量</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974435</data>
      <data key="d13" />
    </edge>
    <edge source="信息量" target="硬币">
      <data key="d7">1.0</data>
      <data key="d8">投掷硬币的次数与信息量是加性的关系，多次投掷的信息量是单次投掷信息量的总和。</data>
      <data key="d9">加性性质,示例</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974437</data>
      <data key="d13" />
    </edge>
    <edge source="信息量" target="配分函数">
      <data key="d7">1.0</data>
      <data key="d8">The partition function represents the quantity of information retained on the original nodes of the network.</data>
      <data key="d9">quantification,representation</data>
      <data key="d10">chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975338</data>
      <data key="d13" />
    </edge>
    <edge source="先验分布" target="生成式模型">
      <data key="d7">1.0</data>
      <data key="d8">生成式模型包含对模型参数的先验分布假设。</data>
      <data key="d9">概率框架,模型假设</data>
      <data key="d10">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976216</data>
      <data key="d13" />
    </edge>
    <edge source="女孩" target="男孩">
      <data key="d7">1.0</data>
      <data key="d8">In the communication model analogy, the boy sends a love confession (information) to the girl, who is the receiver.</data>
      <data key="d9">信息传递,通信模型</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974429</data>
      <data key="d13" />
    </edge>
    <edge source="女孩" target="四川">
      <data key="d7">1.0</data>
      <data key="d8">女孩听到男孩关于四川气候的陈述后会感到震惊，因为这是一个低概率事件。</data>
      <data key="d9">接收信息,震惊反应</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974436</data>
      <data key="d13" />
    </edge>
    <edge source="男孩" target="四川">
      <data key="d7">1.0</data>
      <data key="d8">男孩陈述了四川遭遇极端气候的事件，这句话信息量很大。</data>
      <data key="d9">信息传递,陈述事件</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974435</data>
      <data key="d13" />
    </edge>
    <edge source="刘慈欣" target="流浪地球">
      <data key="d7">1.0</data>
      <data key="d8">Liu Cixin is the author who created the science fiction story "The Wandering Earth."</data>
      <data key="d9">作品归属,创作关系</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="流浪地球" target="太阳从西边升起">
      <data key="d7">1.0</data>
      <data key="d8">In the story "The Wandering Earth," a key event is that the sun rises from the west due to changes in Earth's rotation.</data>
      <data key="d9">事件描述,情节包含</data>
      <data key="d10">chunk-e01785b3e2f06c5896c3aec7204ebd49</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974431</data>
      <data key="d13" />
    </edge>
    <edge source="A Symbolic Analysis of Relay and Switching Circuits" target="Transactions of the American Institute of Electrical Engineers">
      <data key="d7">1.0</data>
      <data key="d8">论文《A Symbolic Analysis of Relay and Switching Circuits》发表在Transactions of the American Institute of Electrical Engineers期刊上。</data>
      <data key="d9">刊登,发表</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="信息传递模型" target="信源">
      <data key="d7">1.0</data>
      <data key="d8">信息传递模型包含信源作为信息的发送方。</data>
      <data key="d9">包含,定义</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="信息传递模型" target="信宿">
      <data key="d7">1.0</data>
      <data key="d8">信息传递模型包含信宿作为信息的接收方。</data>
      <data key="d9">包含,定义</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974430</data>
      <data key="d13" />
    </edge>
    <edge source="信息传递模型" target="编码">
      <data key="d7">1.0</data>
      <data key="d8">信息传递过程涉及对信息使用不同的编码方式。</data>
      <data key="d9">使用,涉及</data>
      <data key="d10">chunk-a6f27f56460cd35be08035e374a80238</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974433</data>
      <data key="d13" />
    </edge>
    <edge source="编码" target="通信系统">
      <data key="d7">1.0</data>
      <data key="d8">编码是通信系统的一个关键组成部分，负责信息的转换处理。</data>
      <data key="d9">信息处理,组成部分</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974438</data>
      <data key="d13" />
    </edge>
    <edge source="彩票" target="彩票机构员工">
      <data key="d7">1.0</data>
      <data key="d8">社会新闻爆出中奖者是彩票机构员工，这引发了人们对彩票系统公正性的怀疑。</data>
      <data key="d9">中奖关联,系统质疑</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974436</data>
      <data key="d13" />
    </edge>
    <edge source="通信系统" target="信息发送方">
      <data key="d7">1.0</data>
      <data key="d8">信息发送方是通信系统的起点，负责发出信息。</data>
      <data key="d9">信息源头,组成部分</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974439</data>
      <data key="d13" />
    </edge>
    <edge source="通信系统" target="信息接收方">
      <data key="d7">1.0</data>
      <data key="d8">信息接收方是通信系统的终点，接收信息并消除不确定性。</data>
      <data key="d9">信息终点,组成部分</data>
      <data key="d10">chunk-e19131f5f89a9bc65d85c1a09afb2973</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974439</data>
      <data key="d13" />
    </edge>
    <edge source="文本信息" target="字母">
      <data key="d7">1.0</data>
      <data key="d8">文本信息由字母组成。</data>
      <data key="d9">包含,组成</data>
      <data key="d10">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974465</data>
      <data key="d13" />
    </edge>
    <edge source="字母" target="出现概率">
      <data key="d7">1.0</data>
      <data key="d8">每个字母都有一个对应的出现概率。</data>
      <data key="d9">属性,描述</data>
      <data key="d10">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974466</data>
      <data key="d13" />
    </edge>
    <edge source="出现概率" target="最佳编码长度">
      <data key="d7">1.0</data>
      <data key="d8">字母的最佳编码长度由其出现概率的对数决定。</data>
      <data key="d9">决定,计算</data>
      <data key="d10">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974466</data>
      <data key="d13" />
    </edge>
    <edge source="最佳编码长度" target="平均编码长度">
      <data key="d7">1.0</data>
      <data key="d8">所有字母的最佳编码长度按概率加权求和，得到整段文本的平均编码长度。</data>
      <data key="d9">构成,求和</data>
      <data key="d10">chunk-0da87cc9d247bbbc97d0642c59a0a3ce</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974465</data>
      <data key="d13" />
    </edge>
    <edge source="编码定理" target="汉明码">
      <data key="d7">1.0</data>
      <data key="d8">编码定理的理论为汉明码等纠错码的发展和应用提供了理论基础。</data>
      <data key="d9">应用,理论推动</data>
      <data key="d10">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974494</data>
      <data key="d13" />
    </edge>
    <edge source="编码定理" target="卷积码">
      <data key="d7">1.0</data>
      <data key="d8">编码定理的理论为卷积码等纠错码的发展和应用提供了理论基础。</data>
      <data key="d9">应用,理论推动</data>
      <data key="d10">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974494</data>
      <data key="d13" />
    </edge>
    <edge source="编码定理" target="纠错码">
      <data key="d7">1.0</data>
      <data key="d8">编码定理的理论为纠错码的发展和应用提供了理论基础。</data>
      <data key="d9">应用,理论推动</data>
      <data key="d10">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974495</data>
      <data key="d13" />
    </edge>
    <edge source="编码定理" target="最优编码">
      <data key="d7">1.0</data>
      <data key="d8">编码定理从数学上证明了最优编码的存在。</data>
      <data key="d9">存在性证明,理论核心</data>
      <data key="d10">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974517</data>
      <data key="d13" />
    </edge>
    <edge source="编码定理" target="数学观点">
      <data key="d7">1.0</data>
      <data key="d8">从数学观点看，编码定理是关于最优编码的存在性定理。</data>
      <data key="d9">性质界定,理论视角</data>
      <data key="d10">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974517</data>
      <data key="d13" />
    </edge>
    <edge source="编码定理" target="工程观点">
      <data key="d7">1.0</data>
      <data key="d8">从工程观点看，编码定理不是结构性的，不能直接指导实现。</data>
      <data key="d9">实践视角,局限性</data>
      <data key="d10">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974518</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·香农" target="通信的数学理论">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农是《通信的数学理论》这篇论文的作者。</data>
      <data key="d9">创作,发表</data>
      <data key="d10">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974493</data>
      <data key="d13" />
    </edge>
    <edge source="克劳德·香农" target="信道容量">
      <data key="d7">1.0</data>
      <data key="d8">克劳德·香农在《通信的数学理论》中首次提出了信道容量的概念。</data>
      <data key="d9">定义,提出</data>
      <data key="d10">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974494</data>
      <data key="d13" />
    </edge>
    <edge source="通信的数学理论" target="信道容量">
      <data key="d7">1.0</data>
      <data key="d8">《通信的数学理论》这篇论文首次系统阐述了信道容量的概念。</data>
      <data key="d9">包含,阐述</data>
      <data key="d10">chunk-c78284e4671aee8befd9c6871d1db529</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974494</data>
      <data key="d13" />
    </edge>
    <edge source="信道编码定理" target="最优编码">
      <data key="d7">1.0</data>
      <data key="d8">信道编码定理从数学上证明了最优编码的存在。</data>
      <data key="d9">存在性证明,理论核心</data>
      <data key="d10">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974517</data>
      <data key="d13" />
    </edge>
    <edge source="信道编码定理" target="数学观点">
      <data key="d7">1.0</data>
      <data key="d8">从数学观点看，信道编码定理是关于最优编码的存在性定理。</data>
      <data key="d9">性质界定,理论视角</data>
      <data key="d10">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974518</data>
      <data key="d13" />
    </edge>
    <edge source="信道编码定理" target="工程观点">
      <data key="d7">1.0</data>
      <data key="d8">从工程观点看，信道编码定理不是结构性的，不能直接指导实现。</data>
      <data key="d9">实践视角,局限性</data>
      <data key="d10">chunk-5d34d389fc9a72d98bce995b723199a6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974518</data>
      <data key="d13" />
    </edge>
    <edge source="Toderici G" target="Full Resolution Image Compression With Recurrent Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">Toderici G is an author of the paper "Full Resolution Image Compression With Recurrent Neural Networks".</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974566</data>
      <data key="d13" />
    </edge>
    <edge source="Vincent D" target="Full Resolution Image Compression With Recurrent Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">Vincent D is an author of the paper "Full Resolution Image Compression With Recurrent Neural Networks".</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974568</data>
      <data key="d13" />
    </edge>
    <edge source="Johnston N" target="Full Resolution Image Compression With Recurrent Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">Johnston N is an author of the paper "Full Resolution Image Compression With Recurrent Neural Networks".</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974569</data>
      <data key="d13" />
    </edge>
    <edge source="Full Resolution Image Compression With Recurrent Neural Networks" target="IEEE Conference on Computer Vision and Pattern Recognition">
      <data key="d7">1.0</data>
      <data key="d8">The paper "Full Resolution Image Compression With Recurrent Neural Networks" was presented at the IEEE Conference on Computer Vision and Pattern Recognition.</data>
      <data key="d9">presentation,publication venue</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974569</data>
      <data key="d13" />
    </edge>
    <edge source="Successive Refinement Of Images With Deep Joint Source-Channel Coding" target="IEEE 20th International Workshop On Signal Processing Advances In Wireless Communications (SPAWC)">
      <data key="d7">1.0</data>
      <data key="d8">The paper "Successive Refinement Of Images With Deep Joint Source-Channel Coding" was presented at the IEEE 20th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC).</data>
      <data key="d9">presentation,publication venue</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974566</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Joint Source-Channel Coding For Wireless Image Retrieval" target="ICASSP 2020 IEEE International Conference On Acoustics, Speech And Signal Processing (ICASSP)">
      <data key="d7">1.0</data>
      <data key="d8">The paper "Deep Joint Source-Channel Coding For Wireless Image Retrieval" was presented at the ICASSP 2020 IEEE International Conference on Acoustics, Speech and Signal Processing.</data>
      <data key="d9">presentation,publication venue</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974566</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning For Joint Source-Channel Coding Of Text" target="2018 IEEE International Conference On Acoustics, Speech And Signal Processing (ICASSP)">
      <data key="d7">1.0</data>
      <data key="d8">The paper "Deep Learning For Joint Source-Channel Coding Of Text" was presented at the 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).</data>
      <data key="d9">presentation,publication venue</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974566</data>
      <data key="d13" />
    </edge>
    <edge source="M To 1 Joint Source-Channel Coding Of Gaussian Sources Via Dichotomy Of The Input Space Based On Deep Learning" target="2019 Data Compression Conference (DCC)">
      <data key="d7">1.0</data>
      <data key="d8">The paper "M To 1 Joint Source-Channel Coding Of Gaussian Sources Via Dichotomy Of The Input Space Based On Deep Learning" was presented at the 2019 Data Compression Conference (DCC).</data>
      <data key="d9">presentation,publication venue</data>
      <data key="d10">chunk-5b929f1d50e05258f54389ac4f58f0ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974567</data>
      <data key="d13" />
    </edge>
    <edge source="弱约束" target="强约束">
      <data key="d7">1.0</data>
      <data key="d8">弱约束是相对于“强”约束而言的，两者是约束满足问题中不同类型的约束条件。</data>
      <data key="d9">对比,相对性</data>
      <data key="d10">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974591</data>
      <data key="d13" />
    </edge>
    <edge source="并行计算结构" target="人工神经网络">
      <data key="d7">1.0</data>
      <data key="d8">文中明确指出，这里的并行计算结构就是人工神经网络。</data>
      <data key="d9">具体化,等同</data>
      <data key="d10">chunk-29b81edcfc109c880298f79878843454</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974591</data>
      <data key="d13" />
    </edge>
    <edge source="人工神经网络" target="映射关系">
      <data key="d7">1.0</data>
      <data key="d8">The artificial neural network is used to model and predict the mapping relationship between mesoscopic damage and macroscopic stiffness.</data>
      <data key="d9">modeling,prediction</data>
      <data key="d10">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975018</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machines" target="Feature Learning">
      <data key="d7">1.0</data>
      <data key="d8">Restricted Boltzmann Machines are primarily used for the task of feature learning.</data>
      <data key="d9">capability,primary use</data>
      <data key="d10">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974617</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machines" target="Data Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Restricted Boltzmann Machines are primarily used for the task of data modeling.</data>
      <data key="d9">capability,primary use</data>
      <data key="d10">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974618</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machines" target="Energy-Based Model">
      <data key="d7">1.0</data>
      <data key="d8">Restricted Boltzmann Machines are a type of energy-based model.</data>
      <data key="d9">classification,foundation</data>
      <data key="d10">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974618</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machines" target="Stochastic Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Restricted Boltzmann Machines are a type of stochastic neural network.</data>
      <data key="d9">classification,structure</data>
      <data key="d10">chunk-74ac9b8a3a08c569f1c072b77c552920</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974618</data>
      <data key="d13" />
    </edge>
    <edge source="深度玻尔兹曼机" target="受限玻尔兹曼机">
      <data key="d7">2.0</data>
      <data key="d8">深度玻尔兹曼机以受限玻尔兹曼机为基础构建而成。&lt;SEP&gt;The Deep Boltzmann Machine (DBM) is an extension and generalization of the Restricted Boltzmann Machine (RBM).</data>
      <data key="d9">extension,generalization,基础,构成</data>
      <data key="d10">chunk-93a18801c2737ad9536660fe9501c9d8&lt;SEP&gt;chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974847</data>
      <data key="d13" />
    </edge>
    <edge source="深度玻尔兹曼机" target="深度学习模型">
      <data key="d7">1.0</data>
      <data key="d8">深度玻尔兹曼机是一种深度学习模型。</data>
      <data key="d9">属于,类别</data>
      <data key="d10">chunk-93a18801c2737ad9536660fe9501c9d8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974637</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="可见单元">
      <data key="d7">1.0</data>
      <data key="d8">受限玻尔兹曼机包含代表输入或可观测数据的可见单元。</data>
      <data key="d9">数据表示,模型结构</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974743</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="隐藏单元">
      <data key="d7">1.0</data>
      <data key="d8">受限玻尔兹曼机包含学习数据潜在表示的隐藏单元。</data>
      <data key="d9">模型结构,特征学习</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974745</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="隐藏层">
      <data key="d7">1.0</data>
      <data key="d8">The RBM model structure contains a hidden layer composed of neurons.</data>
      <data key="d9">contains,structural component</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974848</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="可见层">
      <data key="d7">1.0</data>
      <data key="d8">The RBM model structure contains a visible layer composed of neurons.</data>
      <data key="d9">contains,structural component</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974849</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="权重矩阵W">
      <data key="d7">1.0</data>
      <data key="d8">The RBM model uses the weight matrix $W$ to define the full connections between its hidden and visible layers.</data>
      <data key="d9">defines connections,parameter</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974850</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="偏倚系数向量a">
      <data key="d7">1.0</data>
      <data key="d8">The RBM model uses the bias coefficient vector $a$ for its visible layer neurons.</data>
      <data key="d9">bias,parameter</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974850</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="偏倚系数向量b">
      <data key="d7">1.0</data>
      <data key="d8">The RBM model uses the bias coefficient vector $b$ for its hidden layer neurons.</data>
      <data key="d9">bias,parameter</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974851</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="能量函数">
      <data key="d7">1.0</data>
      <data key="d8">The RBM model uses an energy function $E(v,h)$ to define the state energy given vectors $v$ and $h$.</data>
      <data key="d9">defines,uses</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974858</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="sigmoid激活函数">
      <data key="d7">1.0</data>
      <data key="d8">The RBM employs the sigmoid activation function for transformations between its visible and hidden layers.</data>
      <data key="d9">activation,employs</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974851</data>
      <data key="d13" />
    </edge>
    <edge source="受限玻尔兹曼机" target="对数损失函数">
      <data key="d7">1.0</data>
      <data key="d8">The RBM model uses the logarithmic loss function for training on a dataset to optimize its parameters $W, a, b$.</data>
      <data key="d9">optimization,uses for training</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974851</data>
      <data key="d13" />
    </edge>
    <edge source="隐藏单元" target="循环神经网络">
      <data key="d7">1.0</data>
      <data key="d8">Interconnected hidden units can form recurrent neural networks.</data>
      <data key="d9">formation,interconnection</data>
      <data key="d10">chunk-b2aa136f0a91bbc88ed87eed07a66512</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974653</data>
      <data key="d13" />
    </edge>
    <edge source="隐藏单元" target="层内连接">
      <data key="d7">1.0</data>
      <data key="d8">Restricting connections between hidden units (intra-layer connections) can make the model easier to train.</data>
      <data key="d9">restriction,training facilitation</data>
      <data key="d10">chunk-b2aa136f0a91bbc88ed87eed07a66512</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974653</data>
      <data key="d13" />
    </edge>
    <edge source="循环神经网络" target="自回归生成模型">
      <data key="d7">1.0</data>
      <data key="d8">Autoregressive generative models include recurrent neural networks as a specific type.</data>
      <data key="d9">includes,model category</data>
      <data key="d10">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975396</data>
      <data key="d13" />
    </edge>
    <edge source="HopField Network" target="Neuron">
      <data key="d7">1.0</data>
      <data key="d8">A HopField Network is composed of multiple neurons that interact with each other.</data>
      <data key="d9">computational unit,network architecture</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974741</data>
      <data key="d13" />
    </edge>
    <edge source="HopField Network" target="Energy Function">
      <data key="d7">1.0</data>
      <data key="d8">The dynamics of a HopField Network are governed by an energy function that it minimizes to reach a stable state.</data>
      <data key="d9">convergence,optimization</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974742</data>
      <data key="d13" />
    </edge>
    <edge source="HopField Network" target="Discrete HopField Network">
      <data key="d7">1.0</data>
      <data key="d8">A Discrete HopField Network is a specific type of HopField Network that uses a discrete activation function.</data>
      <data key="d9">model type,specialization</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974743</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Visible Unit">
      <data key="d7">1.0</data>
      <data key="d8">A Restricted Boltzmann Machine contains visible units that represent the input or observable data.</data>
      <data key="d9">data representation,model structure</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974741</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Hidden Unit">
      <data key="d7">1.0</data>
      <data key="d8">A Restricted Boltzmann Machine contains hidden units that learn latent representations of the data.</data>
      <data key="d9">feature learning,model structure</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974742</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Gradient Descent">
      <data key="d7">1.0</data>
      <data key="d8">Gradient descent is the theoretical optimization method for training a Restricted Boltzmann Machine.</data>
      <data key="d9">optimization,theoretical foundation</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974838</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Contrastive Divergence">
      <data key="d7">1.0</data>
      <data key="d8">Contrastive Divergence is a practical method commonly used to train Restricted Boltzmann Machines by approximating the gradient.</data>
      <data key="d9">approximation,training method</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974839</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Collaborative Filtering">
      <data key="d7">1.0</data>
      <data key="d8">Restricted Boltzmann Machines have been applied to the problem of collaborative filtering, as noted in referenced literature.</data>
      <data key="d9">application domain</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974839</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Gradient Formula">
      <data key="d7">1.0</data>
      <data key="d8">The training of an RBM involves calculating gradient formulas for its parameters (a, W, b) to update them.</data>
      <data key="d9">mathematical derivation,parameter update</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974840</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Visible Unit V">
      <data key="d7">1.0</data>
      <data key="d8">Visible units (V) are the observed layer of variables in the Restricted Boltzmann Machine model.</data>
      <data key="d9">model component,observed variable</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974841</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machine (Rbm)" target="Hidden Unit H">
      <data key="d7">1.0</data>
      <data key="d8">Hidden units (H) are the latent layer of variables in the Restricted Boltzmann Machine model.</data>
      <data key="d9">latent variable,model component</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974841</data>
      <data key="d13" />
    </edge>
    <edge source="Neuron" target="Weight">
      <data key="d7">1.0</data>
      <data key="d8">Connections between neurons are characterized by weights that modulate the signal strength.</data>
      <data key="d9">connection parameter,signal transmission</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974742</data>
      <data key="d13" />
    </edge>
    <edge source="Neuron" target="Threshold">
      <data key="d7">1.0</data>
      <data key="d8">Each neuron has a threshold that influences whether its state changes based on the weighted input.</data>
      <data key="d9">activation parameter,state change</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974743</data>
      <data key="d13" />
    </edge>
    <edge source="Neuron" target="State">
      <data key="d7">1.0</data>
      <data key="d8">The state of a neuron is its output value at a specific time, which changes according to network dynamics.</data>
      <data key="d9">activation value,temporal dynamics</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974744</data>
      <data key="d13" />
    </edge>
    <edge source="Discrete HopField Network" target="Sgn Function">
      <data key="d7">1.0</data>
      <data key="d8">The Discrete HopField Network uses the Sgn Function as its activation function to determine neuron states.</data>
      <data key="d9">activation,computation</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974745</data>
      <data key="d13" />
    </edge>
    <edge source="HopField网络" target="能量函数">
      <data key="d7">1.0</data>
      <data key="d8">HopField网络的动力学受其最小化的能量函数支配，以达到稳定状态。</data>
      <data key="d9">优化,收敛</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974743</data>
      <data key="d13" />
    </edge>
    <edge source="HopField网络" target="离散型HopField网络">
      <data key="d7">1.0</data>
      <data key="d8">离散型HopField网络是使用离散激活函数的一种特定类型的HopField网络。</data>
      <data key="d9">模型类型,特化</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974745</data>
      <data key="d13" />
    </edge>
    <edge source="HopField网络" target="递推式">
      <data key="d7">1.0</data>
      <data key="d8">HopField网络中神经元的状态更新由递推式描述。</data>
      <data key="d9">动态描述,数学建模</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974745</data>
      <data key="d13" />
    </edge>
    <edge source="HopField网络" target="权重矩阵">
      <data key="d7">1.0</data>
      <data key="d8">HopField网络的连接结构由对称且无自连接的权重矩阵定义。</data>
      <data key="d9">参数定义,连接结构</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974746</data>
      <data key="d13" />
    </edge>
    <edge source="阈值" target="ID3">
      <data key="d7">1.0</data>
      <data key="d8">The ID3 algorithm uses a threshold parameter to decide whether the information gain of the best feature is sufficient to continue splitting.</data>
      <data key="d9">algorithm parameter,stopping condition</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975935</data>
      <data key="d13" />
    </edge>
    <edge source="能量函数" target="能量增量">
      <data key="d7">1.0</data>
      <data key="d8">能量函数的总变化由每个神经元的能量增量组成，其负值保证了网络的收敛。</data>
      <data key="d9">局部变化,整体优化</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974745</data>
      <data key="d13" />
    </edge>
    <edge source="能量函数" target="概率分布P(v,h)">
      <data key="d7">1.0</data>
      <data key="d8">The energy function $E(v,h)$ serves as the basis for defining the probability distribution $P(v,h)$ of the RBM state.</data>
      <data key="d9">basis for,defines</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974849</data>
      <data key="d13" />
    </edge>
    <edge source="离散型HopField网络" target="符号函数">
      <data key="d7">1.0</data>
      <data key="d8">离散型HopField网络使用符号函数作为其激活函数来确定神经元状态。</data>
      <data key="d9">激活,计算</data>
      <data key="d10">chunk-52188c2297ba9ea322f462b96137a3c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974743</data>
      <data key="d13" />
    </edge>
    <edge source="Markov Chain Monte Carlo (Mcmc)" target="Gibbs Sampling">
      <data key="d7">1.0</data>
      <data key="d8">Gibbs Sampling is a specific type of Markov Chain Monte Carlo method used for sampling.</data>
      <data key="d9">simulation method,subclass</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974838</data>
      <data key="d13" />
    </edge>
    <edge source="Gibbs Sampling" target="Contrastive Divergence">
      <data key="d7">1.0</data>
      <data key="d8">The Contrastive Divergence method for training RBMs is based on the Gibbs sampling algorithm.</data>
      <data key="d9">algorithm basis,sampling technique</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974839</data>
      <data key="d13" />
    </edge>
    <edge source="Contrastive Divergence" target="Sample Gradient">
      <data key="d7">1.0</data>
      <data key="d8">Contrastive Divergence is used to approximate the sample gradient for each data point, which are then summed, making RBM training feasible.</data>
      <data key="d9">approximation method,training efficiency</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974842</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient Formula" target="Parameter A">
      <data key="d7">1.0</data>
      <data key="d8">The gradient formula includes the derivation for the gradient of parameter 'a'.</data>
      <data key="d9">defines gradient,mathematical expression</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974841</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient Formula" target="Parameter W">
      <data key="d7">1.0</data>
      <data key="d8">The gradient formula includes the derivation for the gradient of the weight matrix parameter 'W'.</data>
      <data key="d9">defines gradient,mathematical expression</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974841</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient Formula" target="Parameter B">
      <data key="d7">1.0</data>
      <data key="d8">The gradient formula includes the derivation for the gradient of the bias parameter 'b'.</data>
      <data key="d9">defines gradient,mathematical expression</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974844</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Ian Goodfellow">
      <data key="d7">1.0</data>
      <data key="d8">Ian Goodfellow is an author of the book "Deep Learning".</data>
      <data key="d9">authorship</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974840</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Yoshua Bengio">
      <data key="d7">1.0</data>
      <data key="d8">Yoshua Bengio is an author of the book "Deep Learning".</data>
      <data key="d9">authorship</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974841</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Aaron Courville">
      <data key="d7">1.0</data>
      <data key="d8">Aaron Courville is an author of the book "Deep Learning".</data>
      <data key="d9">authorship</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974842</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Digital Pathology">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning has applications in the analysis of digital pathology.</data>
      <data key="d9">application,tool</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975162</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Cell And Tissue Detection And Segmentation">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning is applied in the detection and segmentation of cells and tissues in digital pathology.</data>
      <data key="d9">application,capability</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975163</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Cancer Classification And Grading">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning is applied in the classification and grading of cancer in digital pathology.</data>
      <data key="d9">application,capability</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975164</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="This Paper">
      <data key="d7">1.0</data>
      <data key="d8">This paper describes the basic concept of deep learning.</data>
      <data key="d9">description,overview</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975166</data>
      <data key="d13" />
    </edge>
    <edge source="A Practical Guide To Training Restricted Boltzmann Machines" target="G.">
      <data key="d7">1.0</data>
      <data key="d8">G. is the author of the reference "A Practical Guide to Training Restricted Boltzmann Machines".</data>
      <data key="d9">authorship</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974848</data>
      <data key="d13" />
    </edge>
    <edge source="Restricted Boltzmann Machines For Collaborative Filtering" target="G.">
      <data key="d7">1.0</data>
      <data key="d8">G. is the author of the reference "Restricted Boltzmann Machines for Collaborative Filtering".</data>
      <data key="d9">authorship</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974842</data>
      <data key="d13" />
    </edge>
    <edge source="刘建平Pinard" target="Blog Post">
      <data key="d7">1.0</data>
      <data key="d8">刘建平Pinard is the author of the blog post containing the technical discussion on RBMs.</data>
      <data key="d9">authorship,content creation</data>
      <data key="d10">chunk-1fc2a79f5ff94f4338a312c2e0a2db74</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974842</data>
      <data key="d13" />
    </edge>
    <edge source="刘建平Pinard" target="深度学习">
      <data key="d7">1.0</data>
      <data key="d8">刘建平Pinard authored a document that discusses the field of deep learning and its neural network models.</data>
      <data key="d9">authoring,discussion</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974848</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="前向神经网络">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning encompasses the category of feedforward neural network models, which includes DNN and CNN.</data>
      <data key="d9">categorization,includes</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974844</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="反馈神经网络">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning encompasses the category of feedback neural network models, which includes RNN and LSTM.</data>
      <data key="d9">categorization,includes</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974844</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="数字病理">
      <data key="d7">2.0</data>
      <data key="d8">深度学习技术被应用于数字病理领域，用于对数字病理切片进行定量分析，辅助病理诊断。&lt;SEP&gt;深度学习是应用于数字病理分析的人工智能技术。</data>
      <data key="d9">application,technology,技术应用,数据分析</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975166</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="定量分析">
      <data key="d7">1.0</data>
      <data key="d8">深度学习推动病理分析从定性向定量分析转变。</data>
      <data key="d9">enables,transformation</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975166</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="细胞检测">
      <data key="d7">1.0</data>
      <data key="d8">深度学习被用于数字病理中的细胞检测。</data>
      <data key="d9">application,method</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975167</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="组织分割">
      <data key="d7">1.0</data>
      <data key="d8">深度学习被用于数字病理中的组织分割。</data>
      <data key="d9">application,method</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975168</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="癌症分类">
      <data key="d7">1.0</data>
      <data key="d8">深度学习被用于数字病理中组织层面上的癌症分类。</data>
      <data key="d9">application,method</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975169</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="癌症分级">
      <data key="d7">1.0</data>
      <data key="d8">深度学习被用于数字病理中组织层面上的癌症分级。</data>
      <data key="d9">application,method</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975170</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="人工智能">
      <data key="d7">1.0</data>
      <data key="d8">深度学习是人工智能技术的一种代表。</data>
      <data key="d9">includes,technology</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975172</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="传统机器学习算法">
      <data key="d7">1.0</data>
      <data key="d8">传统机器学习算法与深度学习算法都可用于定量分析，但深度学习能自动学习图像特征，处理能力更强。</data>
      <data key="d9">特征提取,算法对比</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975175</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="卷积神经网络">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络是深度学习的一种常用网络结构，特别适用于图像处理与计算机视觉任务。</data>
      <data key="d9">图像处理,网络结构</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975184</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="卷积">
      <data key="d7">1.0</data>
      <data key="d8">深度学习网络使用卷积技术来自动学习图像的特征表达。</data>
      <data key="d9">技术构成,特征提取</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975176</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="池化">
      <data key="d7">1.0</data>
      <data key="d8">深度学习网络使用池化技术来降低特征图的维度。</data>
      <data key="d9">技术构成,维度降低</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975177</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="Dropout">
      <data key="d7">1.0</data>
      <data key="d8">深度学习使用Dropout技术来辅助训练，防止模型过拟合。</data>
      <data key="d9">技术辅助,防止过拟合</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975178</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="ReLU函数">
      <data key="d7">1.0</data>
      <data key="d8">深度学习使用ReLU函数作为激活函数来引入非线性。</data>
      <data key="d9">技术辅助,激活函数</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975179</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="GPU">
      <data key="d7">1.0</data>
      <data key="d8">深度学习网络的训练过程可以使用GPU来加速计算。</data>
      <data key="d9">模型训练,硬件支持</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975181</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="交叉熵损失函数">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵损失函数是深度学习中用于衡量模型预测结果与实际标签差异的核心工具。</data>
      <data key="d9">应用领域,核心工具</data>
      <data key="d10">chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975621</data>
      <data key="d13" />
    </edge>
    <edge source="前向神经网络" target="DNN">
      <data key="d7">1.0</data>
      <data key="d8">The feedforward neural network category includes DNN as a specific model type.</data>
      <data key="d9">example,includes</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974844</data>
      <data key="d13" />
    </edge>
    <edge source="前向神经网络" target="CNN">
      <data key="d7">1.0</data>
      <data key="d8">The feedforward neural network category includes CNN as a specific model type.</data>
      <data key="d9">example,includes</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974846</data>
      <data key="d13" />
    </edge>
    <edge source="反馈神经网络" target="RNN">
      <data key="d7">1.0</data>
      <data key="d8">The feedback neural network category includes RNN as a specific model type.</data>
      <data key="d9">example,includes</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974846</data>
      <data key="d13" />
    </edge>
    <edge source="反馈神经网络" target="LSTM">
      <data key="d7">1.0</data>
      <data key="d8">The feedback neural network category includes LSTM as a specific model type.</data>
      <data key="d9">example,includes</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974848</data>
      <data key="d13" />
    </edge>
    <edge source="概率分布P(v,h)" target="归一化系数Z">
      <data key="d7">1.0</data>
      <data key="d8">The probability distribution $P(v,h)$ uses the normalization constant $Z$ in its formula.</data>
      <data key="d9">normalization,uses</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974849</data>
      <data key="d13" />
    </edge>
    <edge source="对数损失函数" target="梯度计算">
      <data key="d7">1.0</data>
      <data key="d8">Minimizing the logarithmic loss function requires gradient calculations for parameters like $a_i$ during RBM training.</data>
      <data key="d9">optimization step,requires</data>
      <data key="d10">chunk-e378397631b5d452d5eb095ebbfde434</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974850</data>
      <data key="d13" />
    </edge>
    <edge source="M2DNE" target="时间网络">
      <data key="d7">1.0</data>
      <data key="d8">M2DNE is a method designed to model and embed temporal networks.</data>
      <data key="d9">method application,modeling</data>
      <data key="d10">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974873</data>
      <data key="d13" />
    </edge>
    <edge source="M2DNE" target="微观动态">
      <data key="d7">1.0</data>
      <data key="d8">The M2DNE method integrates micro dynamics to capture detailed network formation processes.</data>
      <data key="d9">feature capture,method integration</data>
      <data key="d10">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974873</data>
      <data key="d13" />
    </edge>
    <edge source="M2DNE" target="宏观动态">
      <data key="d7">1.0</data>
      <data key="d8">The M2DNE method integrates macro dynamics to capture network-scale evolutionary patterns.</data>
      <data key="d9">method integration,pattern capture</data>
      <data key="d10">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974874</data>
      <data key="d13" />
    </edge>
    <edge source="时间网络" target="宏观动态">
      <data key="d7">1.0</data>
      <data key="d8">Macro dynamics describe the evolutionary patterns of temporal networks at a larger scale.</data>
      <data key="d9">evolution,pattern description</data>
      <data key="d10">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974873</data>
      <data key="d13" />
    </edge>
    <edge source="微观动态" target="网络结构">
      <data key="d7">1.0</data>
      <data key="d8">Micro dynamics describe the detailed process of network structure formation.</data>
      <data key="d9">formation,process description</data>
      <data key="d10">chunk-9be983c468c91cc26e854198668abadf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974873</data>
      <data key="d13" />
    </edge>
    <edge source="Olaf Sporns" target="Connectomics">
      <data key="d7">1.0</data>
      <data key="d8">Olaf Sporns first proposed the concept of Connectomics in 2005.</data>
      <data key="d9">concept proposal,research initiation</data>
      <data key="d10">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974897</data>
      <data key="d13" />
    </edge>
    <edge source="Olaf Sporns" target="Indiana University">
      <data key="d7">1.0</data>
      <data key="d8">Olaf Sporns is a researcher affiliated with Indiana University.</data>
      <data key="d9">affiliation,research institution</data>
      <data key="d10">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974898</data>
      <data key="d13" />
    </edge>
    <edge source="Connectomics" target="Neural Network Connections">
      <data key="d7">1.0</data>
      <data key="d8">Connectomics is a discipline primarily focused on the study of neural network connections.</data>
      <data key="d9">core subject,research focus</data>
      <data key="d10">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974898</data>
      <data key="d13" />
    </edge>
    <edge source="Connectomics" target="Neural Functional Connectivity Map">
      <data key="d7">1.0</data>
      <data key="d8">Connectomics, as a discipline, studies the neural functional connectivity maps that form the basis of behavior.</data>
      <data key="d9">disciplinary study,foundational research</data>
      <data key="d10">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974899</data>
      <data key="d13" />
    </edge>
    <edge source="Neural Network Connections" target="Neural Functional Connectivity Map">
      <data key="d7">1.0</data>
      <data key="d8">The neural functional connectivity map is built upon and represents the connections within neural networks.</data>
      <data key="d9">foundational structure,neurological basis</data>
      <data key="d10">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974897</data>
      <data key="d13" />
    </edge>
    <edge source="Neural Functional Connectivity Map" target="Organism">
      <data key="d7">1.0</data>
      <data key="d8">The neural functional connectivity map serves as the neurological foundation for any behavior performed by an organism.</data>
      <data key="d9">behavioral basis,biological foundation</data>
      <data key="d10">chunk-e0eade45db8d5fa19aa9c81c7da0ecef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974898</data>
      <data key="d13" />
    </edge>
    <edge source="神经科学家" target="大脑区域">
      <data key="d7">1.0</data>
      <data key="d8">神经科学家追踪大脑区域之间的连接。</data>
      <data key="d9">研究,追踪</data>
      <data key="d10">chunk-c78a1678dd8dd1d890f89ffee94c2631</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974931</data>
      <data key="d13" />
    </edge>
    <edge source="脑神经连结" target="脑网络造影技术">
      <data key="d7">1.0</data>
      <data key="d8">Brain network imaging technology is used to study and image brain neural connections.</data>
      <data key="d9">imaging,research method</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974978</data>
      <data key="d13" />
    </edge>
    <edge source="临床磁共振仪" target="复杂弥散神经影像">
      <data key="d7">1.0</data>
      <data key="d8">Clinical MRI scanners are used to acquire complex diffusion neural images.</data>
      <data key="d9">data acquisition,equipment</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974978</data>
      <data key="d13" />
    </edge>
    <edge source="临床磁共振仪" target="脑神经网络">
      <data key="d7">1.0</data>
      <data key="d8">Clinical MRI scanners are used to obtain data on brain neural networks.</data>
      <data key="d9">data acquisition,equipment</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974980</data>
      <data key="d13" />
    </edge>
    <edge source="树兰俊杰科学Talk第三十五期" target="脑与神经科学">
      <data key="d7">1.0</data>
      <data key="d8">The 35th Shulan Junjie Science Talk has "Brain and Neuroscience" as its conference theme.</data>
      <data key="d9">conference,event theme</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974978</data>
      <data key="d13" />
    </edge>
    <edge source="树兰俊杰科学Talk第三十五期" target="2022/07/28">
      <data key="d7">1.0</data>
      <data key="d8">The 35th Shulan Junjie Science Talk was scheduled to occur on July 28, 2022.</data>
      <data key="d9">date,event scheduling</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974980</data>
      <data key="d13" />
    </edge>
    <edge source="树兰俊杰科学Talk第三十五期" target="14:00-17:00">
      <data key="d7">1.0</data>
      <data key="d8">The 35th Shulan Junjie Science Talk was scheduled to take place from 14:00 to 17:00.</data>
      <data key="d9">event scheduling,time</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974981</data>
      <data key="d13" />
    </edge>
    <edge source="脑与神经科学" target="宏观尺度">
      <data key="d7">1.0</data>
      <data key="d8">The theme of brain and neuroscience encompasses discussions at the macro scale.</data>
      <data key="d9">concept scope,scale</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974980</data>
      <data key="d13" />
    </edge>
    <edge source="脑与神经科学" target="介观尺度">
      <data key="d7">1.0</data>
      <data key="d8">The theme of brain and neuroscience encompasses discussions at the meso scale.</data>
      <data key="d9">concept scope,scale</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974981</data>
      <data key="d13" />
    </edge>
    <edge source="脑与神经科学" target="微观尺度">
      <data key="d7">1.0</data>
      <data key="d8">The theme of brain and neuroscience encompasses discussions at the micro scale.</data>
      <data key="d9">concept scope,scale</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974981</data>
      <data key="d13" />
    </edge>
    <edge source="连接" target="涌现">
      <data key="d7">1.0</data>
      <data key="d8">Connection and emergence are both key concepts discussed in the conference theme.</data>
      <data key="d9">conference,thematic concepts</data>
      <data key="d10">chunk-3fa882df56ee354fb7b7e6d63cec74d9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768974979</data>
      <data key="d13" />
    </edge>
    <edge source="张滔韬" target="杨玉新">
      <data key="d7">1.0</data>
      <data key="d8">张滔韬and杨玉新are co-researchers on the study of solid propellant properties.</data>
      <data key="d9">collaboration,research</data>
      <data key="d10">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975018</data>
      <data key="d13" />
    </edge>
    <edge source="细观损伤" target="宏观刚度">
      <data key="d7">1.0</data>
      <data key="d8">Mesoscopic damage is correlated with and influences the macroscopic stiffness of solid propellants.</data>
      <data key="d9">correlation,material property</data>
      <data key="d10">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975018</data>
      <data key="d13" />
    </edge>
    <edge source="单轴拉伸" target="宏观刚度预报能力">
      <data key="d7">1.0</data>
      <data key="d8">Uniaxial tension is a condition used to test and validate the predictive capability for macroscopic stiffness.</data>
      <data key="d9">testing,validation</data>
      <data key="d10">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975018</data>
      <data key="d13" />
    </edge>
    <edge source="等双轴拉伸" target="宏观刚度预报能力">
      <data key="d7">1.0</data>
      <data key="d8">Equibiaxial tension is a condition used to test and validate the predictive capability for macroscopic stiffness.</data>
      <data key="d9">testing,validation</data>
      <data key="d10">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975019</data>
      <data key="d13" />
    </edge>
    <edge source="纯剪切" target="宏观刚度预报能力">
      <data key="d7">1.0</data>
      <data key="d8">Pure shear is a condition used to test and validate the predictive capability for macroscopic stiffness.</data>
      <data key="d9">testing,validation</data>
      <data key="d10">chunk-f922579134fc1d01217fc44031832b5f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975019</data>
      <data key="d13" />
    </edge>
    <edge source="Pathological Analysis" target="Quantitative Analysis">
      <data key="d7">1.0</data>
      <data key="d8">Pathological analysis is gradually evolving from qualitative analysis to quantitative analysis.</data>
      <data key="d9">evolution,methodological progression</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975162</data>
      <data key="d13" />
    </edge>
    <edge source="Pathological Analysis" target="Pathologist">
      <data key="d7">1.0</data>
      <data key="d8">Pathologists are the professionals who usually perform pathological analysis and prognosis.</data>
      <data key="d9">performs,responsibility</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975181</data>
      <data key="d13" />
    </edge>
    <edge source="Pathological Analysis" target="Prognosis">
      <data key="d7">1.0</data>
      <data key="d8">Pathological analysis and prognosis are both parts of the diagnostic process performed by pathologists.</data>
      <data key="d9">component,process</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975183</data>
      <data key="d13" />
    </edge>
    <edge source="AI Technology" target="Pathological Diagnosis">
      <data key="d7">1.0</data>
      <data key="d8">AI technology, especially deep neural networks, has greatly promoted the progress of pathological diagnosis.</data>
      <data key="d9">improvement,technological advancement</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975162</data>
      <data key="d13" />
    </edge>
    <edge source="AI Technology" target="Deep Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Deep neural network is a specific type of AI technology mentioned as a key promoter.</data>
      <data key="d9">component,subtype</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975163</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network" target="AlexNet">
      <data key="d7">1.0</data>
      <data key="d8">AlexNet is a prominent example of a deep convolutional network (a type of deep neural network).</data>
      <data key="d9">architecture,exemplar</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975188</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network" target="Image Classification">
      <data key="d7">1.0</data>
      <data key="d8">Deep neural networks like AlexNet are applied to tasks such as image classification.</data>
      <data key="d9">application,task</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975190</data>
      <data key="d13" />
    </edge>
    <edge source="Pathological Diagnosis" target="Pathological Slice">
      <data key="d7">1.0</data>
      <data key="d8">The pathological slice serves as the gold standard for pathological diagnosis.</data>
      <data key="d9">diagnostic standard,tool</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975163</data>
      <data key="d13" />
    </edge>
    <edge source="Pathological Diagnosis" target="Pathologist">
      <data key="d7">2.0</data>
      <data key="d8">A pathologist performs pathological diagnosis by examining pathological slices.&lt;SEP&gt;Pathologists perform pathological diagnosis by examining pathological slides.</data>
      <data key="d9">examination,expertise,performer,performs</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5&lt;SEP&gt;chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975164</data>
      <data key="d13" />
    </edge>
    <edge source="Pathologist" target="Prognostic Assessment">
      <data key="d7">1.0</data>
      <data key="d8">Pathologists perform prognostic assessment based on their examination of pathological slides.</data>
      <data key="d9">evaluation,performs</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975169</data>
      <data key="d13" />
    </edge>
    <edge source="Digital Pathology Analysis" target="This Paper">
      <data key="d7">1.0</data>
      <data key="d8">This paper describes the application of deep learning in digital pathology analysis.</data>
      <data key="d9">description,overview</data>
      <data key="d10">chunk-3c411bf3eba58c89e49b5bb56fce33e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975163</data>
      <data key="d13" />
    </edge>
    <edge source="闫雯" target="北京航空航天大学">
      <data key="d7">1.0</data>
      <data key="d8">闫雯是北京航空航天大学生物与医学工程系的作者。</data>
      <data key="d9">affiliation,authorship</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975163</data>
      <data key="d13" />
    </edge>
    <edge source="汤烨" target="北京航空航天大学">
      <data key="d7">1.0</data>
      <data key="d8">汤烨是北京航空航天大学生物与医学工程系的作者。</data>
      <data key="d9">affiliation,authorship</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975165</data>
      <data key="d13" />
    </edge>
    <edge source="张益肇" target="微软亚洲研究院">
      <data key="d7">1.0</data>
      <data key="d8">张益肇是微软亚洲研究院的作者。</data>
      <data key="d9">affiliation,authorship</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975164</data>
      <data key="d13" />
    </edge>
    <edge source="来茂德" target="浙江大学医学院">
      <data key="d7">1.0</data>
      <data key="d8">来茂德是浙江大学医学院基础医学院的作者。</data>
      <data key="d9">affiliation,authorship</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975164</data>
      <data key="d13" />
    </edge>
    <edge source="许燕" target="生物医学工程高精尖创新中心">
      <data key="d7">1.0</data>
      <data key="d8">许燕也隶属于生物医学工程高精尖创新中心。</data>
      <data key="d9">affiliation</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975165</data>
      <data key="d13" />
    </edge>
    <edge source="许燕" target="北京航空航天大学">
      <data key="d7">1.0</data>
      <data key="d8">许燕是通信作者，隶属于北京航空航天大学生物与医学工程系和软件开发环境国家重点实验室。</data>
      <data key="d9">affiliation,correspondence</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975174</data>
      <data key="d13" />
    </edge>
    <edge source="国家自然科学基金" target="深度学习在数字病理中的应用">
      <data key="d7">1.0</data>
      <data key="d8">国家自然科学基金(项目号81771910)为这项关于深度学习在数字病理中应用的研究提供了资金支持。</data>
      <data key="d9">funding,support</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975168</data>
      <data key="d13" />
    </edge>
    <edge source="深圳科创委" target="深度学习在数字病理中的应用">
      <data key="d7">1.0</data>
      <data key="d8">深圳科创委技术攻关项目(项目号shenfagai2016627)为这项研究提供了资金支持。</data>
      <data key="d9">funding,support</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975168</data>
      <data key="d13" />
    </edge>
    <edge source="北京市自然科学基金" target="深度学习在数字病理中的应用">
      <data key="d7">1.0</data>
      <data key="d8">北京市自然科学基金(项目号4152033)为这项研究提供了资金支持。</data>
      <data key="d9">funding,support</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975169</data>
      <data key="d13" />
    </edge>
    <edge source="国家科学技术重大专项" target="深度学习在数字病理中的应用">
      <data key="d7">1.0</data>
      <data key="d8">国家科学技术重大专项(项目号2017yfc0110903)为这项研究提供了资金支持。</data>
      <data key="d9">funding,support</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975170</data>
      <data key="d13" />
    </edge>
    <edge source="软件开发环境国家重点实验室" target="深度学习在数字病理中的应用">
      <data key="d7">1.0</data>
      <data key="d8">软件开发环境国家重点实验室中央高校基础研究基金(项目号sklsde-2017zx-08)为这项研究提供了资金支持。</data>
      <data key="d9">funding,support</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975174</data>
      <data key="d13" />
    </edge>
    <edge source="111项目" target="深度学习在数字病理中的应用">
      <data key="d7">1.0</data>
      <data key="d8">中国的111项目(项目号b13003)为这项研究提供了资金支持。</data>
      <data key="d9">funding,support</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975176</data>
      <data key="d13" />
    </edge>
    <edge source="数字病理" target="病理切片">
      <data key="d7">2.0</data>
      <data key="d8">数字病理涉及将传统的病理切片通过染色和数字化技术转换为数字病理切片，便于分析和存储。&lt;SEP&gt;数字病理涉及病理切片的数字化和分析。</data>
      <data key="d9">analysis,digitization,医学影像,数字化处理</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02&lt;SEP&gt;chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975166</data>
      <data key="d13" />
    </edge>
    <edge source="数字病理" target="全片数字化图像">
      <data key="d7">1.0</data>
      <data key="d8">全片数字化图像(WSI)是数字病理中的一种关键技术，实现了病理切片的全面数字化。</data>
      <data key="d9">技术实现,数据格式</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975171</data>
      <data key="d13" />
    </edge>
    <edge source="病理切片" target="癌症诊断">
      <data key="d7">1.0</data>
      <data key="d8">病理切片是癌症诊断的临床金标准。</data>
      <data key="d9">standard,tool</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975167</data>
      <data key="d13" />
    </edge>
    <edge source="病理切片" target="定量分析">
      <data key="d7">1.0</data>
      <data key="d8">定量分析应用于病理切片，通过计算量化指标(如有丝分裂数目)来提供更客观的病理诊断。</data>
      <data key="d9">客观评估,诊断方法</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975173</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="交叉熵损失函数">
      <data key="d7">1.0</data>
      <data key="d8">交叉熵损失函数在人工智能领域被用作衡量预测与标签差异的重要工具。</data>
      <data key="d9">应用领域,衡量工具</data>
      <data key="d10">chunk-04c7bf4ab86cafa8d0bdc6180c0f4db5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975620</data>
      <data key="d13" />
    </edge>
    <edge source="定量分析" target="定性分析">
      <data key="d7">1.0</data>
      <data key="d8">定性分析与定量分析是两种病理分析方法，前者主观且不可复现，后者客观且基于量化指标。</data>
      <data key="d9">主观与客观,分析方法对比</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975175</data>
      <data key="d13" />
    </edge>
    <edge source="定量分析" target="病理医生">
      <data key="d7">1.0</data>
      <data key="d8">病理医生越来越认识到定量分析的重要性，并借助其提供的客观指标来辅助完成病理诊断。</data>
      <data key="d9">专业应用,辅助诊断</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975184</data>
      <data key="d13" />
    </edge>
    <edge source="定量分析" target="有丝分裂数目">
      <data key="d7">1.0</data>
      <data key="d8">定量分析通过计算有丝分裂数目等指标来对病理切片进行评估。</data>
      <data key="d9">病理评估,计算指标</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975176</data>
      <data key="d13" />
    </edge>
    <edge source="定量分析" target="肿瘤的实质与间质的比例">
      <data key="d7">1.0</data>
      <data key="d8">定量分析通过计算肿瘤的实质与间质的比例来对病理切片进行评估。</data>
      <data key="d9">病理评估,计算指标</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975177</data>
      <data key="d13" />
    </edge>
    <edge source="定量分析" target="黏液湖和癌细胞的比例">
      <data key="d7">1.0</data>
      <data key="d8">定量分析通过计算黏液湖和癌细胞的比例来对病理切片进行评估。</data>
      <data key="d9">病理评估,计算指标</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975178</data>
      <data key="d13" />
    </edge>
    <edge source="中国生物医学工程学报" target="Deep Learning in Digital Pathology">
      <data key="d7">1.0</data>
      <data key="d8">The article "Deep Learning in Digital Pathology" was published in the Chinese Journal of Biomedical Engineering.</data>
      <data key="d9">content,publication</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975170</data>
      <data key="d13" />
    </edge>
    <edge source="Qualitative Analysis" target="Artificial Intelligence">
      <data key="d7">1.0</data>
      <data key="d8">Artificial intelligence technology is driving the transformation of pathological analysis from qualitative to quantitative analysis.</data>
      <data key="d9">technology,transformation</data>
      <data key="d10">chunk-3017e1ef0fe1ecc38a99f6da86ad2c02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975170</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能技术" target="病理分析">
      <data key="d7">1.0</data>
      <data key="d8">人工智能技术进入病理分析领域，推动了该领域从定性分析向定量分析的过渡和发展。</data>
      <data key="d9">技术推动,领域变革</data>
      <data key="d10">chunk-b332af60e3fc8fedacf0ad7703f20c18</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975176</data>
      <data key="d13" />
    </edge>
    <edge source="Krizhevsky" target="AlexNet">
      <data key="d7">2.0</data>
      <data key="d8">Krizhevsky proposed the deep convolutional network AlexNet in 2012.&lt;SEP&gt;The AlexNet deep convolutional network was proposed by Krizhevsky in 2012.</data>
      <data key="d9">development,origin,proposal,proposer</data>
      <data key="d10">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db&lt;SEP&gt;chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975177</data>
      <data key="d13" />
    </edge>
    <edge source="AlexNet" target="ImageNet">
      <data key="d7">2.0</data>
      <data key="d8">AlexNet was applied to the ImageNet dataset for image classification, achieving a 17.0% error rate.&lt;SEP&gt;AlexNet was evaluated and achieved significant results on the ImageNet dataset.</data>
      <data key="d9">application,dataset,evaluation,performance</data>
      <data key="d10">chunk-ea8a6fc4ba2e7bba693b03aaff3df4db&lt;SEP&gt;chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975178</data>
      <data key="d13" />
    </edge>
    <edge source="图2" target="水分子">
      <data key="d7">1.0</data>
      <data key="d8">图2展示了水分子的结构。</data>
      <data key="d9">图示,展示</data>
      <data key="d10">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975214</data>
      <data key="d13" />
    </edge>
    <edge source="图2" target="微观堆积结构">
      <data key="d7">1.0</data>
      <data key="d8">图2展示了水分子的微观堆积结构。</data>
      <data key="d9">图示,展示</data>
      <data key="d10">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975214</data>
      <data key="d13" />
    </edge>
    <edge source="State Key Laboratory Of Software Development Environment" target="Beihang University">
      <data key="d7">1.0</data>
      <data key="d8">The State Key Laboratory of Software Development Environment is part of or affiliated with Beihang University.</data>
      <data key="d9">affiliation,research</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975179</data>
      <data key="d13" />
    </edge>
    <edge source="Key Laboratory Of Biomechanics And Mechanobiology" target="Ministry Of Education">
      <data key="d7">1.0</data>
      <data key="d8">The Key Laboratory of Biomechanics and Mechanobiology is under the Ministry of Education.</data>
      <data key="d9">affiliation,governance</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975180</data>
      <data key="d13" />
    </edge>
    <edge source="Key Laboratory Of Biomechanics And Mechanobiology" target="Beihang University">
      <data key="d7">1.0</data>
      <data key="d8">The Key Laboratory of Biomechanics and Mechanobiology is affiliated with or located at Beihang University.</data>
      <data key="d9">affiliation,research</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975183</data>
      <data key="d13" />
    </edge>
    <edge source="Beihang University" target="Beijing Advanced Innovation Center For Biomedical Engineering">
      <data key="d7">1.0</data>
      <data key="d8">Beihang University is associated with the Beijing Advanced Innovation Center for Biomedical Engineering.</data>
      <data key="d9">affiliation,collaboration</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975181</data>
      <data key="d13" />
    </edge>
    <edge source="Beijing Advanced Innovation Center For Biomedical Engineering" target="Beijing">
      <data key="d7">1.0</data>
      <data key="d8">The Beijing Advanced Innovation Center for Biomedical Engineering is located in Beijing.</data>
      <data key="d9">location,operation</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975183</data>
      <data key="d13" />
    </edge>
    <edge source="Microsoft Research" target="Beijing">
      <data key="d7">1.0</data>
      <data key="d8">Microsoft Research has a location in Beijing, China.</data>
      <data key="d9">location,operation</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975184</data>
      <data key="d13" />
    </edge>
    <edge source="Department Of Pathology, School Of Medicine, Zhejiang University" target="Hangzhou">
      <data key="d7">1.0</data>
      <data key="d8">The Department of Pathology, School of Medicine, Zhejiang University is located in Hangzhou, China.</data>
      <data key="d9">location,operation</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975182</data>
      <data key="d13" />
    </edge>
    <edge source="Pathology" target="Cancer">
      <data key="d7">1.0</data>
      <data key="d8">Pathology is the gold standard for the diagnosis of cancer.</data>
      <data key="d9">diagnosis,standard</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975180</data>
      <data key="d13" />
    </edge>
    <edge source="Whole Slide Pathology" target="Artificial Intelligence">
      <data key="d7">1.0</data>
      <data key="d8">The development of whole slide pathology is aided by artificial intelligence, which may promote pathological analysis.</data>
      <data key="d9">development,promotion</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975189</data>
      <data key="d13" />
    </edge>
    <edge source="Shenzhen" target="Research Institute Of Beihang University">
      <data key="d7">1.0</data>
      <data key="d8">The Research Institute of Beihang University is located in Shenzhen.</data>
      <data key="d9">location,operation</data>
      <data key="d10">chunk-7dfbc91c9b402abe636a1533d1036084</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975182</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Convolutional Layer">
      <data key="d7">1.0</data>
      <data key="d8">A Convolutional Neural Network is constituted by a convolutional layer.</data>
      <data key="d9">component,network architecture</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975183</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Pooling Layer">
      <data key="d7">1.0</data>
      <data key="d8">A Convolutional Neural Network is constituted by a pooling layer.</data>
      <data key="d9">component,network architecture</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975184</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Fully Connected Layer">
      <data key="d7">1.0</data>
      <data key="d8">A Convolutional Neural Network is constituted by a fully connected layer.</data>
      <data key="d9">component,network architecture</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975185</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Weight Sharing">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks introduce the concept of weight sharing, which greatly reduces the number of parameters.</data>
      <data key="d9">core principle,parameter reduction</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975188</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Local Receptive Field">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks introduce the concept of a local receptive field.</data>
      <data key="d9">core principle,feature extraction</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975189</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Cost Function">
      <data key="d7">1.0</data>
      <data key="d8">Training a Convolutional Neural Network involves minimizing a cost function to fit the training data.</data>
      <data key="d9">optimization,training objective</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975191</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Traditional Recognition Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks take images directly as input, avoiding the complex manual feature design process of traditional recognition algorithms.</data>
      <data key="d9">automation,feature extraction</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975191</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Layer" target="Weight Sharing">
      <data key="d7">1.0</data>
      <data key="d8">Hidden neurons in a convolutional layer use weight sharing, having the same weights and biases.</data>
      <data key="d9">implementation,parameter sharing</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975184</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Layer" target="Activation Function">
      <data key="d7">1.0</data>
      <data key="d8">The output of a neuron in a convolutional layer is computed using an activation function.</data>
      <data key="d9">component,non-linearity</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975185</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Layer" target="ReLU Function">
      <data key="d7">1.0</data>
      <data key="d8">The ReLU function is a commonly used activation function that often appears with convolutional layers.</data>
      <data key="d9">activation,common usage</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975188</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Layer" target="Feature Map">
      <data key="d7">1.0</data>
      <data key="d8">Each hidden neuron in a convolutional layer learns a specific feature map.</data>
      <data key="d9">output,representation</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975189</data>
      <data key="d13" />
    </edge>
    <edge source="Pooling Layer" target="Max-Pooling">
      <data key="d7">1.0</data>
      <data key="d8">Max-pooling is a common type of pooling layer operation.</data>
      <data key="d9">down-sampling,operation type</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975186</data>
      <data key="d13" />
    </edge>
    <edge source="Pooling Layer" target="Average-Pooling">
      <data key="d7">1.0</data>
      <data key="d8">Average-pooling is a common type of pooling layer operation.</data>
      <data key="d9">down-sampling,operation type</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975188</data>
      <data key="d13" />
    </edge>
    <edge source="Pooling Layer" target="Overfitting">
      <data key="d7">1.0</data>
      <data key="d8">Pooling layers help reduce the number of parameters and prevent overfitting.</data>
      <data key="d9">prevention,regularization</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975190</data>
      <data key="d13" />
    </edge>
    <edge source="ReLU Function" target="Vanishing Gradient Problem">
      <data key="d7">1.0</data>
      <data key="d8">The ReLU function helps alleviate the vanishing gradient problem during backpropagation.</data>
      <data key="d9">mitigation,training stability</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975190</data>
      <data key="d13" />
    </edge>
    <edge source="Cost Function" target="Backpropagation Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">The backpropagation algorithm is used to efficiently minimize the cost function during network training.</data>
      <data key="d9">gradient computation,optimization method</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975186</data>
      <data key="d13" />
    </edge>
    <edge source="Backpropagation Algorithm" target="Rumelhart">
      <data key="d7">1.0</data>
      <data key="d8">The backpropagation algorithm was proposed by Rumelhart in 1986.</data>
      <data key="d9">origin,proposer</data>
      <data key="d10">chunk-7a3587ecc73a04aa2e8c9c6682b98cec</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975188</data>
      <data key="d13" />
    </edge>
    <edge source="水分子" target="氢">
      <data key="d7">1.0</data>
      <data key="d8">水分子由两个氢原子和一个氧原子通过化学键结合而成。</data>
      <data key="d9">化学键,组成</data>
      <data key="d10">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975214</data>
      <data key="d13" />
    </edge>
    <edge source="水分子" target="氧">
      <data key="d7">1.0</data>
      <data key="d8">水分子由一个氧原子和两个氢原子通过化学键结合而成。</data>
      <data key="d9">化学键,组成</data>
      <data key="d10">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975214</data>
      <data key="d13" />
    </edge>
    <edge source="微观堆积结构" target="物理化学性质">
      <data key="d7">1.0</data>
      <data key="d8">水的特殊物理化学性质源于其微观堆积结构。</data>
      <data key="d9">决定,起源</data>
      <data key="d10">chunk-ce6ef636e7f1aba9c1d2e5f6ef438c33</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975214</data>
      <data key="d13" />
    </edge>
    <edge source="Allen Mouse Brain Common Coordinate Framework" target="Wang Q X">
      <data key="d7">1.0</data>
      <data key="d8">Wang Q X is an author of the paper describing the Allen Mouse Brain Common Coordinate Framework.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975278</data>
      <data key="d13" />
    </edge>
    <edge source="Allen Mouse Brain Common Coordinate Framework" target="Ding S L">
      <data key="d7">1.0</data>
      <data key="d8">Ding S L is an author of the paper describing the Allen Mouse Brain Common Coordinate Framework.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975278</data>
      <data key="d13" />
    </edge>
    <edge source="Allen Mouse Brain Common Coordinate Framework" target="Li Y">
      <data key="d7">1.0</data>
      <data key="d8">Li Y is an author of the paper describing the Allen Mouse Brain Common Coordinate Framework.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975279</data>
      <data key="d13" />
    </edge>
    <edge source="Allen Mouse Brain Common Coordinate Framework" target="Cell">
      <data key="d7">1.0</data>
      <data key="d8">The paper on the Allen Mouse Brain Common Coordinate Framework was published in the journal Cell.</data>
      <data key="d9">publication,venue</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975281</data>
      <data key="d13" />
    </edge>
    <edge source="The Logic Of Single-Cell Projections From Visual Cortex" target="Han Y Y">
      <data key="d7">1.0</data>
      <data key="d8">Han Y Y is an author of the paper on the logic of single-cell projections from visual cortex.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975278</data>
      <data key="d13" />
    </edge>
    <edge source="The Logic Of Single-Cell Projections From Visual Cortex" target="Kebschull J M">
      <data key="d7">1.0</data>
      <data key="d8">Kebschull J M is an author of the paper on the logic of single-cell projections from visual cortex.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975278</data>
      <data key="d13" />
    </edge>
    <edge source="The Logic Of Single-Cell Projections From Visual Cortex" target="Campbell R A A">
      <data key="d7">1.0</data>
      <data key="d8">Campbell R A A is an author of the paper on the logic of single-cell projections from visual cortex.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975279</data>
      <data key="d13" />
    </edge>
    <edge source="The Logic Of Single-Cell Projections From Visual Cortex" target="Nature">
      <data key="d7">1.0</data>
      <data key="d8">The paper on the logic of single-cell projections from visual cortex was published in the journal Nature.</data>
      <data key="d9">publication,venue</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975281</data>
      <data key="d13" />
    </edge>
    <edge source="Nature" target="High-Performance Brain-To-Text Communication Via Handwriting">
      <data key="d7">1.0</data>
      <data key="d8">The paper on high-performance brain-to-text communication via handwriting was published in the journal Nature.</data>
      <data key="d9">publication,venue</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975285</data>
      <data key="d13" />
    </edge>
    <edge source="Hippocampal Contribution To Ordinal Psychological Time In The Human Brain" target="Gauthier B">
      <data key="d7">1.0</data>
      <data key="d8">Gauthier B is an author of the paper on hippocampal contribution to ordinal psychological time.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975278</data>
      <data key="d13" />
    </edge>
    <edge source="Hippocampal Contribution To Ordinal Psychological Time In The Human Brain" target="Prabhu P">
      <data key="d7">1.0</data>
      <data key="d8">Prabhu P is an author of the paper on hippocampal contribution to ordinal psychological time.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975279</data>
      <data key="d13" />
    </edge>
    <edge source="Hippocampal Contribution To Ordinal Psychological Time In The Human Brain" target="Kotegar K A">
      <data key="d7">1.0</data>
      <data key="d8">Kotegar K A is an author of the paper on hippocampal contribution to ordinal psychological time.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975281</data>
      <data key="d13" />
    </edge>
    <edge source="Hippocampal Contribution To Ordinal Psychological Time In The Human Brain" target="Journal Of Cognitive Neuroscience">
      <data key="d7">1.0</data>
      <data key="d8">The paper on hippocampal contribution to ordinal psychological time was published in the Journal of Cognitive Neuroscience.</data>
      <data key="d9">publication,venue</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975283</data>
      <data key="d13" />
    </edge>
    <edge source="High-Performance Brain-To-Text Communication Via Handwriting" target="Willett F R">
      <data key="d7">1.0</data>
      <data key="d8">Willett F R is an author of the paper on high-performance brain-to-text communication via handwriting.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975280</data>
      <data key="d13" />
    </edge>
    <edge source="High-Performance Brain-To-Text Communication Via Handwriting" target="Avansino D T">
      <data key="d7">1.0</data>
      <data key="d8">Avansino D T is an author of the paper on high-performance brain-to-text communication via handwriting.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975281</data>
      <data key="d13" />
    </edge>
    <edge source="High-Performance Brain-To-Text Communication Via Handwriting" target="Hochberg L R">
      <data key="d7">1.0</data>
      <data key="d8">Hochberg L R is an author of the paper on high-performance brain-to-text communication via handwriting.</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-7f7cfd0cd4e85028a17edf6e5da1190c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975283</data>
      <data key="d13" />
    </edge>
    <edge source="网络" target="输出层配分函数">
      <data key="d7">1.0</data>
      <data key="d8">The network possesses an output layer partition function as one of its properties.</data>
      <data key="d9">component,property</data>
      <data key="d10">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975311</data>
      <data key="d13" />
    </edge>
    <edge source="网络" target="配分函数">
      <data key="d7">1.0</data>
      <data key="d8">The partition function is defined for the network and has a clear physical meaning related to information.</data>
      <data key="d9">mathematical representation,physical meaning</data>
      <data key="d10">chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975337</data>
      <data key="d13" />
    </edge>
    <edge source="网络" target="特征值">
      <data key="d7">1.0</data>
      <data key="d8">The eigenvalues of a matrix L are used in the calculation of the network's partition function.</data>
      <data key="d9">calculation,mathematical property</data>
      <data key="d10">chunk-7d7618b6fffb013ab6c5a2ca3a3fea50</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975338</data>
      <data key="d13" />
    </edge>
    <edge source="输出层配分函数" target="配分函数">
      <data key="d7">1.0</data>
      <data key="d8">The output layer partition function is stated to be equal to the partition function of the input data.</data>
      <data key="d9">equivalence,identity</data>
      <data key="d10">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975311</data>
      <data key="d13" />
    </edge>
    <edge source="输出层配分函数" target="输入数据">
      <data key="d7">1.0</data>
      <data key="d8">The output layer partition function is equal to the partition function of the input data.</data>
      <data key="d9">equivalence,identity</data>
      <data key="d10">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975312</data>
      <data key="d13" />
    </edge>
    <edge source="输入数据" target="一维伊辛模型">
      <data key="d7">1.0</data>
      <data key="d8">The input data is specifically represented by a one-dimensional Ising model.</data>
      <data key="d9">instance,representation</data>
      <data key="d10">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975311</data>
      <data key="d13" />
    </edge>
    <edge source="输入数据" target="神经网络训练">
      <data key="d7">1.0</data>
      <data key="d8">Neural network training utilizes input data to learn and optimize the model.</data>
      <data key="d9">processing,utilization</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975589</data>
      <data key="d13" />
    </edge>
    <edge source="输入数据" target="类别概率分布">
      <data key="d7">1.0</data>
      <data key="d8">Input data is characterized by its actual category probability distribution.</data>
      <data key="d9">characterization,representation</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975591</data>
      <data key="d13" />
    </edge>
    <edge source="输入数据" target="误差">
      <data key="d7">1.0</data>
      <data key="d8">Error is calculated by comparing the model prediction against the input data's actual distribution.</data>
      <data key="d9">comparison,discrepancy</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975591</data>
      <data key="d13" />
    </edge>
    <edge source="配分函数" target="训练过程">
      <data key="d7">1.0</data>
      <data key="d8">During the training process, the value of the partition function remains invariant as time progresses.</data>
      <data key="d9">constraint,invariance</data>
      <data key="d10">chunk-bc6cd88a44423ac7bc4a08969a8b99f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975311</data>
      <data key="d13" />
    </edge>
    <edge source="配分函数" target="对数似然">
      <data key="d7">1.0</data>
      <data key="d8">对数似然相对于参数的梯度包含一项对应于配分函数梯度的项，体现了它们之间的数学依赖关系。</data>
      <data key="d9">数学关系,梯度计算</data>
      <data key="d10">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975420</data>
      <data key="d13" />
    </edge>
    <edge source="配分函数" target="无向模型">
      <data key="d7">1.0</data>
      <data key="d8">无向模型的概率计算依赖于配分函数，该函数是模型的一个关键组成部分。</data>
      <data key="d9">依赖关系,模型组件</data>
      <data key="d10">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975421</data>
      <data key="d13" />
    </edge>
    <edge source="配分函数" target="归一化常数">
      <data key="d7">1.0</data>
      <data key="d8">The partition function is also referred to as the normalization constant.</data>
      <data key="d9">mathematical equivalence,synonym</data>
      <data key="d10">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975457</data>
      <data key="d13" />
    </edge>
    <edge source="配分函数" target="对数-配分函数">
      <data key="d7">1.0</data>
      <data key="d8">The log-partition function is the logarithm of the partition function.</data>
      <data key="d9">derived property,mathematical operation</data>
      <data key="d10">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975457</data>
      <data key="d13" />
    </edge>
    <edge source="配分函数" target="统计物理学">
      <data key="d7">1.0</data>
      <data key="d8">The partition function originates from and is a key concept in statistical physics.</data>
      <data key="d9">application domain,theoretical origin</data>
      <data key="d10">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975458</data>
      <data key="d13" />
    </edge>
    <edge source="Batchsize" target="显存">
      <data key="d7">1.0</data>
      <data key="d8">降低Batchsize可以带来显存使用量的大幅减少，从而优化资源利用。</data>
      <data key="d9">性能优化,资源节省</data>
      <data key="d10">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975361</data>
      <data key="d13" />
    </edge>
    <edge source="计算开销" target="通信">
      <data key="d7">1.0</data>
      <data key="d8">通信和存储的成本通常高于纯粹的计算开销，这是系统设计中的一个重要考量。</data>
      <data key="d9">成本对比,系统开销</data>
      <data key="d10">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975360</data>
      <data key="d13" />
    </edge>
    <edge source="计算开销" target="存储">
      <data key="d7">1.0</data>
      <data key="d8">存储的成本通常高于纯粹的计算开销，这是系统设计中的一个重要考量。</data>
      <data key="d9">成本对比,系统开销</data>
      <data key="d10">chunk-36562522576eae8192339d548d0a1406</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975361</data>
      <data key="d13" />
    </edge>
    <edge source="动力配分函数" target="创新方法">
      <data key="d7">1.0</data>
      <data key="d8">The innovative method is applied for the efficient calculation of the dynamic partition function.</data>
      <data key="d9">application,calculation</data>
      <data key="d10">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975396</data>
      <data key="d13" />
    </edge>
    <edge source="PixelCNN" target="自回归生成模型">
      <data key="d7">1.0</data>
      <data key="d8">Autoregressive generative models include PixelCNN as a specific type.</data>
      <data key="d9">includes,model category</data>
      <data key="d10">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975397</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="自回归生成模型">
      <data key="d7">1.0</data>
      <data key="d8">Autoregressive generative models include Transformer as a specific type.</data>
      <data key="d9">includes,model category</data>
      <data key="d10">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975404</data>
      <data key="d13" />
    </edge>
    <edge source="自回归生成模型" target="创新方法">
      <data key="d7">1.0</data>
      <data key="d8">The innovative method utilizes autoregressive generative models.</data>
      <data key="d9">methodology,utilizes</data>
      <data key="d10">chunk-5b96b65f16399f35c9b04de8b22d0796</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975397</data>
      <data key="d13" />
    </edge>
    <edge source="最大似然学习" target="无向模型">
      <data key="d7">1.0</data>
      <data key="d8">最大似然学习方法被应用于无向模型，但由于配分函数依赖参数，导致学习过程特别困难。</data>
      <data key="d9">参数估计,学习困难</data>
      <data key="d10">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975420</data>
      <data key="d13" />
    </edge>
    <edge source="对数似然" target="∇θlog˜p(x;θ)">
      <data key="d7">1.0</data>
      <data key="d8">对数似然的梯度包含未归一化对数概率的梯度项。</data>
      <data key="d9">数学分解,梯度项</data>
      <data key="d10">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975421</data>
      <data key="d13" />
    </edge>
    <edge source="对数似然" target="∇θlogZ(θ)">
      <data key="d7">1.0</data>
      <data key="d8">对数似然的梯度包含配分函数对数的梯度项。</data>
      <data key="d9">数学分解,梯度项</data>
      <data key="d10">chunk-f5c5908d5644515cf8bcda82498e6671</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975429</data>
      <data key="d13" />
    </edge>
    <edge source="归一化常数" target="softmax">
      <data key="d7">1.0</data>
      <data key="d8">The softmax function utilizes a normalization constant in its computation.</data>
      <data key="d9">implementation,mathematical function</data>
      <data key="d10">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975457</data>
      <data key="d13" />
    </edge>
    <edge source="统计物理学" target="粒子群">
      <data key="d7">1.0</data>
      <data key="d8">Statistical physics models the distribution of particle ensembles.</data>
      <data key="d9">modeling subject,theoretical framework</data>
      <data key="d10">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975458</data>
      <data key="d13" />
    </edge>
    <edge source="NDArray" target="softmax">
      <data key="d7">1.0</data>
      <data key="d8">The softmax function takes an NDArray as its input parameter X.</data>
      <data key="d9">data structure,input parameter</data>
      <data key="d10">chunk-882f6cc5b251194ec83bb3e0280e7611</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975458</data>
      <data key="d13" />
    </edge>
    <edge source="Yu J F" target="Rev. B">
      <data key="d7">1.0</data>
      <data key="d8">Yu J F is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975511</data>
      <data key="d13" />
    </edge>
    <edge source="Xie Z Y" target="Rev. B">
      <data key="d7">1.0</data>
      <data key="d8">Xie Z Y is an author of multiple papers published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975511</data>
      <data key="d13" />
    </edge>
    <edge source="Meurice Y" target="Rev. B">
      <data key="d7">1.0</data>
      <data key="d8">Meurice Y is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975512</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Liu W Y">
      <data key="d7">1.0</data>
      <data key="d8">Liu W Y is an author of multiple papers published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975519</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Dong S">
      <data key="d7">1.0</data>
      <data key="d8">Dong S is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975512</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Wang C">
      <data key="d7">1.0</data>
      <data key="d8">Wang C is an author of papers published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975512</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Liao H J">
      <data key="d7">1.0</data>
      <data key="d8">Liao H J is an author of multiple papers published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975512</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Huang R Z">
      <data key="d7">1.0</data>
      <data key="d8">Huang R Z is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975512</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Chen J">
      <data key="d7">1.0</data>
      <data key="d8">Chen J is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975513</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Han Y J">
      <data key="d7">1.0</data>
      <data key="d8">Han Y J is an author of papers published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975513</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Dong S J">
      <data key="d7">1.0</data>
      <data key="d8">Dong S J is an author of papers published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975513</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Liang X">
      <data key="d7">1.0</data>
      <data key="d8">Liang X is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975514</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Lin P Z">
      <data key="d7">1.0</data>
      <data key="d8">Lin P Z is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975514</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Liu J G">
      <data key="d7">1.0</data>
      <data key="d8">Liu J G is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975515</data>
      <data key="d13" />
    </edge>
    <edge source="Rev. B" target="Wang L">
      <data key="d7">1.0</data>
      <data key="d8">Wang L is an author of a paper published in the journal Rev. B.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-f18946bdfdf43151c934dc17cbcb459e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975516</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络训练" target="模型参数">
      <data key="d7">1.0</data>
      <data key="d8">The primary goal of neural network training is to optimize the model parameters.</data>
      <data key="d9">adjustment,optimization</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975591</data>
      <data key="d13" />
    </edge>
    <edge source="类别概率分布" target="模型预测">
      <data key="d7">1.0</data>
      <data key="d8">The model prediction generates a predicted category probability distribution.</data>
      <data key="d9">generation,output</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975591</data>
      <data key="d13" />
    </edge>
    <edge source="模型预测" target="误差">
      <data key="d7">1.0</data>
      <data key="d8">Error represents the discrepancy between the model's predicted distribution and the actual distribution.</data>
      <data key="d9">comparison,discrepancy</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975593</data>
      <data key="d13" />
    </edge>
    <edge source="误差" target="损失">
      <data key="d7">1.0</data>
      <data key="d8">Error is synonymous with loss, quantifying the model's prediction inaccuracy.</data>
      <data key="d9">quantification,synonymy</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975599</data>
      <data key="d13" />
    </edge>
    <edge source="误差" target="输出端">
      <data key="d7">1.0</data>
      <data key="d8">The error/loss is initially calculated at the output end of the network.</data>
      <data key="d9">calculation,origin</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975592</data>
      <data key="d13" />
    </edge>
    <edge source="误差" target="输入端">
      <data key="d7">1.0</data>
      <data key="d8">The calculated error is propagated backward from the output end to the input end to guide optimization.</data>
      <data key="d9">optimization signal,propagation</data>
      <data key="d10">chunk-c110f5c53d8d82646eee2498b51ba01a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975592</data>
      <data key="d13" />
    </edge>
    <edge source="均方误差" target="Huber损失">
      <data key="d7">1.0</data>
      <data key="d8">Huber损失旨在平衡均方误差和平均绝对误差的优势，提供更好的优化特性。</data>
      <data key="d9">优化,平衡</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975711</data>
      <data key="d13" />
    </edge>
    <edge source="均方误差" target="L2损失">
      <data key="d7">1.0</data>
      <data key="d8">均方误差也被称为L2损失或二次损失。</data>
      <data key="d9">别名,术语</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975712</data>
      <data key="d13" />
    </edge>
    <edge source="均方误差" target="二次损失">
      <data key="d7">1.0</data>
      <data key="d8">均方误差也被称为二次损失或L2损失。</data>
      <data key="d9">别名,术语</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975713</data>
      <data key="d13" />
    </edge>
    <edge source="平均绝对误差" target="Huber损失">
      <data key="d7">1.0</data>
      <data key="d8">Huber损失结合了平均绝对误差对异常值的鲁棒性。</data>
      <data key="d9">平衡,鲁棒性</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975711</data>
      <data key="d13" />
    </edge>
    <edge source="平均绝对误差" target="L1损失">
      <data key="d7">1.0</data>
      <data key="d8">平均绝对误差也被称为L1损失。</data>
      <data key="d9">别名,术语</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975712</data>
      <data key="d13" />
    </edge>
    <edge source="Huber损失" target="平滑L1损失">
      <data key="d7">1.0</data>
      <data key="d8">Huber损失也被称为平滑L1损失。</data>
      <data key="d9">别名,术语</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975712</data>
      <data key="d13" />
    </edge>
    <edge source="Huber损失" target="超参数δ">
      <data key="d7">1.0</data>
      <data key="d8">Huber损失函数包含一个可调整的超参数δ，该参数定义了其行为的过渡点。</data>
      <data key="d9">包含,参数</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975714</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Granite" target="IBM">
      <data key="d7">2.0</data>
      <data key="d8">IBM Granite是IBM开发并提供的一个开放式、性能优异的AI模型系列。&lt;SEP&gt;IBM Granite is a series of AI models developed and offered by IBM.</data>
      <data key="d9">corporate ownership,product development,开发,提供</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976058</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="Think时事通讯">
      <data key="d7">2.0</data>
      <data key="d8">Think时事通讯由IBM发布，用户订阅时需要参阅IBM隐私声明。&lt;SEP&gt;IBM publishes the Think newsletter, which provides AI news and insights.</data>
      <data key="d9">content distribution,publication,发布,订阅</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976062</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="指南">
      <data key="d7">1.0</data>
      <data key="d8">指南是IBM发布的关于在AI新时代树立信任的指导性内容。</data>
      <data key="d9">内容,发布</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975714</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="调查报告">
      <data key="d7">1.0</data>
      <data key="d8">调查报告是IBM对2000家组织进行的调查并发布的结果。</data>
      <data key="d9">发布,进行</data>
      <data key="d10">chunk-408bf4ea5cb0bf2933de13a97fd69ee6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975715</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="IBM watsonx.ai">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai is an AI development platform created and offered by IBM.</data>
      <data key="d9">corporate ownership,product development</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976061</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="2024年AI实际应用">
      <data key="d7">1.0</data>
      <data key="d8">IBM conducted a survey and published the "2024 AI Actual Application" report.</data>
      <data key="d9">industry analysis,research publication</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976070</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Language">
      <data key="d7">1.0</data>
      <data key="d8">AI applications are optimized for language capabilities.</data>
      <data key="d9">capability,optimization</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975714</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Code">
      <data key="d7">1.0</data>
      <data key="d8">AI applications are optimized for code capabilities.</data>
      <data key="d9">capability,optimization</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975714</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Time Series">
      <data key="d7">1.0</data>
      <data key="d8">AI applications are optimized for time series capabilities.</data>
      <data key="d9">capability,optimization</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975715</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Guardrail Options">
      <data key="d7">1.0</data>
      <data key="d8">AI applications are optimized for guardrail options.</data>
      <data key="d9">capability,optimization</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975716</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Key Workflows">
      <data key="d7">2.0</data>
      <data key="d8">AI applications are used to reshape key workflows, enhancing business processes.&lt;SEP&gt;AI applications are used to reshape and transform key business workflows.</data>
      <data key="d9">integration,process improvement,transformation,transformation tool</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976062</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Operations">
      <data key="d7">2.0</data>
      <data key="d8">AI applications are used to reshape operations, enhancing business functions.&lt;SEP&gt;AI applications are used to reshape and transform business operations.</data>
      <data key="d9">integration,operational improvement,transformation,transformation tool</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976063</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="IBM Watsonx.Ai">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai is the platform used to build AI applications quickly with minimal data.</data>
      <data key="d9">development platform,rapid deployment</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976060</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Experience">
      <data key="d7">1.0</data>
      <data key="d8">The deployment of AI applications aims to maximize user and customer experience.</data>
      <data key="d9">enhancement,value driver</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976063</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Real-Time Decision-Making">
      <data key="d7">1.0</data>
      <data key="d8">The deployment of AI applications aims to enhance real-time decision-making capabilities.</data>
      <data key="d9">capability enhancement,value driver</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976064</data>
      <data key="d13" />
    </edge>
    <edge source="AI Applications" target="Business Value">
      <data key="d7">1.0</data>
      <data key="d8">The deployment of AI applications aims to maximize overall business value.</data>
      <data key="d9">outcome,value driver</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976065</data>
      <data key="d13" />
    </edge>
    <edge source="Survey" target="AI Plans">
      <data key="d7">1.0</data>
      <data key="d8">The survey of 2,000 organizations was conducted to understand their AI plans and identify effective and ineffective methods.</data>
      <data key="d9">analysis,research</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975716</data>
      <data key="d13" />
    </edge>
    <edge source="Survey" target="2,000 Organizations">
      <data key="d7">1.0</data>
      <data key="d8">The survey was conducted on 2,000 organizations to collect data on their AI plans.</data>
      <data key="d9">data collection,research method</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976063</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Generative AI">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai is a platform for training, validating, tuning, and deploying generative AI.&lt;SEP&gt;IBM Watsonx.Ai is a platform used to train, validate, tune, and deploy generative AI.</data>
      <data key="d9">deployment,model deployment,platform capability,platform functionality</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976066</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Foundation Models">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai is a platform for training, validating, tuning, and deploying foundation models.&lt;SEP&gt;IBM Watsonx.Ai is a platform used to train, validate, tune, and deploy foundation models.</data>
      <data key="d9">deployment,model deployment,platform capability,platform functionality</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976066</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Machine Learning">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai is a platform for training, validating, tuning, and deploying machine learning.</data>
      <data key="d9">deployment,platform functionality</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975716</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="AI Development Lifecycle">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai provides one-stop access to features across the AI development lifecycle.&lt;SEP&gt;IBM Watsonx.Ai provides one-stop access to functionalities spanning the entire AI development lifecycle.</data>
      <data key="d9">development,lifecycle management,platform access,platform capability</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976061</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="User-Friendly Interface">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai offers a user-friendly interface for building AI solutions.&lt;SEP&gt;IBM Watsonx.Ai offers a user-friendly interface as part of its development environment.</data>
      <data key="d9">ease of use,platform feature,usability</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976062</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Workflow">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai provides workflow tools for building AI solutions.</data>
      <data key="d9">development,platform feature</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975718</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Industry-Standard APIs">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai provides access to industry-standard APIs for building AI solutions.&lt;SEP&gt;IBM Watsonx.Ai provides access to industry-standard APIs for building AI solutions.</data>
      <data key="d9">development tools,integration,platform feature,platform integration</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976063</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="SDKs">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai provides access to SDKs for building AI solutions.&lt;SEP&gt;IBM Watsonx.Ai provides access to SDKs for building AI solutions.</data>
      <data key="d9">development tools,integration,platform feature,platform integration</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc&lt;SEP&gt;chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976064</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Powerful AI Solutions">
      <data key="d7">1.0</data>
      <data key="d8">The IBM watsonx.ai platform enables the generation of powerful AI solutions through its integrated features.</data>
      <data key="d9">development,platform capability</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975720</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Workflows">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai provides workflows to aid in the AI solution development process.</data>
      <data key="d9">platform feature,process automation</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976063</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="AI Solutions">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai enables the generation of powerful AI solutions.</data>
      <data key="d9">platform output,solution generation</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976065</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Machine Learning Capabilities">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai is a platform used to train, validate, tune, and deploy machine learning capabilities.</data>
      <data key="d9">function deployment,platform capability</data>
      <data key="d10">chunk-37b06bc80ac6550d31f35870a6bd024f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976067</data>
      <data key="d13" />
    </edge>
    <edge source="Key Workflows" target="Experience">
      <data key="d7">1.0</data>
      <data key="d8">Reshaping key workflows with AI aims to maximize the user or customer experience.</data>
      <data key="d9">enhancement,outcome</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975717</data>
      <data key="d13" />
    </edge>
    <edge source="Key Workflows" target="Real-Time Decision-Making">
      <data key="d7">1.0</data>
      <data key="d8">Reshaping key workflows with AI aims to maximize real-time decision-making capabilities.</data>
      <data key="d9">enhancement,outcome</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975718</data>
      <data key="d13" />
    </edge>
    <edge source="Key Workflows" target="Business Value">
      <data key="d7">1.0</data>
      <data key="d8">Reshaping key workflows with AI aims to maximize overall business value.</data>
      <data key="d9">enhancement,outcome</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975719</data>
      <data key="d13" />
    </edge>
    <edge source="Operations" target="Experience">
      <data key="d7">1.0</data>
      <data key="d8">Reshaping operations with AI aims to maximize the user or customer experience.</data>
      <data key="d9">enhancement,outcome</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975718</data>
      <data key="d13" />
    </edge>
    <edge source="Operations" target="Real-Time Decision-Making">
      <data key="d7">1.0</data>
      <data key="d8">Reshaping operations with AI aims to maximize real-time decision-making capabilities.</data>
      <data key="d9">enhancement,outcome</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975719</data>
      <data key="d13" />
    </edge>
    <edge source="Operations" target="Business Value">
      <data key="d7">1.0</data>
      <data key="d8">Reshaping operations with AI aims to maximize overall business value.</data>
      <data key="d9">enhancement,outcome</data>
      <data key="d10">chunk-810fec6799c7d5d8ae38f77aabcec3dc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975720</data>
      <data key="d13" />
    </edge>
    <edge source="18年期末" target="表格">
      <data key="d7">1.0</data>
      <data key="d8">The problem from the 2018 final exam provides a similar context and likely includes a data table for calculating the first branch.</data>
      <data key="d9">data source,problem reference</data>
      <data key="d10">chunk-93b5920864ffe7c0f735f87ccf578d34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975749</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="分类">
      <data key="d7">1.0</data>
      <data key="d8">Decision Tree is a model applicable to classification tasks.</data>
      <data key="d9">application,model capability</data>
      <data key="d10">chunk-a79596200294b5109fdd0cf885110f83</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975821</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="回归">
      <data key="d7">1.0</data>
      <data key="d8">Decision Tree is a model applicable to regression tasks.</data>
      <data key="d9">application,model capability</data>
      <data key="d10">chunk-a79596200294b5109fdd0cf885110f83</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975821</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="ID3">
      <data key="d7">2.0</data>
      <data key="d8">ID3是用于生成决策树的一种算法。&lt;SEP&gt;ID3是决策树算法发展过程中的一个重要版本，使用信息增益进行特征选择。</data>
      <data key="d9">algorithm development,comparison,实现算法,构建方法</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975932</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="C4.5">
      <data key="d7">2.0</data>
      <data key="d8">C4.5是用于生成决策树的一种算法。&lt;SEP&gt;C4.5是决策树算法发展过程中的一个重要版本，使用信息增益比进行特征选择以改进ID3。</data>
      <data key="d9">algorithm development,comparison,实现算法,构建方法</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975933</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="CART">
      <data key="d7">2.0</data>
      <data key="d8">CART是用于生成决策树的一种算法。&lt;SEP&gt;CART是决策树算法发展过程中的一个重要版本，使用基尼系数进行特征选择。</data>
      <data key="d9">algorithm development,comparison,实现算法,构建方法</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975934</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="特征选择">
      <data key="d7">1.0</data>
      <data key="d8">特征选择是决策树学习过程中的三个关键步骤之一。</data>
      <data key="d9">component,learning step</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975935</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="决策树的生成">
      <data key="d7">1.0</data>
      <data key="d8">决策树的生成是决策树学习过程中的三个关键步骤之一。</data>
      <data key="d9">component,learning step</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975937</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="决策树的剪枝">
      <data key="d7">1.0</data>
      <data key="d8">决策树的剪枝是决策树学习过程中的三个关键步骤之一。</data>
      <data key="d9">component,learning step</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975938</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="NP难问题">
      <data key="d7">1.0</data>
      <data key="d8">寻找最优的决策树是一个NP难问题，这限制了其精确求解。</data>
      <data key="d9">理论限制,计算复杂性</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975940</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="集成学习">
      <data key="d7">1.0</data>
      <data key="d8">集成学习可以用来改善决策树的性能，避免陷入局部最优。</data>
      <data key="d9">性能改善,扩展方法</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975940</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="异或">
      <data key="d7">1.0</data>
      <data key="d8">决策树模型存在学习局限，难以有效学习像异或这样的复杂逻辑关系。</data>
      <data key="d9">关系复杂性,学习局限</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975950</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="过拟合">
      <data key="d7">2.0</data>
      <data key="d8">过拟合是决策树模型可能遇到的问题，源于构建了过于复杂的树。&lt;SEP&gt;Large, complex decision trees are prone to overfitting, reducing their ability to generalize.</data>
      <data key="d9">generalization issue,model error,复杂性后果,模型问题</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976056</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="分而治之">
      <data key="d7">1.0</data>
      <data key="d8">Decision tree learning employs the divide-and-conquer strategy as its core methodology.</data>
      <data key="d9">algorithmic approach,learning strategy</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976053</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="贪心搜索">
      <data key="d7">1.0</data>
      <data key="d8">Decision tree learning uses a greedy search to identify the best split point in the tree.</data>
      <data key="d9">optimization,split point selection</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976060</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="类标签">
      <data key="d7">1.0</data>
      <data key="d8">The goal of a decision tree is to classify records into specific class labels.</data>
      <data key="d9">classification,target outcome</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976053</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="纯净叶节点">
      <data key="d7">1.0</data>
      <data key="d8">Smaller decision trees aim to achieve pure leaf nodes where all data points belong to one class.</data>
      <data key="d9">classification goal,model purity</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976053</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="数据碎片">
      <data key="d7">1.0</data>
      <data key="d8">As decision trees grow larger, they risk data fragmentation, which can lead to overfitting.</data>
      <data key="d9">model complexity,overfitting risk</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976054</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="奥卡姆剃刀">
      <data key="d7">1.0</data>
      <data key="d8">The principle of Occam's Razor supports using smaller decision trees, favoring simplicity.</data>
      <data key="d9">model simplicity,parsimony principle</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976058</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="修剪">
      <data key="d7">1.0</data>
      <data key="d8">Pruning is a method applied to decision trees to reduce complexity and prevent overfitting.</data>
      <data key="d9">complexity reduction,model optimization</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976058</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="交叉验证">
      <data key="d7">1.0</data>
      <data key="d8">Cross-validation is a process used to evaluate the fit of a decision tree model.</data>
      <data key="d9">fit assessment,model evaluation</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976060</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="第九讲： Bayes分类、熵、决策树、特征选择">
      <data key="d7">1.0</data>
      <data key="d8">The lecture covers the topic of decision trees.</data>
      <data key="d9">educational content,topic coverage</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976210</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="ID3决策树">
      <data key="d7">1.0</data>
      <data key="d8">ID3 is a specific type of decision tree algorithm.</data>
      <data key="d9">algorithm type,example</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976211</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="C4.5决策树">
      <data key="d7">1.0</data>
      <data key="d8">C4.5 is a specific type of decision tree algorithm.</data>
      <data key="d9">algorithm type,example</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976212</data>
      <data key="d13" />
    </edge>
    <edge source="决策树" target="其他决策树">
      <data key="d7">1.0</data>
      <data key="d8">The category of decision trees includes other algorithms besides ID3 and C4.5.</data>
      <data key="d9">category,includes</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976215</data>
      <data key="d13" />
    </edge>
    <edge source="薛定谔" target="生命是什么">
      <data key="d7">1.0</data>
      <data key="d8">薛定谔撰写了著作《生命是什么》，在其中阐述了他的科学思想。</data>
      <data key="d9">思想传播,著作撰写</data>
      <data key="d10">chunk-62fad8ab846c9df991d8fe50bdf2edf6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975798</data>
      <data key="d13" />
    </edge>
    <edge source="ID3" target="训练集">
      <data key="d7">1.0</data>
      <data key="d8">The ID3 algorithm takes a training set as its primary input for building the decision tree model.</data>
      <data key="d9">algorithm input,data processing</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975937</data>
      <data key="d13" />
    </edge>
    <edge source="ID3" target="特征集">
      <data key="d7">1.0</data>
      <data key="d8">The ID3 algorithm takes a feature set as input from which it selects the best feature based on information gain.</data>
      <data key="d9">algorithm input,feature selection</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975939</data>
      <data key="d13" />
    </edge>
    <edge source="ID3" target="Hunt算法">
      <data key="d7">1.0</data>
      <data key="d8">The Hunt algorithm served as a foundational basis for later decision tree algorithms like ID3.</data>
      <data key="d9">algorithm foundation,historical influence</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976053</data>
      <data key="d13" />
    </edge>
    <edge source="ID3" target="Ross Quinlan">
      <data key="d7">1.0</data>
      <data key="d8">Ross Quinlan is the proposer and developer of the ID3 algorithm.</data>
      <data key="d9">algorithm creation,authorship</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976053</data>
      <data key="d13" />
    </edge>
    <edge source="ID3" target="C4.5">
      <data key="d7">1.0</data>
      <data key="d8">C4.5 is a later iteration and successor to the ID3 algorithm.</data>
      <data key="d9">algorithm iteration,successor</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976058</data>
      <data key="d13" />
    </edge>
    <edge source="C4.5" target="信息增益比">
      <data key="d7">1.0</data>
      <data key="d8">C4.5算法使用信息增益比作为其核心特征选择的标准，以解决ID3的缺陷。</data>
      <data key="d9">core concept,feature selection</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975934</data>
      <data key="d13" />
    </edge>
    <edge source="C4.5" target="Ross Quinlan">
      <data key="d7">1.0</data>
      <data key="d8">Ross Quinlan is also the proposer and developer of the C4.5 algorithm.</data>
      <data key="d9">algorithm creation,authorship</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976055</data>
      <data key="d13" />
    </edge>
    <edge source="C4.5" target="增益比">
      <data key="d7">1.0</data>
      <data key="d8">The C4.5 algorithm can use gain ratio to evaluate splits.</data>
      <data key="d9">evaluation metric,split criterion</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976060</data>
      <data key="d13" />
    </edge>
    <edge source="CART" target="基尼系数">
      <data key="d7">2.0</data>
      <data key="d8">CART算法使用基尼系数作为其核心特征选择的标准。&lt;SEP&gt;The CART algorithm typically uses the Gini index to determine the ideal attribute for splitting.</data>
      <data key="d9">core concept,evaluation metric,feature selection,split criterion</data>
      <data key="d10">chunk-b5a3719d78ce70f7d68e86833b8aa9a9&lt;SEP&gt;chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976059</data>
      <data key="d13" />
    </edge>
    <edge source="CART" target="Leo Breiman">
      <data key="d7">1.0</data>
      <data key="d8">Leo Breiman is the proposer and developer of the CART algorithm.</data>
      <data key="d9">algorithm creation,authorship</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976058</data>
      <data key="d13" />
    </edge>
    <edge source="基尼系数" target="CART算法">
      <data key="d7">1.0</data>
      <data key="d8">CART算法使用基尼系数作为特征选择和数据集纯度度量的标准。</data>
      <data key="d9">特征选择,纯度度量</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975941</data>
      <data key="d13" />
    </edge>
    <edge source="特征选择" target="第九讲： Bayes分类、熵、决策树、特征选择">
      <data key="d7">1.0</data>
      <data key="d8">The lecture covers the topic of feature selection.</data>
      <data key="d9">educational content,topic coverage</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976211</data>
      <data key="d13" />
    </edge>
    <edge source="经验熵" target="叶结点">
      <data key="d7">1.0</data>
      <data key="d8">经验熵是专门用于计算和描述叶结点分类混乱程度的指标。</data>
      <data key="d9">属性描述,计算对象</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975938</data>
      <data key="d13" />
    </edge>
    <edge source="经验熵" target="CCP剪枝法">
      <data key="d7">1.0</data>
      <data key="d8">在CCP剪枝法的损失函数计算中，会涉及到叶节点的经验熵。</data>
      <data key="d9">损失函数组件,计算涉及</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975944</data>
      <data key="d13" />
    </edge>
    <edge source="经验熵" target="叶结点t">
      <data key="d7">1.0</data>
      <data key="d8">经验熵H_t(T)是用于度量叶结点t上分类结果混乱程度的指标。</data>
      <data key="d9">属性度量,混乱程度</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975946</data>
      <data key="d13" />
    </edge>
    <edge source="剪枝" target="过拟合">
      <data key="d7">1.0</data>
      <data key="d8">剪枝是一种通过降低模型复杂度来预防决策树过拟合的技术。</data>
      <data key="d9">模型优化,预防措施</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975939</data>
      <data key="d13" />
    </edge>
    <edge source="剪枝" target="剪枝系数">
      <data key="d7">1.0</data>
      <data key="d8">剪枝系数(α)是执行剪枝操作时的关键计算参数，用于决定是否对子树进行剪枝。</data>
      <data key="d9">关键参数,决策依据</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975940</data>
      <data key="d13" />
    </edge>
    <edge source="NP难问题" target="启发式方法">
      <data key="d7">1.0</data>
      <data key="d8">由于寻找最优决策树是NP难问题，通常采用启发式方法作为近似的解决方案。</data>
      <data key="d9">解决方案,近似算法</data>
      <data key="d10">chunk-3fc4861498cff05f95c61b9202e2155c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975940</data>
      <data key="d13" />
    </edge>
    <edge source="特征A_g" target="特征值A_gi">
      <data key="d7">1.0</data>
      <data key="d8">特征A_g根据其不同的取值A_gi，将对应的样本输出D划分成不同的类别D_i。</data>
      <data key="d9">数据划分,特征取值</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975943</data>
      <data key="d13" />
    </edge>
    <edge source="C4.5算法" target="PEP剪枝法">
      <data key="d7">1.0</data>
      <data key="d8">C4.5算法采用PEP剪枝法作为其剪枝策略。</data>
      <data key="d9">剪枝策略,算法采用</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975940</data>
      <data key="d13" />
    </edge>
    <edge source="CART算法" target="CCP剪枝法">
      <data key="d7">1.0</data>
      <data key="d8">CART算法采用CCP剪枝法作为其剪枝策略。</data>
      <data key="d9">剪枝策略,算法采用</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975943</data>
      <data key="d13" />
    </edge>
    <edge source="CART算法" target="训练集D">
      <data key="d7">1.0</data>
      <data key="d8">训练集D是CART算法的输入数据，用于生成决策树。</data>
      <data key="d9">数据源,算法输入</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975944</data>
      <data key="d13" />
    </edge>
    <edge source="后剪枝" target="CCP剪枝法">
      <data key="d7">1.0</data>
      <data key="d8">CCP剪枝法是后剪枝方法中的一种具体实现。</data>
      <data key="d9">具体方法,包含</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975942</data>
      <data key="d13" />
    </edge>
    <edge source="后剪枝" target="PEP剪枝法">
      <data key="d7">1.0</data>
      <data key="d8">PEP剪枝法是后剪枝方法中的一种具体实现。</data>
      <data key="d9">具体方法,包含</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975950</data>
      <data key="d13" />
    </edge>
    <edge source="CCP剪枝法" target="完全树T_0">
      <data key="d7">1.0</data>
      <data key="d8">CCP剪枝算法从完全树T_0开始进行剪枝操作。</data>
      <data key="d9">初始状态,算法起点</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975946</data>
      <data key="d13" />
    </edge>
    <edge source="最优特征A" target="最优特征值a">
      <data key="d7">1.0</data>
      <data key="d8">最优特征A与其对应的最优特征值a共同作为划分数据集D的依据。</data>
      <data key="d9">划分依据,特征与取值</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975943</data>
      <data key="d13" />
    </edge>
    <edge source="最优特征A" target="数据集D1">
      <data key="d7">1.0</data>
      <data key="d8">根据最优特征A和特征值a，将数据集D划分出子集D1。</data>
      <data key="d9">数据划分,生成子集</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975944</data>
      <data key="d13" />
    </edge>
    <edge source="最优特征A" target="数据集D2">
      <data key="d7">1.0</data>
      <data key="d8">根据最优特征A和特征值a，将数据集D划分出子集D2。</data>
      <data key="d9">数据划分,生成子集</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975946</data>
      <data key="d13" />
    </edge>
    <edge source="树T" target="叶结点t">
      <data key="d7">1.0</data>
      <data key="d8">叶结点t是树T的组成部分，树T的叶结点个数为|T_leaf|。</data>
      <data key="d9">组成部分,结构元素</data>
      <data key="d10">chunk-b787493679d2ca259f397315e308f4b1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768975944</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="生成式AI">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai is a platform for deploying generative AI capabilities.</data>
      <data key="d9">platform capability,technology support</data>
      <data key="d10">chunk-331e8c8473a3dbee58697ad677051f43</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976060</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes分类" target="代价函数">
      <data key="d7">2.0</data>
      <data key="d8">Bayes分类方法的核心是定义一个代价函数来评估和最小化分类错误。&lt;SEP&gt;Cost function is a component or concept used within Bayes classification.</data>
      <data key="d9">component,theoretical basis,性能评估,理论基础</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c&lt;SEP&gt;chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976203</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes分类" target="贝叶斯最优分类器">
      <data key="d7">1.0</data>
      <data key="d8">Bayes分类的目标是找到贝叶斯最优分类器，即最小化期望代价的分类器。</data>
      <data key="d9">优化,目标实现</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976205</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes分类" target="第九讲： Bayes分类、熵、决策树、特征选择">
      <data key="d7">1.0</data>
      <data key="d8">The lecture covers the topic of Bayes classification.</data>
      <data key="d9">educational content,topic coverage</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976209</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes分类" target="Bayes公式">
      <data key="d7">1.0</data>
      <data key="d8">Bayes' formula is the mathematical foundation for Bayes classification.</data>
      <data key="d9">foundation,mathematical basis</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976210</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes分类" target="0.1 Bayes分类">
      <data key="d7">1.0</data>
      <data key="d8">This section heading introduces and discusses the concept of Bayes classification.</data>
      <data key="d9">content part,section</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976212</data>
      <data key="d13" />
    </edge>
    <edge source="代价函数" target="λi,j">
      <data key="d7">1.0</data>
      <data key="d8">代价函数R(ci|x)的定义中使用了错误分类代价 λi,j作为其组成部分。</data>
      <data key="d9">定义,构成</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976204</data>
      <data key="d13" />
    </edge>
    <edge source="代价函数" target="0.1.1代价函数">
      <data key="d7">1.0</data>
      <data key="d8">This subsection heading introduces and explains the concept of the cost function.</data>
      <data key="d9">detailed explanation,subsection</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976212</data>
      <data key="d13" />
    </edge>
    <edge source="贝叶斯最优分类器" target="h">
      <data key="d7">1.0</data>
      <data key="d8">贝叶斯最优分类器h*是从所有可能的分类器函数h中选出的使代价R(h)最小的那个。</data>
      <data key="d9">优化目标,函数关系</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976203</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes公式" target="判别式模型">
      <data key="d7">1.0</data>
      <data key="d8">Bayes公式将条件概率联系起来，是判别式模型与生成式模型相关联的关键。</data>
      <data key="d9">模型关联,理论联系</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976203</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes公式" target="生成式模型">
      <data key="d7">1.0</data>
      <data key="d8">生成式模型通过Bayes公式将后验概率P(c|x)转化为似然P(x|c)和先验P(c)的乘积问题。</data>
      <data key="d9">模型基础,理论推导</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976204</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes公式" target="P(x|y)">
      <data key="d7">1.0</data>
      <data key="d8">Bayes公式的核心是表达了条件概率P(x|y)与联合概率P(x, y)和边缘概率P(y)之间的关系。</data>
      <data key="d9">公式表达,核心关系</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976206</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes公式" target="P(x, y)">
      <data key="d7">1.0</data>
      <data key="d8">Bayes公式将条件概率P(x|y)表示为联合概率P(x, y)除以边缘概率P(y)。</data>
      <data key="d9">公式表达,核心关系</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976207</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes公式" target="P(y)">
      <data key="d7">1.0</data>
      <data key="d8">在Bayes公式中，边缘概率P(y)作为分母出现，用于计算条件概率P(x|y)。</data>
      <data key="d9">公式表达,核心关系</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976208</data>
      <data key="d13" />
    </edge>
    <edge source="Bayes公式" target="P(y|x)">
      <data key="d7">1.0</data>
      <data key="d8">Bayes公式通过P(y)将P(x|y)和P(y|x)联系了起来，这是判别式与生成式模型关联的关键。</data>
      <data key="d9">公式联系,双向关系</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976209</data>
      <data key="d13" />
    </edge>
    <edge source="判别式模型" target="P(c|x)">
      <data key="d7">1.0</data>
      <data key="d8">判别式模型直接根据后验概率P(c|x)的大小来决定样本点的分类结果。</data>
      <data key="d9">决策依据,核心概念</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976205</data>
      <data key="d13" />
    </edge>
    <edge source="生成式模型" target="P(x|c)">
      <data key="d7">1.0</data>
      <data key="d8">生成式模型的核心是估计似然概率P(x|c)，即给定类别下观测到样本的概率。</data>
      <data key="d9">似然估计,建模核心</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976206</data>
      <data key="d13" />
    </edge>
    <edge source="生成式模型" target="P(c)">
      <data key="d7">1.0</data>
      <data key="d8">生成式模型在分类时需要考虑类别的先验概率P(c)。</data>
      <data key="d9">先验知识,建模核心</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976207</data>
      <data key="d13" />
    </edge>
    <edge source="生成式模型" target="最小二乘法">
      <data key="d7">1.0</data>
      <data key="d8">当生成式模型的先验分布为均匀分布时，其最大似然估计在数学形式上等价于最小二乘法。</data>
      <data key="d9">参数估计,等价关系</data>
      <data key="d10">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976213</data>
      <data key="d13" />
    </edge>
    <edge source="线性回归" target="朴素贝叶斯分类器">
      <data key="d7">1.0</data>
      <data key="d8">在线性回归的例子中，通过假设噪声分布和样本独立，引出了朴素贝叶斯分类器的参数学习方法。</data>
      <data key="d9">参数估计,模型假设</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976203</data>
      <data key="d13" />
    </edge>
    <edge source="线性回归" target="噪音ϵi">
      <data key="d7">1.0</data>
      <data key="d8">在线性回归模型中，噪音 ϵi被定义为观测值与模型预测值之间的差异，并假设其服从正态分布。</data>
      <data key="d9">模型假设,误差项</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976206</data>
      <data key="d13" />
    </edge>
    <edge source="线性回归" target="似然函数Li">
      <data key="d7">1.0</data>
      <data key="d8">基于噪音分布假设，线性回归为每个样本点构建了似然函数Li，用于参数a的估计。</data>
      <data key="d9">参数估计,概率模型</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976207</data>
      <data key="d13" />
    </edge>
    <edge source="朴素贝叶斯分类器" target="lnL">
      <data key="d7">1.0</data>
      <data key="d8">在朴素贝叶斯分类器的参数学习中，通过取似然函数的自然对数lnL来简化最大似然估计的计算。</data>
      <data key="d9">优化方法,计算简化</data>
      <data key="d10">chunk-92f40240065404b9b3529cf829f8077c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976207</data>
      <data key="d13" />
    </edge>
    <edge source="第九讲： Bayes分类、熵、决策树、特征选择" target="徐玥珠">
      <data key="d7">1.0</data>
      <data key="d8">The lecture material is authored or presented by Xu Yue Zhu.</data>
      <data key="d9">authorship,presentation</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976207</data>
      <data key="d13" />
    </edge>
    <edge source="第九讲： Bayes分类、熵、决策树、特征选择" target="张锦岳">
      <data key="d7">1.0</data>
      <data key="d8">The lecture material is authored or presented by Zhang Jin Yue.</data>
      <data key="d9">authorship,presentation</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976208</data>
      <data key="d13" />
    </edge>
    <edge source="第九讲： Bayes分类、熵、决策树、特征选择" target="2020年6月24日">
      <data key="d7">1.0</data>
      <data key="d8">The lecture material is dated June 24, 2020.</data>
      <data key="d9">creation date,scheduling</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976214</data>
      <data key="d13" />
    </edge>
    <edge source="第九讲： Bayes分类、熵、决策树、特征选择" target="目录">
      <data key="d7">1.0</data>
      <data key="d8">The lecture material has a table of contents that organizes its topics.</data>
      <data key="d9">organization,structure</data>
      <data key="d10">chunk-2f3b241c528a53767a4138490b41e2f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976216</data>
      <data key="d13" />
    </edge>
    <edge source="骰子" target="期望">
      <data key="d7">1.0</data>
      <data key="d8">骰子被用作一个随机实验的例子，其结果的期望值是一个给定的约束条件。</data>
      <data key="d9">统计特性,随机实验</data>
      <data key="d10">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976215</data>
      <data key="d13" />
    </edge>
    <edge source="骰子" target="事件域">
      <data key="d7">1.0</data>
      <data key="d8">骰子投掷结果的所有可能取值构成了事件域。</data>
      <data key="d9">样本空间,随机实验</data>
      <data key="d10">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976217</data>
      <data key="d13" />
    </edge>
    <edge source="似然函数" target="自然对数">
      <data key="d7">1.0</data>
      <data key="d8">对似然函数取自然对数可以简化乘积运算为求和运算，便于求最大值。</data>
      <data key="d9">优化,数学变换</data>
      <data key="d10">chunk-16343ccef51a9f838ddefbe4951cc3c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976215</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习算法" target="多层神经网络">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning algorithms are often implemented using multi-layer neural networks.</data>
      <data key="d9">architecture,implementation</data>
      <data key="d10">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976255</data>
      <data key="d13" />
    </edge>
    <edge source="多层神经网络" target="拟合能力">
      <data key="d7">1.0</data>
      <data key="d8">Multi-layer neural networks possess powerful fitting capabilities.</data>
      <data key="d9">attribute,capability</data>
      <data key="d10">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976256</data>
      <data key="d13" />
    </edge>
    <edge source="多层神经网络" target="性能">
      <data key="d7">1.0</data>
      <data key="d8">Multi-layer neural networks exhibit excellent performance.</data>
      <data key="d9">attribute,quality</data>
      <data key="d10">chunk-d6085544a08784bc3999c91c72c5594a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1768976256</data>
      <data key="d13" />
    </edge>
  </graph>
</graphml>

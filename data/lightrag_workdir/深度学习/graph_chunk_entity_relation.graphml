<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d13" for="edge" attr.name="truncate" attr.type="string" />
  <key id="d12" for="edge" attr.name="created_at" attr.type="long" />
  <key id="d11" for="edge" attr.name="file_path" attr.type="string" />
  <key id="d10" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d9" for="edge" attr.name="keywords" attr.type="string" />
  <key id="d8" for="edge" attr.name="description" attr.type="string" />
  <key id="d7" for="edge" attr.name="weight" attr.type="double" />
  <key id="d6" for="node" attr.name="truncate" attr.type="string" />
  <key id="d5" for="node" attr.name="created_at" attr.type="long" />
  <key id="d4" for="node" attr.name="file_path" attr.type="string" />
  <key id="d3" for="node" attr.name="source_id" attr.type="string" />
  <key id="d2" for="node" attr.name="description" attr.type="string" />
  <key id="d1" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d0" for="node" attr.name="entity_id" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="深度学习模型">
      <data key="d0">深度学习模型</data>
      <data key="d1">method</data>
      <data key="d2">深度学习模型是一种能够识别复杂数据模式(如图片、文本和声音)并生成准确见解和预测的人工智能模型。&lt;SEP&gt;深度学习模型是基于深度神经网络架构的模型，从多层感知器到复杂的生成式AI网络，依赖反向传播进行训练。&lt;SEP&gt;深度学习模型是一种用于处理自然语言的神经网络方法，在2013年左右被研究者广泛使用。&lt;SEP&gt;深度学习模型是一种特定的机器学习模型，其分析过程需要文本经过NLP预处理转换成特定格式。&lt;SEP&gt;Deep learning models are used within natural language processing to handle human language.</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-fd544a0511ae2b1911f2ec7bdc2235ae&lt;SEP&gt;chunk-38b1076024c94a070f64f72dcaea1102&lt;SEP&gt;chunk-b572e7e95c9e5e07043de0b3cb587187</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006717</data>
      <data key="d6" />
    </node>
    <node id="神经网络">
      <data key="d0">神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">神经网络是一种受人脑或生物神经系统结构及功能启发的计算模型，它是深度学习算法的底层技术基础。神经网络由多层互连的节点（或称神经元）组成，这些节点分层排列，形成一种分层结构。它能够通过前向传播处理输入数据，并利用反向传播等算法进行训练和学习，从而完成快速的数据分类、聚类以及预测任务，广泛应用于语音识别、图像识别等机器学习与人工智能领域。自编码器是神经网络中的一类特定类型，属于一种深度前馈结构。&lt;SEP&gt;Neural networks are computational models where communication between layers and between different networks occurs through vectors.&lt;SEP&gt;神经网络是模拟人脑神经元连接的计算模型，是深度学习和语言模型的基础。&lt;SEP&gt;构成大语言模型等人工智能模型的基础计算模型。&lt;SEP&gt;神经网络是一种计算模型，是深度学习的基础，通过模拟生物神经网络的结构和功能来进行信息处理。&lt;SEP&gt;神经网络是深度学习的基本概念。</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531&lt;SEP&gt;chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-ecf37963c494ecfacb6a6432c237dd3b&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-e101b215c048456f8049a66e9ebd2c54&lt;SEP&gt;chunk-0a82bdcf222bdb547252e178dfe4d622&lt;SEP&gt;chunk-03a5749c6bb89c89b202fa903dbb847f&lt;SEP&gt;chunk-1eb9c8a9254475c3a6672347d5ac549f&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008413</data>
      <data key="d6" />
    </node>
    <node id="节点">
      <data key="d0">节点</data>
      <data key="d1">concept</data>
      <data key="d2">节点是神经网络中的基本计算单元，在分层结构中相互连接。&lt;SEP&gt;节点是计算图中的基本单元，在正向传播中计算输出，在反向传播中计算并传递梯度。&lt;SEP&gt;节点是神经网络中与神经元相连的基本单元。</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531&lt;SEP&gt;chunk-7844fb38c827827af06d614fe4afb4df&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002917</data>
      <data key="d6" />
    </node>
    <node id="神经元">
      <data key="d0">神经元</data>
      <data key="d1">concept</data>
      <data key="d2">神经元是神经网络中节点的别称，是构成网络的基本单元。&lt;SEP&gt;神经元是神经网络的基本计算单元，接收输入并应用激活函数产生输出。&lt;SEP&gt;神经元是神经网络的基本单元，由输入值与权重系数乘积的和以及一个激活函数组成，其输出为y=f(e)。&lt;SEP&gt;神经元是神经网络中的基本单元，类似于生物神经细胞。&lt;SEP&gt;A basic computational unit in a neural network, organized in layers.</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531&lt;SEP&gt;chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-2bd963b40a794cdd2a7befd072b521f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003575</data>
      <data key="d6" />
    </node>
    <node id="图片">
      <data key="d0">图片</data>
      <data key="d1">data</data>
      <data key="d2">图片是一种可以被深度学习模型识别的复杂数据模式。</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001792</data>
      <data key="d6" />
    </node>
    <node id="文本">
      <data key="d0">文本</data>
      <data key="d1">data</data>
      <data key="d2">文本是一种可以被深度学习模型识别的复杂数据模式。</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001793</data>
      <data key="d6" />
    </node>
    <node id="声音">
      <data key="d0">声音</data>
      <data key="d1">data</data>
      <data key="d2">声音是一种可以被深度学习模型识别的复杂数据模式。</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001793</data>
      <data key="d6" />
    </node>
    <node id="分层结构">
      <data key="d0">分层结构</data>
      <data key="d1">concept</data>
      <data key="d2">分层结构是神经网络的组织形式，节点或神经元在其中互连。</data>
      <data key="d3">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001793</data>
      <data key="d6" />
    </node>
    <node id="Michael Nielsen">
      <data key="d0">Michael Nielsen</data>
      <data key="d1">person</data>
      <data key="d2">Michael Nielsen is the author of the open-source textbook "Neural Networks and Deep Learning".&lt;SEP&gt;Michael Nielsen是《神经网络与深度学习》在线教科书的作者，在书中比较了反向传播算法与计算梯度的直观方法。</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002457</data>
      <data key="d6" />
    </node>
    <node id="Neural Networks And Deep Learning">
      <data key="d0">Neural Networks And Deep Learning</data>
      <data key="d1">content</data>
      <data key="d2">"Neural Networks and Deep Learning" is an open-source textbook that explains concepts in an easy-to-understand manner.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001886</data>
      <data key="d6" />
    </node>
    <node id="Artificial Neuron">
      <data key="d0">Artificial Neuron</data>
      <data key="d1">concept</data>
      <data key="d2">An artificial neuron is a model designed to simulate biological neurons and serves as the basic building block of artificial neural networks.&lt;SEP&gt;An artificial neuron is a computational model inspired by biological neurons, used as a building block for artificial neural networks to simulate thinking.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001886</data>
      <data key="d6" />
    </node>
    <node id="Perceptron">
      <data key="d0">Perceptron</data>
      <data key="d1">concept</data>
      <data key="d2">The perceptron is an early model of an artificial neuron proposed in the 1960s and is still in use today.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001887</data>
      <data key="d6" />
    </node>
    <node id="Weight">
      <data key="d0">Weight</data>
      <data key="d1">concept</data>
      <data key="d2">Weights are parameters in a neural network model that are multiplied by input factors to calculate a weighted sum.&lt;SEP&gt;Weight is a parameter in neural networks whose significance was relearned clearly and profoundly by the narrator.&lt;SEP&gt;The fixed values within a convolution kernel (filter) used during the convolution operation.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-90d06b6fbc58cfba3d096615baf2b706&lt;SEP&gt;chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002928</data>
      <data key="d6" />
    </node>
    <node id="Threshold">
      <data key="d0">Threshold</data>
      <data key="d1">concept</data>
      <data key="d2">The threshold is a value used in a perceptron to determine the output; it is often represented as a bias `b`.&lt;SEP&gt;Threshold is a parameter in neural networks whose significance was relearned clearly and profoundly by the narrator.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001887</data>
      <data key="d6" />
    </node>
    <node id="Bias">
      <data key="d0">Bias</data>
      <data key="d1">concept</data>
      <data key="d2">Bias, denoted as `b`, is defined as the negative of the threshold and is a parameter adjusted during model training.&lt;SEP&gt;An additive constant in a neuron's calculation that allows the activation function to be shifted.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002714</data>
      <data key="d6" />
    </node>
    <node id="Training">
      <data key="d0">Training</data>
      <data key="d1">method</data>
      <data key="d2">Training is the process of iteratively adjusting weights and bias through trial and error to find the values that produce the most accurate output.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001888</data>
      <data key="d6" />
    </node>
    <node id="Dataset">
      <data key="d0">Dataset</data>
      <data key="d1">data</data>
      <data key="d2">A dataset with known answers is used to train a model to estimate optimal weights and bias.&lt;SEP&gt;A collection of 2,913,272 loan observation results from April 2019 to March 2022, used after excluding incomplete loan data.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005601</data>
      <data key="d6" />
    </node>
    <node id="Sigmoid Function">
      <data key="d0">Sigmoid Function</data>
      <data key="d1">method</data>
      <data key="d2">The sigmoid function, σ(z) = 1 / (1 + e^(-z)), transforms the perceptron's output into a continuous function between 0 and 1.&lt;SEP&gt;A specific activation function that maps any input value to a value between 0 and 1.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002714</data>
      <data key="d6" />
    </node>
    <node id="License Plate Photo">
      <data key="d0">License Plate Photo</data>
      <data key="d1">data</data>
      <data key="d2">A license plate photo is an example of input data for a model, where the output is the recognized license plate number.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001889</data>
      <data key="d6" />
    </node>
    <node id="Image Comparison Algorithm">
      <data key="d0">Image Comparison Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">An image comparison algorithm acts as a perceptron to analyze input like photos and produce a probability-based result.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001889</data>
      <data key="d6" />
    </node>
    <node id="Nano Degree Course">
      <data key="d0">Nano Degree Course</data>
      <data key="d1">content</data>
      <data key="d2">The nano degree course mentioned involves code review by mentors and one-on-one tutoring sessions to improve personal skills.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001889</data>
      <data key="d6" />
    </node>
    <node id="Prolog">
      <data key="d0">Prolog</data>
      <data key="d1">concept</data>
      <data key="d2">Prolog is a programming language distinct from software development languages, specialized for solving logic problems.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001890</data>
      <data key="d6" />
    </node>
    <node id="Yin Wang">
      <data key="d0">Yin Wang</data>
      <data key="d1">person</data>
      <data key="d2">Yin Wang is referenced in a blog post discussing AI research and its relation to brain science.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001890</data>
      <data key="d6" />
    </node>
    <node id="Input Vector">
      <data key="d0">Input Vector</data>
      <data key="d1">concept</data>
      <data key="d2">The input vector, denoted as `x`, represents external factors in a simplified vector form.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001890</data>
      <data key="d6" />
    </node>
    <node id="Weight Vector">
      <data key="d0">Weight Vector</data>
      <data key="d1">concept</data>
      <data key="d2">The weight vector, denoted as `w`, represents the corresponding weights for each input factor in vector form.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001890</data>
      <data key="d6" />
    </node>
    <node id="Dot Product">
      <data key="d0">Dot Product</data>
      <data key="d1">concept</data>
      <data key="d2">The dot product, `w⋅x`, is defined as the sum of the products of each factor and its corresponding weight.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001891</data>
      <data key="d6" />
    </node>
    <node id="Trial And Error">
      <data key="d0">Trial And Error</data>
      <data key="d1">method</data>
      <data key="d2">Trial and error is a method described for finding the correct weights and bias by making small changes and observing the output.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001891</data>
      <data key="d6" />
    </node>
    <node id="Model">
      <data key="d0">Model</data>
      <data key="d1">concept</data>
      <data key="d2">A model, such as one for recognizing license plates, is trained using data to produce outputs and correct its parameters.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001891</data>
      <data key="d6" />
    </node>
    <node id="Output">
      <data key="d0">Output</data>
      <data key="d1">concept</data>
      <data key="d2">Output refers to the result produced by a model, such as a recognized license plate number, which can be binary or continuous.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001891</data>
      <data key="d6" />
    </node>
    <node id="Continuous Function">
      <data key="d0">Continuous Function</data>
      <data key="d1">concept</data>
      <data key="d2">A continuous function, like the sigmoid output, is necessary for training sensitivity as opposed to a binary output.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001892</data>
      <data key="d6" />
    </node>
    <node id="Partial Derivative">
      <data key="d0">Partial Derivative</data>
      <data key="d1">concept</data>
      <data key="d2">Partial derivatives describe the linear relationship between changes in the output (`Δσ`) and changes in weights or bias (`Δw`, `Δb`).&lt;SEP&gt;A mathematical derivative of a function with respect to one variable while holding others constant, used in calculating error gradients.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917&lt;SEP&gt;chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002715</data>
      <data key="d6" />
    </node>
    <node id="Code Review">
      <data key="d0">Code Review</data>
      <data key="d1">method</data>
      <data key="d2">Code review is a feature of the mentioned nano degree course where a mentor reviews each line of code submitted by students.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001892</data>
      <data key="d6" />
    </node>
    <node id="One-On-One Tutoring">
      <data key="d0">One-On-One Tutoring</data>
      <data key="d1">method</data>
      <data key="d2">One-on-one tutoring is a weekly session available to students in the nano degree course for personalized guidance.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001892</data>
      <data key="d6" />
    </node>
    <node id="Enrollment Quota">
      <data key="d0">Enrollment Quota</data>
      <data key="d1">data</data>
      <data key="d2">The enrollment quota for the current session of the nano degree course is limited to 200 spots, with 67 already reserved.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001892</data>
      <data key="d6" />
    </node>
    <node id="Prolog Language Introduction Tutorial">
      <data key="d0">Prolog Language Introduction Tutorial</data>
      <data key="d1">content</data>
      <data key="d2">"Prolog Language Introduction Tutorial" is a tutorial published on January 28, 2019, introducing the Prolog programming language.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001892</data>
      <data key="d6" />
    </node>
    <node id="Logic Problem">
      <data key="d0">Logic Problem</data>
      <data key="d1">concept</data>
      <data key="d2">A logic problem is a type of problem that Prolog is designed to solve, such as deductive reasoning about Socrates.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001893</data>
      <data key="d6" />
    </node>
    <node id="AI Research">
      <data key="d0">AI Research</data>
      <data key="d1">concept</data>
      <data key="d2">AI research is referenced in a contrast with Yin Wang's blog post, questioning how many researchers actually study the human brain.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001893</data>
      <data key="d6" />
    </node>
    <node id="Brain Science">
      <data key="d0">Brain Science</data>
      <data key="d1">concept</data>
      <data key="d2">Brain science is mentioned as a field whose research findings are contrasted with the practices of some AI researchers.</data>
      <data key="d3">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001894</data>
      <data key="d6" />
    </node>
    <node id="Artificial Neural Network">
      <data key="d0">Artificial Neural Network</data>
      <data key="d1">concept</data>
      <data key="d2">An artificial neural network is a computational system composed of interconnected artificial neurons, designed to simulate cognitive processes like thinking.&lt;SEP&gt;An artificial neural network is a system where the modification of connection strengths enables learning.&lt;SEP&gt;Artificial neural network is a computational model used by AlphaFold to learn the relationship between sequences and structures.&lt;SEP&gt;Computational models designed to simulate the way biological neural networks work, used for flood forecasting and rainfall-runoff modeling.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706&lt;SEP&gt;chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-13f6a612ad21f33701d7916a1d76aa3e&lt;SEP&gt;chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010106</data>
      <data key="d6" />
    </node>
    <node id="Wang Yin">
      <data key="d0">Wang Yin</data>
      <data key="d1">person</data>
      <data key="d2">Wang Yin is a commentator who wrote an essay critiquing the approach of AI researchers, questioning their engagement with neuroscience and cognitive science.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001894</data>
      <data key="d6" />
    </node>
    <node id="Douglas Hofstadter">
      <data key="d0">Douglas Hofstadter</data>
      <data key="d1">person</data>
      <data key="d2">Douglas Hofstadter is a renowned cognitive scientist who has criticized AI experts for their lack of genuine interest in understanding how the brain and mind work.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001895</data>
      <data key="d6" />
    </node>
    <node id="AI Researcher">
      <data key="d0">AI Researcher</data>
      <data key="d1">person</data>
      <data key="d2">AI researchers are individuals working in the field of artificial intelligence, who are criticized for not studying the human brain, conducting brain experiments, or reading neuroscience research.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001895</data>
      <data key="d6" />
    </node>
    <node id="Brain">
      <data key="d0">Brain</data>
      <data key="d1">naturalobject</data>
      <data key="d2">The brain is the biological organ studied in neuroscience and cognitive science, serving as the inspiration for artificial intelligence models.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001895</data>
      <data key="d6" />
    </node>
    <node id="Neuroscience">
      <data key="d0">Neuroscience</data>
      <data key="d1">concept</data>
      <data key="d2">Neuroscience is the scientific study of the nervous system and the brain, whose research findings are cited as lacking in the background of many AI researchers.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001895</data>
      <data key="d6" />
    </node>
    <node id="Cognitive Science">
      <data key="d0">Cognitive Science</data>
      <data key="d1">concept</data>
      <data key="d2">Cognitive science is the interdisciplinary study of the mind and its processes, which critics argue is not adequately engaged with by AI researchers.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001896</data>
      <data key="d6" />
    </node>
    <node id="Mind">
      <data key="d0">Mind</data>
      <data key="d1">concept</data>
      <data key="d2">The mind refers to consciousness and mental processes, whose workings AI experts are accused of not being interested in or deeply researching.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001896</data>
      <data key="d6" />
    </node>
    <node id="Artificial General Intelligence (AGI)">
      <data key="d0">Artificial General Intelligence (AGI)</data>
      <data key="d1">concept</data>
      <data key="d2">Artificial General Intelligence (AGI) is the stated goal of achieving human-level or general intelligence in machines, which critics like Douglas Hofstadter deem a vain dream due to the field's disconnect from brain and mind research.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001896</data>
      <data key="d6" />
    </node>
    <node id="AI">
      <data key="d0">AI</data>
      <data key="d1">concept</data>
      <data key="d2">AI, or Artificial Intelligence, is the field of study focused on creating intelligent machines, described in the text as remaining a vain dream because its practitioners allegedly ignore brain and cognitive science.&lt;SEP&gt;AI (Artificial Intelligence) is a technology that can run on basic hardware for simple tasks but requires more computational power for complex models.&lt;SEP&gt;Artificial Intelligence, a broad field of computer science focused on creating intelligent machines.&lt;SEP&gt;AI is described as being trained on massive data and capable of judgment beyond human intuition, but it follows mathematical logic, emphasizes computation, causality, and recursion, and aims to execute commands and complete tasks. It lacks intuitive ability towards the external world and the reflective and negative nature of dialectical thinking.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706&lt;SEP&gt;chunk-cb25bd59eb20459d90d689a472568aea&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010994</data>
      <data key="d6" />
    </node>
    <node id="AI Expert">
      <data key="d0">AI Expert</data>
      <data key="d1">person</data>
      <data key="d2">AI experts are individuals in the field of artificial intelligence who are criticized by Douglas Hofstadter for lacking genuine interest in how the brain and mind function.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001904</data>
      <data key="d6" />
    </node>
    <node id="Narrator">
      <data key="d0">Narrator</data>
      <data key="d1">person</data>
      <data key="d2">The narrator is the individual recounting their learning journey, who relearned the concepts of weight and threshold and encountered various resources like Neural Networks and Deep Learning.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001904</data>
      <data key="d6" />
    </node>
    <node id="Neural Networks and Deep Learning">
      <data key="d0">Neural Networks and Deep Learning</data>
      <data key="d1">content</data>
      <data key="d2">Neural Networks and Deep Learning is a resource or material encountered by the narrator during their learning journey.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001898</data>
      <data key="d6" />
    </node>
    <node id="α Tutorial">
      <data key="d0">α Tutorial</data>
      <data key="d1">content</data>
      <data key="d2">α Tutorial is one of the learning resources mentioned by the narrator as part of their educational path.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001898</data>
      <data key="d6" />
    </node>
    <node id="ES6">
      <data key="d0">ES6</data>
      <data key="d1">content</data>
      <data key="d2">ES6 is one of the learning resources mentioned by the narrator as part of their educational path.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001898</data>
      <data key="d6" />
    </node>
    <node id="How to Become Thoughtful">
      <data key="d0">How to Become Thoughtful</data>
      <data key="d1">content</data>
      <data key="d2">How to Become Thoughtful is one of the learning resources mentioned by the narrator as part of their educational path.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001898</data>
      <data key="d6" />
    </node>
    <node id="Hackers and Painters">
      <data key="d0">Hackers and Painters</data>
      <data key="d1">content</data>
      <data key="d2">Hackers and Painters is one of the learning resources mentioned by the narrator as part of their educational path.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001898</data>
      <data key="d6" />
    </node>
    <node id="Survivors of the Future World">
      <data key="d0">Survivors of the Future World</data>
      <data key="d1">content</data>
      <data key="d2">Survivors of the Future World is one of the learning resources mentioned by the narrator as part of their educational path.</data>
      <data key="d3">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001899</data>
      <data key="d6" />
    </node>
    <node id="Azure机器学习">
      <data key="d0">Azure机器学习</data>
      <data key="d1">organization</data>
      <data key="d2">Azure机器学习是微软提供的一个云平台，用于构建、训练和部署机器学习与深度学习模型。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001974</data>
      <data key="d6" />
    </node>
    <node id="深度学习">
      <data key="d0">深度学习</data>
      <data key="d1">concept</data>
      <data key="d2">深度学习是机器学习的一个子集，也是人工智能（AI）的核心领域与关键技术引擎。它是一种基于人工神经网络，特别是包含多个层级（即“深度”）的深层神经网络的人工智能方法。深度学习专注于通过表示学习或深度表征学习，从数据中自动学习复杂的特征和模式，其核心优势在于能够实现端到端的自动化学习，无需大量手动特征工程，从而颠覆了传统的研发模式并实现了框架的标准化。

该方法框架通用性好，能够学习较远的上下文特征，并可以利用无监督语料进行训练以提升效果。深度学习涵盖了一系列算法和神经网络架构，其中卷积神经网络和循环神经网络是两种重要且典型的架构，分别擅长处理图像和序列数据。它尤其擅长处理图像、语音、文本等非结构化数据，在自然语言处理、图像识别、语音识别、语言翻译等领域扮演关键角色。

深度学习在众多实际应用中表现出色，例如网络搜索、广告推送、金融量化交易等，其性能在某些任务上甚至超越了人类。基于深度学习的大模型技术被视为人工智能技术演进的关键，是一项正在快速变革多个行业的颠覆性技术。此外，它也是掌握计算认知和计算神经科学的基础，为脑科学研究、蛋白质结构预测等科学计算领域提供了重要工具。总体而言，深度学习在大数据背景下蓬勃发展，极大地推动了多个领域的技术进步。&lt;SEP&gt;用于实现遥感图像目标检测的核心技术方法。&lt;SEP&gt;一种机器学习方法，用于从数据中学习特征和模式。&lt;SEP&gt;深度学习是人工智能领域的核心技术之一，近年来在研究和应用层面取得了显著进展，是一种强大的机器学习方法。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-d22adf07bd762e4e32d9bceea2fa6218&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-c79b805e7da972f5a80b0f9eb1144d75&lt;SEP&gt;chunk-225c135f952fba89e32fc67dcf80d0f5&lt;SEP&gt;chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8&lt;SEP&gt;chunk-88c27f8b7b31c4aea51cfc3d8f79a013&lt;SEP&gt;chunk-92f537cdcce6583c2c63c400d634feaf&lt;SEP&gt;chunk-9ed0526c7eff8b1a424224e53050b149&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-03a5749c6bb89c89b202fa903dbb847f&lt;SEP&gt;chunk-c5eafae240ac5d07dadf7c4eb744e8eb&lt;SEP&gt;chunk-62c73611ffdf6388dc832abdf23ad216&lt;SEP&gt;chunk-dcad4a5abb7347f0e6403bab97eb576b&lt;SEP&gt;chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-0ff265f7709913907a277247870f20cc&lt;SEP&gt;chunk-6bc1d4e50f0179dd98e01918a3be7977&lt;SEP&gt;chunk-ead8239d6c7d35f7d27952face0dd715&lt;SEP&gt;chunk-a6a52780a97b8eca9204ad8ed2f86840&lt;SEP&gt;chunk-c00652dd3948d32546676fffc8064300&lt;SEP&gt;chunk-5e9c7c6b034fa0090c148c9fb494cca9&lt;SEP&gt;chunk-5ec46d561fc83169cc4cb16171e4b90d&lt;SEP&gt;chunk-432af570193bd3df6d564434ee8bfbbb&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc&lt;SEP&gt;chunk-326a81b79c40b3a07062403d80063e34&lt;SEP&gt;chunk-506b50fbb39065edcc65dbbbc31a2bd7&lt;SEP&gt;chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010717</data>
      <data key="d6" />
    </node>
    <node id="机器学习">
      <data key="d0">机器学习</data>
      <data key="d1">method</data>
      <data key="d2">机器学习是人工智能（AI）的一个核心子集与实现路径，也是一种数据分析方法和方法论。其核心思想是让计算机系统能够从数据中“学习”经验并改进性能，而无需进行明确的编程。机器学习专注于设计算法，使计算机能够通过分析数据来自我学习，自动构建分析模型，识别模式，从而优化任务执行能力、做出预测或决策，例如最小化预测错误。

该领域包含多种技术，其中深度学习是其一个重要分支。机器学习的应用范围极为广泛，包括但不限于商业领域的个性化产品推荐系统、科学研究的蛋白质结构预测、金融领域的量化交易（其算法在中低频和高频交易场景中均有应用，且在高频环境下可能更具优势），以及自然语言处理。它也被应用于模型风险管理，特别是在模型验证和实时模型监控阶段。此外，机器学习为脑科学研究提供了处理数据的新方法和模拟脑功能的新思路。

作为一门成熟的学科，其基础知识已在多所高等学府的相关课程中被系统介绍。&lt;SEP&gt;A method used for weather prediction and climate simulation, noted for being faster and more energy-efficient than traditional models.</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-92f537cdcce6583c2c63c400d634feaf&lt;SEP&gt;chunk-c5eafae240ac5d07dadf7c4eb744e8eb&lt;SEP&gt;chunk-dcad4a5abb7347f0e6403bab97eb576b&lt;SEP&gt;chunk-0ff265f7709913907a277247870f20cc&lt;SEP&gt;chunk-6bc1d4e50f0179dd98e01918a3be7977&lt;SEP&gt;chunk-2103a1c2471cc6226897b2080204b309&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771&lt;SEP&gt;chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009999</data>
      <data key="d6" />
    </node>
    <node id="人工智能">
      <data key="d0">人工智能</data>
      <data key="d1">concept</data>
      <data key="d2">人工智能（Artificial Intelligence，简称AI）是一个广泛的科学领域与研究学科，其核心目标是创建能够模拟、延伸和扩展人类智能与认知功能的机器或软件系统，使其能够执行通常需要人类智能才能完成的任务。该领域旨在使计算机具备解决复杂问题的能力，例如推理、学习、问题解决、理解语言、面部识别、决策制定和语言翻译等。

从研究本质上看，人工智能致力于探索如何使机器模拟人类的思维和意识，一些观点进一步将其与对生命智能的研究联系起来。它是一个内容丰富的综合性领域，整合了多种关键技术和方法，其中包括机器学习、深度学习（被视为其核心技术之一）以及卷积神经网络等。预测性人工智能和自然语言处理都是其重要的组成部分或子领域。

人工智能的发展范式正从专注于特定任务的“狭义AI”向具备广泛能力的“通用AI”迈进。作为一个技术科学，其研究和应用范围不断扩展，例如有研究者正将其与气候学等领域相结合。总体而言，人工智能是一门专注于开发能展现智能行为、执行智能任务的人造系统的技术科学。&lt;SEP&gt;人工智能是一种技术，其迅猛发展对传统哲学的主体概念、社会安全性和哲学研究视域构成了多重挑战。&lt;SEP&gt;Artificial Intelligence, especially large language models and deep learning algorithms, presents challenges to philosophical research by affecting information processing and human thought patterns.&lt;SEP&gt;Artificial intelligence, whose development and application must consider social conditions and ensure it serves humanity, according to Wang Tian. It carries multiple values like ethics and culture.&lt;SEP&gt;A technology that is widely applied and is reshaping the era, prompting philosophical reflection.</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-b572e7e95c9e5e07043de0b3cb587187&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771&lt;SEP&gt;chunk-4a38cf117c062d1c34ec79abbff9e244&lt;SEP&gt;chunk-ea37ab1462f7ff56b1e76b106d6df9dd&lt;SEP&gt;chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010967</data>
      <data key="d6" />
    </node>
    <node id="生成式AI">
      <data key="d0">生成式AI</data>
      <data key="d1">concept</data>
      <data key="d2">生成式AI是AI的一个子集，使用深度学习等技术生成新的内容，如图像、文本或音频。&lt;SEP&gt;Generative AI is a technology that can improve return on investment and is used to build innovative solutions.&lt;SEP&gt;Generative AI is a technology that can be used to build innovative solutions and improve investment returns.&lt;SEP&gt;生成式AI是指能够生成新内容(如文本、图像)的人工智能，其复杂深度神经网络架构的训练依赖于反向传播。&lt;SEP&gt;Generative AI, a type of artificial intelligence that can create new content, such as text or images.&lt;SEP&gt;生成式AI是人工智能的一种类型，可以创建新的内容，常与代理式AI进行对比。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008976</data>
      <data key="d6" />
    </node>
    <node id="人工神经网络">
      <data key="d0">人工神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">人工神经网络是深度学习的基础结构，包含输入层、输出层和多个隐藏层，用于转换数据和进行预测。&lt;SEP&gt;人工神经网络是一种模仿生物神经网络结构和功能的计算模型，是反向传播算法训练的对象。&lt;SEP&gt;人工神经网络是卷积神经网络的简称，是一种算法数学模型。&lt;SEP&gt;A computational model inspired by biological neural networks. It faced a decline from the 1990s to 2006 due to issues like getting stuck in local minima, but was revived with the advent of deep learning.&lt;SEP&gt;Artificial Neural Networks (ANN) are computing systems inspired by biological neural networks, serving as the foundational architecture for deep learning models.</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008480</data>
      <data key="d6" />
    </node>
    <node id="特征提取">
      <data key="d0">特征提取</data>
      <data key="d1">method</data>
      <data key="d2">特征提取是机器学习中的一种技术，通过从数据中识别和选择关键信息来告知算法如何进行准确的预测。&lt;SEP&gt;特征提取是将原始文本转换为数字表示的过程，以便机器分析。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007394</data>
      <data key="d6" />
    </node>
    <node id="GPU">
      <data key="d0">GPU</data>
      <data key="d1">artifact</data>
      <data key="d2">GPU(图形处理单元)是高端计算机硬件，能够有效优化深度学习所需的大量矩阵乘法运算。&lt;SEP&gt;GPU (Graphics Processing Unit) is a type of high-performance computing resource used for parallel computations in AI and machine learning.&lt;SEP&gt;图形处理器，用于高效并行计算卷积操作，使得卷积神经网络的计算更加高效。&lt;SEP&gt;Computational hardware required for the training and inference of deep learning models, contributing to high technical and cost thresholds.&lt;SEP&gt;图形处理器是一种专为并行计算设计的硬件，其加速能力对深度学习等计算密集型算法的训练速度影响巨大。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-cb25bd59eb20459d90d689a472568aea&lt;SEP&gt;chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-2dc1c848682669d15114cbb84e3cd6b4&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006890</data>
      <data key="d6" />
    </node>
    <node id="迁移学习">
      <data key="d0">迁移学习</data>
      <data key="d1">method</data>
      <data key="d2">迁移学习是一种技术，通过重新调整预训练模型的最终层用途，来减少训练新模型所需的时间、数据和计算资源。&lt;SEP&gt;迁移学习是一种前沿技术，属于机器学习领域。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006836</data>
      <data key="d6" />
    </node>
    <node id="Foundry模型">
      <data key="d0">Foundry模型</data>
      <data key="d1">artifact</data>
      <data key="d2">Foundry模型是Azure机器学习中预先训练的深度学习模型，可针对特定用例进行微调。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001977</data>
      <data key="d6" />
    </node>
    <node id="生成对抗网络">
      <data key="d0">生成对抗网络</data>
      <data key="d1">concept</data>
      <data key="d2">生成对抗网络是一种用于创建真实内容(如图像)的生成模型，由生成器和判别器两个网络组成，通过竞争进行训练。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001977</data>
      <data key="d6" />
    </node>
    <node id="转换器">
      <data key="d0">转换器</data>
      <data key="d1">concept</data>
      <data key="d2">转换器是一种用于处理序列问题(如文本或时序数据)的模型架构，包含编码器层和解码器层。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001984</data>
      <data key="d6" />
    </node>
    <node id="欺诈检测">
      <data key="d0">欺诈检测</data>
      <data key="d1">concept</data>
      <data key="d2">欺诈检测是深度学习的一个应用场景，指利用模型识别欺诈行为。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001984</data>
      <data key="d6" />
    </node>
    <node id="语音识别">
      <data key="d0">语音识别</data>
      <data key="d1">concept</data>
      <data key="d2">语音识别是深度学习的一个应用场景，指利用模型识别和理解人类语音。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001978</data>
      <data key="d6" />
    </node>
    <node id="面部识别">
      <data key="d0">面部识别</data>
      <data key="d1">concept</data>
      <data key="d2">面部识别是深度学习的一个应用场景，指利用模型识别和验证人脸。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001978</data>
      <data key="d6" />
    </node>
    <node id="情绪分析">
      <data key="d0">情绪分析</data>
      <data key="d1">concept</data>
      <data key="d2">情绪分析是深度学习的一个应用场景，指利用模型分析文本或语音中的情感倾向。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001978</data>
      <data key="d6" />
    </node>
    <node id="时序预测">
      <data key="d0">时序预测</data>
      <data key="d1">concept</data>
      <data key="d2">时序预测是深度学习的一个应用场景，指利用模型预测时间序列数据的未来趋势。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001978</data>
      <data key="d6" />
    </node>
    <node id="Microsoft Azure Global Edition">
      <data key="d0">Microsoft Azure Global Edition</data>
      <data key="d1">organization</data>
      <data key="d2">Microsoft Azure Global Edition is the global version of Microsoft's cloud platform, hosting technical documentation.</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001979</data>
      <data key="d6" />
    </node>
    <node id="Microsoft Azure China">
      <data key="d0">Microsoft Azure China</data>
      <data key="d1">organization</data>
      <data key="d2">Microsoft Azure China is the version of Microsoft Azure operated by 21Vianet in China, with a separate technical documentation site.</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001979</data>
      <data key="d6" />
    </node>
    <node id="PyTorch">
      <data key="d0">PyTorch</data>
      <data key="d1">method</data>
      <data key="d2">PyTorch is an open-source machine learning framework mentioned in the context of training deep learning models using transfer learning in Azure Machine Learning.&lt;SEP&gt;PyTorch是一个深度学习框架，用于实现卷积神经网络模型。&lt;SEP&gt;PyTorch is an open-source machine learning library based on the Torch library.&lt;SEP&gt;PyTorch is a deep learning framework used for building and implementing models for tasks like remote sensing image object detection and segmentation.</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009791</data>
      <data key="d6" />
    </node>
    <node id="编码器">
      <data key="d0">编码器</data>
      <data key="d1">concept</data>
      <data key="d2">编码器是转换器模型架构中的一个组成部分，负责接收输入序列并将其转换为内部表示。&lt;SEP&gt;编码器是自动编码器的一部分，负责将输入数据转换为一种编码表示。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003436</data>
      <data key="d6" />
    </node>
    <node id="解码器">
      <data key="d0">解码器</data>
      <data key="d1">concept</data>
      <data key="d2">解码器是转换器模型架构中的一个组成部分，通常负责基于编码器的输出生成目标序列。&lt;SEP&gt;解码器是自动编码器的一部分，负责从编码表示中重建或生成数据。</data>
      <data key="d3">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003436</data>
      <data key="d6" />
    </node>
    <node id="Synthetic Content">
      <data key="d0">Synthetic Content</data>
      <data key="d1">concept</data>
      <data key="d2">Content that is artificially generated and is indistinguishable from real content.</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001980</data>
      <data key="d6" />
    </node>
    <node id="Discriminator">
      <data key="d0">Discriminator</data>
      <data key="d1">concept</data>
      <data key="d2">A component that attempts to correctly classify input as either real content or synthetic content.</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001980</data>
      <data key="d6" />
    </node>
    <node id="Transformer">
      <data key="d0">Transformer</data>
      <data key="d1">concept</data>
      <data key="d2">A model architecture used for solving problems involving sequences, such as text or time-series data.&lt;SEP&gt;Transformer model is known for its powerful sequence processing and parallel computing capabilities, recently introduced into financial time series prediction.&lt;SEP&gt;Transformer is a type of deep learning model mentioned alongside LSTM for predicting future price trends or judging short-term directions.&lt;SEP&gt;Transformer is a deep learning model architecture consisting of Encoder blocks and Decoder blocks, used for sequence-to-sequence tasks.&lt;SEP&gt;Transformer is a model that utilizes attention mechanisms to improve training speed and is a deep learning model entirely based on self-attention mechanisms.&lt;SEP&gt;Transformer is a neural network architecture that transforms input sequences into output sequences by learning content and tracking relationships between sequence elements.&lt;SEP&gt;Transformer is a machine learning model architecture introduced in the paper "Attention Is All You Need".</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6&lt;SEP&gt;chunk-82bdb1406dfe17a400fa95a5a4727859&lt;SEP&gt;chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-3ac3b580cca11b5e1d0122810a6ec5f5&lt;SEP&gt;chunk-778f83860f7db1907e0da6e0cb412723&lt;SEP&gt;chunk-f11a177649a52b5177411e9ce9bb9885&lt;SEP&gt;chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008273</data>
      <data key="d6" />
    </node>
    <node id="Encoder">
      <data key="d0">Encoder</data>
      <data key="d1">artifact</data>
      <data key="d2">A layer within a transformer that accepts input and maps it to a numerical representation containing contextual information.&lt;SEP&gt;A component of the encoder-decoder model that processes input data and converts it into a context representation.&lt;SEP&gt;The Encoder is a stack of multiple Encoder blocks that processes the entire input sequence to produce a contextualized representation.</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007685</data>
      <data key="d6" />
    </node>
    <node id="Decoder">
      <data key="d0">Decoder</data>
      <data key="d1">artifact</data>
      <data key="d2">A layer within a transformer that uses information from the encoder to generate output, such as translated text.&lt;SEP&gt;A component of the encoder-decoder model that generates output data based on the context representation from the encoder.&lt;SEP&gt;The Decoder is a stack of multiple Decoder blocks that generates the output sequence autoregressively, using the Encoder's output and its own previous outputs.</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007685</data>
      <data key="d6" />
    </node>
    <node id="Attention Sublayer">
      <data key="d0">Attention Sublayer</data>
      <data key="d1">concept</data>
      <data key="d2">A component that makes transformers distinct from other encoder-decoder architectures.</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001981</data>
      <data key="d6" />
    </node>
    <node id="Attention">
      <data key="d0">Attention</data>
      <data key="d1">method</data>
      <data key="d2">A mechanism that focuses on specific parts of the input based on their contextual importance relative to other parts of the sequence.&lt;SEP&gt;Attention is a mechanism used in AlphaFold2 to integrate 1D and 2D information.&lt;SEP&gt;A mechanism added before transitioning from the word level to the sentence level to identify the most important words within a sentence. Another Attention layer is added before the final output to learn which sentences are most important.</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6&lt;SEP&gt;chunk-224a7273b9442fd233a7ec61f799fa44&lt;SEP&gt;chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006938</data>
      <data key="d6" />
    </node>
    <node id="Bidirectional Encoder Representations From Transformers (BERT)">
      <data key="d0">Bidirectional Encoder Representations From Transformers (BERT)</data>
      <data key="d1">concept</data>
      <data key="d2">A specific model based on the transformer architecture.</data>
      <data key="d3">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769001982</data>
      <data key="d6" />
    </node>
    <node id="监督学习">
      <data key="d0">监督学习</data>
      <data key="d1">method</data>
      <data key="d2">监督学习是一种机器学习方法，使用标记数据集来训练算法。&lt;SEP&gt;监督学习是一种机器学习范式，模型在带有标签的数据集上进行训练，反向传播是其训练神经网络做出更优质预测的关键技术。&lt;SEP&gt;Supervised learning is a machine learning paradigm where models are trained using labeled data.&lt;SEP&gt;A learning paradigm where an artificial neural network is trained using data where the final answers are known in advance. This is contrasted with creative thinking which may not have a predefined answer.&lt;SEP&gt;机器学习的一种范式。&lt;SEP&gt;Supervised Learning is a type of machine learning where models are trained on labeled data (input-output pairs) to learn a mapping function.</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008419</data>
      <data key="d6" />
    </node>
    <node id="无监督学习">
      <data key="d0">无监督学习</data>
      <data key="d1">method</data>
      <data key="d2">无监督学习是一种机器学习方法，不依赖标记数据集，可以处理原始非结构化数据。&lt;SEP&gt;无监督学习是一种机器学习任务类型，自编码器是执行此类任务的结构。&lt;SEP&gt;Unsupervised learning is a machine learning paradigm where models find patterns in unlabeled data.&lt;SEP&gt;机器学习的一种范式。&lt;SEP&gt;Unsupervised Learning is a type of machine learning where models find patterns and structures in unlabeled data without predefined outputs.&lt;SEP&gt;Unsupervised learning is the process that guides LLMs, facilitated by the Transformer architecture and its parameters.</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-e101b215c048456f8049a66e9ebd2c54&lt;SEP&gt;chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008988</data>
      <data key="d6" />
    </node>
    <node id="Amazon">
      <data key="d0">Amazon</data>
      <data key="d1">organization</data>
      <data key="d2">Amazon是一家使用机器学习根据客户浏览和购买历史进行产品推荐的公司。&lt;SEP&gt;Amazon is a technology company that developed the Alexa voice assistant.</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007391</data>
      <data key="d6" />
    </node>
    <node id="Google">
      <data key="d0">Google</data>
      <data key="d1">organization</data>
      <data key="d2">Google的搜索算法是神经网络的一个著名应用示例。&lt;SEP&gt;Google是一家科技公司，投入巨资研究卷积神经网络的变体。&lt;SEP&gt;A technology company where Geoffrey Hinton worked part-time. It also acquired DeepMind.</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003870</data>
      <data key="d6" />
    </node>
    <node id="IBM">
      <data key="d0">IBM</data>
      <data key="d1">organization</data>
      <data key="d2">IBM（国际商业机器公司）是一家跨国科技公司。该公司在人工智能（AI）领域提供广泛的专业知识、解决方案和咨询服务，具体包括数据与AI解决方案、网络研讨会、报告和课程，以帮助企业实施AI。

IBM开发了多个AI模型和平台，其中包括IBM Granite系列AI模型以及名为watsonx.ai的开发平台。在其Watson Studio和watsonx.ai平台中，IBM提供对卷积神经网络（CNN）架构的支持，以实现高性能部署，应用领域涵盖医疗影像诊断、自动驾驶感知和智能安防等。

此外，IBM还提供如IBM Cloud Pak for Business Automation等解决方案，用于运营管理和自动化。公司也发布相关通讯，如Think Newsletter，并设有隐私声明。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-2103a1c2471cc6226897b2080204b309&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008179</data>
      <data key="d6" />
    </node>
    <node id="IBM Data and AI Team">
      <data key="d0">IBM Data and AI Team</data>
      <data key="d1">organization</data>
      <data key="d2">IBM Data and AI Team是IBM内部专注于数据和人工智能的团队。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002051</data>
      <data key="d6" />
    </node>
    <node id="IBM Granite">
      <data key="d0">IBM Granite</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM Granite是一个AI模型，由IBM提供深入了解的课程。&lt;SEP&gt;IBM Granite是IBM推出的一个开放式、高性能、可信赖的AI模型系列，专为企业定制并经过优化，用于扩展AI应用程序。&lt;SEP&gt;IBM's series of open, performant, and trustworthy AI models tailored for enterprise use.&lt;SEP&gt;A series of open, high-performance, and trusted AI models from IBM, tailored and optimized for enterprise use.&lt;SEP&gt;An open-source, high-performance, and trustworthy series of AI models tailored for enterprises, optimized for scaling AI applications across language, code, time series, and guardrail options.</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008141</data>
      <data key="d6" />
    </node>
    <node id="生成式人工智能">
      <data key="d0">生成式人工智能</data>
      <data key="d1">concept</data>
      <data key="d2">生成式人工智能是一种AI技术，用于创建新内容或解决方案，可以提高投资回报率。&lt;SEP&gt;Generative AI is the latest technology but may not be suitable for financial forecasting as other mature models can achieve similar results with less effort and lower cost.&lt;SEP&gt;生成式人工智能是能够生成新内容的人工智能，自然语言处理的研究有助于推动其发展。&lt;SEP&gt;生成式人工智能的迅猛发展激发出新的哲学问题(如道德地位、事故归责)，并可能颠覆传统的哲学观念和视野。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-2103a1c2471cc6226897b2080204b309&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011127</data>
      <data key="d6" />
    </node>
    <node id="智能体式人工智能">
      <data key="d0">智能体式人工智能</data>
      <data key="d1">concept</data>
      <data key="d2">智能体式人工智能是一种AI方法，旨在实现投资回报并推动业务增长。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002051</data>
      <data key="d6" />
    </node>
    <node id="数据管理">
      <data key="d0">数据管理</data>
      <data key="d1">concept</data>
      <data key="d2">数据管理涉及构建系统来管理数据，包括存储、清理和控制偏差，是实现AI目标的前提。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002052</data>
      <data key="d6" />
    </node>
    <node id="混合AI就绪型架构">
      <data key="d0">混合AI就绪型架构</data>
      <data key="d1">concept</data>
      <data key="d2">混合AI就绪型架构是一种能够成功使用位于任何地方(如大型机、云、边缘)的数据的架构。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002052</data>
      <data key="d6" />
    </node>
    <node id="AI模型选择框架">
      <data key="d0">AI模型选择框架</data>
      <data key="d1">concept</data>
      <data key="d2">AI模型选择框架是一种用于平衡模型性能要求与成本、风险和部署需求的工具。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002052</data>
      <data key="d6" />
    </node>
    <node id="2024年AI实际应用报告">
      <data key="d0">2024年AI实际应用报告</data>
      <data key="d1">content</data>
      <data key="d2">2024年AI实际应用报告是一份基于对2000家组织调查的报告，旨在了解有效的AI实施方法。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002053</data>
      <data key="d6" />
    </node>
    <node id="从推行AI项目到实现盈利报告">
      <data key="d0">从推行AI项目到实现盈利报告</data>
      <data key="d1">content</data>
      <data key="d2">从推行AI项目到实现盈利报告探讨了组织如何从AI试点转向利用AI推动核心业务转型。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002053</data>
      <data key="d6" />
    </node>
    <node id="让AI充分发挥作用指南">
      <data key="d0">让AI充分发挥作用指南</data>
      <data key="d1">content</data>
      <data key="d2">让AI充分发挥作用指南提供了关于利用生成式AI提高投资回报率的指导。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002053</data>
      <data key="d6" />
    </node>
    <node id="解锁生成式AI + ML的强大功能电子书">
      <data key="d0">解锁生成式AI + ML的强大功能电子书</data>
      <data key="d1">content</data>
      <data key="d2">解锁生成式AI + ML的强大功能电子书是一本关于生成式人工智能和机器学习的电子书。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002053</data>
      <data key="d6" />
    </node>
    <node id="树立信任，从容自信指南">
      <data key="d0">树立信任，从容自信指南</data>
      <data key="d1">content</data>
      <data key="d2">树立信任，从容自信指南是一份关于建立AI信任的指南。</data>
      <data key="d3">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002053</data>
      <data key="d6" />
    </node>
    <node id="体式AI">
      <data key="d0">体式AI</data>
      <data key="d1">concept</data>
      <data key="d2">体式AI is a concept mentioned as promoting growth.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002053</data>
      <data key="d6" />
    </node>
    <node id="投资回报率">
      <data key="d0">投资回报率</data>
      <data key="d1">concept</data>
      <data key="d2">Return on Investment (ROI) is a metric that generative AI can help improve.&lt;SEP&gt;Return on Investment (ROI) is a key metric that can be improved by leveraging generative AI.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002447</data>
      <data key="d6" />
    </node>
    <node id="AI投资">
      <data key="d0">AI投资</data>
      <data key="d1">concept</data>
      <data key="d2">AI investment refers to financial commitments made into artificial intelligence technologies.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002054</data>
      <data key="d6" />
    </node>
    <node id="电子书">
      <data key="d0">电子书</data>
      <data key="d1">content</data>
      <data key="d2">An ebook is offered as a resource to unlock the power of generative AI and machine learning.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002055</data>
      <data key="d6" />
    </node>
    <node id="生成式AI + ML">
      <data key="d0">生成式AI + ML</data>
      <data key="d1">concept</data>
      <data key="d2">Generative AI combined with Machine Learning represents a powerful technological capability.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002055</data>
      <data key="d6" />
    </node>
    <node id="AI新时代">
      <data key="d0">AI新时代</data>
      <data key="d1">concept</data>
      <data key="d2">The new era of AI is a period characterized by the need for trust and confidence to thrive.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002055</data>
      <data key="d6" />
    </node>
    <node id="IBM watsonx.ai">
      <data key="d0">IBM watsonx.ai</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM watsonx.ai is an enterprise-grade development platform for building, training, validating, tuning, and deploying generative AI, foundation models, and machine learning capabilities.&lt;SEP&gt;IBM watsonx.ai is a next-generation enterprise-grade development platform for training, validating, tuning, and deploying generative AI, foundation models, and machine learning capabilities.&lt;SEP&gt;IBM watsonx.ai是IBM面向AI构建者的新一代企业级开发平台，用于训练、验证和调整AI模型。&lt;SEP&gt;An enterprise-grade development platform from IBM for training, validating, tuning, and deploying generative AI and foundation models.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003515</data>
      <data key="d6" />
    </node>
    <node id="基础模型">
      <data key="d0">基础模型</data>
      <data key="d1">concept</data>
      <data key="d2">Foundation models are a type of AI model that can be deployed using platforms like IBM watsonx.ai.&lt;SEP&gt;Foundation models, large AI models trained on broad data that can be adapted to a wide range of tasks.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003175</data>
      <data key="d6" />
    </node>
    <node id="机器学习功能">
      <data key="d0">机器学习功能</data>
      <data key="d1">concept</data>
      <data key="d2">Machine learning capabilities are functionalities that can be developed and deployed alongside generative AI.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002056</data>
      <data key="d6" />
    </node>
    <node id="AI应用程序">
      <data key="d0">AI应用程序</data>
      <data key="d1">concept</data>
      <data key="d2">AI applications are software programs that can be built quickly with minimal data using platforms like IBM watsonx.ai.&lt;SEP&gt;AI applications can be built quickly using a small subset of data on platforms like IBM watsonx.ai.&lt;SEP&gt;AI applications are software programs that utilize artificial intelligence to perform specific tasks or provide services.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003179</data>
      <data key="d6" />
    </node>
    <node id="IBM Consulting AI服务">
      <data key="d0">IBM Consulting AI服务</data>
      <data key="d1">organization</data>
      <data key="d2">IBM Consulting AI Services is an offering that helps reshape how enterprises use AI for transformation.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002057</data>
      <data key="d6" />
    </node>
    <node id="指南">
      <data key="d0">指南</data>
      <data key="d1">content</data>
      <data key="d2">A guide is a type of content that helps AI reach its full potential and build trust in the new AI era.&lt;SEP&gt;The guide provides instructions on how to leverage generative AI to improve investment returns.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002450</data>
      <data key="d6" />
    </node>
    <node id="AI构建器">
      <data key="d0">AI构建器</data>
      <data key="d1">person</data>
      <data key="d2">AI builders are individuals who use enterprise-grade development platforms like IBM watsonx.ai to create AI solutions.&lt;SEP&gt;AI builders are skilled personnel who can construct and deliver innovative new solutions.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002447</data>
      <data key="d6" />
    </node>
    <node id="新一代企业级开发平台">
      <data key="d0">新一代企业级开发平台</data>
      <data key="d1">concept</data>
      <data key="d2">The new generation of enterprise-grade development platforms refers to advanced tools like IBM watsonx.ai for building AI.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002058</data>
      <data key="d6" />
    </node>
    <node id="一小部分数据">
      <data key="d0">一小部分数据</data>
      <data key="d1">data</data>
      <data key="d2">A small amount of data is sufficient to build AI applications quickly using platforms like IBM watsonx.ai.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002065</data>
      <data key="d6" />
    </node>
    <node id="IBM业界领先的AI专业知识和解决方案组合">
      <data key="d0">IBM业界领先的AI专业知识和解决方案组合</data>
      <data key="d1">concept</data>
      <data key="d2">IBM's industry-leading AI expertise and solution portfolio enables AI to function effectively within a business.</data>
      <data key="d3">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002065</data>
      <data key="d6" />
    </node>
    <node id="Google Cloud">
      <data key="d0">Google Cloud</data>
      <data key="d1">organization</data>
      <data key="d2">Google Cloud is a cloud computing platform offering various AI, machine learning, and other cloud services and products.&lt;SEP&gt;Google Cloud is an enterprise AI platform that integrates Google DeepMind's technologies to provide generative AI services.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea&lt;SEP&gt;chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009396</data>
      <data key="d6" />
    </node>
    <node id="Vertex AI">
      <data key="d0">Vertex AI</data>
      <data key="d1">artifact</data>
      <data key="d2">Vertex AI is a managed machine learning platform offered by Google Cloud, available for trial with promotional credits.&lt;SEP&gt;Vertex AI is a service on Google Cloud that provides access to Gemini and other generative AI models for building and testing AI applications.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea&lt;SEP&gt;chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009400</data>
      <data key="d6" />
    </node>
    <node id="Machine Learning">
      <data key="d0">Machine Learning</data>
      <data key="d1">method</data>
      <data key="d2">{"entities": ["熵", "热力学第二定律", "耗散结构", "香农", "薛定谔", "玻尔兹曼", "最大熵原理", "公式 S=k*lnW", "生命是什么"]}</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-ac1ed9e88e425ab885199259d92315e5&lt;SEP&gt;chunk-9f34e4a3e164d008eba0c74c96804047&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1&lt;SEP&gt;chunk-833d835632b095e419f4a96b3c5dac04&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81&lt;SEP&gt;chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010286</data>
      <data key="d6" />
    </node>
    <node id="TPU">
      <data key="d0">TPU</data>
      <data key="d1">artifact</data>
      <data key="d2">TPU (Tensor Processing Unit) is a type of high-performance computing resource used for efficient training in AI and machine learning.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002143</data>
      <data key="d6" />
    </node>
    <node id="CPU">
      <data key="d0">CPU</data>
      <data key="d1">artifact</data>
      <data key="d2">CPU (Central Processing Unit) is a standard processor on which AI can typically run, though complex models demand more computational power.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002144</data>
      <data key="d6" />
    </node>
    <node id="Gemini For Google Cloud">
      <data key="d0">Gemini For Google Cloud</data>
      <data key="d1">artifact</data>
      <data key="d2">Gemini for Google Cloud is an AI-powered assistant available within Google Cloud and IDEs.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002144</data>
      <data key="d6" />
    </node>
    <node id="Oracle Workload Migration">
      <data key="d0">Oracle Workload Migration</data>
      <data key="d1">method</data>
      <data key="d2">Oracle Workload Migration is a service for migrating Oracle workloads to run on Google Cloud.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002144</data>
      <data key="d6" />
    </node>
    <node id="SQL Server On Google Cloud">
      <data key="d0">SQL Server On Google Cloud</data>
      <data key="d1">method</data>
      <data key="d2">SQL Server on Google Cloud refers to various solutions for running SQL Server virtual machines on the Google Cloud platform.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002145</data>
      <data key="d6" />
    </node>
    <node id="Red Hat On Google Cloud">
      <data key="d0">Red Hat On Google Cloud</data>
      <data key="d1">method</data>
      <data key="d2">Red Hat on Google Cloud is an enterprise-grade platform provided by Google and Red Hat for traditional on-premises and custom applications.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002145</data>
      <data key="d6" />
    </node>
    <node id="Google Distributed Cloud Air-Gapped">
      <data key="d0">Google Distributed Cloud Air-Gapped</data>
      <data key="d1">method</data>
      <data key="d2">Google Distributed Cloud Air-gapped is a solution for deploying Google Cloud services in isolated environments.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002145</data>
      <data key="d6" />
    </node>
    <node id="Relational Database Service">
      <data key="d0">Relational Database Service</data>
      <data key="d1">artifact</data>
      <data key="d2">The Relational Database Service is a managed service for MySQL, PostgreSQL, and SQL Server databases on Google Cloud.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002145</data>
      <data key="d6" />
    </node>
    <node id="GKE">
      <data key="d0">GKE</data>
      <data key="d1">artifact</data>
      <data key="d2">GKE (Google Kubernetes Engine) is a managed Kubernetes service on Google Cloud for containerized applications.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002146</data>
      <data key="d6" />
    </node>
    <node id="Cloud Run">
      <data key="d0">Cloud Run</data>
      <data key="d1">artifact</data>
      <data key="d2">Cloud Run is a managed compute platform on Google Cloud for running containerized applications.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002146</data>
      <data key="d6" />
    </node>
    <node id="Fitbit Data">
      <data key="d0">Fitbit Data</data>
      <data key="d1">data</data>
      <data key="d2">Fitbit data refers to health and activity data collected from Fitbit devices, which can be associated and analyzed on Google Cloud for patient insights.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002146</data>
      <data key="d6" />
    </node>
    <node id="API Deployment And Development Management Service">
      <data key="d0">API Deployment And Development Management Service</data>
      <data key="d1">artifact</data>
      <data key="d2">This is a service on Google Cloud for managing the deployment and development of APIs.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002146</data>
      <data key="d6" />
    </node>
    <node id="Kubernetes Plugins">
      <data key="d0">Kubernetes Plugins</data>
      <data key="d1">artifact</data>
      <data key="d2">Kubernetes plugins are tools used for managing Google Cloud resources within Kubernetes environments.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002146</data>
      <data key="d6" />
    </node>
    <node id="VMware Workload Migration">
      <data key="d0">VMware Workload Migration</data>
      <data key="d1">method</data>
      <data key="d2">VMware Workload Migration is a service for migrating VMware workloads to run natively on Google Cloud.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002147</data>
      <data key="d6" />
    </node>
    <node id="Audit Logs">
      <data key="d0">Audit Logs</data>
      <data key="d1">data</data>
      <data key="d2">Audit logs on Google Cloud are records used for managing and reviewing platform, application, and system activities.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002148</data>
      <data key="d6" />
    </node>
    <node id="Pay-As-You-Go Pricing">
      <data key="d0">Pay-As-You-Go Pricing</data>
      <data key="d1">concept</data>
      <data key="d2">Pay-As-You-Go pricing is a Google Cloud pricing model that automatically provides savings based on monthly usage and discounted rates for prepaid resources.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002148</data>
      <data key="d6" />
    </node>
    <node id="$300 Credit">
      <data key="d0">$300 Credit</data>
      <data key="d1">concept</data>
      <data key="d2">A promotional credit of up to $300 offered to new customers for trying Vertex AI and other Google Cloud products.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002148</data>
      <data key="d6" />
    </node>
    <node id="Always Free Tier">
      <data key="d0">Always Free Tier</data>
      <data key="d1">concept</data>
      <data key="d2">A pricing tier on Google Cloud that offers free usage limits for over 20 products.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002148</data>
      <data key="d6" />
    </node>
    <node id="Continuous Delivery">
      <data key="d0">Continuous Delivery</data>
      <data key="d1">method</data>
      <data key="d2">A fully managed method for continuous delivery to GKE and Cloud Run on Google Cloud.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002148</data>
      <data key="d6" />
    </node>
    <node id="Patient Insights">
      <data key="d0">Patient Insights</data>
      <data key="d1">concept</data>
      <data key="d2">Comprehensive understanding of patients enabled by associating Fitbit data on Google Cloud.</data>
      <data key="d3">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002148</data>
      <data key="d6" />
    </node>
    <node id="反向传播">
      <data key="d0">反向传播</data>
      <data key="d1">method</data>
      <data key="d2">反向传播（Back Propagation）是一种用于训练神经网络的核心算法，也是深度学习的基础。作为一种通用的思想或算法，它利用动态规划思想，通过链式法则从输出层向输入层逐层计算误差（或梯度），以实现高效计算。该过程依赖于正向传播得到的变量当前值，其计算顺序涉及将误差信号乘以节点的局部导数，并将结果向后传递。

反向传播的核心目的是计算神经网络中损失函数对每个参数（如权重）的梯度。这些梯度随后被用于梯度下降等优化算法中，以更新网络权重，从而最小化损失函数。因此，它是几乎所有神经网络训练不可或缺的基础方法。</data>
      <data key="d3">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-29234d7a518b3ee30e3ee9cbc39d7e68&lt;SEP&gt;chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-ecf37963c494ecfacb6a6432c237dd3b&lt;SEP&gt;chunk-7844fb38c827827af06d614fe4afb4df&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-3a728b359622810cd77efd2985a7fcfd&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002648</data>
      <data key="d6" />
    </node>
    <node id="动态规划">
      <data key="d0">动态规划</data>
      <data key="d1">method</data>
      <data key="d2">动态规划是一种通过将问题分解为子问题并存储其结果以避免重复计算的技术。</data>
      <data key="d3">chunk-9fcf6610f361d14578f6d58fe5b5ea26</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002173</data>
      <data key="d6" />
    </node>
    <node id="梯度">
      <data key="d0">梯度</data>
      <data key="d1">concept</data>
      <data key="d2">梯度是反向传播方法计算的目标，用于指导模型参数的更新。&lt;SEP&gt;梯度是函数在某一点上变化率最大的方向，在深度学习中用于参数优化。&lt;SEP&gt;梯度是损失函数对网络参数的偏导数，在反向传播算法中用于更新权重和偏置。&lt;SEP&gt;梯度是损失函数相对于网络参数的偏导数向量，指示了参数调整的方向和幅度。</data>
      <data key="d3">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-3a728b359622810cd77efd2985a7fcfd&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002642</data>
      <data key="d6" />
    </node>
    <node id="输出层">
      <data key="d0">输出层</data>
      <data key="d1">concept</data>
      <data key="d2">输出层是神经网络中反向传播计算误差的起始点。&lt;SEP&gt;输出层是神经网络产生最终预测结果的层。&lt;SEP&gt;输出层是神经网络的最后一层，负责产生模型的最终预测结果，例如通过softmax函数输出分类概率。&lt;SEP&gt;输出层是卷积神经网络的一部分，产生最终的输出结果。&lt;SEP&gt;输出层是卷积神经网络结构的一部分，通常输出分类的类别及其概率，例如手写数字识别中的0-9数字或车型识别中的品牌概率。&lt;SEP&gt;输出层是神经网络的最后一层，负责给出最终的预测结果。&lt;SEP&gt;输出层是多层感知机网络结构中的一层。</data>
      <data key="d3">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-29234d7a518b3ee30e3ee9cbc39d7e68&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922&lt;SEP&gt;chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003561</data>
      <data key="d6" />
    </node>
    <node id="输入层">
      <data key="d0">输入层</data>
      <data key="d1">concept</data>
      <data key="d2">输入层是神经网络中反向传播计算误差的终点。&lt;SEP&gt;输入层是神经网络接收原始数据输入的层。&lt;SEP&gt;输入层是卷积神经网络的一部分，负责接收原始图像数据，通常由三个颜色通道组成一个二维矩阵。&lt;SEP&gt;输入层是卷积神经网络结构的一部分，用于接收文字、语音、图像、视频等各种数字化信号。&lt;SEP&gt;输入层是多层感知机网络结构中的一层。</data>
      <data key="d3">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-29234d7a518b3ee30e3ee9cbc39d7e68&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922&lt;SEP&gt;chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003560</data>
      <data key="d6" />
    </node>
    <node id="误差">
      <data key="d0">误差</data>
      <data key="d1">concept</data>
      <data key="d2">误差是反向传播过程中从输出层向输入层逐层计算的对象。&lt;SEP&gt;误差在神经网络训练中指的是网络输出与真实标签之间的差异，是反向传播过程中用于计算梯度的基础。</data>
      <data key="d3">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002637</data>
      <data key="d6" />
    </node>
    <node id="计算机科学">
      <data key="d0">计算机科学</data>
      <data key="d1">concept</data>
      <data key="d2">计算机科学是反向传播和动态规划等技术所应用的领域。&lt;SEP&gt;The domain or field of study mentioned in the document metadata.&lt;SEP&gt;一个科学领域，与生命科学交叉，是MIT 6.874课程的核心内容之一。&lt;SEP&gt;计算机科学是研究计算机及其应用的学科，自然语言处理是其一个子领域。</data>
      <data key="d3">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-225c135f952fba89e32fc67dcf80d0f5&lt;SEP&gt;chunk-dcad4a5abb7347f0e6403bab97eb576b&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007342</data>
      <data key="d6" />
    </node>
    <node id="Hidden Layer Weight Parameter">
      <data key="d0">Hidden Layer Weight Parameter</data>
      <data key="d1">concept</data>
      <data key="d2">A weight matrix W^(1) in ℝ^(h×d) that transforms the input to the hidden layer in a neural network.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002250</data>
      <data key="d6" />
    </node>
    <node id="Hidden Layer Variable">
      <data key="d0">Hidden Layer Variable</data>
      <data key="d1">concept</data>
      <data key="d2">An intermediate variable h in ℝ^h, which is the result of applying an activation function to the intermediate variable z.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002250</data>
      <data key="d6" />
    </node>
    <node id="Output Layer Weight Parameter">
      <data key="d0">Output Layer Weight Parameter</data>
      <data key="d1">concept</data>
      <data key="d2">A weight matrix W^(2) in ℝ^(q×h) that transforms the hidden layer variable to the output layer variable.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002251</data>
      <data key="d6" />
    </node>
    <node id="Output Layer Variable">
      <data key="d0">Output Layer Variable</data>
      <data key="d1">concept</data>
      <data key="d2">The final output variable o in ℝ^q of the neural network model, produced by the output layer.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002251</data>
      <data key="d6" />
    </node>
    <node id="Regularization Term">
      <data key="d0">Regularization Term</data>
      <data key="d1">concept</data>
      <data key="d2">A term s defined as (λ/2)(‖W^(1)‖_F^2 + ‖W^(2)‖_F^2) added to the objective function to penalize large weights.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002251</data>
      <data key="d6" />
    </node>
    <node id="Objective Function">
      <data key="d0">Objective Function</data>
      <data key="d1">concept</data>
      <data key="d2">The function J = L + s that the model aims to optimize, consisting of a loss term L and a regularization term s.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002252</data>
      <data key="d6" />
    </node>
    <node id="Chain Rule">
      <data key="d0">Chain Rule</data>
      <data key="d1">method</data>
      <data key="d2">A fundamental calculus rule used in backpropagation to compute the gradient of the objective function with respect to parameters by sequentially differentiating through intermediate variables.&lt;SEP&gt;The chain rule is a calculus method applied to compute gradients of composite functions sequentially, used in reverse order of the forward propagation.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb&lt;SEP&gt;chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002531</data>
      <data key="d6" />
    </node>
    <node id="Backpropagation">
      <data key="d0">Backpropagation</data>
      <data key="d1">method</data>
      <data key="d2">An algorithm for computing gradients in neural networks by applying the chain rule in the reverse order of the forward propagation.&lt;SEP&gt;Backpropagation is the algorithm for computing gradients in a neural network by applying the chain rule in reverse order of forward propagation.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb&lt;SEP&gt;chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002536</data>
      <data key="d6" />
    </node>
    <node id="Activation Function">
      <data key="d0">Activation Function</data>
      <data key="d1">concept</data>
      <data key="d2">An element-wise function φ applied to the intermediate variable z to produce the hidden layer variable h.&lt;SEP&gt;A function applied to a neuron's total net input to produce its output, such as sigmoid.&lt;SEP&gt;A function (e.g., ReLU) applied to the output of a convolution layer to introduce non-linearity.&lt;SEP&gt;Activation functions like ReLU, Sigmoid, and Tanh introduce non-linearity into neural networks.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb&lt;SEP&gt;chunk-b0c9962abc15c97c8cc9a40c8f13e070&lt;SEP&gt;chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003606</data>
      <data key="d6" />
    </node>
    <node id="Forward Propagation">
      <data key="d0">Forward Propagation</data>
      <data key="d1">method</data>
      <data key="d2">The process of computing the network's output from the input through successive layers, which provides the current values needed for gradient calculation in backpropagation.&lt;SEP&gt;Forward propagation is the process of computing outputs from inputs through a neural network, determining the values of intermediate variables like the hidden variable h.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb&lt;SEP&gt;chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002531</data>
      <data key="d6" />
    </node>
    <node id="Intermediate Variable Z">
      <data key="d0">Intermediate Variable Z</data>
      <data key="d1">concept</data>
      <data key="d2">An intermediate variable z in ℝ^h, which is the linear transformation of the input by the hidden layer weight parameter before the activation function is applied.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002253</data>
      <data key="d6" />
    </node>
    <node id="Loss Term L">
      <data key="d0">Loss Term L</data>
      <data key="d1">concept</data>
      <data key="d2">The loss term L is a component of the objective function J, representing the error between the model's predictions and the true values.&lt;SEP&gt;The loss term L is a component of the objective function J, measuring the error of the model's predictions.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb&lt;SEP&gt;chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002532</data>
      <data key="d6" />
    </node>
    <node id="Input Variable X">
      <data key="d0">Input Variable X</data>
      <data key="d1">concept</data>
      <data key="d2">The input variable x is the data fed into the neural network, used in the computation of the gradient for the hidden layer weight parameter.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002254</data>
      <data key="d6" />
    </node>
    <node id="Gradient Of Objective Function With Respect To Output">
      <data key="d0">Gradient Of Objective Function With Respect To Output</data>
      <data key="d1">concept</data>
      <data key="d2">The gradient ∂J/∂o in ℝ^q, calculated as part of the backpropagation chain rule, is equal to the gradient of the loss term ∂L/∂o.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002254</data>
      <data key="d6" />
    </node>
    <node id="Gradient Of Objective Function With Respect To Hidden Layer Variable">
      <data key="d0">Gradient Of Objective Function With Respect To Hidden Layer Variable</data>
      <data key="d1">concept</data>
      <data key="d2">The gradient ∂J/∂h in ℝ^h, computed during backpropagation as the product of the transposed output weight parameter and the gradient with respect to the output.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002254</data>
      <data key="d6" />
    </node>
    <node id="Gradient Of Objective Function With Respect To Intermediate Variable Z">
      <data key="d0">Gradient Of Objective Function With Respect To Intermediate Variable Z</data>
      <data key="d1">concept</data>
      <data key="d2">The gradient ∂J/∂z in ℝ^h, calculated using element-wise multiplication involving the gradient with respect to the hidden layer variable and the derivative of the activation function.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002255</data>
      <data key="d6" />
    </node>
    <node id="Gradient Of Objective Function With Respect To Output Layer Weight Parameter">
      <data key="d0">Gradient Of Objective Function With Respect To Output Layer Weight Parameter</data>
      <data key="d1">concept</data>
      <data key="d2">The gradient ∂J/∂W^(2) in ℝ^(q×h), computed via the chain rule as the sum of a product involving the output gradient and the hidden layer variable, plus a regularization term.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002255</data>
      <data key="d6" />
    </node>
    <node id="Gradient Of Objective Function With Respect To Hidden Layer Weight Parameter">
      <data key="d0">Gradient Of Objective Function With Respect To Hidden Layer Weight Parameter</data>
      <data key="d1">concept</data>
      <data key="d2">The gradient ∂J/∂W^(1) in ℝ^(h×d), computed via the chain rule as the sum of a product involving the gradient with respect to z and the input variable, plus a regularization term.</data>
      <data key="d3">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002256</data>
      <data key="d6" />
    </node>
    <node id="梯度计算">
      <data key="d0">梯度计算</data>
      <data key="d1">method</data>
      <data key="d2">梯度计算是反向传播过程中的核心步骤，用于计算损失函数相对于模型参数的偏导数。</data>
      <data key="d3">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002257</data>
      <data key="d6" />
    </node>
    <node id="参数梯度">
      <data key="d0">参数梯度</data>
      <data key="d1">concept</data>
      <data key="d2">参数梯度是损失函数相对于神经网络参数的偏导数，用于在优化过程中更新参数。</data>
      <data key="d3">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002257</data>
      <data key="d6" />
    </node>
    <node id="正向传播">
      <data key="d0">正向传播</data>
      <data key="d1">method</data>
      <data key="d2">正向传播是神经网络中从输入层到输出层计算并存储各层变量当前值的过程。&lt;SEP&gt;正向传播是神经网络中计算输出y=f(x)的过程，其导数用于后续的反向传播。</data>
      <data key="d3">chunk-29234d7a518b3ee30e3ee9cbc39d7e68&lt;SEP&gt;chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002358</data>
      <data key="d6" />
    </node>
    <node id="隐藏层变量">
      <data key="d0">隐藏层变量</data>
      <data key="d1">data</data>
      <data key="d2">隐藏层变量是神经网络正向传播过程中计算并存储的中间值，在反向传播中用于计算参数梯度。</data>
      <data key="d3">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002258</data>
      <data key="d6" />
    </node>
    <node id="损失函数">
      <data key="d0">损失函数</data>
      <data key="d1">concept</data>
      <data key="d2">损失函数是用于衡量模型预测与真实值之间差异的函数，其梯度用于参数更新。&lt;SEP&gt;损失函数用于衡量神经网络预测值与真实值之间的误差，文中以均方误差为例。&lt;SEP&gt;损失函数用于衡量神经网络模型的预测误差，是反向传播过程中计算梯度以更新权重的关键组成部分。&lt;SEP&gt;损失函数用于计算模型预测值与真实标签之间的差异。&lt;SEP&gt;损失函数用于衡量神经网络输出与真实值之间的差异，是反向传播算法中梯度计算的起点。&lt;SEP&gt;损失函数用于衡量神经网络输出与真实标签之间的差异，其值通过正向传播求得，并作为反向传播的起点。</data>
      <data key="d3">chunk-29234d7a518b3ee30e3ee9cbc39d7e68&lt;SEP&gt;chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-3a728b359622810cd77efd2985a7fcfd&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002641</data>
      <data key="d6" />
    </node>
    <node id="模型参数">
      <data key="d0">模型参数</data>
      <data key="d1">concept</data>
      <data key="d2">模型参数是神经网络中需要通过学习优化的权重，如W^(1)和W^(2)。</data>
      <data key="d3">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002258</data>
      <data key="d6" />
    </node>
    <node id="正则化项">
      <data key="d0">正则化项</data>
      <data key="d1">concept</data>
      <data key="d2">正则化项(如 λW)是添加到损失函数中用于防止过拟合的惩罚项。</data>
      <data key="d3">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002259</data>
      <data key="d6" />
    </node>
    <node id="训练样本">
      <data key="d0">训练样本</data>
      <data key="d1">data</data>
      <data key="d2">训练样本是用于训练神经网络的输入数据集合，其数量由N表示。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002320</data>
      <data key="d6" />
    </node>
    <node id="梯度下降法">
      <data key="d0">梯度下降法</data>
      <data key="d1">method</data>
      <data key="d2">Gradient Descent is an optimization method used in deep learning to minimize the error loss function by updating network parameters.&lt;SEP&gt;梯度下降法是一种通过计算损失函数梯度来迭代更新模型权重以最小化损失函数的优化算法。&lt;SEP&gt;梯度下降法是一种优化算法，利用反向传播计算得到的梯度来更新神经网络的参数，以使损失函数逐步减小。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-ecf37963c494ecfacb6a6432c237dd3b&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002642</data>
      <data key="d6" />
    </node>
    <node id="权重参数">
      <data key="d0">权重参数</data>
      <data key="d1">concept</data>
      <data key="d2">权重参数是神经网络中可调整的参数，其更新遵循梯度下降法的规则。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002322</data>
      <data key="d6" />
    </node>
    <node id="学习率">
      <data key="d0">学习率</data>
      <data key="d1">concept</data>
      <data key="d2">学习率是梯度下降法中的一个超参数，用于控制权重更新的步长，通常是一个介于0和1之间的小数。&lt;SEP&gt;学习率是优化器SGD的一个参数，在示例中被设置为0.1。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003339</data>
      <data key="d6" />
    </node>
    <node id="链式法则">
      <data key="d0">链式法则</data>
      <data key="d1">concept</data>
      <data key="d2">链式法则是微积分中的求导法则，在反向传播中用于计算复合函数(如损失函数)对中间变量的梯度。&lt;SEP&gt;链式法则是微积分中的求导法则，是反向传播算法梯度计算的核心数学基础。&lt;SEP&gt;链式法则是链式求导法则的另一种表述，在BP算法中用于分解和计算复合函数的导数。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002646</data>
      <data key="d6" />
    </node>
    <node id="激活函数">
      <data key="d0">激活函数</data>
      <data key="d1">concept</data>
      <data key="d2">The activation function, denoted as f, implements nonlinear transformations within neurons in a neural network.&lt;SEP&gt;激活函数是应用于神经元输入的数学函数，用于引入非线性，使神经网络能够学习复杂模式。&lt;SEP&gt;激活函数是神经网络中的非线性函数，用于决定神经元是否被激活，常见的例子包括tanh和softmax函数。&lt;SEP&gt;激活函数用于为神经网络引入非线性，文中提到sigmoid函数可能不适合多层网络。&lt;SEP&gt;激活函数是神经元中的非线性函数f(e)，用于引入非线性特性，将输入e转换为输出y。&lt;SEP&gt;激活函数如ReLU在卷积操作后应用，为网络引入非线性，使其能够学习复杂特征。&lt;SEP&gt;激活函数是神经网络中引入的非线性因素，卷积神经网络在卷积操作后也会加入激活函数以解决非线性问题。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-ecf37963c494ecfacb6a6432c237dd3b&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003342</data>
      <data key="d6" />
    </node>
    <node id="随机梯度下降法">
      <data key="d0">随机梯度下降法</data>
      <data key="d1">method</data>
      <data key="d2">随机梯度下降法是梯度下降法的一种变体，每次使用一个训练样本来更新模型权重。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002324</data>
      <data key="d6" />
    </node>
    <node id="批量梯度下降法">
      <data key="d0">批量梯度下降法</data>
      <data key="d1">method</data>
      <data key="d2">批量梯度下降法是梯度下降法的一种变体，使用所有训练样本计算总误差后再更新模型权重。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002324</data>
      <data key="d6" />
    </node>
    <node id="小批量梯度下降法">
      <data key="d0">小批量梯度下降法</data>
      <data key="d1">method</data>
      <data key="d2">小批量梯度下降法是梯度下降法的一种变体，每次使用一小批训练样本来更新模型权重。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002324</data>
      <data key="d6" />
    </node>
    <node id="非线性动力学">
      <data key="d0">非线性动力学</data>
      <data key="d1">concept</data>
      <data key="d2">非线性动力学是研究非线性系统行为特性的学科，文中类比了神经网络求导过程的非线性特性。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002324</data>
      <data key="d6" />
    </node>
    <node id="NONLINEAR DYNAMICS AND CHAOS with Applications to Physics, Biology, Chemistry, and Engineering (second edition)">
      <data key="d0">NONLINEAR DYNAMICS AND CHAOS with Applications to Physics, Biology, Chemistry, and Engineering (second edition)</data>
      <data key="d1">content</data>
      <data key="d2">这是一本关于非线性动力学与混沌及其在物理、生物、化学和工程中应用的学术著作的第二版。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002325</data>
      <data key="d6" />
    </node>
    <node id="CRC Press">
      <data key="d0">CRC Press</data>
      <data key="d1">organization</data>
      <data key="d2">CRC Press是一家位于美国佛罗里达州博卡拉顿的学术出版社。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002325</data>
      <data key="d6" />
    </node>
    <node id="盛昭瀚">
      <data key="d0">盛昭瀚</data>
      <data key="d1">person</data>
      <data key="d2">盛昭瀚是《非线性动力系统分析引论》一书的作者之一。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002325</data>
      <data key="d6" />
    </node>
    <node id="马军海">
      <data key="d0">马军海</data>
      <data key="d1">person</data>
      <data key="d2">马军海是《非线性动力系统分析引论》一书的作者之一。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002325</data>
      <data key="d6" />
    </node>
    <node id="非线性动力系统分析引论">
      <data key="d0">非线性动力系统分析引论</data>
      <data key="d1">content</data>
      <data key="d2">这是一本由盛昭瀚和马军海合著，科学出版社于2001年出版的关于非线性动力系统分析的书籍。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002326</data>
      <data key="d6" />
    </node>
    <node id="科学出版社">
      <data key="d0">科学出版社</data>
      <data key="d1">organization</data>
      <data key="d2">科学出版社是中国的一家学术出版机构。</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002326</data>
      <data key="d6" />
    </node>
    <node id="Boca Raton, FL">
      <data key="d0">Boca Raton, FL</data>
      <data key="d1">location</data>
      <data key="d2">Boca Raton is a city in Florida, USA, mentioned as the location of CRC Press.</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002326</data>
      <data key="d6" />
    </node>
    <node id="Doctor of Philosophy">
      <data key="d0">Doctor of Philosophy</data>
      <data key="d1">concept</data>
      <data key="d2">Doctor of Philosophy is the highest academic degree, mentioned as a reason for the connection between science and art.</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002326</data>
      <data key="d6" />
    </node>
    <node id="蝴蝶效应">
      <data key="d0">蝴蝶效应</data>
      <data key="d1">concept</data>
      <data key="d2">The Butterfly Effect is a concept from chaos theory describing how small initial changes can lead to large, long-term chain reactions in a dynamic system.</data>
      <data key="d3">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002327</data>
      <data key="d6" />
    </node>
    <node id="混沌理论">
      <data key="d0">混沌理论</data>
      <data key="d1">concept</data>
      <data key="d2">Chaos theory studies nonlinear dynamical systems that are sensitive to initial conditions, with phenomena like the butterfly effect.</data>
      <data key="d3">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002327</data>
      <data key="d6" />
    </node>
    <node id="非线性动力学系统">
      <data key="d0">非线性动力学系统</data>
      <data key="d1">concept</data>
      <data key="d2">Nonlinear Dynamical Systems are systems described by differential or difference equations, where complexity arises from nonlinearity and sensitivity to initial conditions.</data>
      <data key="d3">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002328</data>
      <data key="d6" />
    </node>
    <node id="Strogatz">
      <data key="d0">Strogatz</data>
      <data key="d1">person</data>
      <data key="d2">Strogatz is an internationally renowned nonlinear dynamicist and a member of the U.S. National Academy of Sciences.</data>
      <data key="d3">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002328</data>
      <data key="d6" />
    </node>
    <node id="三体问题">
      <data key="d0">三体问题</data>
      <data key="d1">concept</data>
      <data key="d2">The three-body problem is a classic problem in physics and dynamics that falls within the domain of three-dimensional nonlinear systems.</data>
      <data key="d3">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002329</data>
      <data key="d6" />
    </node>
    <node id="误差损失函数">
      <data key="d0">误差损失函数</data>
      <data key="d1">concept</data>
      <data key="d2">The error loss function quantifies the dissatisfaction with the network's output, such as the mean squared error between predicted and target values.</data>
      <data key="d3">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002329</data>
      <data key="d6" />
    </node>
    <node id="埃文">
      <data key="d0">埃文</data>
      <data key="d1">person</data>
      <data key="d2">Evan is the protagonist of a film who possesses the supernatural ability to travel back in time to rewrite his fate.</data>
      <data key="d3">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002329</data>
      <data key="d6" />
    </node>
    <node id="科学">
      <data key="d0">科学</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d2">博士学位被称为Doctor of Philosophy，体现了科学和艺术领域之间的深层逻辑联系。&lt;SEP&gt;Science, whose crisis understanding depends on a correct theory of the current social situation, as cited by Wang Tian from Horkheimer.</data>
      <data key="d1">concept</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011012</data>
      <data key="d6" />
    </node>
    <node id="艺术">
      <data key="d0">艺术</data>
      <data key="d3">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d2">博士学位被称为Doctor of Philosophy，体现了科学和艺术领域之间的深层逻辑联系。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002334</data>
      <data key="d6" />
    </node>
    <node id="信号E">
      <data key="d0">信号E</data>
      <data key="d1">data</data>
      <data key="d2">信号E是在反向传播计算过程中被乘以节点局部导数的信号。</data>
      <data key="d3">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002356</data>
      <data key="d6" />
    </node>
    <node id="局部导数">
      <data key="d0">局部导数</data>
      <data key="d1">concept</data>
      <data key="d2">局部导数是指在正向传播中函数y=f(x)的导数，即∂y/∂x，用于反向传播的计算。</data>
      <data key="d3">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002357</data>
      <data key="d6" />
    </node>
    <node id="∂y/∂x">
      <data key="d0">∂y/∂x</data>
      <data key="d1">concept</data>
      <data key="d2">∂y/∂x是函数y=f(x)的导数符号表示，是计算局部导数的具体数学形式。</data>
      <data key="d3">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002358</data>
      <data key="d6" />
    </node>
    <node id="y=f(x)">
      <data key="d0">y=f(x)</data>
      <data key="d1">concept</data>
      <data key="d2">y=f(x)是正向传播中节点执行的函数，其输出为y，输入为x。</data>
      <data key="d3">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002358</data>
      <data key="d6" />
    </node>
    <node id="AI开发生命周期">
      <data key="d0">AI开发生命周期</data>
      <data key="d1">concept</data>
      <data key="d2">The AI development lifecycle encompasses all stages from training to deployment, accessible through a unified platform.</data>
      <data key="d3">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002448</data>
      <data key="d6" />
    </node>
    <node id="工作流程">
      <data key="d0">工作流程</data>
      <data key="d1">concept</data>
      <data key="d2">Workflows are key business processes that can be reshaped by increasing the use of AI to maximize experience, real-time decision-making, and commercial value.</data>
      <data key="d3">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002449</data>
      <data key="d6" />
    </node>
    <node id="运营">
      <data key="d0">运营</data>
      <data key="d1">concept</data>
      <data key="d2">Operations are business functions that can be transformed through AI to enhance decision-making and value.&lt;SEP&gt;Operations refer to the day-to-day activities and processes within an organization that can be optimized using AI.</data>
      <data key="d3">chunk-0e8d4ef62e491849bee6335c81b740ee&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003180</data>
      <data key="d6" />
    </node>
    <node id="用户友好型界面">
      <data key="d0">用户友好型界面</data>
      <data key="d1">artifact</data>
      <data key="d2">User-friendly interfaces are part of the platform that facilitates the creation of powerful AI solutions.</data>
      <data key="d3">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002450</data>
      <data key="d6" />
    </node>
    <node id="行业标准API">
      <data key="d0">行业标准API</data>
      <data key="d1">artifact</data>
      <data key="d2">Industry-standard APIs are accessible tools on the platform for building AI solutions.</data>
      <data key="d3">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002450</data>
      <data key="d6" />
    </node>
    <node id="SDK">
      <data key="d0">SDK</data>
      <data key="d1">artifact</data>
      <data key="d2">SDKs are accessible tools on the platform for building AI solutions.</data>
      <data key="d3">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002451</data>
      <data key="d6" />
    </node>
    <node id="梯度下降算法">
      <data key="d0">梯度下降算法</data>
      <data key="d1">method</data>
      <data key="d2">梯度下降算法是一种优化算法，用于在反向传播过程中根据计算出的梯度调整神经网络的权重和偏差。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002451</data>
      <data key="d6" />
    </node>
    <node id="多层感知器">
      <data key="d0">多层感知器</data>
      <data key="d1">concept</data>
      <data key="d2">多层感知器是一种基本的前馈人工神经网络，包含输入层、一个或多个隐藏层和输出层，是深度学习的基础架构之一。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002454</data>
      <data key="d6" />
    </node>
    <node id="双曲正切函数">
      <data key="d0">双曲正切函数</data>
      <data key="d1">method</data>
      <data key="d2">双曲正切(tanh)函数是一种激活函数，可将输入值映射到介于-1和1之间的范围，常用于神经网络的隐藏层。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002454</data>
      <data key="d6" />
    </node>
    <node id="Softmax函数">
      <data key="d0">Softmax函数</data>
      <data key="d1">method</data>
      <data key="d2">Softmax函数是一种激活函数，将输入向量转换为概率分布，其元素值在0到1之间且总和为1，常用于神经网络的输出层。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002455</data>
      <data key="d6" />
    </node>
    <node id="隐藏层">
      <data key="d0">隐藏层</data>
      <data key="d1">concept</data>
      <data key="d2">隐藏层是神经网络中位于输入层和输出层之间的中间层，负责逐步提取和转换输入数据的关键特征。&lt;SEP&gt;隐藏层是多层感知机网络结构中的一层。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003561</data>
      <data key="d6" />
    </node>
    <node id="神经网络与深度学习">
      <data key="d0">神经网络与深度学习</data>
      <data key="d1">content</data>
      <data key="d2">《神经网络与深度学习》是Michael Nielsen撰写的一本在线教科书，其中讨论了反向传播算法的效率。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002457</data>
      <data key="d6" />
    </node>
    <node id="Think Newsletter">
      <data key="d0">Think Newsletter</data>
      <data key="d1">content</data>
      <data key="d2">The Think Newsletter is a weekly publication by IBM that provides curated insights on important and interesting AI news.&lt;SEP&gt;A weekly newsletter offering curated insights and analysis on the most important and interesting AI news.&lt;SEP&gt;Think Newsletter provides insights on important and interesting industry trends in AI, automation, data, and other areas.</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005496</data>
      <data key="d6" />
    </node>
    <node id="偏置项">
      <data key="d0">偏置项</data>
      <data key="d1">concept</data>
      <data key="d2">偏置项是神经网络神经元中的一个可调参数，与加权输入相加，用于调整神经元的激活阈值。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002459</data>
      <data key="d6" />
    </node>
    <node id="权重">
      <data key="d0">权重</data>
      <data key="d1">concept</data>
      <data key="d2">权重是神经网络中连接两个神经元的参数，决定了输入信号对下游神经元激活的贡献强度。&lt;SEP&gt;权重是神经网络中连接不同神经元之间的参数，其梯度在反向传播算法中通过公式3计算。&lt;SEP&gt;权重是神经网络中可调整的参数，在反向传播过程中根据误差信号进行修正。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002645</data>
      <data key="d6" />
    </node>
    <node id="输入节点">
      <data key="d0">输入节点</data>
      <data key="d1">concept</data>
      <data key="d2">输入节点是神经网络输入层中的单元，负责接收原始数据并将其传递给下一层。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002459</data>
      <data key="d6" />
    </node>
    <node id="隐藏单元">
      <data key="d0">隐藏单元</data>
      <data key="d1">concept</data>
      <data key="d2">隐藏单元是神经网络隐藏层中的神经元，对来自前一层的输入进行加权求和并应用激活函数，将结果传递给下一层。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002460</data>
      <data key="d6" />
    </node>
    <node id="成本函数">
      <data key="d0">成本函数</data>
      <data key="d1">concept</data>
      <data key="d2">成本函数是损失函数的同义词，在某些上下文中用于指代衡量模型预测总体误差的函数。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002460</data>
      <data key="d6" />
    </node>
    <node id="误差函数">
      <data key="d0">误差函数</data>
      <data key="d1">concept</data>
      <data key="d2">误差函数是损失函数的同义词，在某些上下文中用于指代衡量模型预测错误的函数。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002461</data>
      <data key="d6" />
    </node>
    <node id="偏导数">
      <data key="d0">偏导数</data>
      <data key="d1">concept</data>
      <data key="d2">偏导数在反向传播中用于计算损失函数相对于特定权重或参数的变化率，以指导权重更新。</data>
      <data key="d3">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002461</data>
      <data key="d6" />
    </node>
    <node id="Partial W^{(1)}">
      <data key="d0">Partial W^{(1)}</data>
      <data key="d1">concept</data>
      <data key="d2">Partial W^{(1)} is a partial derivative with respect to the first weight matrix in a neural network, involved in gradient calculations during backpropagation.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002530</data>
      <data key="d6" />
    </node>
    <node id="Partial J/Partial W^{(2)}">
      <data key="d0">Partial J/Partial W^{(2)}</data>
      <data key="d1">concept</data>
      <data key="d2">Partial J/Partial W^{(2)} is the partial derivative of the objective function J with respect to the second weight matrix, a target gradient in backpropagation.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002530</data>
      <data key="d6" />
    </node>
    <node id="Objective Function J">
      <data key="d0">Objective Function J</data>
      <data key="d1">concept</data>
      <data key="d2">The objective function J is the sum of a loss term L and a regularization term s, which is the target for optimization.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002531</data>
      <data key="d6" />
    </node>
    <node id="Regularization Term s">
      <data key="d0">Regularization Term s</data>
      <data key="d1">concept</data>
      <data key="d2">The regularization term s is a component of the objective function J, typically involving a penalty on model parameters like W^{(1)} and W^{(2)} to prevent overfitting.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002532</data>
      <data key="d6" />
    </node>
    <node id="Gradient">
      <data key="d0">Gradient</data>
      <data key="d1">concept</data>
      <data key="d2">A gradient represents the partial derivative of a function with respect to its parameters, indicating the direction of steepest ascent.&lt;SEP&gt;Gradient refers to the derivative of a function, crucial for optimization algorithms like backpropagation in neural networks.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe&lt;SEP&gt;chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003606</data>
      <data key="d6" />
    </node>
    <node id="Parameter W^{(1)}">
      <data key="d0">Parameter W^{(1)}</data>
      <data key="d1">concept</data>
      <data key="d2">Parameter W^{(1)} is the first weight matrix in a neural network, whose gradient is calculated during backpropagation and is part of the regularization term.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002533</data>
      <data key="d6" />
    </node>
    <node id="Parameter W^{(2)}">
      <data key="d0">Parameter W^{(2)}</data>
      <data key="d1">concept</data>
      <data key="d2">Parameter W^{(2)} is the second weight matrix in a neural network, closest to the output layer, whose gradient is a key target in the backpropagation calculation.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002541</data>
      <data key="d6" />
    </node>
    <node id="Hidden Variable h">
      <data key="d0">Hidden Variable h</data>
      <data key="d1">concept</data>
      <data key="d2">The hidden variable h is an intermediate value computed during forward propagation, and its current value is used in gradient calculations during backpropagation.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002541</data>
      <data key="d6" />
    </node>
    <node id="Optimization Algorithm">
      <data key="d0">Optimization Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">An optimization algorithm updates model parameters like W^{(1)} and W^{(2)} based on gradients computed from recent iterations of backpropagation.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002534</data>
      <data key="d6" />
    </node>
    <node id="Scalar Function f">
      <data key="d0">Scalar Function f</data>
      <data key="d1">concept</data>
      <data key="d2">A scalar function f takes an n x m matrix X as input, and the dimensionality of its gradient with respect to X is a question posed in the text.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002534</data>
      <data key="d6" />
    </node>
    <node id="Matrix X">
      <data key="d0">Matrix X</data>
      <data key="d1">data</data>
      <data key="d2">Matrix X is an n x m matrix serving as the input to a scalar function f, used in an example question about gradient dimensionality.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002535</data>
      <data key="d6" />
    </node>
    <node id="Partial J/Partial L">
      <data key="d0">Partial J/Partial L</data>
      <data key="d1">concept</data>
      <data key="d2">Partial J/Partial L is the partial derivative of the objective function J with respect to the loss term L, which equals 1 according to the text.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002535</data>
      <data key="d6" />
    </node>
    <node id="Partial J/Partial s">
      <data key="d0">Partial J/Partial s</data>
      <data key="d1">concept</data>
      <data key="d2">Partial J/Partial s is the partial derivative of the objective function J with respect to the regularization term s, which equals 1 according to the text.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002535</data>
      <data key="d6" />
    </node>
    <node id="Partial s/Partial W^{(1)}">
      <data key="d0">Partial s/Partial W^{(1)}</data>
      <data key="d1">concept</data>
      <data key="d2">Partial s/Partial W^{(1)} is the partial derivative of the regularization term s with respect to the first weight matrix, given as λW^{(1)}.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002535</data>
      <data key="d6" />
    </node>
    <node id="Partial s/Partial W^{(2)}">
      <data key="d0">Partial s/Partial W^{(2)}</data>
      <data key="d1">concept</data>
      <data key="d2">Partial s/Partial W^{(2)} is the partial derivative of the regularization term s with respect to the second weight matrix, given as λW^{(2)}.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002535</data>
      <data key="d6" />
    </node>
    <node id="Computational Graph">
      <data key="d0">Computational Graph</data>
      <data key="d1">concept</data>
      <data key="d2">A computational graph represents the sequence of operations in a model, from which gradients are calculated starting from the result.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002536</data>
      <data key="d6" />
    </node>
    <node id="Regularization Parameter λ">
      <data key="d0">Regularization Parameter λ</data>
      <data key="d1">concept</data>
      <data key="d2">The regularization parameter λ is a coefficient used in the calculation of the partial derivatives of the regularization term s with respect to the weight matrices.</data>
      <data key="d3">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002537</data>
      <data key="d6" />
    </node>
    <node id="前向传播">
      <data key="d0">前向传播</data>
      <data key="d1">method</data>
      <data key="d2">前向传播指的是按顺序从输入层到输出层计算和存储神经网络中每层结果的过程。&lt;SEP&gt;前向传播是神经网络中的计算过程，输入数据通过网络层逐层传递，最终产生输出。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002638</data>
      <data key="d6" />
    </node>
    <node id="计算图">
      <data key="d0">计算图</data>
      <data key="d1">concept</data>
      <data key="d2">计算图是一种用于可视化计算中操作符和变量依赖关系的图形表示。&lt;SEP&gt;计算图是深度学习中的一种数据结构，用于表示计算过程，是执行前向传播和反向传播算法的框架。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002638</data>
      <data key="d6" />
    </node>
    <node id="小批量随机梯度下降">
      <data key="d0">小批量随机梯度下降</data>
      <data key="d1">method</data>
      <data key="d2">小批量随机梯度下降是一种用于训练模型的优化算法。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002538</data>
      <data key="d6" />
    </node>
    <node id="自动微分">
      <data key="d0">自动微分</data>
      <data key="d1">method</data>
      <data key="d2">自动微分是一种自动计算梯度的技术，简化了深度学习算法的实现。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002539</data>
      <data key="d6" />
    </node>
    <node id="权重衰减">
      <data key="d0">权重衰减</data>
      <data key="d1">concept</data>
      <data key="d2">权重衰减，也称为L2正则化，是一种通过在损失函数中添加惩罚项来防止模型过拟合的技术。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002539</data>
      <data key="d6" />
    </node>
    <node id="单隐藏层多层感知机">
      <data key="d0">单隐藏层多层感知机</data>
      <data key="d1">concept</data>
      <data key="d2">单隐藏层多层感知机是一种具有一个隐藏层的神经网络架构。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002539</data>
      <data key="d6" />
    </node>
    <node id="隐藏变量">
      <data key="d0">隐藏变量</data>
      <data key="d1">concept</data>
      <data key="d2">隐藏变量是神经网络隐藏层产生的中间变量。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002540</data>
      <data key="d6" />
    </node>
    <node id="输出层变量">
      <data key="d0">输出层变量</data>
      <data key="d1">concept</data>
      <data key="d2">输出层变量是神经网络输出层产生的向量。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002540</data>
      <data key="d6" />
    </node>
    <node id="L2正则化">
      <data key="d0">L2正则化</data>
      <data key="d1">concept</data>
      <data key="d2">L2正则化是一种通过添加权重平方和作为惩罚项的正则化方法。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002540</data>
      <data key="d6" />
    </node>
    <node id="目标函数">
      <data key="d0">目标函数</data>
      <data key="d1">concept</data>
      <data key="d2">目标函数是模型优化过程中需要最小化的函数，通常包括损失项和正则化项。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002540</data>
      <data key="d6" />
    </node>
    <node id="链式规则">
      <data key="d0">链式规则</data>
      <data key="d1">concept</data>
      <data key="d2">链式规则是微积分中用于计算复合函数导数的法则，是反向传播的基础。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002541</data>
      <data key="d6" />
    </node>
    <node id="Frobenius范数">
      <data key="d0">Frobenius范数</data>
      <data key="d1">concept</data>
      <data key="d2">Frobenius范数是矩阵的一种范数，计算方式是将矩阵展平为向量后应用L2范数。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002541</data>
      <data key="d6" />
    </node>
    <node id="参数">
      <data key="d0">参数</data>
      <data key="d1">concept</data>
      <data key="d2">参数是神经网络中需要通过学习进行调整的变量，如权重矩阵。&lt;SEP&gt;Parameters, in the context of LLMs and Transformers, refer to the millions or billions of adjustable elements that enable the model to learn complex patterns.</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008986</data>
      <data key="d6" />
    </node>
    <node id="权重矩阵">
      <data key="d0">权重矩阵</data>
      <data key="d1">concept</data>
      <data key="d2">权重矩阵是神经网络层之间的连接权重参数，如W^(1)和W^(2)。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002542</data>
      <data key="d6" />
    </node>
    <node id="样本标签">
      <data key="d0">样本标签</data>
      <data key="d1">data</data>
      <data key="d2">样本标签是训练数据中每个样本对应的真实值或类别。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002543</data>
      <data key="d6" />
    </node>
    <node id="正则化损失">
      <data key="d0">正则化损失</data>
      <data key="d1">concept</data>
      <data key="d2">正则化损失是目标函数的一部分，由原始损失和正则化惩罚项相加构成。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002543</data>
      <data key="d6" />
    </node>
    <node id="操作符">
      <data key="d0">操作符</data>
      <data key="d1">concept</data>
      <data key="d2">操作符是计算图中表示数学运算的节点，如加法、乘法。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002543</data>
      <data key="d6" />
    </node>
    <node id="张量">
      <data key="d0">张量</data>
      <data key="d1">concept</data>
      <data key="d2">张量是多维数组，是深度学习框架中表示数据的基本单位。</data>
      <data key="d3">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002543</data>
      <data key="d6" />
    </node>
    <node id="BP算法">
      <data key="d0">BP算法</data>
      <data key="d1">method</data>
      <data key="d2">BP算法是一种用于训练神经网络的算法，主要用于通过链式求导法则计算网络中每个参数对于损失函数的梯度，从而通过梯度下降法更新网络参数。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002636</data>
      <data key="d6" />
    </node>
    <node id="链式求导法则">
      <data key="d0">链式求导法则</data>
      <data key="d1">method</data>
      <data key="d2">链式求导法则是微积分中的一种求导方法，在BP算法的推导中被用于计算误差对网络权重的导数。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002637</data>
      <data key="d6" />
    </node>
    <node id="输入值">
      <data key="d0">输入值</data>
      <data key="d1">data</data>
      <data key="d2">输入值是传递给神经网络的原始数据或特征。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002639</data>
      <data key="d6" />
    </node>
    <node id="权重系数">
      <data key="d0">权重系数</data>
      <data key="d1">data</data>
      <data key="d2">权重系数是神经网络中连接不同神经元的参数，其值在训练过程中通过反向传播进行修正。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002639</data>
      <data key="d6" />
    </node>
    <node id="Hadamard乘积">
      <data key="d0">Hadamard乘积</data>
      <data key="d1">method</data>
      <data key="d2">Hadamard乘积是矩阵或向量之间点对点的乘法运算，在反向传播算法的公式1中用于计算错误。&lt;SEP&gt;Hadamard乘积是矩阵或向量之间点对点的乘法运算，在反向传播的公式推导中被使用。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002642</data>
      <data key="d6" />
    </node>
    <node id="博主">
      <data key="d0">博主</data>
      <data key="d1">person</data>
      <data key="d2">博主是发布该篇关于BP算法博客文章的作者，拥有文章的原创版权。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002643</data>
      <data key="d6" />
    </node>
    <node id="CC 4.0 BY-SA版权协议">
      <data key="d0">CC 4.0 BY-SA版权协议</data>
      <data key="d1">content</data>
      <data key="d2">CC 4.0 BY-SA版权协议是本文遵循的版权许可协议，允许在署名和相同方式共享的条件下传播。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002643</data>
      <data key="d6" />
    </node>
    <node id="国外某网站">
      <data key="d0">国外某网站</data>
      <data key="d1">organization</data>
      <data key="d2">国外某网站是提供第一组生动形象图解以讲解神经网络前向传播和反向传播算法的来源。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002644</data>
      <data key="d6" />
    </node>
    <node id="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html">
      <data key="d0">http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html</data>
      <data key="d1">content</data>
      <data key="d2">这是一个外部网页链接，提供了关于反向传播算法的参考资料。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002644</data>
      <data key="d6" />
    </node>
    <node id="https://www.cnblogs.com/charlotte77/p/5629865.html">
      <data key="d0">https://www.cnblogs.com/charlotte77/p/5629865.html</data>
      <data key="d1">content</data>
      <data key="d2">这是一个外部网页链接，提供了关于反向传播算法的参考资料。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002644</data>
      <data key="d6" />
    </node>
    <node id="公式1">
      <data key="d0">公式1</data>
      <data key="d1">content</data>
      <data key="d2">公式1用于计算最后一层神经网络产生的错误，其中使用了Hadamard乘积。&lt;SEP&gt;公式1是用于计算最后一层神经网络产生的错误的数学表达式，涉及Hadamard乘积。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002644</data>
      <data key="d6" />
    </node>
    <node id="公式2">
      <data key="d0">公式2</data>
      <data key="d1">content</data>
      <data key="d2">公式2用于由后往前计算每一层神经网络产生的错误。&lt;SEP&gt;公式2是用于由后往前计算每一层神经网络产生的错误的数学表达式。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002645</data>
      <data key="d6" />
    </node>
    <node id="导数">
      <data key="d0">导数</data>
      <data key="d1">concept</data>
      <data key="d2">导数在反向传播中指的是误差相对于权重等参数的偏导数，用于指导权重的更新。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002645</data>
      <data key="d6" />
    </node>
    <node id="out o1">
      <data key="d0">out o1</data>
      <data key="d1">data</data>
      <data key="d2">out o1是神经网络中某个神经元的输出值，在计算误差E对w5的导数时作为中间变量。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002646</data>
      <data key="d6" />
    </node>
    <node id="net o1">
      <data key="d0">net o1</data>
      <data key="d1">data</data>
      <data key="d2">net o1是神经网络中某个神经元的净输入(加权和)，在计算误差E对w5的导数时作为中间变量。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002647</data>
      <data key="d6" />
    </node>
    <node id="w5">
      <data key="d0">w5</data>
      <data key="d1">data</data>
      <data key="d2">w5是神经网络中的一个具体权重参数，在示例中被用于演示如何通过链式求导计算误差E对其的导数。</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002647</data>
      <data key="d6" />
    </node>
    <node id="AI大模型">
      <data key="d0">AI大模型</data>
      <data key="d1">concept</data>
      <data key="d2">AI大模型是人工智能领域的一种核心技术，其知识和技能的重要性日益凸显。&lt;SEP&gt;AI大模型是人工智能领域的重要技术突破，需要系统学习，文中提及了相关的学习资源。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002648</data>
      <data key="d6" />
    </node>
    <node id="AI大模型学习资源">
      <data key="d0">AI大模型学习资源</data>
      <data key="d1">content</data>
      <data key="d2">AI大模型学习资源是一套全面的学习材料，包括学习路线图、书籍手册、视频教程、实战学习和面试题，旨在帮助学习者系统掌握AI大模型。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002648</data>
      <data key="d6" />
    </node>
    <node id="AI大模型全套学习路线图">
      <data key="d0">AI大模型全套学习路线图</data>
      <data key="d1">content</data>
      <data key="d2">AI大模型全套学习路线图是一份从入门到实战的系统性学习路径规划。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002649</data>
      <data key="d6" />
    </node>
    <node id="精品AI大模型学习书籍手册">
      <data key="d0">精品AI大模型学习书籍手册</data>
      <data key="d1">content</data>
      <data key="d2">精品AI大模型学习书籍手册是高质量的学习书籍和手册。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002649</data>
      <data key="d6" />
    </node>
    <node id="视频教程">
      <data key="d0">视频教程</data>
      <data key="d1">content</data>
      <data key="d2">视频教程是用于学习AI大模型的教学视频。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002649</data>
      <data key="d6" />
    </node>
    <node id="实战学习">
      <data key="d0">实战学习</data>
      <data key="d1">method</data>
      <data key="d2">实战学习是通过实践项目来掌握AI大模型技术的方法。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002650</data>
      <data key="d6" />
    </node>
    <node id="面试题">
      <data key="d0">面试题</data>
      <data key="d1">content</data>
      <data key="d2">面试题是用于评估AI大模型知识和技能的题目。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002650</data>
      <data key="d6" />
    </node>
    <node id="学习AI大模型">
      <data key="d0">学习AI大模型</data>
      <data key="d1">process</data>
      <data key="d2">学习AI大模型是一个从基础开始，逐步深入的系统性过程。</data>
      <data key="d3">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002650</data>
      <data key="d6" />
    </node>
    <node id="反向传播算法">
      <data key="d0">反向传播算法</data>
      <data key="d1">method</data>
      <data key="d2">反向传播算法是一种用于训练人工神经网络的算法，通过计算损失函数对网络参数的梯度来优化网络权重。&lt;SEP&gt;Backpropagation algorithm is a training method used to train Convolutional Neural Networks and other deep learning structures by adjusting weights based on error.&lt;SEP&gt;反向传播算法是一种训练神经网络的算法，在1980年代推动了多层感知机的重大进展。&lt;SEP&gt;Also known as the Back-propagation (BP) algorithm, it is a method for training artificial neural networks. Geoffrey Hinton and his peers promoted its widespread application.</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-93860b80c6ea559ea9b38a8562c8df8c&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003866</data>
      <data key="d6" />
    </node>
    <node id="前向传播算法">
      <data key="d0">前向传播算法</data>
      <data key="d1">method</data>
      <data key="d2">前向传播算法是神经网络中用于从输入层到输出层计算网络输出的过程。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002650</data>
      <data key="d6" />
    </node>
    <node id="偏置">
      <data key="d0">偏置</data>
      <data key="d1">concept</data>
      <data key="d2">偏置是神经网络中神经元的附加参数，其梯度在反向传播算法中通过公式4计算。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002651</data>
      <data key="d6" />
    </node>
    <node id="Sigmoid函数">
      <data key="d0">Sigmoid函数</data>
      <data key="d1">method</data>
      <data key="d2">Sigmoid函数是一种激活函数，在示例的前向传播过程中用于计算神经元的输出。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002651</data>
      <data key="d6" />
    </node>
    <node id="卷积神经网络">
      <data key="d0">卷积神经网络</data>
      <data key="d1">method</data>
      <data key="d2">卷积神经网络（Convolutional Neural Network，CNN）是一种深度学习模型，属于前馈神经网络的一种代表性架构。其设计灵感源于生物视觉系统，旨在模仿生物神经网络的行为特征，特别是受到视觉皮层结构的启发。该网络专门用于处理具有网格结构的数据，如图像，通过利用数据（如图像像素、音频信号、时间序列）间的空间或局部关联性进行高效学习和模式识别。

卷积神经网络的核心架构包含卷积层、池化层和全连接层。卷积层通过卷积运算从输入数据中自动提取局部特征，这是其命名的由来，并赋予了网络强大的特征提取能力，能够直接从原始数据中学习高级、抽象的特征。池化层则用于降低数据的空间维度，增强模型的鲁棒性。最后，全连接层通常负责执行分类或回归等任务。整个网络的训练过程涉及基于反向传播算法的梯度计算。

除了在图像识别、对象检测和计算机视觉领域表现出色外，卷积神经网络也被广泛应用于自然语言处理、音频处理、信号处理以及序列数据编码等其他任务。它因其能够有效捕捉数据中的空间或局部依赖关系，而成为深度学习中的核心模型之一。该模型由Yann LeCun等人发明，并曾成功应用于高效的手写数字识别等任务。&lt;SEP&gt;卷积神经网络是一种深度学习模型，应用于医学影像识别等领域。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2&lt;SEP&gt;chunk-d22adf07bd762e4e32d9bceea2fa6218&lt;SEP&gt;chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-c79065b95e8586e85c1d4a6dfcdb5d37&lt;SEP&gt;chunk-c79b805e7da972f5a80b0f9eb1144d75&lt;SEP&gt;chunk-225c135f952fba89e32fc67dcf80d0f5&lt;SEP&gt;chunk-df57bc33c49fe522c66616c1a4be5336&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922&lt;SEP&gt;chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008467</data>
      <data key="d6" />
    </node>
    <node id="梯度下降">
      <data key="d0">梯度下降</data>
      <data key="d1">method</data>
      <data key="d2">梯度下降是一种优化算法，利用反向传播计算出的梯度来更新网络参数。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002652</data>
      <data key="d6" />
    </node>
    <node id="Adam优化器">
      <data key="d0">Adam优化器</data>
      <data key="d1">method</data>
      <data key="d2">Adam是一种更复杂的优化器，在梯度下降的基础上引入了动量和自适应学习率等机制。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002653</data>
      <data key="d6" />
    </node>
    <node id="公式3">
      <data key="d0">公式3</data>
      <data key="d1">content</data>
      <data key="d2">公式3用于计算权重的梯度。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002653</data>
      <data key="d6" />
    </node>
    <node id="公式4">
      <data key="d0">公式4</data>
      <data key="d1">content</data>
      <data key="d2">公式4用于计算偏置的梯度。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002653</data>
      <data key="d6" />
    </node>
    <node id="Proof of Back Propagation Algorithm.pdf">
      <data key="d0">Proof of Back Propagation Algorithm.pdf</data>
      <data key="d1">artifact</data>
      <data key="d2">Proof of Back Propagation Algorithm.pdf是一份关于反向传播算法证明的文档。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002653</data>
      <data key="d6" />
    </node>
    <node id="陈唯源">
      <data key="d0">陈唯源</data>
      <data key="d1">person</data>
      <data key="d2">陈唯源是《反向传播的工作过程以及公式推导》一文的作者。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002654</data>
      <data key="d6" />
    </node>
    <node id="机器学习算法与自然语言处理公众号">
      <data key="d0">机器学习算法与自然语言处理公众号</data>
      <data key="d1">organization</data>
      <data key="d2">机器学习算法与自然语言处理公众号是一个发布机器学习相关内容的媒体平台。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002654</data>
      <data key="d6" />
    </node>
    <node id="CSDN">
      <data key="d0">CSDN</data>
      <data key="d1">organization</data>
      <data key="d2">CSDN是一个技术社区，文中提到了其平台上关于反向传播算法公式推导的内容。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002654</data>
      <data key="d6" />
    </node>
    <node id="知乎">
      <data key="d0">知乎</data>
      <data key="d1">organization</data>
      <data key="d2">知乎是一个知识分享平台，文中引用了来自知乎作者陈楠的整理内容。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002654</data>
      <data key="d6" />
    </node>
    <node id="陈楠">
      <data key="d0">陈楠</data>
      <data key="d1">person</data>
      <data key="d2">陈楠是知乎上《反向传播算法的直观理解》一文的作者。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002654</data>
      <data key="d6" />
    </node>
    <node id="RNN">
      <data key="d0">RNN</data>
      <data key="d1">concept</data>
      <data key="d2">RNN(循环神经网络)是一种神经网络结构，文中提到了其反向传播公式的推导。&lt;SEP&gt;RNN is an abbreviation for Recurrent Neural Network, a type of neural network used in deep learning for encoding sequences.&lt;SEP&gt;Recurrent Neural Network (RNN) is a type of deep learning model used for processing sequential data.&lt;SEP&gt;RNN is a type of neural network that is good at remembering recent information, as mentioned in contrast to LSTM.&lt;SEP&gt;一种用于处理序列依赖或长时间依赖特征的神经网络模型。&lt;SEP&gt;循环神经网络是一种用于处理序列数据的神经网络，能够捕捉时间序列中的动态temporal behavior。&lt;SEP&gt;Recurrent Neural Network, a previous neural network architecture for sequential data, outperformed by transformer models.</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2&lt;SEP&gt;chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8&lt;SEP&gt;chunk-82bdb1406dfe17a400fa95a5a4727859&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008147</data>
      <data key="d6" />
    </node>
    <node id="CNN">
      <data key="d0">CNN</data>
      <data key="d1">concept</data>
      <data key="d2">CNN（卷积神经网络，Convolutional Neural Network）是一种深度学习模型，属于深度神经网络的一个类别。它主要设计用于处理具有网格状拓扑结构的数据，如图像。其核心结构包含卷积层、池化层等，能够自动从数据中学习并提取局部特征。在计算机视觉领域，CNN是图像识别和处理的基础模型。此外，它也被应用于自然语言处理等任务中，用于提取文本的局部特征，或处理类似图像的序列数据（如金融交易中的K线图），以捕捉技术模式。

值得注意的是，存在一个与上述技术实体同名的媒体实体“CNN”。该实体是一家新闻机构，曾于2021年11月9日发表一篇题为“Zillow’s home-buying debacle shows how hard it is to use AI to value real estate”的文章。此外，在金融领域，“CNN”也可能作为一种高频交易策略的计算模型基础被提及。这些描述指向了与“卷积神经网络”完全不同的实体。</data>
      <data key="d3">chunk-95faa80d73b4394851b10e9cc65232d2&lt;SEP&gt;chunk-d22adf07bd762e4e32d9bceea2fa6218&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-225c135f952fba89e32fc67dcf80d0f5&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-df57bc33c49fe522c66616c1a4be5336&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922&lt;SEP&gt;chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8&lt;SEP&gt;chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3&lt;SEP&gt;chunk-82bdb1406dfe17a400fa95a5a4727859&lt;SEP&gt;chunk-2103a1c2471cc6226897b2080204b309&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-330f64bec90f2f131895d2de62adeb6f&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008165</data>
      <data key="d6" />
    </node>
    <node id="第一组图">
      <data key="d0">第一组图</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d2">国外某网站提供了用于讲解神经网络前向传播和反向传播算法的第一组生动形象的图解。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002658</data>
      <data key="d6" />
    </node>
    <node id="误差E">
      <data key="d0">误差E</data>
      <data key="d3">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d2">在具体计算举例中，通过链式求导过程计算了误差E对权重w5的导数(偏导)。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002666</data>
      <data key="d6" />
    </node>
    <node id="Hidden Layer">
      <data key="d0">Hidden Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A layer in a neural network that processes inputs from the previous layer and passes outputs to the next layer.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002712</data>
      <data key="d6" />
    </node>
    <node id="Weight Coefficient">
      <data key="d0">Weight Coefficient</data>
      <data key="d1">concept</data>
      <data key="d2">A numerical parameter in a neural network that is adjusted during training to minimize error.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002712</data>
      <data key="d6" />
    </node>
    <node id="Neuron">
      <data key="d0">Neuron</data>
      <data key="d1">concept</data>
      <data key="d2">A basic computational unit in a neural network that receives inputs, processes them, and produces an output.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002712</data>
      <data key="d6" />
    </node>
    <node id="Error">
      <data key="d0">Error</data>
      <data key="d1">concept</data>
      <data key="d2">The difference between the predicted output and the target output in a neural network.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002713</data>
      <data key="d6" />
    </node>
    <node id="Training Set">
      <data key="d0">Training Set</data>
      <data key="d1">data</data>
      <data key="d2">A collection of input-output pairs used to train a neural network.&lt;SEP&gt;A subset of the dataset, constituting 80% (2,330,617 observations) of the total data, used to train the machine learning model.&lt;SEP&gt;A training set comprising 75% of the data was used to train the Deep Auto-Encoder model in Experiment Two.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070&lt;SEP&gt;chunk-dd790e22e66ff566c3fcba5e9ed475b3&lt;SEP&gt;chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006127</data>
      <data key="d6" />
    </node>
    <node id="Feed Forward">
      <data key="d0">Feed Forward</data>
      <data key="d1">method</data>
      <data key="d2">A process in a neural network where inputs are passed through layers to produce an output.&lt;SEP&gt;Feed Forward is a fully connected neural network layer applied position-wise within each Transformer block after the attention mechanism.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070&lt;SEP&gt;chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007661</data>
      <data key="d6" />
    </node>
    <node id="Output Layer">
      <data key="d0">Output Layer</data>
      <data key="d1">concept</data>
      <data key="d2">The final layer in a neural network that produces the network's output.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002713</data>
      <data key="d6" />
    </node>
    <node id="Neuron Layer">
      <data key="d0">Neuron Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A group of neurons in a neural network that operate at the same level.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002713</data>
      <data key="d6" />
    </node>
    <node id="Gradient Descent">
      <data key="d0">Gradient Descent</data>
      <data key="d1">method</data>
      <data key="d2">An optimization algorithm used to minimize the error by adjusting weights based on the gradient.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002714</data>
      <data key="d6" />
    </node>
    <node id="Neural Network">
      <data key="d0">Neural Network</data>
      <data key="d1">concept</data>
      <data key="d2">A computational model inspired by biological neural networks, consisting of interconnected layers of neurons.&lt;SEP&gt;A computing system inspired by biological neural networks.&lt;SEP&gt;A Neural Network is a computational model used in LLMs, trained on large datasets to perform tasks like text generation and translation.&lt;SEP&gt;A computational model inspired by biological neural networks, used as a core component in the forecasting method.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81&lt;SEP&gt;chunk-f394bd66e077e288f0b983860f06c440&lt;SEP&gt;chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010097</data>
      <data key="d6" />
    </node>
    <node id="Total Net Input">
      <data key="d0">Total Net Input</data>
      <data key="d1">concept</data>
      <data key="d2">The weighted sum of all inputs to a neuron, plus the bias, before the activation function is applied.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002715</data>
      <data key="d6" />
    </node>
    <node id="Squared Error">
      <data key="d0">Squared Error</data>
      <data key="d1">concept</data>
      <data key="d2">An error calculation method where the error is the square of the difference between the target and actual output.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002715</data>
      <data key="d6" />
    </node>
    <node id="Random Initialization">
      <data key="d0">Random Initialization</data>
      <data key="d1">method</data>
      <data key="d2">The process of setting the initial weights and biases of a neural network to random values before training.</data>
      <data key="d3">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002716</data>
      <data key="d6" />
    </node>
    <node id="ConvNets">
      <data key="d0">ConvNets</data>
      <data key="d1">concept</data>
      <data key="d2">ConvNets是卷积神经网络的另一种称呼，是深度学习中的一种重要模型。</data>
      <data key="d3">chunk-d22adf07bd762e4e32d9bceea2fa6218</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002733</data>
      <data key="d6" />
    </node>
    <node id="本视频">
      <data key="d0">本视频</data>
      <data key="d1">content</data>
      <data key="d2">本视频是一个教学视频，内容涉及探索卷积神经网络的基础知识。</data>
      <data key="d3">chunk-d22adf07bd762e4e32d9bceea2fa6218</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002734</data>
      <data key="d6" />
    </node>
    <node id="图像数据">
      <data key="d0">图像数据</data>
      <data key="d1">data</data>
      <data key="d2">图像数据由二维像素网格组成，每个像素可能包含一个或多个数值，取决于图像是黑白还是彩色。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002780</data>
      <data key="d6" />
    </node>
    <node id="全连接的多层感知机">
      <data key="d0">全连接的多层感知机</data>
      <data key="d1">method</data>
      <data key="d2">一种神经网络架构，通过将图像数据展平为一维向量进行处理，但忽略了图像的空间结构信息。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002780</data>
      <data key="d6" />
    </node>
    <node id="计算机视觉">
      <data key="d0">计算机视觉</data>
      <data key="d1">concept</data>
      <data key="d2">一个领域，其中基于卷积神经网络的模型占主导地位，应用于图像识别、目标检测和语义分割等任务。&lt;SEP&gt;计算机视觉是一个领域，卷积神经网络是其成功的关键构建模块，应用于自动驾驶、智能医疗保健等。&lt;SEP&gt;Computer vision is a field of artificial intelligence where Convolutional Neural Networks (CNNs) are extensively applied for tasks like image and video processing.&lt;SEP&gt;计算机视觉是卷积神经网络最初相遇和应用的领域。&lt;SEP&gt;计算机视觉是人工智能的一个方面，涉及让机器识别和理解图像和视觉信息。&lt;SEP&gt;计算机视觉是人工智能的一个子领域，专注于使计算机能够从图像或视频中获取信息。&lt;SEP&gt;Computer Vision is a subfield of artificial intelligence that enables computers to derive meaningful information from digital images, videos, and other visual inputs.</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008453</data>
      <data key="d6" />
    </node>
    <node id="循环神经网络">
      <data key="d0">循环神经网络</data>
      <data key="d1">method</data>
      <data key="d2">通常用于处理一维序列结构任务(如音频、文本和时间序列分析)的神经网络。&lt;SEP&gt;循环神经网络是一种深度学习系统，具有与卷积神经网络不同的架构。&lt;SEP&gt;循环神经网络是一种常用于深度学习的神经网络架构，用于对序列等数据进行编码。&lt;SEP&gt;Recurrent Neural Networks (RNN) are a type of deep learning model effective at capturing complex nonlinear relationships and long-term dependencies in time series data.&lt;SEP&gt;循环神经网络是一种深度学习模型，应用于语音助手等领域。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-c79065b95e8586e85c1d4a6dfcdb5d37&lt;SEP&gt;chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8&lt;SEP&gt;chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008467</data>
      <data key="d6" />
    </node>
    <node id="卷积层">
      <data key="d0">卷积层</data>
      <data key="d1">concept</data>
      <data key="d2">构成卷积神经网络主干的基本元素，是执行卷积操作的核心组件。&lt;SEP&gt;The convolutional layer is a fundamental component of a CNN that performs convolution operations to extract features from input data using filters.&lt;SEP&gt;卷积层是卷积神经网络的一部分，将输入图像与卷积核进行卷积操作以学习特征。&lt;SEP&gt;Convolutional layers are components of a CNN that perform convolution operations to extract local features from input data, such as images.&lt;SEP&gt;卷积层是卷积神经网络中的一个层组，使用预配置的筛选条件从输入数据中提取信息。&lt;SEP&gt;卷积层是卷积神经网络中的一种网络层，使用卷积核进行特征提取，通过局部连接和共享权重大幅减少模型参数。&lt;SEP&gt;卷积层是卷积神经网络中的一种层，用于提取输入数据的局部特征。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-c79065b95e8586e85c1d4a6dfcdb5d37&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003324</data>
      <data key="d6" />
    </node>
    <node id="填充">
      <data key="d0">填充</data>
      <data key="d1">method</data>
      <data key="d2">卷积神经网络中的一种技术，用于控制输出特征图的大小。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002783</data>
      <data key="d6" />
    </node>
    <node id="步幅">
      <data key="d0">步幅</data>
      <data key="d1">method</data>
      <data key="d2">卷积神经网络中的一种技术，用于控制卷积核在输入上滑动的步长。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002783</data>
      <data key="d6" />
    </node>
    <node id="汇聚层">
      <data key="d0">汇聚层</data>
      <data key="d1">method</data>
      <data key="d2">卷积神经网络中的一种层，用于在相邻区域汇聚信息，通常进行下采样。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002783</data>
      <data key="d6" />
    </node>
    <node id="多通道">
      <data key="d0">多通道</data>
      <data key="d1">concept</data>
      <data key="d2">卷积神经网络中每一层使用多个通道(例如，彩色图像的RGB通道)来处理数据。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002784</data>
      <data key="d6" />
    </node>
    <node id="LeNet模型">
      <data key="d0">LeNet模型</data>
      <data key="d1">artifact</data>
      <data key="d2">第一个成功应用的卷积神经网络模型，其出现时间早于现代深度学习的兴起。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002784</data>
      <data key="d6" />
    </node>
    <node id="生物学">
      <data key="d0">生物学</data>
      <data key="d1">concept</data>
      <data key="d2">现代卷积神经网络的设计受益于生物学的启发。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002784</data>
      <data key="d6" />
    </node>
    <node id="群论">
      <data key="d0">群论</data>
      <data key="d1">concept</data>
      <data key="d2">现代卷积神经网络的设计受益于群论的启发。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002791</data>
      <data key="d6" />
    </node>
    <node id="图结构数据">
      <data key="d0">图结构数据</data>
      <data key="d1">data</data>
      <data key="d2">通过巧妙的调整，卷积神经网络也能在图结构数据中发挥作用。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002784</data>
      <data key="d6" />
    </node>
    <node id="推荐系统">
      <data key="d0">推荐系统</data>
      <data key="d1">concept</data>
      <data key="d2">通过巧妙的调整，卷积神经网络也能在推荐系统中发挥作用。&lt;SEP&gt;推荐系统是互联网行业中使用机器学习/深度学习技术的典型应用，用于实现千人千面的个性化推荐。&lt;SEP&gt;推荐系统是机器学习的一个应用领域，例如使用协同过滤算法。</data>
      <data key="d3">chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-0ff265f7709913907a277247870f20cc&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008461</data>
      <data key="d6" />
    </node>
    <node id="池化层">
      <data key="d0">池化层</data>
      <data key="d1">concept</data>
      <data key="d2">The pooling layer downsamples the feature maps from the convolutional layer, reducing dimensionality and computational load.&lt;SEP&gt;池化层是卷积神经网络中的一层，用于对数据进行下采样。&lt;SEP&gt;Pooling layers are components of a CNN that reduce the spatial dimensions of the features extracted by convolutional layers.&lt;SEP&gt;池化层是卷积神经网络中的一种网络层，用于汇聚局部神经元的输出，减少数据维度，抓取主要特征。&lt;SEP&gt;池化层是卷积神经网络中的一种层，用于通过组合局部神经元的输出并减少数据维度来抓取主要特征，忽略次要因素。</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003331</data>
      <data key="d6" />
    </node>
    <node id="全连接层">
      <data key="d0">全连接层</data>
      <data key="d1">concept</data>
      <data key="d2">全连接层是卷积神经网络中的一层，通常位于网络末端用于输出。&lt;SEP&gt;Fully connected layers are components of a CNN that perform final classification or regression tasks based on the processed features.&lt;SEP&gt;全连接层是神经网络中的一种层结构，其中每层节点都与上一层的所有节点相连，参数众多，容易产生过拟合。&lt;SEP&gt;全连接层是卷积神经网络的最后层，用于从全局出发做出最终结论，并将数据维度降低到与类别数相等。</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003325</data>
      <data key="d6" />
    </node>
    <node id="图像识别">
      <data key="d0">图像识别</data>
      <data key="d1">concept</data>
      <data key="d2">Image recognition is a key application area where Convolutional Neural Networks (CNNs) are used to identify objects or patterns in images.&lt;SEP&gt;The process of identifying and detecting objects or features in a digital image or video.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003180</data>
      <data key="d6" />
    </node>
    <node id="基础CNN">
      <data key="d0">基础CNN</data>
      <data key="d1">concept</data>
      <data key="d2">Basic CNN refers to a simple CNN structure suitable for pure classification tasks, often used as an introductory model.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002898</data>
      <data key="d6" />
    </node>
    <node id="SSD">
      <data key="d0">SSD</data>
      <data key="d1">method</data>
      <data key="d2">SSD (Single Shot MultiBox Detector) is a single-stage object detection model known for its speed, suitable for real-time applications like video surveillance.&lt;SEP&gt;SSD is mentioned as a possible one-stage object detection model for remote sensing applications.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009833</data>
      <data key="d6" />
    </node>
    <node id="Faster R-CNN">
      <data key="d0">Faster R-CNN</data>
      <data key="d1">method</data>
      <data key="d2">Faster R-CNN is a two-stage object detection model known for its high accuracy, suitable for precise detection tasks such as medical imaging.&lt;SEP&gt;Faster R-CNN is a two-stage object detection model mentioned as an example for implementation in remote sensing image object detection tasks.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009798</data>
      <data key="d6" />
    </node>
    <node id="Mask R-CNN">
      <data key="d0">Mask R-CNN</data>
      <data key="d1">concept</data>
      <data key="d2">Mask R-CNN is a comprehensive model capable of both object detection and instance segmentation, suitable for complex scenarios like industrial inspection and autonomous driving.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002906</data>
      <data key="d6" />
    </node>
    <node id="卷积操作">
      <data key="d0">卷积操作</data>
      <data key="d1">concept</data>
      <data key="d2">Convolution operation refers to the mathematical process of performing an inner product between image data (from different windows) and a convolution kernel (a set of fixed weights/filters), which gives the CNN its name.&lt;SEP&gt;卷积操作是卷积层中卷积核与输入图像进行的数学运算过程。</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002906</data>
      <data key="d6" />
    </node>
    <node id="滤波器">
      <data key="d0">滤波器</data>
      <data key="d1">concept</data>
      <data key="d2">A filter (or convolution kernel) is a set of fixed weights used in the convolution operation to detect specific features in the input data.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002899</data>
      <data key="d6" />
    </node>
    <node id="平移不变性">
      <data key="d0">平移不变性</data>
      <data key="d1">concept</data>
      <data key="d2">Translation invariance is a property achieved by CNNs through convolution operations, allowing them to recognize patterns regardless of their position in the input image.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002899</data>
      <data key="d6" />
    </node>
    <node id="层级化特征提取">
      <data key="d0">层级化特征提取</data>
      <data key="d1">concept</data>
      <data key="d2">Hierarchical feature extraction is the process by which CNNs abstract features from basic visual elements to high-level semantic understanding through their layered architecture.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002900</data>
      <data key="d6" />
    </node>
    <node id="一文读懂卷积神经网络CNN.pdf">
      <data key="d0">一文读懂卷积神经网络CNN.pdf</data>
      <data key="d1">content</data>
      <data key="d2">"一文读懂卷积神经网络CNN.pdf" is a document file referenced in the text, described as a complete version providing an explanation of Convolutional Neural Networks.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002902</data>
      <data key="d6" />
    </node>
    <node id="卷积平摊">
      <data key="d0">卷积平摊</data>
      <data key="d1">concept</data>
      <data key="d2">Convolution flattening is a concept mentioned in the context of explaining the principles of Convolutional Neural Networks in deep learning.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002903</data>
      <data key="d6" />
    </node>
    <node id="天善智能">
      <data key="d0">天善智能</data>
      <data key="d1">organization</data>
      <data key="d2">Tianshan Intelligence is a vertical community focused on business intelligence (BI), artificial intelligence (AI), big data analysis, and data mining, providing learning, Q&amp;A, and job-seeking services.&lt;SEP&gt;Tianshan Intelligence is an organization focused on business intelligence (BI), artificial intelligence (AI), and big data analysis, mentioned as the publisher of a detailed explanation on CNN principles.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002903</data>
      <data key="d6" />
    </node>
    <node id="商业智能BI">
      <data key="d0">商业智能BI</data>
      <data key="d1">concept</data>
      <data key="d2">Business Intelligence (BI) is a field mentioned as a focus area of the organization Tianshan Intelligence.&lt;SEP&gt;Business Intelligence (BI) is a field of focus for the Tianshan Intelligence community, involving data analysis for business decision-making.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002904</data>
      <data key="d6" />
    </node>
    <node id="大数据分析">
      <data key="d0">大数据分析</data>
      <data key="d1">concept</data>
      <data key="d2">Big Data Analysis is a field mentioned as a focus area of the organization Tianshan Intelligence.&lt;SEP&gt;Big data analysis is a field of focus for the Tianshan Intelligence community, involving the examination of large and complex data sets.</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002904</data>
      <data key="d6" />
    </node>
    <node id="图像处理">
      <data key="d0">图像处理</data>
      <data key="d1">concept</data>
      <data key="d2">Image processing is a field where deep learning algorithms, specifically CNNs, are applied to analyze and manipulate images.&lt;SEP&gt;图像处理是卷积神经网络应用的一个技术领域。&lt;SEP&gt;Image processing is a field where deep learning technology has made breakthroughs.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009445</data>
      <data key="d6" />
    </node>
    <node id="腾讯云">
      <data key="d0">腾讯云</data>
      <data key="d1">organization</data>
      <data key="d2">Tencent Cloud is a cloud service provider that published an article explaining the basic structure and principles of Convolutional Neural Networks.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002905</data>
      <data key="d6" />
    </node>
    <node id="Hubel">
      <data key="d0">Hubel</data>
      <data key="d1">person</data>
      <data key="d2">Hubel is a scientist whose work, along with Wiesel's, inspired the design of Convolutional Neural Networks based on biological visual systems.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002905</data>
      <data key="d6" />
    </node>
    <node id="Wiesel">
      <data key="d0">Wiesel</data>
      <data key="d1">person</data>
      <data key="d2">Wiesel is a scientist whose work, along with Hubel's, inspired the design of Convolutional Neural Networks based on biological visual systems.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002906</data>
      <data key="d6" />
    </node>
    <node id="生物视觉系统">
      <data key="d0">生物视觉系统</data>
      <data key="d1">concept</data>
      <data key="d2">The biological visual system, particularly the research by Hubel and Wiesel, served as the inspiration for the architectural design of Convolutional Neural Networks.&lt;SEP&gt;生物视觉系统的研究启发了福岛邦彦提出层级化的人工神经网络。</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003336</data>
      <data key="d6" />
    </node>
    <node id="激活层">
      <data key="d0">激活层</data>
      <data key="d1">concept</data>
      <data key="d2">The activation layer applies a non-linear function to the output of the convolutional layer, introducing complexity into the network.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002906</data>
      <data key="d6" />
    </node>
    <node id="全链接层">
      <data key="d0">全链接层</data>
      <data key="d1">concept</data>
      <data key="d2">The fully connected layer connects all neurons from the previous layer to the current layer, typically used for final classification in a CNN.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002907</data>
      <data key="d6" />
    </node>
    <node id="RGB颜色模型">
      <data key="d0">RGB颜色模型</data>
      <data key="d1">concept</data>
      <data key="d2">The RGB color model is a common way to represent color images using combinations of red, green, and blue light.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002907</data>
      <data key="d6" />
    </node>
    <node id="知网">
      <data key="d0">知网</data>
      <data key="d1">organization</data>
      <data key="d2">CNKI (China National Knowledge Infrastructure) is a platform where research papers, including master's theses on CNN training, can be downloaded.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002908</data>
      <data key="d6" />
    </node>
    <node id="PaddlePaddle">
      <data key="d0">PaddlePaddle</data>
      <data key="d1">artifact</data>
      <data key="d2">PaddlePaddle is a deep learning framework used for tasks such as handwritten digit recognition, as mentioned in the context of a previous article.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002908</data>
      <data key="d6" />
    </node>
    <node id="手写数字识别">
      <data key="d0">手写数字识别</data>
      <data key="d1">concept</data>
      <data key="d2">Handwritten digit recognition is a specific application task mentioned as an example where the PaddlePaddle framework was used.&lt;SEP&gt;手写数字识别是LeNet算法被广泛应用的任务之一。</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003337</data>
      <data key="d6" />
    </node>
    <node id="CAJ文档">
      <data key="d0">CAJ文档</data>
      <data key="d1">artifact</data>
      <data key="d2">CAJ documents are a specific file format mentioned as containing research papers on CNN training, requiring a special tool to open.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002908</data>
      <data key="d6" />
    </node>
    <node id="CAJ工具">
      <data key="d0">CAJ工具</data>
      <data key="d1">artifact</data>
      <data key="d2">CAJ tool is a software application required to open and read CAJ document files.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002908</data>
      <data key="d6" />
    </node>
    <node id="一文读懂卷积神经网络CNN.docx">
      <data key="d0">一文读懂卷积神经网络CNN.docx</data>
      <data key="d1">content</data>
      <data key="d2">"一文读懂卷积神经网络CNN.docx" is a document file that provides a detailed explanation of Convolutional Neural Networks.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002909</data>
      <data key="d6" />
    </node>
    <node id="一文搞懂卷积神经网络(CNN)的原理(超详细)">
      <data key="d0">一文搞懂卷积神经网络(CNN)的原理(超详细)</data>
      <data key="d1">content</data>
      <data key="d2">"一文搞懂卷积神经网络(CNN)的原理(超详细)" is a title or piece of content that offers a very detailed explanation of CNN principles.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002909</data>
      <data key="d6" />
    </node>
    <node id="数据挖掘">
      <data key="d0">数据挖掘</data>
      <data key="d1">method</data>
      <data key="d2">Data mining is a field of focus for the Tianshan Intelligence community, involving discovering patterns in large data sets.&lt;SEP&gt;数据挖掘is the process of discovering patterns and knowledge from large datasets, related to the field of data analysis.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008511</data>
      <data key="d6" />
    </node>
    <node id="Python">
      <data key="d0">Python</data>
      <data key="d1">artifact</data>
      <data key="d2">Python is a programming language mentioned as being of interest to students in data-related fields.&lt;SEP&gt;A programming language used for writing programs to scrape data and perform basic analysis.&lt;SEP&gt;Python is the programming language used to write the Natural Language Toolkit (NLTK).</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-6bc1d4e50f0179dd98e01918a3be7977&lt;SEP&gt;chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007337</data>
      <data key="d6" />
    </node>
    <node id="R">
      <data key="d0">R</data>
      <data key="d1">artifact</data>
      <data key="d2">R is a programming language mentioned as being of interest to students in data-related fields.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002910</data>
      <data key="d6" />
    </node>
    <node id="数据爱好者交流群">
      <data key="d0">数据爱好者交流群</data>
      <data key="d1">organization</data>
      <data key="d2">The Data Enthusiasts Exchange Group is a community mentioned for people interested in data fields like BI, big data, and machine learning.</data>
      <data key="d3">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002910</data>
      <data key="d6" />
    </node>
    <node id="卷积核">
      <data key="d0">卷积核</data>
      <data key="d1">concept</data>
      <data key="d2">卷积核是卷积层中用于与输入图像进行卷积操作的工具。&lt;SEP&gt;卷积核是卷积层中进行特征提取的小矩阵(如3x3)，通过二维离散卷积操作实现高效的图像特征提取，并具备空间平移不变性。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003340</data>
      <data key="d6" />
    </node>
    <node id="ReLU">
      <data key="d0">ReLU</data>
      <data key="d1">method</data>
      <data key="d2">ReLU是一种激活函数，用于在卷积神经网络中引入非线性。&lt;SEP&gt;Rectified Linear Unit, a common activation function used in neural networks.&lt;SEP&gt;ReLU is an activation function in neural networks, with its gradient being a key property for backpropagation.</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003605</data>
      <data key="d6" />
    </node>
    <node id="感知器">
      <data key="d0">感知器</data>
      <data key="d1">concept</data>
      <data key="d2">感知器是神经网络单元的数学模型，接收多个输入并产生一个输出。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002912</data>
      <data key="d6" />
    </node>
    <node id="自动驾驶">
      <data key="d0">自动驾驶</data>
      <data key="d1">concept</data>
      <data key="d2">自动驾驶是计算机视觉的一个应用领域。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002914</data>
      <data key="d6" />
    </node>
    <node id="智能医疗保健">
      <data key="d0">智能医疗保健</data>
      <data key="d1">concept</data>
      <data key="d2">智能医疗保健是计算机视觉的一个应用领域。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002914</data>
      <data key="d6" />
    </node>
    <node id="自助零售">
      <data key="d0">自助零售</data>
      <data key="d1">concept</data>
      <data key="d2">自助零售是计算机视觉的一个应用领域。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002914</data>
      <data key="d6" />
    </node>
    <node id="面部解锁">
      <data key="d0">面部解锁</data>
      <data key="d1">concept</data>
      <data key="d2">面部解锁是计算机视觉在日常生活中的一个应用。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002914</data>
      <data key="d6" />
    </node>
    <node id="自动修图">
      <data key="d0">自动修图</data>
      <data key="d1">concept</data>
      <data key="d2">自动修图是计算机视觉在日常生活中的一个应用。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002915</data>
      <data key="d6" />
    </node>
    <node id="二维卷积层">
      <data key="d0">二维卷积层</data>
      <data key="d1">concept</data>
      <data key="d2">二维卷积层是卷积神经网络中最常见的卷积层，有高和宽两个空间维度，用于处理图像数据。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002915</data>
      <data key="d6" />
    </node>
    <node id="ANNs">
      <data key="d0">ANNs</data>
      <data key="d1">concept</data>
      <data key="d2">ANNs是人工神经网络的英文缩写。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002915</data>
      <data key="d6" />
    </node>
    <node id="多层堆叠">
      <data key="d0">多层堆叠</data>
      <data key="d1">concept</data>
      <data key="d2">多层堆叠是卷积神经网络的一种构造方式，指将多个卷积层、激活层和池化层叠加在一起。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002916</data>
      <data key="d6" />
    </node>
    <node id="颜色通道">
      <data key="d0">颜色通道</data>
      <data key="d1">concept</data>
      <data key="d2">颜色通道指图像数据中红、绿、蓝三个组成部分，共同形成表示像素强度值的二维矩阵。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002916</data>
      <data key="d6" />
    </node>
    <node id="像素强度值">
      <data key="d0">像素强度值</data>
      <data key="d1">data</data>
      <data key="d2">像素强度值是图像数据中表示每个像素点颜色亮度的数值。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002916</data>
      <data key="d6" />
    </node>
    <node id="二维矩阵">
      <data key="d0">二维矩阵</data>
      <data key="d1">data</data>
      <data key="d2">二维矩阵是用于存储图像像素强度值的数据结构。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002917</data>
      <data key="d6" />
    </node>
    <node id="非线性">
      <data key="d0">非线性</data>
      <data key="d1">concept</data>
      <data key="d2">非线性是通过激活函数引入的特性，使神经网络能够学习复杂的特征。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002917</data>
      <data key="d6" />
    </node>
    <node id="特征">
      <data key="d0">特征</data>
      <data key="d1">concept</data>
      <data key="d2">特征是卷积神经网络从输入数据中学习到的模式或信息。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002917</data>
      <data key="d6" />
    </node>
    <node id="连接">
      <data key="d0">连接</data>
      <data key="d1">concept</data>
      <data key="d2">连接是神经网络中节点之间的通路，模拟生物神经网络的突触。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002917</data>
      <data key="d6" />
    </node>
    <node id="突触">
      <data key="d0">突触</data>
      <data key="d1">concept</data>
      <data key="d2">突触是生物神经网络中神经元之间的连接点，被人工神经网络模型所模仿。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002918</data>
      <data key="d6" />
    </node>
    <node id="外部刺激">
      <data key="d0">外部刺激</data>
      <data key="d1">concept</data>
      <data key="d2">外部刺激是感知器模型中输入的类比，类似于神经末梢感受的环境变化。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002918</data>
      <data key="d6" />
    </node>
    <node id="电信号">
      <data key="d0">电信号</data>
      <data key="d1">concept</data>
      <data key="d2">电信号是感知器产生输出的类比，类似于生物神经元转导的信号。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002918</data>
      <data key="d6" />
    </node>
    <node id="构建模块">
      <data key="d0">构建模块</data>
      <data key="d1">concept</data>
      <data key="d2">构建模块指卷积神经网络是计算机视觉取得巨大成功的关键组成部分。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002918</data>
      <data key="d6" />
    </node>
    <node id="数学方程">
      <data key="d0">数学方程</data>
      <data key="d1">content</data>
      <data key="d2">数学方程是文章中包含的用于解释卷积神经网络原理的复杂公式。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002919</data>
      <data key="d6" />
    </node>
    <node id="线性代数">
      <data key="d0">线性代数</data>
      <data key="d1">concept</data>
      <data key="d2">线性代数是理解卷积神经网络所需的一种数学知识。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002919</data>
      <data key="d6" />
    </node>
    <node id="微分">
      <data key="d0">微分</data>
      <data key="d1">concept</data>
      <data key="d2">微分是理解卷积神经网络所需的一种数学知识。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002919</data>
      <data key="d6" />
    </node>
    <node id="空间维度">
      <data key="d0">空间维度</data>
      <data key="d1">concept</data>
      <data key="d2">空间维度指二维卷积层所具有的高和宽两个方向。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002919</data>
      <data key="d6" />
    </node>
    <node id="架构设计">
      <data key="d0">架构设计</data>
      <data key="d1">concept</data>
      <data key="d2">架构设计指构建卷积神经网络模型时对网络结构的规划。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002919</data>
      <data key="d6" />
    </node>
    <node id="应用方法">
      <data key="d0">应用方法</data>
      <data key="d1">method</data>
      <data key="d2">应用方法指使用卷积神经网络解决实际问题的方式和步骤。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002919</data>
      <data key="d6" />
    </node>
    <node id="训练">
      <data key="d0">训练</data>
      <data key="d1">method</data>
      <data key="d2">训练是使卷积神经网络学习特征和优化参数的过程。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002920</data>
      <data key="d6" />
    </node>
    <node id="下采样">
      <data key="d0">下采样</data>
      <data key="d1">method</data>
      <data key="d2">下采样是池化层对数据进行缩减采样的操作。</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002920</data>
      <data key="d6" />
    </node>
    <node id="Convolutional Neural Network">
      <data key="d0">Convolutional Neural Network</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning model inspired by biological visual systems, designed to simulate human visual processing, widely used in computer vision.&lt;SEP&gt;A feedforward neural network whose artificial neurons can respond to surrounding units within a partial coverage area, demonstrating excellent performance in large-scale image processing.&lt;SEP&gt;A class of deep neural networks, commonly applied to analyzing visual imagery, abbreviated as CNN.&lt;SEP&gt;A type of deep learning model used for extracting global features from images.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-df57bc33c49fe522c66616c1a4be5336&lt;SEP&gt;chunk-fe2c7c19ec682c0e709a26a55e0b8005&lt;SEP&gt;chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009654</data>
      <data key="d6" />
    </node>
    <node id="Computer Vision">
      <data key="d0">Computer Vision</data>
      <data key="d1">concept</data>
      <data key="d2">A field of computer science where Convolutional Neural Networks have achieved significant success.&lt;SEP&gt;A field of artificial intelligence (AI) that enables computers and systems to derive meaningful information from digital images, videos, and other visual inputs, and to take actions based on those inputs.&lt;SEP&gt;A research direction applied in biomedicine by Nankai Statistics.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004235</data>
      <data key="d6" />
    </node>
    <node id="Image">
      <data key="d0">Image</data>
      <data key="d1">concept</data>
      <data key="d2">Represented in a computer as a sequence of numbers from 0 to 255, with 0 being darkest and 255 brightest.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002921</data>
      <data key="d6" />
    </node>
    <node id="Grayscale Image">
      <data key="d0">Grayscale Image</data>
      <data key="d1">concept</data>
      <data key="d2">An image composed only of black and white colors.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002921</data>
      <data key="d6" />
    </node>
    <node id="RGB Color Model">
      <data key="d0">RGB Color Model</data>
      <data key="d1">concept</data>
      <data key="d2">A color model using red, green, and blue primary colors combined in different proportions to produce various colors.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002921</data>
      <data key="d6" />
    </node>
    <node id="Channel">
      <data key="d0">Channel</data>
      <data key="d1">concept</data>
      <data key="d2">In the context of an image, a single matrix representing one color component (e.g., red, green, blue).</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002921</data>
      <data key="d6" />
    </node>
    <node id="Traditional Neural Network">
      <data key="d0">Traditional Neural Network</data>
      <data key="d1">concept</data>
      <data key="d2">A type of neural network that may struggle to recognize objects in different positions.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002922</data>
      <data key="d6" />
    </node>
    <node id="Invariance">
      <data key="d0">Invariance</data>
      <data key="d1">concept</data>
      <data key="d2">The property where an object is recognized as the same regardless of its position in the image.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002922</data>
      <data key="d6" />
    </node>
    <node id="Translation Invariance">
      <data key="d0">Translation Invariance</data>
      <data key="d1">concept</data>
      <data key="d2">A specific type of invariance where object recognition is unaffected by its location in the image.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002922</data>
      <data key="d6" />
    </node>
    <node id="Convolution Operation">
      <data key="d0">Convolution Operation</data>
      <data key="d1">method</data>
      <data key="d2">An operation in CNNs involving a movable small window (data window) performing element-wise multiplication and summation with an image.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002922</data>
      <data key="d6" />
    </node>
    <node id="Data Window">
      <data key="d0">Data Window</data>
      <data key="d1">concept</data>
      <data key="d2">A small, movable window used in the convolution operation to scan across an image.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002923</data>
      <data key="d6" />
    </node>
    <node id="Filter">
      <data key="d0">Filter</data>
      <data key="d1">artifact</data>
      <data key="d2">A set of fixed weights, also known as a convolution kernel, used in the convolution operation to extract features.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002923</data>
      <data key="d6" />
    </node>
    <node id="Convolution Kernel">
      <data key="d0">Convolution Kernel</data>
      <data key="d1">artifact</data>
      <data key="d2">Synonymous with filter; a small matrix of weights used to perform convolution on an image.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002923</data>
      <data key="d6" />
    </node>
    <node id="Zero-Padding">
      <data key="d0">Zero-Padding</data>
      <data key="d1">method</data>
      <data key="d2">A technique of adding circles of zeros around the edges of an input image to facilitate convolution.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002923</data>
      <data key="d6" />
    </node>
    <node id="Stride">
      <data key="d0">Stride</data>
      <data key="d1">concept</data>
      <data key="d2">The step size by which the convolution kernel moves across the input image during the convolution operation.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002924</data>
      <data key="d6" />
    </node>
    <node id="Feature Map">
      <data key="d0">Feature Map</data>
      <data key="d1">concept</data>
      <data key="d2">The output resulting from applying a convolution kernel to an input image.&lt;SEP&gt;The output of applying a filter (kernel) to the input data during the convolution operation in a CNN.&lt;SEP&gt;A feature map is the output generated by applying a convolution filter to an input in a convolutional neural network.&lt;SEP&gt;Outputs created by convolutional layers in a CNN, from which max-pooling extracts the most significant features.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-330f64bec90f2f131895d2de62adeb6f&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006961</data>
      <data key="d6" />
    </node>
    <node id="Input Layer">
      <data key="d0">Input Layer</data>
      <data key="d1">concept</data>
      <data key="d2">The layer of a CNN that receives the raw image data, typically a 2D matrix of pixel intensity values.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002931</data>
      <data key="d6" />
    </node>
    <node id="Convolution Layer">
      <data key="d0">Convolution Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A layer in a CNN that performs the convolution operation on the input image using convolution kernels.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002931</data>
      <data key="d6" />
    </node>
    <node id="CSDN Blog">
      <data key="d0">CSDN Blog</data>
      <data key="d1">content</data>
      <data key="d2">A blog post titled "深入了解神经网络：构建人工智能的基石" referenced as a resource for understanding neural networks.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002924</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning">
      <data key="d0">Deep Learning</data>
      <data key="d1">concept</data>
      <data key="d2">深度学习是机器学习的一个子领域，它基于人工神经网络，特别是利用具有多层的神经网络来学习数据的表征。作为一种方法，它能够克服传统模型（如条件随机场在捕捉长距离上下文方面的局限性）的缺点。深度学习在多个具体应用领域中展现出强大的能力：在计算机视觉领域，它用于图像识别、对象检测和图像分割；在语音处理领域，它用于语音识别；在生物科学领域，它支撑了如AlphaFold这样的突破性工具；在金融领域，它被应用于量化交易和公司债券信用风险评估，以提高欺诈检测的准确性、实现实时检测并减少误报；在遥感领域，它用于提取卫星遥感图像的全局特征以进行检索和定位，并完成对象检测、模型优化等任务；在气象与气候科学领域，它被用于开发天气和气候预测技术。该领域的发展与关键研究人员如Yann LeCun、Yoshua Bengio和Geoffrey Hinton的贡献密不可分。&lt;SEP&gt;A subset of machine learning involving neural networks with multiple layers, used here for meteorological forecasting.&lt;SEP&gt;A subset of machine learning methods based on artificial neural networks.&lt;SEP&gt;Deep learning is a field of artificial intelligence that has fundamentally changed since around 2015.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-c79b805e7da972f5a80b0f9eb1144d75&lt;SEP&gt;chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837&lt;SEP&gt;chunk-5899806c994fc2f391826abc901a8669&lt;SEP&gt;chunk-d9ecda3ea425b03f3129938c0ba44219&lt;SEP&gt;chunk-2dc1c848682669d15114cbb84e3cd6b4&lt;SEP&gt;chunk-6d22dc080f5fd339b89bf3f7732fc258&lt;SEP&gt;chunk-fe2c7c19ec682c0e709a26a55e0b8005&lt;SEP&gt;chunk-ac1ed9e88e425ab885199259d92315e5&lt;SEP&gt;chunk-330f64bec90f2f131895d2de62adeb6f&lt;SEP&gt;chunk-3ac3b580cca11b5e1d0122810a6ec5f5&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81&lt;SEP&gt;chunk-fb89c8462c112775ff8e6c43e7d050e8&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1&lt;SEP&gt;chunk-babf4b9b036bdc4286b6ed4dc016cba8&lt;SEP&gt;chunk-ed300ee31268ac8e853d58a7e20740f0&lt;SEP&gt;chunk-333ff749c2940b520a06027eb3c17eac&lt;SEP&gt;chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010775</data>
      <data key="d6" />
    </node>
    <node id="Artificial Intelligence">
      <data key="d0">Artificial Intelligence</data>
      <data key="d1">concept</data>
      <data key="d2">The broader field of study that encompasses neural networks and deep learning.&lt;SEP&gt;Artificial Intelligence is a field that was significantly advanced by the abstract modeling of neural systems.&lt;SEP&gt;Artificial Intelligence is a field of technology that current fraud detection systems rely on, though it has not fully addressed all related challenges.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006121</data>
      <data key="d6" />
    </node>
    <node id="Pixel">
      <data key="d0">Pixel</data>
      <data key="d1">concept</data>
      <data key="d2">The smallest unit of a digital image, represented by a numerical value indicating brightness.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002926</data>
      <data key="d6" />
    </node>
    <node id="Tensor">
      <data key="d0">Tensor</data>
      <data key="d1">concept</data>
      <data key="d2">A multi-dimensional array used to represent data, such as an image with three color channels.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002926</data>
      <data key="d6" />
    </node>
    <node id="Width">
      <data key="d0">Width</data>
      <data key="d1">concept</data>
      <data key="d2">One of the dimensions used to describe an image, along with height and depth.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002926</data>
      <data key="d6" />
    </node>
    <node id="Height">
      <data key="d0">Height</data>
      <data key="d1">concept</data>
      <data key="d2">One of the dimensions used to describe an image, along with width and depth.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002926</data>
      <data key="d6" />
    </node>
    <node id="Depth">
      <data key="d0">Depth</data>
      <data key="d1">concept</data>
      <data key="d2">In the context of an image, refers to the number of color channels (e.g., 3 for RGB).</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002927</data>
      <data key="d6" />
    </node>
    <node id="Object Detection">
      <data key="d0">Object Detection</data>
      <data key="d1">concept</data>
      <data key="d2">A computer vision task where Convolutional Neural Networks have shown significant progress.&lt;SEP&gt;A primary task that Convolutional Neural Networks (CNNs) are designed for, involving locating and classifying objects within images.&lt;SEP&gt;Object Detection is a computer vision task for identifying and locating objects in images, with specific applications and model evaluations (e.g., mAP) discussed for remote sensing.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009803</data>
      <data key="d6" />
    </node>
    <node id="Image Generation">
      <data key="d0">Image Generation</data>
      <data key="d1">concept</data>
      <data key="d2">A computer vision task where Convolutional Neural Networks have shown significant progress.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002927</data>
      <data key="d6" />
    </node>
    <node id="Biological Visual System">
      <data key="d0">Biological Visual System</data>
      <data key="d1">concept</data>
      <data key="d2">The biological inspiration for the design of Convolutional Neural Networks.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002927</data>
      <data key="d6" />
    </node>
    <node id="Human Visual Processing">
      <data key="d0">Human Visual Processing</data>
      <data key="d1">concept</data>
      <data key="d2">The process that Convolutional Neural Networks aim to simulate.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002928</data>
      <data key="d6" />
    </node>
    <node id="Local Feature">
      <data key="d0">Local Feature</data>
      <data key="d1">concept</data>
      <data key="d2">Features in an image that are captured by the convolution operation in a CNN.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002928</data>
      <data key="d6" />
    </node>
    <node id="Padding">
      <data key="d0">Padding</data>
      <data key="d1">concept</data>
      <data key="d2">The general concept of adding values (like zeros) around the edges of an input, with zero-padding being a specific type.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002928</data>
      <data key="d6" />
    </node>
    <node id="Output Feature Map">
      <data key="d0">Output Feature Map</data>
      <data key="d1">data</data>
      <data key="d2">The result of the convolution operation, which may have its dimensions affected by stride and padding.</data>
      <data key="d3">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002928</data>
      <data key="d6" />
    </node>
    <node id="人工智能AI">
      <data key="d0">人工智能AI</data>
      <data key="d3">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d2">The organization Tianshan Intelligence focuses on the field of Artificial Intelligence (AI).</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002941</data>
      <data key="d6" />
    </node>
    <node id="神经网络单元">
      <data key="d0">神经网络单元</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d2">神经网络单元的数学模型被称为感知器。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002941</data>
      <data key="d6" />
    </node>
    <node id="输入图像">
      <data key="d0">输入图像</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d2">卷积操作的目标是处理输入图像。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002945</data>
      <data key="d6" />
    </node>
    <node id="文章">
      <data key="d0">文章</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d2">文章中包含了复杂的数学方程来解释卷积神经网络的原理。&lt;SEP&gt;文章是书面作品，GPT-4等模型可以生成文章。</data>
      <data key="d1">content</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007419</data>
      <data key="d6" />
    </node>
    <node id="讲义">
      <data key="d0">讲义</data>
      <data key="d3">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d2">讲义内容涵盖了卷积神经网络的架构设计。</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002949</data>
      <data key="d6" />
    </node>
    <node id="深度学习系统">
      <data key="d0">深度学习系统</data>
      <data key="d1">concept</data>
      <data key="d2">深度学习系统是计算机科学领域中的一种系统类型，主要包含卷积神经网络和循环神经网络两种不同架构。</data>
      <data key="d3">chunk-c79065b95e8586e85c1d4a6dfcdb5d37</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002978</data>
      <data key="d6" />
    </node>
    <node id="CNN架构">
      <data key="d0">CNN架构</data>
      <data key="d1">concept</data>
      <data key="d2">CNN架构是卷积神经网络的特定结构，包含三个层组，其中卷积层负责使用预配置的筛选条件提取信息。</data>
      <data key="d3">chunk-c79065b95e8586e85c1d4a6dfcdb5d37</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002978</data>
      <data key="d6" />
    </node>
    <node id="预配置的筛选条件">
      <data key="d0">预配置的筛选条件</data>
      <data key="d1">concept</data>
      <data key="d2">预配置的筛选条件是卷积层中用于从输入数据中提取信息的工具或参数。</data>
      <data key="d3">chunk-c79065b95e8586e85c1d4a6dfcdb5d37</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769002979</data>
      <data key="d6" />
    </node>
    <node id="卷积计算">
      <data key="d0">卷积计算</data>
      <data key="d1">concept</data>
      <data key="d2">Convolutional computation, a type of mathematical operation used within neural networks.</data>
      <data key="d3">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003001</data>
      <data key="d6" />
    </node>
    <node id="前馈神经网络">
      <data key="d0">前馈神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">Feedforward Neural Networks, a type of artificial neural network where connections between nodes do not form cycles.&lt;SEP&gt;前馈神经网络是一种神经网络架构，其中连接不形成循环，信息单向向前传播。&lt;SEP&gt;前馈神经网络是一种有监督学习方法。&lt;SEP&gt;前馈神经网络是一种神经网络架构，多层感知机是其中的一种。</data>
      <data key="d3">chunk-c79b805e7da972f5a80b0f9eb1144d75&lt;SEP&gt;chunk-df57bc33c49fe522c66616c1a4be5336&lt;SEP&gt;chunk-0c8c61555719c99f2248173e3fd5ae4f&lt;SEP&gt;chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003567</data>
      <data key="d6" />
    </node>
    <node id="Convolutional Neural Networks">
      <data key="d0">Convolutional Neural Networks</data>
      <data key="d1">concept</data>
      <data key="d2">A class of feedforward neural networks that includes convolutional computation and has a deep structure, and is a representative of deep learning.</data>
      <data key="d3">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003002</data>
      <data key="d6" />
    </node>
    <node id="Convolutional Computation">
      <data key="d0">Convolutional Computation</data>
      <data key="d1">concept</data>
      <data key="d2">Convolutional computation, a type of mathematical operation used within neural networks.</data>
      <data key="d3">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003002</data>
      <data key="d6" />
    </node>
    <node id="Feedforward Neural Networks">
      <data key="d0">Feedforward Neural Networks</data>
      <data key="d1">concept</data>
      <data key="d2">Feedforward Neural Networks, a type of artificial neural network where connections between nodes do not form cycles.</data>
      <data key="d3">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003003</data>
      <data key="d6" />
    </node>
    <node id="ConvNet">
      <data key="d0">ConvNet</data>
      <data key="d1">concept</data>
      <data key="d2">卷积神经网络的英文缩写，是一种直接从数据中学习的深度学习网络架构。</data>
      <data key="d3">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003035</data>
      <data key="d6" />
    </node>
    <node id="图像">
      <data key="d0">图像</data>
      <data key="d1">data</data>
      <data key="d2">一种数据类型，卷积神经网络特别适合在其中寻找模式以识别对象、类和类别。</data>
      <data key="d3">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003038</data>
      <data key="d6" />
    </node>
    <node id="音频">
      <data key="d0">音频</data>
      <data key="d1">data</data>
      <data key="d2">一种数据类型，卷积神经网络能很好地对它进行处理。</data>
      <data key="d3">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003038</data>
      <data key="d6" />
    </node>
    <node id="时间序列">
      <data key="d0">时间序列</data>
      <data key="d1">concept</data>
      <data key="d2">一种数据类型，卷积神经网络能很好地对它进行处理。&lt;SEP&gt;Refers to time series models or AI capabilities for analyzing sequential data over time.</data>
      <data key="d3">chunk-225c135f952fba89e32fc67dcf80d0f5&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003173</data>
      <data key="d6" />
    </node>
    <node id="信号">
      <data key="d0">信号</data>
      <data key="d1">data</data>
      <data key="d2">一种数据类型，卷积神经网络能很好地对它进行处理。</data>
      <data key="d3">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003039</data>
      <data key="d6" />
    </node>
    <node id="Convolutional Neural Network (CNN)">
      <data key="d0">Convolutional Neural Network (CNN)</data>
      <data key="d1">concept</data>
      <data key="d2">A class of deep learning models specifically designed for image recognition and object detection, capable of automatically extracting image features and performing classification tasks through the combination of convolutional layers, pooling layers, and fully connected layers.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003159</data>
      <data key="d6" />
    </node>
    <node id="Convolutional Layer">
      <data key="d0">Convolutional Layer</data>
      <data key="d1">concept</data>
      <data key="d2">The core building block of a CNN, responsible for performing most of the computations. It involves components like input data, filters, and feature maps, and performs the convolution operation by moving a filter across the receptive fields of an image.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003159</data>
      <data key="d6" />
    </node>
    <node id="Pooling Layer">
      <data key="d0">Pooling Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A layer in a CNN that helps reduce complexity, improve efficiency, and limit the risk of overfitting, although it involves losing some information.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003167</data>
      <data key="d6" />
    </node>
    <node id="Fully Connected Layer">
      <data key="d0">Fully Connected Layer</data>
      <data key="d1">concept</data>
      <data key="d2">The final layer in a convolutional neural network architecture.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003167</data>
      <data key="d6" />
    </node>
    <node id="Rectified Linear Unit (ReLU)">
      <data key="d0">Rectified Linear Unit (ReLU)</data>
      <data key="d1">concept</data>
      <data key="d2">A transformation applied to the feature map after each convolution operation to introduce non-linearity into the CNN model.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003167</data>
      <data key="d6" />
    </node>
    <node id="Kernel (Filter)">
      <data key="d0">Kernel (Filter)</data>
      <data key="d1">concept</data>
      <data key="d2">A feature detector that moves across the receptive fields of an image in a convolutional layer to check for the presence of features.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003168</data>
      <data key="d6" />
    </node>
    <node id="Feature Hierarchy">
      <data key="d0">Feature Hierarchy</data>
      <data key="d1">concept</data>
      <data key="d2">The hierarchical structure in a CNN where lower-level patterns (like parts of an object) combine to form higher-level patterns (like the complete object), enabling the network to recognize complex objects.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003168</data>
      <data key="d6" />
    </node>
    <node id="LeNet-5">
      <data key="d0">LeNet-5</data>
      <data key="d1">artifact</data>
      <data key="d2">An early and influential CNN architecture.&lt;SEP&gt;A classic and widely recognized convolutional neural network architecture.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003169</data>
      <data key="d6" />
    </node>
    <node id="AlexNet">
      <data key="d0">AlexNet</data>
      <data key="d1">method</data>
      <data key="d2">A groundbreaking CNN architecture that significantly advanced the field of deep learning for computer vision.&lt;SEP&gt;A common CNN architecture suitable for image tasks with varying complexity and performance requirements.&lt;SEP&gt;AlexNet是由Hinton等人提出的卷积神经网络，在2012年ImageNet竞赛中取得超高的识别率，展示了卷积神经网络的巨大潜力。&lt;SEP&gt;AlexNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009804</data>
      <data key="d6" />
    </node>
    <node id="VGGNet">
      <data key="d0">VGGNet</data>
      <data key="d1">artifact</data>
      <data key="d2">A CNN architecture known for its simplicity and depth, using very small convolutional filters.&lt;SEP&gt;A common CNN architecture suitable for image tasks with varying complexity and performance requirements.&lt;SEP&gt;VGGNet是牛津大学提出的卷积神经网络模型，采用堆积的小卷积核替代大的卷积核，以增加判别性并减少参数量。</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003332</data>
      <data key="d6" />
    </node>
    <node id="GoogLeNet">
      <data key="d0">GoogLeNet</data>
      <data key="d1">artifact</data>
      <data key="d2">A CNN architecture that introduced the Inception module for efficient computation.&lt;SEP&gt;A common CNN architecture suitable for image tasks with varying complexity and performance requirements.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003170</data>
      <data key="d6" />
    </node>
    <node id="ResNet">
      <data key="d0">ResNet</data>
      <data key="d1">method</data>
      <data key="d2">Residual Network, a CNN architecture featuring skip connections that enable the training of very deep networks.&lt;SEP&gt;A common CNN architecture suitable for image tasks with varying complexity and performance requirements.&lt;SEP&gt;ResNet是一种卷积神经网络，解决了网络模型的退化问题，允许神经网络变得更深。&lt;SEP&gt;ResNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009806</data>
      <data key="d6" />
    </node>
    <node id="Watson Studio">
      <data key="d0">Watson Studio</data>
      <data key="d1">artifact</data>
      <data key="d2">An IBM platform for data scientists and AI developers to build, train, and manage models.&lt;SEP&gt;An IBM platform that provides tools for building, training, tuning, and deploying CNN models as part of end-to-end solutions for image recognition and intelligent vision.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003171</data>
      <data key="d6" />
    </node>
    <node id="watsonx.ai">
      <data key="d0">watsonx.ai</data>
      <data key="d1">artifact</data>
      <data key="d2">An IBM enterprise AI and data platform for building and scaling AI.&lt;SEP&gt;An IBM platform that provides tools for building, training, tuning, and deploying CNN models as part of end-to-end solutions for image recognition and intelligent vision.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003171</data>
      <data key="d6" />
    </node>
    <node id="Medical Imaging Diagnosis">
      <data key="d0">Medical Imaging Diagnosis</data>
      <data key="d1">concept</data>
      <data key="d2">An application area where CNNs are widely used, exemplified by deployment support on platforms like IBM's.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003173</data>
      <data key="d6" />
    </node>
    <node id="Autonomous Driving Perception">
      <data key="d0">Autonomous Driving Perception</data>
      <data key="d1">concept</data>
      <data key="d2">An application area where CNNs are widely used, exemplified by deployment support on platforms like IBM's.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003173</data>
      <data key="d6" />
    </node>
    <node id="Intelligent Security">
      <data key="d0">Intelligent Security</data>
      <data key="d1">concept</data>
      <data key="d2">An application area where CNNs are widely used, exemplified by deployment support on platforms like IBM's.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003173</data>
      <data key="d6" />
    </node>
    <node id="Facial Recognition">
      <data key="d0">Facial Recognition</data>
      <data key="d1">concept</data>
      <data key="d2">An application area where CNNs are widely used.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003174</data>
      <data key="d6" />
    </node>
    <node id="Industrial Defect Detection">
      <data key="d0">Industrial Defect Detection</data>
      <data key="d1">concept</data>
      <data key="d2">An application area where CNNs are widely used.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003174</data>
      <data key="d6" />
    </node>
    <node id="Retail Visual Search">
      <data key="d0">Retail Visual Search</data>
      <data key="d1">concept</data>
      <data key="d2">An application area where CNNs are widely used.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003174</data>
      <data key="d6" />
    </node>
    <node id="Traditional Feedforward Neural Network">
      <data key="d0">Traditional Feedforward Neural Network</data>
      <data key="d1">concept</data>
      <data key="d2">A type of neural network compared to which CNNs possess parameter sharing and local receptive field capabilities, making them more efficient for processing structured data like images and audio.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003174</data>
      <data key="d6" />
    </node>
    <node id="Parameter Sharing">
      <data key="d0">Parameter Sharing</data>
      <data key="d1">concept</data>
      <data key="d2">A capability of Convolutional Neural Networks (CNNs) that contributes to their efficiency compared to traditional feedforward neural networks by reducing the number of model parameters.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003174</data>
      <data key="d6" />
    </node>
    <node id="Local Receptive Field">
      <data key="d0">Local Receptive Field</data>
      <data key="d1">concept</data>
      <data key="d2">A capability of Convolutional Neural Networks (CNNs) that allows them to focus on local regions of input data (like image patches), contributing to efficiency in processing structured data.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003175</data>
      <data key="d6" />
    </node>
    <node id="Mixture of Experts">
      <data key="d0">Mixture of Experts</data>
      <data key="d1">content</data>
      <data key="d2">A series or episode (Episode 85, December 12th) mentioned in the text, though its direct connection to CNN is not elaborated.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003175</data>
      <data key="d6" />
    </node>
    <node id="Image Recognition">
      <data key="d0">Image Recognition</data>
      <data key="d1">concept</data>
      <data key="d2">A primary task that Convolutional Neural Networks (CNNs) are designed for, involving the identification of objects or features within images.&lt;SEP&gt;Image recognition is one of the many practical applications of deep learning technology.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003863</data>
      <data key="d6" />
    </node>
    <node id="Structured Data">
      <data key="d0">Structured Data</data>
      <data key="d1">concept</data>
      <data key="d2">Data with a high degree of organization, such as images and audio, which CNNs are particularly efficient at processing.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003176</data>
      <data key="d6" />
    </node>
    <node id="RGB">
      <data key="d0">RGB</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the three color channels (Red, Green, Blue) that constitute the depth dimension of a color image input for a CNN.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003177</data>
      <data key="d6" />
    </node>
    <node id="Receptive Field">
      <data key="d0">Receptive Field</data>
      <data key="d1">concept</data>
      <data key="d2">The region in the input space (e.g., a patch of an image) that a particular CNN filter's features are responsive to.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003177</data>
      <data key="d6" />
    </node>
    <node id="Non-Linearity">
      <data key="d0">Non-Linearity</data>
      <data key="d1">concept</data>
      <data key="d2">A property introduced into CNN models through transformations like ReLU, enabling them to learn and represent more complex patterns.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003177</data>
      <data key="d6" />
    </node>
    <node id="Overfitting">
      <data key="d0">Overfitting</data>
      <data key="d1">concept</data>
      <data key="d2">A risk in machine learning where a model performs well on training data but poorly on unseen data; pooling layers in CNNs help limit this risk.&lt;SEP&gt;A risk where deep learning models perform well on training data but poorly on unseen data due to memorizing historical noise instead of genuine market patterns.</data>
      <data key="d3">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004938</data>
      <data key="d6" />
    </node>
    <node id="影像分析">
      <data key="d0">影像分析</data>
      <data key="d1">concept</data>
      <data key="d2">A field of computer vision that involves analyzing images to extract information.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003178</data>
      <data key="d6" />
    </node>
    <node id="自动驾驶感知">
      <data key="d0">自动驾驶感知</data>
      <data key="d1">concept</data>
      <data key="d2">A field of computer vision focused on enabling autonomous vehicles to perceive their environment.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003178</data>
      <data key="d6" />
    </node>
    <node id="安防监控">
      <data key="d0">安防监控</data>
      <data key="d1">concept</data>
      <data key="d2">A field of computer vision applied to security and surveillance systems.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003178</data>
      <data key="d6" />
    </node>
    <node id="人脸识别">
      <data key="d0">人脸识别</data>
      <data key="d1">artifact</data>
      <data key="d2">A technology within computer vision used to identify or verify individuals from images or video.&lt;SEP&gt;Facial Recognition is a technology that identifies or verifies a person from a digital image or video frame.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008500</data>
      <data key="d6" />
    </node>
    <node id="工业缺陷检测">
      <data key="d0">工业缺陷检测</data>
      <data key="d1">concept</data>
      <data key="d2">A computer vision application for identifying defects in industrial manufacturing processes.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003179</data>
      <data key="d6" />
    </node>
    <node id="零售视觉搜索">
      <data key="d0">零售视觉搜索</data>
      <data key="d1">concept</data>
      <data key="d2">A computer vision application in retail that allows searching for products using images.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003179</data>
      <data key="d6" />
    </node>
    <node id="计算机视觉模型">
      <data key="d0">计算机视觉模型</data>
      <data key="d1">concept</data>
      <data key="d2">A type of AI model designed to process and interpret visual information from the world.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003179</data>
      <data key="d6" />
    </node>
    <node id="智能视觉解决方案">
      <data key="d0">智能视觉解决方案</data>
      <data key="d1">concept</data>
      <data key="d2">Comprehensive AI-driven solutions that leverage computer vision to solve business problems.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003180</data>
      <data key="d6" />
    </node>
    <node id="AI模型">
      <data key="d0">AI模型</data>
      <data key="d1">concept</data>
      <data key="d2">Artificial Intelligence model, a mathematical framework for making predictions or decisions based on data.&lt;SEP&gt;AI模型是人工智能领域的核心，通过模拟人类智能的方式使机器能够执行复杂任务，涵盖了机器学习、自然语言处理、计算机视觉等多个方面。</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008505</data>
      <data key="d6" />
    </node>
    <node id="语言">
      <data key="d0">语言</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to language models or AI capabilities related to natural language processing.&lt;SEP&gt;语言是人类感官之一，在人工智能中对应自然语言处理技术。&lt;SEP&gt;语言在大语言模型中是核心，它不仅是模型的学习对象，也是推理过程中用于生成和理解的基础，模型通过训练掌握语言的使用规则和模式。&lt;SEP&gt;语言帮助人类表达思想和情感，并使得人类能够以创造性的方式运用。</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008449</data>
      <data key="d6" />
    </node>
    <node id="代码">
      <data key="d0">代码</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to code models or AI capabilities related to programming and software development.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003173</data>
      <data key="d6" />
    </node>
    <node id="护栏选项">
      <data key="d0">护栏选项</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to guardrail options or safety features for controlling AI model behavior.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003173</data>
      <data key="d6" />
    </node>
    <node id="报告2024年AI实际应用">
      <data key="d0">报告2024年AI实际应用</data>
      <data key="d1">content</data>
      <data key="d2">A report on the practical application of AI in 2024, based on a survey of organizations.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003174</data>
      <data key="d6" />
    </node>
    <node id="指南面向CEO的生成式AI指南">
      <data key="d0">指南面向CEO的生成式AI指南</data>
      <data key="d1">content</data>
      <data key="d2">A guide for CEOs on generative AI, focusing on balancing value, investment, and risk.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003174</data>
      <data key="d6" />
    </node>
    <node id="图像任务">
      <data key="d0">图像任务</data>
      <data key="d1">concept</data>
      <data key="d2">Image tasks refer to various applications and problems in computer vision that require processing and analyzing visual data.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003176</data>
      <data key="d6" />
    </node>
    <node id="数据集">
      <data key="d0">数据集</data>
      <data key="d1">data</data>
      <data key="d2">A dataset is a collection of data used for training, validating, and testing AI models.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003177</data>
      <data key="d6" />
    </node>
    <node id="性能">
      <data key="d0">性能</data>
      <data key="d1">concept</data>
      <data key="d2">Performance refers to the effectiveness and efficiency of an AI model in completing its intended tasks.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003177</data>
      <data key="d6" />
    </node>
    <node id="成本">
      <data key="d0">成本</data>
      <data key="d1">concept</data>
      <data key="d2">Cost refers to the financial expenditure associated with developing, training, deploying, and maintaining an AI model.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003177</data>
      <data key="d6" />
    </node>
    <node id="风险">
      <data key="d0">风险</data>
      <data key="d1">concept</data>
      <data key="d2">Risk refers to potential negative outcomes or uncertainties associated with deploying and using AI models.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003177</data>
      <data key="d6" />
    </node>
    <node id="部署需求">
      <data key="d0">部署需求</data>
      <data key="d1">concept</data>
      <data key="d2">Deployment requirements refer to the technical and operational needs for integrating an AI model into a production environment.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003178</data>
      <data key="d6" />
    </node>
    <node id="利益相关者要求">
      <data key="d0">利益相关者要求</data>
      <data key="d1">concept</data>
      <data key="d2">Stakeholder requirements refer to the needs and expectations of all parties affected by the AI model's development and use.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003178</data>
      <data key="d6" />
    </node>
    <node id="最佳模型">
      <data key="d0">最佳模型</data>
      <data key="d1">concept</data>
      <data key="d2">The best model refers to the optimal AI model selected after balancing various factors like performance, cost, and requirements.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003178</data>
      <data key="d6" />
    </node>
    <node id="AI计划">
      <data key="d0">AI计划</data>
      <data key="d1">concept</data>
      <data key="d2">AI plans refer to the strategies and initiatives organizations undertake to adopt and implement artificial intelligence.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003179</data>
      <data key="d6" />
    </node>
    <node id="投资">
      <data key="d0">投资</data>
      <data key="d1">concept</data>
      <data key="d2">Investment refers to the allocation of resources, typically financial, into AI technologies and projects.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003179</data>
      <data key="d6" />
    </node>
    <node id="回报">
      <data key="d0">回报</data>
      <data key="d1">concept</data>
      <data key="d2">Return refers to the benefits or value gained from investments in AI.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003187</data>
      <data key="d6" />
    </node>
    <node id="关键工作流程">
      <data key="d0">关键工作流程</data>
      <data key="d1">concept</data>
      <data key="d2">Key workflows are essential business processes that can be transformed or enhanced through AI integration.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003187</data>
      <data key="d6" />
    </node>
    <node id="体验">
      <data key="d0">体验</data>
      <data key="d1">concept</data>
      <data key="d2">Experience refers to the user or customer experience that can be improved through AI applications.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003180</data>
      <data key="d6" />
    </node>
    <node id="实时决策">
      <data key="d0">实时决策</data>
      <data key="d1">concept</data>
      <data key="d2">Real-time decision making involves making immediate choices based on data analysis, a capability enhanced by AI.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003180</data>
      <data key="d6" />
    </node>
    <node id="商业价值">
      <data key="d0">商业价值</data>
      <data key="d1">concept</data>
      <data key="d2">Business value refers to the economic benefits and competitive advantages gained from implementing AI solutions.</data>
      <data key="d3">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003181</data>
      <data key="d6" />
    </node>
    <node id="人工神经元">
      <data key="d0">人工神经元</data>
      <data key="d1">concept</data>
      <data key="d2">人工神经元是神经网络的基本计算单元，可以响应特定范围内的输入信号。</data>
      <data key="d3">chunk-df57bc33c49fe522c66616c1a4be5336</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003216</data>
      <data key="d6" />
    </node>
    <node id="大型图像处理">
      <data key="d0">大型图像处理</data>
      <data key="d1">concept</data>
      <data key="d2">大型图像处理是指对尺寸或分辨率较高的图像进行分析和操作的计算任务。</data>
      <data key="d3">chunk-df57bc33c49fe522c66616c1a4be5336</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003216</data>
      <data key="d6" />
    </node>
    <node id="Pooling">
      <data key="d0">Pooling</data>
      <data key="d1">concept</data>
      <data key="d2">Pooling是池化层的英文术语，意为汇聚或淤积，在神经网络中用于降维和特征提取。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003331</data>
      <data key="d6" />
    </node>
    <node id="最大池化">
      <data key="d0">最大池化</data>
      <data key="d1">method</data>
      <data key="d2">最大池化是一种池化运算，在一个小矩阵中寻找最大值以提取主要特征。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003331</data>
      <data key="d6" />
    </node>
    <node id="平均池化">
      <data key="d0">平均池化</data>
      <data key="d1">method</data>
      <data key="d2">平均池化是一种池化运算，在一个小矩阵中计算平均值以提取特征。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003324</data>
      <data key="d6" />
    </node>
    <node id="过拟合">
      <data key="d0">过拟合</data>
      <data key="d1">concept</data>
      <data key="d2">过拟合是机器学习模型在训练数据上表现过好，在未见数据上表现差的现象，在全连接层数多时容易发生。&lt;SEP&gt;过拟合是机器学习中的一个问题，指模型在训练数据上表现过好，但在新数据上泛化能力差。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003324</data>
      <data key="d6" />
    </node>
    <node id="福岛邦彦">
      <data key="d0">福岛邦彦</data>
      <data key="d1">person</data>
      <data key="d2">福岛邦彦是日本学者，受生物视觉系统研究启发，提出了层级化的人工神经网络“神经认知模型”，被认为是卷积神经网络的前身。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003327</data>
      <data key="d6" />
    </node>
    <node id="神经认知模型">
      <data key="d0">神经认知模型</data>
      <data key="d1">concept</data>
      <data key="d2">神经认知模型是福岛邦彦提出的层级化人工神经网络，用于处理手写字符识别问题。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003327</data>
      <data key="d6" />
    </node>
    <node id="Yann LeCun">
      <data key="d0">Yann LeCun</data>
      <data key="d1">person</data>
      <data key="d2">Yann LeCun是法国学者，在1998年提出了基于梯度学习的卷积神经网络算法LeNet，广泛应用于手写数字和字符识别。&lt;SEP&gt;Yann LeCun is a co-author of the 2015 Nature review article on deep learning.&lt;SEP&gt;Another foundational figure in deep learning. Inspired by the principles of the nervous system, he extended the organizational structure of the brain's visual system to artificial neural networks, inventing Convolutional Neural Networks (CNNs) for efficient handwritten digit recognition.</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003867</data>
      <data key="d6" />
    </node>
    <node id="LeNet">
      <data key="d0">LeNet</data>
      <data key="d1">artifact</data>
      <data key="d2">LeNet是由Yann LeCun等人提出的卷积神经网络算法，被广泛应用于美国邮政系统的手写数字和字符识别。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003337</data>
      <data key="d6" />
    </node>
    <node id="ImageNet竞赛">
      <data key="d0">ImageNet竞赛</data>
      <data key="d1">event</data>
      <data key="d2">ImageNet竞赛是计算机视觉领域的重要比赛，有“世界杯”之称。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003337</data>
      <data key="d6" />
    </node>
    <node id="Hinton">
      <data key="d0">Hinton</data>
      <data key="d1">person</data>
      <data key="d2">Hinton是研究人员，在2012年ImageNet竞赛中凭借AlexNet一举夺魁。&lt;SEP&gt;Hinton is a person whose interview is included in the book "Talking Nets".</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003884</data>
      <data key="d6" />
    </node>
    <node id="Facebook">
      <data key="d0">Facebook</data>
      <data key="d1">organization</data>
      <data key="d2">Facebook是一家科技公司，投入巨资研究卷积神经网络的变体。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003331</data>
      <data key="d6" />
    </node>
    <node id="微软">
      <data key="d0">微软</data>
      <data key="d1">organization</data>
      <data key="d2">微软是一家科技公司，投入巨资研究卷积神经网络的变体。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003331</data>
      <data key="d6" />
    </node>
    <node id="BAT">
      <data key="d0">BAT</data>
      <data key="d1">organization</data>
      <data key="d2">BAT是国内科技公司的简称，投入巨资研究卷积神经网络的变体。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003331</data>
      <data key="d6" />
    </node>
    <node id="ZFNet">
      <data key="d0">ZFNet</data>
      <data key="d1">artifact</data>
      <data key="d2">ZFNet是一种卷积神经网络变体，通过可视化展示了卷积神经网络各层的功能和作用。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003332</data>
      <data key="d6" />
    </node>
    <node id="GoogleNet">
      <data key="d0">GoogleNet</data>
      <data key="d1">method</data>
      <data key="d2">GoogleNet是一种卷积神经网络，增加了网络的宽度，使用1x1卷积降维减少参数量，并在多个不同尺寸的卷积核上进行卷积后再聚合。&lt;SEP&gt;GoogleNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009806</data>
      <data key="d6" />
    </node>
    <node id="MNIST模型">
      <data key="d0">MNIST模型</data>
      <data key="d1">artifact</data>
      <data key="d2">MNIST模型是一个用于图像分类任务的卷积神经网络示例，其数据集已集成在主流框架中。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003333</data>
      <data key="d6" />
    </node>
    <node id="交叉熵">
      <data key="d0">交叉熵</data>
      <data key="d1">concept</data>
      <data key="d2">交叉熵是一种损失函数，常用于图像分类任务中。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003334</data>
      <data key="d6" />
    </node>
    <node id="SGD">
      <data key="d0">SGD</data>
      <data key="d1">method</data>
      <data key="d2">SGD是一种优化器，用于训练神经网络，学习率可设置为0.1。&lt;SEP&gt;SGD是随机梯度下降的缩写，是一种优化算法。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003716</data>
      <data key="d6" />
    </node>
    <node id="局部池化">
      <data key="d0">局部池化</data>
      <data key="d1">method</data>
      <data key="d2">局部池化是一种池化操作，通常选择2x2的矩阵来减少数据维度。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003335</data>
      <data key="d6" />
    </node>
    <node id="2x2矩阵">
      <data key="d0">2x2矩阵</data>
      <data key="d1">concept</data>
      <data key="d2">2x2矩阵是局部池化操作中常用的小矩阵尺寸。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003335</data>
      <data key="d6" />
    </node>
    <node id="手写字符识别">
      <data key="d0">手写字符识别</data>
      <data key="d1">concept</data>
      <data key="d2">手写字符识别是早期卷积神经网络前身“神经认知模型”处理的问题。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003336</data>
      <data key="d6" />
    </node>
    <node id="美国邮政系统">
      <data key="d0">美国邮政系统</data>
      <data key="d1">organization</data>
      <data key="d2">美国邮政系统是LeNet算法被广泛应用进行手写数字和字符识别的机构。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003336</data>
      <data key="d6" />
    </node>
    <node id="层叠的卷积层">
      <data key="d0">层叠的卷积层</data>
      <data key="d1">concept</data>
      <data key="d2">层叠的卷积层是AlexNet使用的结构，用于获取特征，使网络更深更大。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003337</data>
      <data key="d6" />
    </node>
    <node id="超高识别率">
      <data key="d0">超高识别率</data>
      <data key="d1">concept</data>
      <data key="d2">超高识别率是AlexNet在ImageNet竞赛中表现出的性能，展示了卷积神经网络的潜力。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003337</data>
      <data key="d6" />
    </node>
    <node id="牛津大学">
      <data key="d0">牛津大学</data>
      <data key="d1">organization</data>
      <data key="d2">牛津大学是提出VGGNet模型的机构。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003337</data>
      <data key="d6" />
    </node>
    <node id="1x1卷积">
      <data key="d0">1x1卷积</data>
      <data key="d1">method</data>
      <data key="d2">1x1卷积是GoogleNet中使用的一种卷积操作，用于降维和减少参数量。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003337</data>
      <data key="d6" />
    </node>
    <node id="网络模型退化问题">
      <data key="d0">网络模型退化问题</data>
      <data key="d1">concept</data>
      <data key="d2">网络模型退化问题是ResNet解决的核心问题，允许构建更深的神经网络。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003338</data>
      <data key="d6" />
    </node>
    <node id="Conv2d">
      <data key="d0">Conv2d</data>
      <data key="d1">method</data>
      <data key="d2">Conv2d是PyTorch框架中用于定义二维卷积层的函数。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003338</data>
      <data key="d6" />
    </node>
    <node id="MaxPool2d">
      <data key="d0">MaxPool2d</data>
      <data key="d1">method</data>
      <data key="d2">MaxPool2d是PyTorch框架中用于定义最大池化层的函数。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003338</data>
      <data key="d6" />
    </node>
    <node id="Linear">
      <data key="d0">Linear</data>
      <data key="d1">method</data>
      <data key="d2">Linear是PyTorch框架中用于定义全连接层的函数。</data>
      <data key="d3">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003339</data>
      <data key="d6" />
    </node>
    <node id="特征图">
      <data key="d0">特征图</data>
      <data key="d1">concept</data>
      <data key="d2">特征图是卷积运算得到的结果，其上的每个点由上一层若干个点共同决定，点的集合范围称为感受野。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003340</data>
      <data key="d6" />
    </node>
    <node id="感受野">
      <data key="d0">感受野</data>
      <data key="d1">concept</data>
      <data key="d2">感受野是特征图上每个点所依赖的上一层点的范围(如3x3卷积核对应9个点)，网络层数越多，感受野越大，越能捕捉更大尺寸的特征。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003340</data>
      <data key="d6" />
    </node>
    <node id="深度卷积网络">
      <data key="d0">深度卷积网络</data>
      <data key="d1">concept</data>
      <data key="d2">深度卷积网络是通过层层堆叠卷积层构成的网络，层数越多，对复杂特征的表达能力越强。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003341</data>
      <data key="d6" />
    </node>
    <node id="数字化信号">
      <data key="d0">数字化信号</data>
      <data key="d1">data</data>
      <data key="d2">数字化信号是卷积神经网络输入层可以接收的数据形式，包括文字、语音、图像、视频等。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003343</data>
      <data key="d6" />
    </node>
    <node id="手写体数字">
      <data key="d0">手写体数字</data>
      <data key="d1">content</data>
      <data key="d2">手写体数字是卷积神经网络进行识别任务的一个具体输入示例，输出对应0-9这10个数字的分类。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003343</data>
      <data key="d6" />
    </node>
    <node id="车型">
      <data key="d0">车型</data>
      <data key="d1">content</data>
      <data key="d2">车型是卷积神经网络进行识别任务的另一个具体输入示例，输出对应奔驰、宝马、奥迪等品牌的概率。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003343</data>
      <data key="d6" />
    </node>
    <node id="计算机学者">
      <data key="d0">计算机学者</data>
      <data key="d1">person</data>
      <data key="d2">计算机学者是受生理学家和数学家启发而创造卷积神经网络等模型的研究人员。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003344</data>
      <data key="d6" />
    </node>
    <node id="生理学家">
      <data key="d0">生理学家</data>
      <data key="d1">person</data>
      <data key="d2">生理学家是启发计算机学者创造卷积神经网络等模型的科学家之一。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003344</data>
      <data key="d6" />
    </node>
    <node id="数学家">
      <data key="d0">数学家</data>
      <data key="d1">person</data>
      <data key="d2">数学家是启发计算机学者创造卷积神经网络等模型的科学家之一。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003344</data>
      <data key="d6" />
    </node>
    <node id="二维图像">
      <data key="d0">二维图像</data>
      <data key="d1">data</data>
      <data key="d2">二维图像是卷积运算(如使用3x3卷积核)进行特征提取的一个具体应用场景。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003344</data>
      <data key="d6" />
    </node>
    <node id="二维离散卷积">
      <data key="d0">二维离散卷积</data>
      <data key="d1">method</data>
      <data key="d2">二维离散卷积是卷积层中用于特征提取的数学操作，将全连接变为局部连接。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003345</data>
      <data key="d6" />
    </node>
    <node id="空间平移不变性">
      <data key="d0">空间平移不变性</data>
      <data key="d1">concept</data>
      <data key="d2">空间平移不变性是卷积核具备的特性，指对于图像中的目标，无论其位置如何，卷积核都能识别出来。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003352</data>
      <data key="d6" />
    </node>
    <node id="图像分类">
      <data key="d0">图像分类</data>
      <data key="d1">method</data>
      <data key="d2">图像分类是深度卷积网络的一个应用示例，通过逐层卷积学习边缘、花纹、物体部位等特征。&lt;SEP&gt;图像分类是一种深度学习应用，将输入的二维像素矩阵处理后输出类别标签，属于一对一问题。</data>
      <data key="d3">chunk-0424a179537a1b36c1d9bf13f9a5a922&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006991</data>
      <data key="d6" />
    </node>
    <node id="自编码器">
      <data key="d0">自编码器</data>
      <data key="d1">method</data>
      <data key="d2">自编码器是一种执行无监督学习任务的神经网络结构，旨在学习数据的重新表达或编码。&lt;SEP&gt;自编码器是一种前馈神经网络，最初用于数据降维和特征提取，现在也用于生成模型，例如生成图片。</data>
      <data key="d3">chunk-e101b215c048456f8049a66e9ebd2c54&lt;SEP&gt;chunk-0c8c61555719c99f2248173e3fd5ae4f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003448</data>
      <data key="d6" />
    </node>
    <node id="编码">
      <data key="d0">编码</data>
      <data key="d1">concept</data>
      <data key="d2">编码是自编码器学习的目标，即对输入数据的一种重新表达。</data>
      <data key="d3">chunk-e101b215c048456f8049a66e9ebd2c54</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003379</data>
      <data key="d6" />
    </node>
    <node id="深度前馈神经网络">
      <data key="d0">深度前馈神经网络</data>
      <data key="d1">concept</data>
      <data key="d2">深度前馈神经网络是一种包含若干隐藏层的网络结构，自编码器属于此类结构。</data>
      <data key="d3">chunk-e101b215c048456f8049a66e9ebd2c54</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003379</data>
      <data key="d6" />
    </node>
    <node id="Auto-Encoder">
      <data key="d0">Auto-Encoder</data>
      <data key="d1">concept</data>
      <data key="d2">Auto-encoder is a type of neural network structure that performs unsupervised learning tasks, aiming to learn a re-expression or encoding of data.</data>
      <data key="d3">chunk-e101b215c048456f8049a66e9ebd2c54</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003387</data>
      <data key="d6" />
    </node>
    <node id="序列">
      <data key="d0">序列</data>
      <data key="d1">concept</data>
      <data key="d2">序列是需要被编码的数据形式，是深度学习中卷积神经网络或循环神经网络处理的对象。</data>
      <data key="d3">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003406</data>
      <data key="d6" />
    </node>
    <node id="注意力机制">
      <data key="d0">注意力机制</data>
      <data key="d1">concept</data>
      <data key="d2">注意力机制是一种模型组件，在深度学习中用于增强对输入信息的聚焦能力。</data>
      <data key="d3">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003407</data>
      <data key="d6" />
    </node>
    <node id="词元序列">
      <data key="d0">词元序列</data>
      <data key="d1">data</data>
      <data key="d2">词元序列是输入到注意力池化中的具体数据形式，由一系列词元组成。</data>
      <data key="d3">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003407</data>
      <data key="d6" />
    </node>
    <node id="注意力池化">
      <data key="d0">注意力池化</data>
      <data key="d1">method</data>
      <data key="d2">注意力池化是一种处理方法，接收词元序列作为输入，并利用注意力机制进行信息聚合。</data>
      <data key="d3">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003407</data>
      <data key="d6" />
    </node>
    <node id="自动编码器">
      <data key="d0">自动编码器</data>
      <data key="d1">concept</data>
      <data key="d2">自动编码器是一种神经网络，通常包括编码器和解码器两部分，它们串联合作以实现数据降维或特征学习，并广泛用于生成模型。</data>
      <data key="d3">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003436</data>
      <data key="d6" />
    </node>
    <node id="数据降维">
      <data key="d0">数据降维</data>
      <data key="d1">concept</data>
      <data key="d2">数据降维是减少数据集中变量数量的过程，是自动编码器的应用之一。</data>
      <data key="d3">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003437</data>
      <data key="d6" />
    </node>
    <node id="特征学习">
      <data key="d0">特征学习</data>
      <data key="d1">concept</data>
      <data key="d2">特征学习是从原始数据中自动发现有用表示的过程，是自动编码器的应用之一。</data>
      <data key="d3">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003437</data>
      <data key="d6" />
    </node>
    <node id="生成模型">
      <data key="d0">生成模型</data>
      <data key="d1">concept</data>
      <data key="d2">生成模型是能够生成新数据的模型，自动编码器现在被广泛用于此领域。</data>
      <data key="d3">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003438</data>
      <data key="d6" />
    </node>
    <node id="AutoEncoder">
      <data key="d0">AutoEncoder</data>
      <data key="d1">concept</data>
      <data key="d2">AutoEncoder is a type of neural network, generally consisting of two parts: an encoder and a decoder, which work in series to achieve data dimensionality reduction or feature learning, and is now widely used in generative models.</data>
      <data key="d3">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003439</data>
      <data key="d6" />
    </node>
    <node id="有监督学习">
      <data key="d0">有监督学习</data>
      <data key="d1">method</data>
      <data key="d2">有监督学习是一种机器学习方法。</data>
      <data key="d3">chunk-0c8c61555719c99f2248173e3fd5ae4f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003448</data>
      <data key="d6" />
    </node>
    <node id="Encoder-Decoder Architecture">
      <data key="d0">Encoder-Decoder Architecture</data>
      <data key="d1">concept</data>
      <data key="d2">An architecture used in AI models, particularly for sequence-to-sequence tasks like machine translation.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003513</data>
      <data key="d6" />
    </node>
    <node id="Generative AI">
      <data key="d0">Generative AI</data>
      <data key="d1">concept</data>
      <data key="d2">A type of artificial intelligence focused on creating new content, such as text or code.&lt;SEP&gt;A field of artificial intelligence catalyzed by the development of large language models like GPT-3, focused on creating new content.&lt;SEP&gt;Generative AI refers to AI models capable of generating content, such as text or images, and is a core service offered on Google Cloud's Vertex AI platform.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686&lt;SEP&gt;chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009402</data>
      <data key="d6" />
    </node>
    <node id="Foundation Models">
      <data key="d0">Foundation Models</data>
      <data key="d1">concept</data>
      <data key="d2">Large-scale AI models trained on broad data that can be adapted to a wide range of downstream tasks.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003515</data>
      <data key="d6" />
    </node>
    <node id="IBM Privacy Statement">
      <data key="d0">IBM Privacy Statement</data>
      <data key="d1">content</data>
      <data key="d2">A document outlining IBM's privacy policies and practices.&lt;SEP&gt;The IBM Privacy Statement is referenced in relation to the Think Newsletter subscription and data management.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005499</data>
      <data key="d6" />
    </node>
    <node id="Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition">
      <data key="d0">Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition</data>
      <data key="d1">content</data>
      <data key="d2">A textbook by Martin, J. (Third edition, 2023) covering NLP, computational linguistics, and speech recognition.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003524</data>
      <data key="d6" />
    </node>
    <node id="Natural Language Processing with Transformers">
      <data key="d0">Natural Language Processing with Transformers</data>
      <data key="d1">content</data>
      <data key="d2">A book (Revised Edition, O’Reilly, 2022) about applying transformer models to NLP tasks.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003524</data>
      <data key="d6" />
    </node>
    <node id="Neural network methods for Natural Language Processing">
      <data key="d0">Neural network methods for Natural Language Processing</data>
      <data key="d1">content</data>
      <data key="d2">A book (Springer, 2022) on neural network techniques for NLP.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003525</data>
      <data key="d6" />
    </node>
    <node id="Hands-on Large Language Models">
      <data key="d0">Hands-on Large Language Models</data>
      <data key="d1">content</data>
      <data key="d2">A book (O’Reilly, 2024) providing practical guidance on working with large language models.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003525</data>
      <data key="d6" />
    </node>
    <node id="Transformers for Natural Language Processing">
      <data key="d0">Transformers for Natural Language Processing</data>
      <data key="d1">content</data>
      <data key="d2">A book (Second Edition, 2022) focused on transformer models in NLP.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003525</data>
      <data key="d6" />
    </node>
    <node id="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding">
      <data key="d0">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</data>
      <data key="d1">content</data>
      <data key="d2">A seminal research paper (2019) introducing the BERT model for language understanding.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003525</data>
      <data key="d6" />
    </node>
    <node id="IBM Granite Large Language Models Whitepaper">
      <data key="d0">IBM Granite Large Language Models Whitepaper</data>
      <data key="d1">content</data>
      <data key="d2">A whitepaper (2024) detailing IBM's Granite series of large language models.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003526</data>
      <data key="d6" />
    </node>
    <node id="Natural Language Processing">
      <data key="d0">Natural Language Processing</data>
      <data key="d1">concept</data>
      <data key="d2">A subfield of AI focused on enabling computers to understand, interpret, and generate human language.&lt;SEP&gt;A research direction applied in biomedicine by Nankai Statistics.&lt;SEP&gt;Natural Language Processing (NLP) is a field of artificial intelligence focused on enabling computers to understand, interpret, and generate human language.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-95ce0b0b365782f95d313a054721a437&lt;SEP&gt;chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007311</data>
      <data key="d6" />
    </node>
    <node id="Computational Linguistics">
      <data key="d0">Computational Linguistics</data>
      <data key="d1">concept</data>
      <data key="d2">An interdisciplinary field concerned with the computational modeling of natural language.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003527</data>
      <data key="d6" />
    </node>
    <node id="Speech Recognition">
      <data key="d0">Speech Recognition</data>
      <data key="d1">concept</data>
      <data key="d2">The technology that enables the recognition and translation of spoken language into text by computers.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003527</data>
      <data key="d6" />
    </node>
    <node id="Transformers">
      <data key="d0">Transformers</data>
      <data key="d1">artifact</data>
      <data key="d2">A deep learning model architecture that relies on self-attention mechanisms, foundational for modern NLP.&lt;SEP&gt;Transformers is an NLP package developed by Hugging Face for loading most pre-trained models.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008016</data>
      <data key="d6" />
    </node>
    <node id="Large Language Models">
      <data key="d0">Large Language Models</data>
      <data key="d1">concept</data>
      <data key="d2">A type of foundation model based on the transformer architecture, trained on massive text datasets.&lt;SEP&gt;A language model built from deep neural networks containing hundreds of billions of weights, trained using self-supervised learning on large amounts of unlabeled text.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-3678971988880bb3960a90e15878444d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008633</data>
      <data key="d6" />
    </node>
    <node id="BERT">
      <data key="d0">BERT</data>
      <data key="d1">method</data>
      <data key="d2">Bidirectional Encoder Representations from Transformers, a pre-trained transformer model for language understanding.&lt;SEP&gt;BERT is a pre-trained model based on the Transformer encoder that adapts the representation of the same token to different contexts.&lt;SEP&gt;BERT is a large-scale language model whose rise has increased adoption of the Transformers library.&lt;SEP&gt;BERT is a specific pre-trained language model designed to understand the context of words in search queries and text.&lt;SEP&gt;A transformer-based machine learning technique for natural language processing.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-747e06575d3f3c246eac89670d12c86e&lt;SEP&gt;chunk-07c6d2ca0b23fef78261afa6105b1fe0&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009207</data>
      <data key="d6" />
    </node>
    <node id="Martin, J.">
      <data key="d0">Martin, J.</data>
      <data key="d1">person</data>
      <data key="d2">An author of the textbook "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition".</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003528</data>
      <data key="d6" />
    </node>
    <node id="OReilly">
      <data key="d0">OReilly</data>
      <data key="d1">organization</data>
      <data key="d2">A publisher of technology and business books, including several cited works on NLP and Transformers.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003529</data>
      <data key="d6" />
    </node>
    <node id="Springer">
      <data key="d0">Springer</data>
      <data key="d1">organization</data>
      <data key="d2">A global publisher of academic books and journals, including works on neural network methods for NLP.</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003529</data>
      <data key="d6" />
    </node>
    <node id="AI News">
      <data key="d0">AI News</data>
      <data key="d3">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d2">The Think Newsletter provides curated insights and analysis on AI news.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003531</data>
      <data key="d6" />
    </node>
    <node id="多层感知机">
      <data key="d0">多层感知机</data>
      <data key="d1">concept</data>
      <data key="d2">多层感知机是一种前馈神经网络，最早由Frank Rosenblatt在1950年代提出，并在1980年代通过反向传播算法取得重大进展。&lt;SEP&gt;A type of deep network composed of multiple layers of neurons, where each layer is connected to the layers below (receiving input) and above (influencing the current layer).&lt;SEP&gt;多层感知机是一种前馈人工神经网络，包含一个或多个隐含层，用于增强模型的表达能力。</data>
      <data key="d3">chunk-93860b80c6ea559ea9b38a8562c8df8c&lt;SEP&gt;chunk-2bd963b40a794cdd2a7befd072b521f8&lt;SEP&gt;chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003694</data>
      <data key="d6" />
    </node>
    <node id="MLP">
      <data key="d0">MLP</data>
      <data key="d1">concept</data>
      <data key="d2">MLP是多层感知机的英文缩写，是一种前馈神经网络。</data>
      <data key="d3">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003560</data>
      <data key="d6" />
    </node>
    <node id="Frank Rosenblatt">
      <data key="d0">Frank Rosenblatt</data>
      <data key="d1">person</data>
      <data key="d2">Frank Rosenblatt在1950年代提出了多层感知机。</data>
      <data key="d3">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003560</data>
      <data key="d6" />
    </node>
    <node id="认知神经科学">
      <data key="d0">认知神经科学</data>
      <data key="d1">concept</data>
      <data key="d2">认知神经科学是输入文本中提到的研究领域。&lt;SEP&gt;认知神经科学是研究认知过程与神经机制之间关系的交叉学科领域。&lt;SEP&gt;The domain or field of study mentioned in the document metadata, which is cognitive neuroscience.&lt;SEP&gt;A field of study that combines cognitive psychology and neuroscience to understand the neural mechanisms underlying mental processes.&lt;SEP&gt;认知神经科学is the domain or field of study mentioned in the document metadata.&lt;SEP&gt;A field of study mentioned as the domain of the document.</data>
      <data key="d3">chunk-93860b80c6ea559ea9b38a8562c8df8c&lt;SEP&gt;chunk-88c27f8b7b31c4aea51cfc3d8f79a013&lt;SEP&gt;chunk-92f537cdcce6583c2c63c400d634feaf&lt;SEP&gt;chunk-03a5749c6bb89c89b202fa903dbb847f&lt;SEP&gt;chunk-3954d1f048ce5cd91b5693da96becc81&lt;SEP&gt;chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003989</data>
      <data key="d6" />
    </node>
    <node id="深度网络">
      <data key="d0">深度网络</data>
      <data key="d1">concept</data>
      <data key="d2">A type of artificial neural network with multiple layers, also referred to as a deep neural network.</data>
      <data key="d3">chunk-2bd963b40a794cdd2a7befd072b521f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003575</data>
      <data key="d6" />
    </node>
    <node id="Sigmoid">
      <data key="d0">Sigmoid</data>
      <data key="d1">method</data>
      <data key="d2">Sigmoid is an activation function in neural networks, with its gradient being a key property for backpropagation.</data>
      <data key="d3">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003605</data>
      <data key="d6" />
    </node>
    <node id="Tanh">
      <data key="d0">Tanh</data>
      <data key="d1">method</data>
      <data key="d2">Tanh is an activation function in neural networks, with its gradient being a key property for backpropagation.</data>
      <data key="d3">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003612</data>
      <data key="d6" />
    </node>
    <node id="Mathematical Proof">
      <data key="d0">Mathematical Proof</data>
      <data key="d1">concept</data>
      <data key="d2">A mathematical proof is a logical argument demonstrating the truth of a statement, such as the identity relating Tanh and Sigmoid.</data>
      <data key="d3">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003606</data>
      <data key="d6" />
    </node>
    <node id="Identity Tanh Plus One Equals Two Sigmoid Two X">
      <data key="d0">Identity Tanh Plus One Equals Two Sigmoid Two X</data>
      <data key="d1">concept</data>
      <data key="d2">This is a mathematical identity stating that tanh(x) + 1 equals 2 * sigmoid(2x), linking two activation functions.</data>
      <data key="d3">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003606</data>
      <data key="d6" />
    </node>
    <node id="线上机器学习">
      <data key="d0">线上机器学习</data>
      <data key="d1">concept</data>
      <data key="d2">Online machine learning is a method where models are updated continuously as new data arrives.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003675</data>
      <data key="d6" />
    </node>
    <node id="元学习">
      <data key="d0">元学习</data>
      <data key="d1">concept</data>
      <data key="d2">Meta-learning, or learning to learn, is a subfield of machine learning focused on how learning algorithms can be adapted.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003676</data>
      <data key="d6" />
    </node>
    <node id="半监督学习">
      <data key="d0">半监督学习</data>
      <data key="d1">concept</data>
      <data key="d2">Semi-supervised learning is a machine learning paradigm that uses a small amount of labeled data with a large amount of unlabeled data.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003676</data>
      <data key="d6" />
    </node>
    <node id="自监督学习">
      <data key="d0">自监督学习</data>
      <data key="d1">method</data>
      <data key="d2">Self-supervised learning is a machine learning paradigm where models generate their own supervisory signal from the data.&lt;SEP&gt;Self-supervised learning is a method widely used for pre-training text representations by predicting hidden parts of text using surrounding text.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006463</data>
      <data key="d6" />
    </node>
    <node id="强化学习">
      <data key="d0">强化学习</data>
      <data key="d1">method</data>
      <data key="d2">Reinforcement learning is a machine learning paradigm where an agent learns by interacting with an environment to maximize cumulative reward.&lt;SEP&gt;A concept from neuroscience integrated with deep learning by DeepMind. It was used to create AlphaGo.&lt;SEP&gt;强化学习是机器学习的一种范式，智能体通过与环境互动并基于奖励信号来学习采取行动。&lt;SEP&gt;强化学习是一种前沿技术，属于机器学习领域。&lt;SEP&gt;Reinforcement Learning is a type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties from the environment.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-432af570193bd3df6d564434ee8bfbbb&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008482</data>
      <data key="d6" />
    </node>
    <node id="基于规则的机器学习">
      <data key="d0">基于规则的机器学习</data>
      <data key="d1">concept</data>
      <data key="d2">Rule-based machine learning is a paradigm where the learning system constructs or modifies a set of rules.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003677</data>
      <data key="d6" />
    </node>
    <node id="量子机器学习">
      <data key="d0">量子机器学习</data>
      <data key="d1">concept</data>
      <data key="d2">Quantum machine learning explores the intersection of quantum computing and machine learning algorithms.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003677</data>
      <data key="d6" />
    </node>
    <node id="Q学习">
      <data key="d0">Q学习</data>
      <data key="d1">concept</data>
      <data key="d2">Q-learning is a model-free reinforcement learning algorithm for learning the value of actions in given states.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003678</data>
      <data key="d6" />
    </node>
    <node id="SARSA">
      <data key="d0">SARSA</data>
      <data key="d1">concept</data>
      <data key="d2">SARSA is an on-policy reinforcement learning algorithm for learning a Markov decision process policy.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003678</data>
      <data key="d6" />
    </node>
    <node id="时序差分">
      <data key="d0">时序差分</data>
      <data key="d1">concept</data>
      <data key="d2">Temporal-difference learning is a class of model-free reinforcement learning methods that learn by bootstrapping from the current estimate.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003678</data>
      <data key="d6" />
    </node>
    <node id="多智能体">
      <data key="d0">多智能体</data>
      <data key="d1">concept</data>
      <data key="d2">Multi-agent reinforcement learning involves multiple agents learning to interact in a shared environment.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003678</data>
      <data key="d6" />
    </node>
    <node id="Self-play">
      <data key="d0">Self-play</data>
      <data key="d1">concept</data>
      <data key="d2">Self-play is a reinforcement learning technique where an agent improves by playing against versions of itself.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003669</data>
      <data key="d6" />
    </node>
    <node id="RLHF">
      <data key="d0">RLHF</data>
      <data key="d1">method</data>
      <data key="d2">Reinforcement Learning from Human Feedback is a technique that aligns machine learning models with human preferences.&lt;SEP&gt;Reinforcement Learning from Human Feedback, a method for aligning AI with human values.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009207</data>
      <data key="d6" />
    </node>
    <node id="主动学习">
      <data key="d0">主动学习</data>
      <data key="d1">concept</data>
      <data key="d2">Active learning is a machine learning paradigm where the algorithm can query a user to label new data points.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003670</data>
      <data key="d6" />
    </node>
    <node id="众包">
      <data key="d0">众包</data>
      <data key="d1">concept</data>
      <data key="d2">Crowdsourcing involves obtaining input or data from a large group of people, often used for data labeling.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003670</data>
      <data key="d6" />
    </node>
    <node id="Human-in-the-loop">
      <data key="d0">Human-in-the-loop</data>
      <data key="d1">concept</data>
      <data key="d2">Human-in-the-loop is an approach that combines human and machine intelligence to solve problems.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003671</data>
      <data key="d6" />
    </node>
    <node id="学习曲线">
      <data key="d0">学习曲线</data>
      <data key="d1">concept</data>
      <data key="d2">A learning curve in machine learning is a plot that shows model performance as a function of training time or data size.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003671</data>
      <data key="d6" />
    </node>
    <node id="NeurIPS">
      <data key="d0">NeurIPS</data>
      <data key="d1">event</data>
      <data key="d2">NeurIPS is a leading annual conference in machine learning and computational neuroscience.&lt;SEP&gt;A major conference in the field of machine learning and computational neuroscience.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007943</data>
      <data key="d6" />
    </node>
    <node id="ICML">
      <data key="d0">ICML</data>
      <data key="d1">event</data>
      <data key="d2">The International Conference on Machine Learning is a premier annual machine learning conference.&lt;SEP&gt;The International Conference on Machine Learning, a premier academic conference.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007944</data>
      <data key="d6" />
    </node>
    <node id="ICLR">
      <data key="d0">ICLR</data>
      <data key="d1">event</data>
      <data key="d2">The International Conference on Learning Representations is a top-tier conference focused on representation learning.&lt;SEP&gt;The International Conference on Learning Representations, a top-tier conference focused on representation learning.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007946</data>
      <data key="d6" />
    </node>
    <node id="AAAI">
      <data key="d0">AAAI</data>
      <data key="d1">event</data>
      <data key="d2">The AAAI Conference on Artificial Intelligence is a major annual conference in the field of AI.&lt;SEP&gt;The Conference on Artificial Intelligence, a major AI conference.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007946</data>
      <data key="d6" />
    </node>
    <node id="IJCAI">
      <data key="d0">IJCAI</data>
      <data key="d1">event</data>
      <data key="d2">The International Joint Conference on Artificial Intelligence is a major biennial AI conference.&lt;SEP&gt;The International Joint Conference on Artificial Intelligence, a leading AI conference.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007948</data>
      <data key="d6" />
    </node>
    <node id="CVPR">
      <data key="d0">CVPR</data>
      <data key="d1">event</data>
      <data key="d2">The Conference on Computer Vision and Pattern Recognition is a premier annual conference in computer vision.&lt;SEP&gt;The Conference on Computer Vision and Pattern Recognition, a premier computer vision conference.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007949</data>
      <data key="d6" />
    </node>
    <node id="ML">
      <data key="d0">ML</data>
      <data key="d1">content</data>
      <data key="d2">Machine Learning is a scientific journal dedicated to machine learning research.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003673</data>
      <data key="d6" />
    </node>
    <node id="JMLR">
      <data key="d0">JMLR</data>
      <data key="d1">content</data>
      <data key="d2">The Journal of Machine Learning Research is an open-access scientific journal covering machine learning.&lt;SEP&gt;The Journal of Machine Learning Research, a prominent open-access journal in the field.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007950</data>
      <data key="d6" />
    </node>
    <node id="Theano">
      <data key="d0">Theano</data>
      <data key="d1">artifact</data>
      <data key="d2">Theano is a Python library for defining, optimizing, and evaluating mathematical expressions involving multi-dimensional arrays.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003673</data>
      <data key="d6" />
    </node>
    <node id="TensorFlow">
      <data key="d0">TensorFlow</data>
      <data key="d1">artifact</data>
      <data key="d2">TensorFlow is an open-source machine learning framework developed by Google.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003673</data>
      <data key="d6" />
    </node>
    <node id="Keras">
      <data key="d0">Keras</data>
      <data key="d1">artifact</data>
      <data key="d2">Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003673</data>
      <data key="d6" />
    </node>
    <node id="Caffe">
      <data key="d0">Caffe</data>
      <data key="d1">artifact</data>
      <data key="d2">Caffe is a deep learning framework made with expression, speed, and modularity in mind.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003674</data>
      <data key="d6" />
    </node>
    <node id="JAX">
      <data key="d0">JAX</data>
      <data key="d1">artifact</data>
      <data key="d2">JAX is a Python library for high-performance numerical computing and machine learning research.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003674</data>
      <data key="d6" />
    </node>
    <node id="MindSpore">
      <data key="d0">MindSpore</data>
      <data key="d1">artifact</data>
      <data key="d2">MindSpore is an open-source deep learning training/inference framework developed by Huawei.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003674</data>
      <data key="d6" />
    </node>
    <node id="Flux.jl">
      <data key="d0">Flux.jl</data>
      <data key="d1">artifact</data>
      <data key="d2">Flux.jl is a machine learning library for the Julia programming language.</data>
      <data key="d3">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003675</data>
      <data key="d6" />
    </node>
    <node id="隐含层">
      <data key="d0">隐含层</data>
      <data key="d1">concept</data>
      <data key="d2">隐含层是神经网络中位于输入层和输出层之间的中间层，负责处理和转换输入数据。</data>
      <data key="d3">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003694</data>
      <data key="d6" />
    </node>
    <node id="单层感知机">
      <data key="d0">单层感知机</data>
      <data key="d1">concept</data>
      <data key="d2">单层感知机是一种基础的神经网络模型，仅包含输入层和输出层，表达能力有限。</data>
      <data key="d3">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003694</data>
      <data key="d6" />
    </node>
    <node id="非线性激活函数">
      <data key="d0">非线性激活函数</data>
      <data key="d1">concept</data>
      <data key="d2">非线性激活函数是神经网络中的一种函数，用于引入非线性变换，使网络能够学习和表示更复杂的关系。</data>
      <data key="d3">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003694</data>
      <data key="d6" />
    </node>
    <node id="连续函数">
      <data key="d0">连续函数</data>
      <data key="d1">concept</data>
      <data key="d2">连续函数是一种数学函数，其图像没有间断点，在任意小的区间内变化平缓。</data>
      <data key="d3">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003695</data>
      <data key="d6" />
    </node>
    <node id="随机梯度下降">
      <data key="d0">随机梯度下降</data>
      <data key="d1">method</data>
      <data key="d2">随机梯度下降是一种优化算法，用于在深度学习中通过迭代更新模型参数来最小化损失函数。</data>
      <data key="d3">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003713</data>
      <data key="d6" />
    </node>
    <node id="损失函数地形">
      <data key="d0">损失函数地形</data>
      <data key="d1">concept</data>
      <data key="d2">损失函数地形描述了模型参数空间中损失函数值的几何形状，影响优化算法的导航路径。</data>
      <data key="d3">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003714</data>
      <data key="d6" />
    </node>
    <node id="有效学习">
      <data key="d0">有效学习</data>
      <data key="d1">concept</data>
      <data key="d2">有效学习指的是模型通过优化过程高效地达到低损失状态并具备良好泛化能力的机制。</data>
      <data key="d3">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003715</data>
      <data key="d6" />
    </node>
    <node id="研究">
      <data key="d0">研究</data>
      <data key="d1">content</data>
      <data key="d2">这项研究深入探讨了深度学习中的优化机制。</data>
      <data key="d3">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003715</data>
      <data key="d6" />
    </node>
    <node id="计算神经科学">
      <data key="d0">计算神经科学</data>
      <data key="d1">concept</data>
      <data key="d2">A field of study considered foundational for achieving world-class innovation in brain-inspired artificial intelligence.&lt;SEP&gt;计算神经科学是一个研究领域，旨在加深对其的理解。</data>
      <data key="d3">chunk-92f537cdcce6583c2c63c400d634feaf&lt;SEP&gt;chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003753</data>
      <data key="d6" />
    </node>
    <node id="类脑智能技术">
      <data key="d0">类脑智能技术</data>
      <data key="d1">concept</data>
      <data key="d2">A type of technological innovation inspired by the brain, whose world-class advancement is dependent on world-class computational neuroscience.</data>
      <data key="d3">chunk-92f537cdcce6583c2c63c400d634feaf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003733</data>
      <data key="d6" />
    </node>
    <node id="脑科学数据">
      <data key="d0">脑科学数据</data>
      <data key="d1">data</data>
      <data key="d2">Data from brain science research that can be processed using new methods introduced by machine learning.</data>
      <data key="d3">chunk-92f537cdcce6583c2c63c400d634feaf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003733</data>
      <data key="d6" />
    </node>
    <node id="脑功能">
      <data key="d0">脑功能</data>
      <data key="d1">concept</data>
      <data key="d2">The functions of the brain that can be simulated using new ideas introduced by machine learning.</data>
      <data key="d3">chunk-92f537cdcce6583c2c63c400d634feaf</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003734</data>
      <data key="d6" />
    </node>
    <node id="计算认知">
      <data key="d0">计算认知</data>
      <data key="d1">concept</data>
      <data key="d2">计算认知是一个研究领域，旨在加深对其的理解。</data>
      <data key="d3">chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003751</data>
      <data key="d6" />
    </node>
    <node id="Coursera">
      <data key="d0">Coursera</data>
      <data key="d1">organization</data>
      <data key="d2">Coursera是一个在线学习平台，上面有推荐的课程。</data>
      <data key="d3">chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003753</data>
      <data key="d6" />
    </node>
    <node id="动手学">
      <data key="d0">动手学</data>
      <data key="d1">content</data>
      <data key="d2">“动手学”是一本被推荐的用于学习深度学习基础知识的资料或书籍。</data>
      <data key="d3">chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003753</data>
      <data key="d6" />
    </node>
    <node id="李澄宇">
      <data key="d0">李澄宇</data>
      <data key="d1">person</data>
      <data key="d2">李澄宇is the author of the text discussing the intersection of machine learning and neuroscience.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003854</data>
      <data key="d6" />
    </node>
    <node id="Walter Pitts">
      <data key="d0">Walter Pitts</data>
      <data key="d1">person</data>
      <data key="d2">Walter Pitts was a child prodigy who taught himself logic, corresponded with Bertrand Russell, and co-developed the McCulloch-Pitts neural network model.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003854</data>
      <data key="d6" />
    </node>
    <node id="Alfred North Whitehead">
      <data key="d0">Alfred North Whitehead</data>
      <data key="d1">person</data>
      <data key="d2">Alfred North Whitehead co-authored the Principia Mathematica with Bertrand Russell.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003855</data>
      <data key="d6" />
    </node>
    <node id="Bertrand Russell">
      <data key="d0">Bertrand Russell</data>
      <data key="d1">person</data>
      <data key="d2">Bertrand Russell co-authored the Principia Mathematica, corresponded with Walter Pitts, and invited him to study in England.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003855</data>
      <data key="d6" />
    </node>
    <node id="Principia Mathematica">
      <data key="d0">Principia Mathematica</data>
      <data key="d1">artifact</data>
      <data key="d2">Principia Mathematica is a three-volume work by Whitehead and Russell that aims to provide a logical foundation for pure mathematics.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003855</data>
      <data key="d6" />
    </node>
    <node id="Carnap">
      <data key="d0">Carnap</data>
      <data key="d1">person</data>
      <data key="d2">Carnap was a University of Chicago mathematics professor and author of a logic book, whose work was critiqued by Walter Pitts.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003855</data>
      <data key="d6" />
    </node>
    <node id="Warren McCulloch">
      <data key="d0">Warren McCulloch</data>
      <data key="d1">person</data>
      <data key="d2">Warren McCulloch was a University of Illinois professor who collaborated with Walter Pitts on modeling neural logic.&lt;SEP&gt;Co-creator of the McCulloch–Pitts neuron mathematical model.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003856</data>
      <data key="d6" />
    </node>
    <node id="University Of Illinois">
      <data key="d0">University Of Illinois</data>
      <data key="d1">organization</data>
      <data key="d2">University of Illinois is the institution where Warren McCulloch was a professor.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003863</data>
      <data key="d6" />
    </node>
    <node id="University Of Chicago">
      <data key="d0">University Of Chicago</data>
      <data key="d1">organization</data>
      <data key="d2">University of Chicago is the institution where Walter Pitts studied and interacted with Professor Carnap.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003856</data>
      <data key="d6" />
    </node>
    <node id="McCulloch-Pitts Network">
      <data key="d0">McCulloch-Pitts Network</data>
      <data key="d1">concept</data>
      <data key="d2">The McCulloch-Pitts network is a simplified binary model of neural activity and an early form of a finite automaton.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003856</data>
      <data key="d6" />
    </node>
    <node id="A Logical Calculus Of The Ideas Immanent In Nervous Activity">
      <data key="d0">A Logical Calculus Of The Ideas Immanent In Nervous Activity</data>
      <data key="d1">content</data>
      <data key="d2">This 1943 paper by McCulloch and Pitts is a foundational work in computational neuroscience and artificial intelligence.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003856</data>
      <data key="d6" />
    </node>
    <node id="Finite Automata">
      <data key="d0">Finite Automata</data>
      <data key="d1">concept</data>
      <data key="d2">Finite automata are computational models, with the McCulloch-Pitts network being an early example.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003857</data>
      <data key="d6" />
    </node>
    <node id="Computational Neuroscience">
      <data key="d0">Computational Neuroscience</data>
      <data key="d1">concept</data>
      <data key="d2">Computational neuroscience is a field for which the McCulloch-Pitts work provided an early logical foundation.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003857</data>
      <data key="d6" />
    </node>
    <node id="Synapse">
      <data key="d0">Synapse</data>
      <data key="d1">concept</data>
      <data key="d2">A synapse is a neural connection whose strength can be modified by neuronal activity, potentially forming the basis of learning.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003858</data>
      <data key="d6" />
    </node>
    <node id="Geoffrey Hinton">
      <data key="d0">Geoffrey Hinton</data>
      <data key="d1">person</data>
      <data key="d2">Geoffrey Hinton is a co-author of the 2015 Nature review article on deep learning.&lt;SEP&gt;Geoffrey Hinton is a researcher who made significant contributions to training artificial neural networks and the deep learning revolution.&lt;SEP&gt;A foundational figure in deep learning who made outstanding contributions. He was born in the UK, educated in Christian schools, and co-invented the Boltzmann machine with Terry Sejnowski around 1982. He also promoted the widespread use of the Back-propagation algorithm and invented deep learning training methods in 2006.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003858</data>
      <data key="d6" />
    </node>
    <node id="Terry Sejnowski">
      <data key="d0">Terry Sejnowski</data>
      <data key="d1">person</data>
      <data key="d2">Terry Sejnowski collaborated with Geoffrey Hinton in finding methods to train artificial neural networks.&lt;SEP&gt;Co-inventor of the Boltzmann machine with Geoffrey Hinton around 1982.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003859</data>
      <data key="d6" />
    </node>
    <node id="AlphaGo">
      <data key="d0">AlphaGo</data>
      <data key="d1">artifact</data>
      <data key="d2">An artificial intelligence program created by a team led by DeepMind. It combines deep learning with reinforcement learning and defeated top professional Go players like Lee Sedol.&lt;SEP&gt;AlphaGo is an artificial intelligence algorithm that defeated top human Go players, including Ke Jie.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003860</data>
      <data key="d6" />
    </node>
    <node id="Ke Jie">
      <data key="d0">Ke Jie</data>
      <data key="d1">person</data>
      <data key="d2">Ke Jie is a top Go professional player who was defeated by the AlphaGo AI.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003861</data>
      <data key="d6" />
    </node>
    <node id="Alan Turing">
      <data key="d0">Alan Turing</data>
      <data key="d1">person</data>
      <data key="d2">Alan Turing published a famous article on the universal computing engine six years before the collaboration between McCulloch and Pitts.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003861</data>
      <data key="d6" />
    </node>
    <node id="Gottfried Wilhelm Leibniz">
      <data key="d0">Gottfried Wilhelm Leibniz</data>
      <data key="d1">person</data>
      <data key="d2">Gottfried Wilhelm Leibniz proved centuries ago that any well-defined problem could be computed by a 'logical machine'.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003861</data>
      <data key="d6" />
    </node>
    <node id="Logical Machine">
      <data key="d0">Logical Machine</data>
      <data key="d1">concept</data>
      <data key="d2">A logical machine is a theoretical device, as discussed by Leibniz, capable of computing any well-defined problem.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003861</data>
      <data key="d6" />
    </node>
    <node id="Universal Computing Engine">
      <data key="d0">Universal Computing Engine</data>
      <data key="d1">concept</data>
      <data key="d2">The universal computing engine is a concept discussed by Alan Turing in his famous article.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003861</data>
      <data key="d6" />
    </node>
    <node id="Connection Strength Matrix">
      <data key="d0">Connection Strength Matrix</data>
      <data key="d1">concept</data>
      <data key="d2">The connection strength matrix is a component of the McCulloch-Pitts model that standardizes the influence between neurons.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003861</data>
      <data key="d6" />
    </node>
    <node id="Learning">
      <data key="d0">Learning</data>
      <data key="d1">concept</data>
      <data key="d2">Learning is recognized as important for both biological and computer behavior, with its basis in modifiable synapses.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003861</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning Revolution">
      <data key="d0">Deep Learning Revolution</data>
      <data key="d1">event</data>
      <data key="d2">The deep learning revolution refers to the period where deep learning methods became extremely influential across numerous applications.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003862</data>
      <data key="d6" />
    </node>
    <node id="Network Search">
      <data key="d0">Network Search</data>
      <data key="d1">concept</data>
      <data key="d2">Network search is one of the many practical applications of deep learning technology.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003863</data>
      <data key="d6" />
    </node>
    <node id="Website Filtering">
      <data key="d0">Website Filtering</data>
      <data key="d1">concept</data>
      <data key="d2">Website filtering is one of the many practical applications of deep learning technology.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003863</data>
      <data key="d6" />
    </node>
    <node id="Advertising Push">
      <data key="d0">Advertising Push</data>
      <data key="d1">concept</data>
      <data key="d2">Advertising push is one of the many practical applications of deep learning technology.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003863</data>
      <data key="d6" />
    </node>
    <node id="Language Translation">
      <data key="d0">Language Translation</data>
      <data key="d1">concept</data>
      <data key="d2">Language translation is one of the many practical applications of deep learning technology.</data>
      <data key="d3">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003863</data>
      <data key="d6" />
    </node>
    <node id="玻尔兹曼机">
      <data key="d0">玻尔兹曼机</data>
      <data key="d1">method</data>
      <data key="d2">A type of artificial neural network invented by Geoffrey Hinton and Terry Sejnowski around 1982. It is a beautiful method for training neural networks and has important applications in both artificial intelligence and computational neuroscience.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003864</data>
      <data key="d6" />
    </node>
    <node id="深脑">
      <data key="d0">深脑</data>
      <data key="d1">organization</data>
      <data key="d2">Also known as DeepMind, a company created by systems neuroscientists. It was acquired by Google. The company combines deep learning with concepts from reinforcement learning in neuroscience.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003868</data>
      <data key="d6" />
    </node>
    <node id="Pitts">
      <data key="d0">Pitts</data>
      <data key="d1">person</data>
      <data key="d2">A contributor to the McCulloch–Pitts neuron model. He made significant contributions but strongly rejected formal societal recognition, refusing degrees and faculty positions from MIT. He was knowledgeable, eloquent, and easy to get along with according to those who knew him.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003878</data>
      <data key="d6" />
    </node>
    <node id="McCulloch–Pitts神经元">
      <data key="d0">McCulloch–Pitts神经元</data>
      <data key="d1">concept</data>
      <data key="d2">The mathematical model of a neuron, named after Warren McCulloch and Walter Pitts. It represents a foundational concept in neural network theory.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003871</data>
      <data key="d6" />
    </node>
    <node id="局部极小值">
      <data key="d0">局部极小值</data>
      <data key="d1">concept</data>
      <data key="d2">A problem in training artificial neural networks where the optimization algorithm gets stuck in a local minimum instead of finding the global minimum, hindering problem-solving. This issue diminished with the advent of big data and deep learning.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003872</data>
      <data key="d6" />
    </node>
    <node id="全局最小值">
      <data key="d0">全局最小值</data>
      <data key="d1">concept</data>
      <data key="d2">The optimal solution sought during the training of artificial neural networks. With big data and deep learning, networks became more likely to find global minima instead of getting stuck in local minima.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003873</data>
      <data key="d6" />
    </node>
    <node id="神经科学">
      <data key="d0">神经科学</data>
      <data key="d1">concept</data>
      <data key="d2">The study of the nervous system. It has provided inspirational principles for artificial intelligence, such as the visual system inspiring CNNs and the layered organization of the cerebral cortex inspiring deep learning architectures. It is seen as a source for future key principles to expand AI capabilities.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003873</data>
      <data key="d6" />
    </node>
    <node id="MIT">
      <data key="d0">MIT</data>
      <data key="d1">organization</data>
      <data key="d2">The Massachusetts Institute of Technology, which offered Pitts a degree and a formal faculty position, both of which he refused.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003874</data>
      <data key="d6" />
    </node>
    <node id="Norbert">
      <data key="d0">Norbert</data>
      <data key="d1">person</data>
      <data key="d2">A person who may have arranged for MIT to offer Pitts a degree.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003874</data>
      <data key="d6" />
    </node>
    <node id="芝加哥大学">
      <data key="d0">芝加哥大学</data>
      <data key="d1">organization</data>
      <data key="d2">The University of Chicago, where Pitts audited classes without registering as a student.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003874</data>
      <data key="d6" />
    </node>
    <node id="李世石">
      <data key="d0">李世石</data>
      <data key="d1">person</data>
      <data key="d2">A top professional Go player who was defeated by AlphaGo.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003874</data>
      <data key="d6" />
    </node>
    <node id="Jim Anderson">
      <data key="d0">Jim Anderson</data>
      <data key="d1">person</data>
      <data key="d2">Jim Anderson is an author or interviewee featured in the book "Talking Nets".&lt;SEP&gt;Co-author of the interview collection "Talking nets" which contains interviews with Lettvin and Hinton.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003875</data>
      <data key="d6" />
    </node>
    <node id="Edward Rosenfeld">
      <data key="d0">Edward Rosenfeld</data>
      <data key="d1">person</data>
      <data key="d2">Edward Rosenfeld is an author of the book "Talking Nets".&lt;SEP&gt;Co-author of the interview collection "Talking nets" with James Anderson.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003875</data>
      <data key="d6" />
    </node>
    <node id="Lettvin">
      <data key="d0">Lettvin</data>
      <data key="d1">person</data>
      <data key="d2">Lettvin is a person referenced in an interview with Jim Anderson.&lt;SEP&gt;A person interviewed in "Talking nets", a source of information about Pitts.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003875</data>
      <data key="d6" />
    </node>
    <node id="Talking Nets">
      <data key="d0">Talking Nets</data>
      <data key="d1">content</data>
      <data key="d2">"Talking Nets" is a book published by MIT Press in 1998, authored by James Anderson and Edward Rosenfeld.&lt;SEP&gt;A 1998 MIT Press book by James Anderson and Edward Rosenfeld containing interview records, including those with Lettvin and Hinton, which are sources of information about Pitts and Hinton.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003875</data>
      <data key="d6" />
    </node>
    <node id="Christian Ideology">
      <data key="d0">Christian Ideology</data>
      <data key="d1">concept</data>
      <data key="d2">Christian ideology is a belief system that Hinton considered to be "complete rubbish" during childhood.&lt;SEP&gt;The system of beliefs associated with Christianity, which Geoffrey Hinton considered to be complete rubbish during his childhood and schooling.</data>
      <data key="d3">chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003883</data>
      <data key="d6" />
    </node>
    <node id="James Anderson">
      <data key="d0">James Anderson</data>
      <data key="d1">person</data>
      <data key="d2">James Anderson is an author of the book "Talking Nets".</data>
      <data key="d3">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003883</data>
      <data key="d6" />
    </node>
    <node id="MIT Press">
      <data key="d0">MIT Press</data>
      <data key="d1">organization</data>
      <data key="d2">MIT Press is the publisher of the book "Talking Nets".</data>
      <data key="d3">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003884</data>
      <data key="d6" />
    </node>
    <node id="Yoshua Bengio">
      <data key="d0">Yoshua Bengio</data>
      <data key="d1">person</data>
      <data key="d2">Yoshua Bengio is a co-author of the 2015 Nature review article on deep learning.</data>
      <data key="d3">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003884</data>
      <data key="d6" />
    </node>
    <node id="Nature">
      <data key="d0">Nature</data>
      <data key="d1">content</data>
      <data key="d2">Nature is a scientific journal that published the 2015 review article "Deep learning".&lt;SEP&gt;Nature is a specialist science press publication that covered the story of AlphaFold 2's success.&lt;SEP&gt;Nature is a weekly journal where the paper detailing AlphaFold2 was published online on July 15, 2021.&lt;SEP&gt;Nature is a scientific journal that published the 2020 and 2021 papers on AlphaFold2.</data>
      <data key="d3">chunk-e7712ad4739a66b6cf3b8376df6a6837&lt;SEP&gt;chunk-d23247c8edaf8929e7855d9186007c46&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2&lt;SEP&gt;chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004669</data>
      <data key="d6" />
    </node>
    <node id="电话">
      <data key="d0">电话</data>
      <data key="d1">artifact</data>
      <data key="d2">电话is a contact number provided in the text: 86-21-54921723.</data>
      <data key="d3">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003885</data>
      <data key="d6" />
    </node>
    <node id="传真">
      <data key="d0">传真</data>
      <data key="d1">artifact</data>
      <data key="d2">传真is a fax number provided in the text: 86-21-54921735.</data>
      <data key="d3">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003885</data>
      <data key="d6" />
    </node>
    <node id="邮件">
      <data key="d0">邮件</data>
      <data key="d1">artifact</data>
      <data key="d2">邮件is an email address provided in the text: query@ion.ac.cn.</data>
      <data key="d3">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003885</data>
      <data key="d6" />
    </node>
    <node id="Excel">
      <data key="d0">Excel</data>
      <data key="d1">artifact</data>
      <data key="d2">A spreadsheet software application used for data organization, calculation, and analysis, mentioned in the context of replicating neural network calculations.</data>
      <data key="d3">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003920</data>
      <data key="d6" />
    </node>
    <node id="科学实证">
      <data key="d0">科学实证</data>
      <data key="d1">method</data>
      <data key="d2">An approach or principle emphasizing verification and evidence based on scientific methods.</data>
      <data key="d3">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003922</data>
      <data key="d6" />
    </node>
    <node id="人生外挂">
      <data key="d0">人生外挂</data>
      <data key="d1">concept</data>
      <data key="d2">A metaphorical term suggesting tools or strategies that can significantly enhance one's life, presented as being scientifically validated.</data>
      <data key="d3">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003922</data>
      <data key="d6" />
    </node>
    <node id="运气">
      <data key="d0">运气</data>
      <data key="d1">concept</data>
      <data key="d2">The concept of luck or fortune, discussed in the context of being a product of thought or mindset according to scientific validation.</data>
      <data key="d3">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003922</data>
      <data key="d6" />
    </node>
    <node id="9分钟带你了解神经网络&amp;深度学习(Excel还原神经网络计算)">
      <data key="d0">9分钟带你了解神经网络&amp;深度学习(Excel还原神经网络计算)</data>
      <data key="d1">content</data>
      <data key="d2">A video or content piece with the title "9 minutes to understand neural networks &amp; deep learning (Excel restores neural network calculations)" that has 607 views.</data>
      <data key="d3">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003922</data>
      <data key="d6" />
    </node>
    <node id="科學實證的「人生外掛」總整理，即學即用!">
      <data key="d0">科學實證的「人生外掛」總整理，即學即用!</data>
      <data key="d1">content</data>
      <data key="d2">A content piece with the title "A complete summary of scientifically proven 'life hacks', learn and use immediately!".</data>
      <data key="d3">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003923</data>
      <data key="d6" />
    </node>
    <node id="科學驗證：運氣是想出來的">
      <data key="d0">科學驗證：運氣是想出來的</data>
      <data key="d1">content</data>
      <data key="d2">A content piece with the title "Scientific verification: Luck is thought out".</data>
      <data key="d3">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003924</data>
      <data key="d6" />
    </node>
    <node id="焦李成">
      <data key="d0">焦李成</data>
      <data key="d1">person</data>
      <data key="d2">焦李成is the author of the cited work in the field of cognitive neuroscience.</data>
      <data key="d3">chunk-3954d1f048ce5cd91b5693da96becc81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003941</data>
      <data key="d6" />
    </node>
    <node id="类脑智能">
      <data key="d0">类脑智能</data>
      <data key="d1">concept</data>
      <data key="d2">类脑智能aims to simulate the operational mechanisms, perceptual patterns, and cognitive principles of the human brain, leveraging powerful machine capabilities for information integration, search, and computation to construct intelligent machines approaching human-level intelligence through a new form of hardware-software integrated intelligence.</data>
      <data key="d3">chunk-3954d1f048ce5cd91b5693da96becc81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003941</data>
      <data key="d6" />
    </node>
    <node id="人脑神经元">
      <data key="d0">人脑神经元</data>
      <data key="d1">concept</data>
      <data key="d2">人脑神经元refers to the neurons in the human brain, whose operational mechanisms are a target of simulation in brain-inspired intelligence.</data>
      <data key="d3">chunk-3954d1f048ce5cd91b5693da96becc81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003942</data>
      <data key="d6" />
    </node>
    <node id="智能机器">
      <data key="d0">智能机器</data>
      <data key="d1">artifact</data>
      <data key="d2">智能机器refers to intelligent machines constructed to approach human-level intelligence, representing a new form of hardware-software integrated intelligence.</data>
      <data key="d3">chunk-3954d1f048ce5cd91b5693da96becc81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003942</data>
      <data key="d6" />
    </node>
    <node id="教育部重点实验室">
      <data key="d0">教育部重点实验室</data>
      <data key="d1">organization</data>
      <data key="d2">A key laboratory under the Ministry of Education.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003989</data>
      <data key="d6" />
    </node>
    <node id="认知神经科学中心">
      <data key="d0">认知神经科学中心</data>
      <data key="d1">organization</data>
      <data key="d2">A center dedicated to cognitive neuroscience research.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003989</data>
      <data key="d6" />
    </node>
    <node id="生物医学影像中心">
      <data key="d0">生物医学影像中心</data>
      <data key="d1">organization</data>
      <data key="d2">A biomedical imaging center, also known as the Zhangjiang International Brain Imaging Center.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003990</data>
      <data key="d6" />
    </node>
    <node id="张江国际脑影像中心">
      <data key="d0">张江国际脑影像中心</data>
      <data key="d1">organization</data>
      <data key="d2">The international brain imaging center located in Zhangjiang.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003990</data>
      <data key="d6" />
    </node>
    <node id="生物医学大数据中心">
      <data key="d0">生物医学大数据中心</data>
      <data key="d1">organization</data>
      <data key="d2">A biomedical big data center, also known as the Zhangjiang International Brain Bank.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003990</data>
      <data key="d6" />
    </node>
    <node id="张江国际脑库">
      <data key="d0">张江国际脑库</data>
      <data key="d1">organization</data>
      <data key="d2">The international brain bank located in Zhangjiang.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003991</data>
      <data key="d6" />
    </node>
    <node id="神经与智能工程中心">
      <data key="d0">神经与智能工程中心</data>
      <data key="d1">organization</data>
      <data key="d2">A center for neural and intelligent engineering.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003991</data>
      <data key="d6" />
    </node>
    <node id="全脑计算平台">
      <data key="d0">全脑计算平台</data>
      <data key="d1">organization</data>
      <data key="d2">A whole-brain computing platform.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003998</data>
      <data key="d6" />
    </node>
    <node id="群体神经科学中心">
      <data key="d0">群体神经科学中心</data>
      <data key="d1">organization</data>
      <data key="d2">A center for population neuroscience.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003991</data>
      <data key="d6" />
    </node>
    <node id="老年脑健康智能科学中心">
      <data key="d0">老年脑健康智能科学中心</data>
      <data key="d1">organization</data>
      <data key="d2">An intelligent science center for aging brain health.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003991</data>
      <data key="d6" />
    </node>
    <node id="计算系统生物学中心">
      <data key="d0">计算系统生物学中心</data>
      <data key="d1">organization</data>
      <data key="d2">A center for computational systems biology.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003991</data>
      <data key="d6" />
    </node>
    <node id="人工智能算法中心">
      <data key="d0">人工智能算法中心</data>
      <data key="d1">organization</data>
      <data key="d2">A center for artificial intelligence algorithms.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003992</data>
      <data key="d6" />
    </node>
    <node id="上海市市级科技重大专项">
      <data key="d0">上海市市级科技重大专项</data>
      <data key="d1">event</data>
      <data key="d2">A major municipal science and technology project in Shanghai.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003992</data>
      <data key="d6" />
    </node>
    <node id="固定科研人员">
      <data key="d0">固定科研人员</data>
      <data key="d1">person</data>
      <data key="d2">Permanent research staff, listed in alphabetical order by pinyin.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003992</data>
      <data key="d6" />
    </node>
    <node id="兼职科研人员">
      <data key="d0">兼职科研人员</data>
      <data key="d1">person</data>
      <data key="d2">Part-time research staff.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003992</data>
      <data key="d6" />
    </node>
    <node id="行政管理">
      <data key="d0">行政管理</data>
      <data key="d1">person</data>
      <data key="d2">Administrative management personnel.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003992</data>
      <data key="d6" />
    </node>
    <node id="博士后">
      <data key="d0">博士后</data>
      <data key="d1">person</data>
      <data key="d2">Postdoctoral researchers.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="专任工程师">
      <data key="d0">专任工程师</data>
      <data key="d1">person</data>
      <data key="d2">Full-time engineers.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="助理研究员">
      <data key="d0">助理研究员</data>
      <data key="d1">person</data>
      <data key="d2">Assistant researchers.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="来访学者">
      <data key="d0">来访学者</data>
      <data key="d1">person</data>
      <data key="d2">Visiting scholars.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="专任研究系列">
      <data key="d0">专任研究系列</data>
      <data key="d1">person</data>
      <data key="d2">Full-time research series personnel.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="科研助理">
      <data key="d0">科研助理</data>
      <data key="d1">person</data>
      <data key="d2">Research assistants.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="仪器设备简介">
      <data key="d0">仪器设备简介</data>
      <data key="d1">content</data>
      <data key="d2">An introduction to instruments and equipment.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="科研进展">
      <data key="d0">科研进展</data>
      <data key="d1">content</data>
      <data key="d2">Research progress updates.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003993</data>
      <data key="d6" />
    </node>
    <node id="科研项目">
      <data key="d0">科研项目</data>
      <data key="d1">content</data>
      <data key="d2">Research projects.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003994</data>
      <data key="d6" />
    </node>
    <node id="科研成果">
      <data key="d0">科研成果</data>
      <data key="d1">content</data>
      <data key="d2">Research achievements.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003994</data>
      <data key="d6" />
    </node>
    <node id="学术报告">
      <data key="d0">学术报告</data>
      <data key="d1">content</data>
      <data key="d2">Academic reports.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003994</data>
      <data key="d6" />
    </node>
    <node id="伦理申请">
      <data key="d0">伦理申请</data>
      <data key="d1">content</data>
      <data key="d2">Ethics application procedures.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003994</data>
      <data key="d6" />
    </node>
    <node id="通知公告">
      <data key="d0">通知公告</data>
      <data key="d1">content</data>
      <data key="d2">Notices and announcements.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003994</data>
      <data key="d6" />
    </node>
    <node id="招生">
      <data key="d0">招生</data>
      <data key="d1">content</data>
      <data key="d2">Student recruitment information.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003995</data>
      <data key="d6" />
    </node>
    <node id="培养">
      <data key="d0">培养</data>
      <data key="d1">content</data>
      <data key="d2">Training programs.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003995</data>
      <data key="d6" />
    </node>
    <node id="学位">
      <data key="d0">学位</data>
      <data key="d1">content</data>
      <data key="d2">Degree-related information.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003995</data>
      <data key="d6" />
    </node>
    <node id="奖助体系">
      <data key="d0">奖助体系</data>
      <data key="d1">content</data>
      <data key="d2">Scholarship and support systems.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003995</data>
      <data key="d6" />
    </node>
    <node id="服务指南">
      <data key="d0">服务指南</data>
      <data key="d1">content</data>
      <data key="d2">Service guides.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003995</data>
      <data key="d6" />
    </node>
    <node id="下载专区">
      <data key="d0">下载专区</data>
      <data key="d1">content</data>
      <data key="d2">Download area for resources.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003995</data>
      <data key="d6" />
    </node>
    <node id="国际合作">
      <data key="d0">国际合作</data>
      <data key="d1">content</data>
      <data key="d2">International cooperation initiatives.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003996</data>
      <data key="d6" />
    </node>
    <node id="产学研合作">
      <data key="d0">产学研合作</data>
      <data key="d1">content</data>
      <data key="d2">Industry-academia-research collaboration.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003996</data>
      <data key="d6" />
    </node>
    <node id="联合研究中心">
      <data key="d0">联合研究中心</data>
      <data key="d1">content</data>
      <data key="d2">Joint research centers.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003996</data>
      <data key="d6" />
    </node>
    <node id="固定科研团队">
      <data key="d0">固定科研团队</data>
      <data key="d1">content</data>
      <data key="d2">Permanent research teams.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769003996</data>
      <data key="d6" />
    </node>
    <node id="联系地址">
      <data key="d0">联系地址</data>
      <data key="d1">content</data>
      <data key="d2">Contact address information.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004003</data>
      <data key="d6" />
    </node>
    <node id="综合新闻">
      <data key="d0">综合新闻</data>
      <data key="d1">content</data>
      <data key="d2">General news section.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004003</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-a3329ce0">
      <data key="d0">DOC_ID: chunk-a3329ce0</data>
      <data key="d1">data</data>
      <data key="d2">A document identifier for the provided text chunk.</data>
      <data key="d3">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004003</data>
      <data key="d6" />
    </node>
    <node id="蛋白质结构预测">
      <data key="d0">蛋白质结构预测</data>
      <data key="d1">concept</data>
      <data key="d2">蛋白质结构预测是指借助计算机计算模拟方法从氨基酸序列推断其三维空间结构的过程。&lt;SEP&gt;蛋白质结构预测是生物信息学领域的研究方向，涉及预测蛋白质的三维空间结构。&lt;SEP&gt;Protein structure prediction is a major problem in life sciences that was significantly advanced by AlphaFold2.&lt;SEP&gt;Protein structure prediction is the computational task of predicting a protein's 3D structure from its amino acid sequence.</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d&lt;SEP&gt;chunk-c5eafae240ac5d07dadf7c4eb744e8eb&lt;SEP&gt;chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004663</data>
      <data key="d6" />
    </node>
    <node id="氨基酸序列">
      <data key="d0">氨基酸序列</data>
      <data key="d1">data</data>
      <data key="d2">氨基酸序列是构成蛋白质的一级结构，是蛋白质结构预测的输入信息。&lt;SEP&gt;构成蛋白质的氨基酸排列顺序，是蛋白质结构预测的输入数据。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d&lt;SEP&gt;chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004069</data>
      <data key="d6" />
    </node>
    <node id="三维空间结构">
      <data key="d0">三维空间结构</data>
      <data key="d1">concept</data>
      <data key="d2">三维空间结构是蛋白质的立体构象，决定了其生理功能。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004023</data>
      <data key="d6" />
    </node>
    <node id="生理功能">
      <data key="d0">生理功能</data>
      <data key="d1">concept</data>
      <data key="d2">生理功能是蛋白质在生物体内所发挥的作用，由其三维空间结构决定。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004023</data>
      <data key="d6" />
    </node>
    <node id="计算机计算模拟方法">
      <data key="d0">计算机计算模拟方法</data>
      <data key="d1">method</data>
      <data key="d2">计算机计算模拟方法是用于从氨基酸序列预测蛋白质三维空间结构的技术手段。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004023</data>
      <data key="d6" />
    </node>
    <node id="物理学">
      <data key="d0">物理学</data>
      <data key="d1">concept</data>
      <data key="d2">物理学是一门基础科学，其原理可用于蛋白质结构预测，但单纯基于物理学的预测能力有限。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004024</data>
      <data key="d6" />
    </node>
    <node id="王天尧">
      <data key="d0">王天尧</data>
      <data key="d1">person</data>
      <data key="d2">王天尧是2024年一篇被引用1次的生物信息学相关文献的作者。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004024</data>
      <data key="d6" />
    </node>
    <node id="生物信息学">
      <data key="d0">生物信息学</data>
      <data key="d1">concept</data>
      <data key="d2">生物信息学是王天尧所著文献所属的研究领域。&lt;SEP&gt;生物信息学是本文所讨论的蛋白质结构预测所属的领域。&lt;SEP&gt;一个研究领域，涉及使用计算方法分析生物数据。&lt;SEP&gt;生物信息学是应用计算机科学和信息技术来分析和解释生物数据的交叉学科领域。&lt;SEP&gt;一个交叉学科领域，是MIT 6.874课程所属的领域。&lt;SEP&gt;生物信息学(Bioinformatics) is the domain or field of study to which the lecture content belongs.&lt;SEP&gt;Bioinformatics is the field of study mentioned in the document metadata.</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d&lt;SEP&gt;chunk-c5eafae240ac5d07dadf7c4eb744e8eb&lt;SEP&gt;chunk-62c73611ffdf6388dc832abdf23ad216&lt;SEP&gt;chunk-8ac6b800c024bfc59d45d5769abdcb86&lt;SEP&gt;chunk-dcad4a5abb7347f0e6403bab97eb576b&lt;SEP&gt;chunk-41671c7e5bea6a9ae05e6b008b3a38f2&lt;SEP&gt;chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004669</data>
      <data key="d6" />
    </node>
    <node id="2024">
      <data key="d0">2024</data>
      <data key="d1">event</data>
      <data key="d2">2024年是王天尧发表相关文献的年份。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004024</data>
      <data key="d6" />
    </node>
    <node id="基于单纯物理学的预测">
      <data key="d0">基于单纯物理学的预测</data>
      <data key="d1">method</data>
      <data key="d2">基于单纯物理学的预测是一种仅能应对较短序列的蛋白质结构预测方法。</data>
      <data key="d3">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004025</data>
      <data key="d6" />
    </node>
    <node id="算法">
      <data key="d0">算法</data>
      <data key="d1">concept</data>
      <data key="d2">算法是用于蛋白质结构预测的常用计算工具。&lt;SEP&gt;人工智能系统用来从数据中学习并做出智能决策的计算过程或规则集。&lt;SEP&gt;算法是人类智慧的集体体现，以精确化、数字化、组织化的方式实现对当代社会的整体建构，拓展了人类文明发展的可能空间。&lt;SEP&gt;A tool that shapes inequality gaps and is a key instrument of AI technology.</data>
      <data key="d3">chunk-c5eafae240ac5d07dadf7c4eb744e8eb&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011038</data>
      <data key="d6" />
    </node>
    <node id="模型架构">
      <data key="d0">模型架构</data>
      <data key="d1">method</data>
      <data key="d2">模型架构是用于构建蛋白质结构预测模型的设计框架。</data>
      <data key="d3">chunk-c5eafae240ac5d07dadf7c4eb744e8eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004041</data>
      <data key="d6" />
    </node>
    <node id="优化策略">
      <data key="d0">优化策略</data>
      <data key="d1">method</data>
      <data key="d2">优化策略是用于改进蛋白质结构预测模型性能的技术。</data>
      <data key="d3">chunk-c5eafae240ac5d07dadf7c4eb744e8eb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004041</data>
      <data key="d6" />
    </node>
    <node id="FAIR">
      <data key="d0">FAIR</data>
      <data key="d1">organization</data>
      <data key="d2">一个组织，开发了ESMFold方法。</data>
      <data key="d3">chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004066</data>
      <data key="d6" />
    </node>
    <node id="ESMFold">
      <data key="d0">ESMFold</data>
      <data key="d1">method</data>
      <data key="d2">一种基于深度学习的高精度方法，用于根据氨基酸序列预测蛋白质结构。</data>
      <data key="d3">chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004068</data>
      <data key="d6" />
    </node>
    <node id="蛋白质结构">
      <data key="d0">蛋白质结构</data>
      <data key="d1">concept</data>
      <data key="d2">蛋白质分子的三维空间构型，是生物信息学预测的目标。</data>
      <data key="d3">chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004069</data>
      <data key="d6" />
    </node>
    <node id="DeepMind">
      <data key="d0">DeepMind</data>
      <data key="d1">organization</data>
      <data key="d2">DeepMind is a company that developed the AlphaFold system for protein structure prediction.&lt;SEP&gt;DeepMind is an organization that issued press releases regarding AlphaFold 2's success.&lt;SEP&gt;DeepMind is the organization whose researchers described the properties predicted by the neural networks.&lt;SEP&gt;DeepMind is a company that developed the AlphaFold system and later improved it to create AlphaFold2.&lt;SEP&gt;DeepMind is the AI research lab that developed AlphaFold2 and presented slides at CASP14.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-d23247c8edaf8929e7855d9186007c46&lt;SEP&gt;chunk-7d901977dd7e6d929821ca079c401c7e&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2&lt;SEP&gt;chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004665</data>
      <data key="d6" />
    </node>
    <node id="AlphaFold">
      <data key="d0">AlphaFold</data>
      <data key="d1">method</data>
      <data key="d2">AlphaFold is a system for protein structure prediction developed by DeepMind, with an initial version that was later improved.&lt;SEP&gt;AlphaFold is a method that builds models using deep neural networks to predict protein properties from gene sequences.&lt;SEP&gt;AlphaFold is a method that uses artificial neural networks to directly learn the complex relationship between sequences and structures.&lt;SEP&gt;AlphaFold is a technology that combines deep learning with bioinformatics to analyze protein sequences and structures.&lt;SEP&gt;AlphaFold is a system for protein structure prediction, with its initial version being re-examined and improved upon by a team.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-7d901977dd7e6d929821ca079c401c7e&lt;SEP&gt;chunk-13f6a612ad21f33701d7916a1d76aa3e&lt;SEP&gt;chunk-5899806c994fc2f391826abc901a8669&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004504</data>
      <data key="d6" />
    </node>
    <node id="江珀">
      <data key="d0">江珀</data>
      <data key="d1">person</data>
      <data key="d2">Jiang Po led a young team to re-examine and comprehensively adjust the initial version of AlphaFold, introducing new ideas for improvement.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004141</data>
      <data key="d6" />
    </node>
    <node id="AlphaFold2">
      <data key="d0">AlphaFold2</data>
      <data key="d1">method</data>
      <data key="d2">AlphaFold2 is the improved version of AlphaFold that achieved a breakthrough in protein structure prediction, notably performing excellently in the CASP14 competition.&lt;SEP&gt;AlphaFold2是一种深度学习方法，在蛋白质结构预测领域取得了突破性进展，但其对孤儿蛋白和多结构域蛋白的预测存在短板。&lt;SEP&gt;AlphaFold2 is an improved version of AlphaFold that achieved a breakthrough in protein structure prediction, notably performing exceptionally well in the 14th CASP competition.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-a4bf6e4cf6f9e616e1d6f994a99479a8&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004496</data>
      <data key="d6" />
    </node>
    <node id="CASP 14">
      <data key="d0">CASP 14</data>
      <data key="d1">event</data>
      <data key="d2">The 14th Critical Assessment of protein Structure Prediction (CASP) competition was an event where AlphaFold2 demonstrated superior performance.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004148</data>
      <data key="d6" />
    </node>
    <node id="《自然》周刊">
      <data key="d0">《自然》周刊</data>
      <data key="d1">content</data>
      <data key="d2">Nature is a weekly journal where the paper detailing AlphaFold2 was published online on July 15, 2021.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004141</data>
      <data key="d6" />
    </node>
    <node id="《科学》周刊">
      <data key="d0">《科学》周刊</data>
      <data key="d1">content</data>
      <data key="d2">Science is a weekly journal that selected the achievement of AlphaFold2 as the top scientific breakthrough of 2021.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004141</data>
      <data key="d6" />
    </node>
    <node id="自然-方法学">
      <data key="d0">自然-方法学</data>
      <data key="d1">content</data>
      <data key="d2">Nature Methods is a journal that named protein structure prediction as its 2021 Method of the Year.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004142</data>
      <data key="d6" />
    </node>
    <node id="GDT">
      <data key="d0">GDT</data>
      <data key="d1">concept</data>
      <data key="d2">GDT (Global Distance Test) is a scoring metric used in CASP competitions to evaluate the accuracy of predicted protein structures.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004142</data>
      <data key="d6" />
    </node>
    <node id="Demis Hassabis">
      <data key="d0">Demis Hassabis</data>
      <data key="d1">person</data>
      <data key="d2">Demis Hassabis is a developer of AlphaFold and a co-recipient of the 2023 Albert Lasker Basic Medical Research Award.&lt;SEP&gt;Demis Hassabis is a developer of AlphaFold and a co-recipient of the 2023 Albert Lasker Basic Medical Research Award.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004499</data>
      <data key="d6" />
    </node>
    <node id="John Jumper">
      <data key="d0">John Jumper</data>
      <data key="d1">person</data>
      <data key="d2">John Jumper is a developer of AlphaFold and a co-recipient of the 2023 Albert Lasker Basic Medical Research Award.&lt;SEP&gt;John Jumper is a developer of AlphaFold and a co-recipient of the 2023 Albert Lasker Basic Medical Research Award.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004500</data>
      <data key="d6" />
    </node>
    <node id="Albert Lasker Basic Medical Research Award">
      <data key="d0">Albert Lasker Basic Medical Research Award</data>
      <data key="d1">event</data>
      <data key="d2">The Albert Lasker Basic Medical Research Award is a prestigious award received by Demis Hassabis and John Jumper in 2023 for their work on AlphaFold.&lt;SEP&gt;The Albert Lasker Basic Medical Research Award is an award shared in 2023 by AlphaFold developers Demis Hassabis and John Jumper.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004499</data>
      <data key="d6" />
    </node>
    <node id="空间立体结构">
      <data key="d0">空间立体结构</data>
      <data key="d1">concept</data>
      <data key="d2">Spatial three-dimensional structure is a concept introduced into the AlphaFold improvement process.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004144</data>
      <data key="d6" />
    </node>
    <node id="进化理念">
      <data key="d0">进化理念</data>
      <data key="d1">concept</data>
      <data key="d2">Evolutionary concept is an idea integrated into the AlphaFold improvement process.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004144</data>
      <data key="d6" />
    </node>
    <node id="机器有效学习策略">
      <data key="d0">机器有效学习策略</data>
      <data key="d1">method</data>
      <data key="d2">Effective machine learning strategy is a method refined during the AlphaFold improvement to maximize information extraction from limited data.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004144</data>
      <data key="d6" />
    </node>
    <node id="传统算法">
      <data key="d0">传统算法</data>
      <data key="d1">method</data>
      <data key="d2">Traditional algorithms are methods whose constraints were abandoned during the development of AlphaFold2 in favor of new approaches.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004145</data>
      <data key="d6" />
    </node>
    <node id="生命科学研究">
      <data key="d0">生命科学研究</data>
      <data key="d1">concept</data>
      <data key="d2">Life science research is a field that experienced an incredible breakthrough due to the speed and cost reduction enabled by AlphaFold2.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004145</data>
      <data key="d6" />
    </node>
    <node id="大数据">
      <data key="d0">大数据</data>
      <data key="d1">data</data>
      <data key="d2">Big data is described as an important characteristic of current scientific development, exemplified by genome sequencing results and massive papers.&lt;SEP&gt;Big data, a key context for the rapid development of deep learning.&lt;SEP&gt;大数据refers to large volumes of data that support the development and learning of AI models.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-5e9c7c6b034fa0090c148c9fb494cca9&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008508</data>
      <data key="d6" />
    </node>
    <node id="AI工具">
      <data key="d0">AI工具</data>
      <data key="d1">method</data>
      <data key="d2">AI tools are described as an important direction for solving life science problems.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004146</data>
      <data key="d6" />
    </node>
    <node id="AlphaFold2 Paper">
      <data key="d0">AlphaFold2 Paper</data>
      <data key="d1">content</data>
      <data key="d2">The paper detailing AlphaFold2 was published online in Nature on July 15, 2021, and has been cited nearly ten thousand times.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004146</data>
      <data key="d6" />
    </node>
    <node id="AlphaFold2 Algorithm">
      <data key="d0">AlphaFold2 Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">The algorithm for AlphaFold2 was made freely available by DeepMind for global researchers to use.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004146</data>
      <data key="d6" />
    </node>
    <node id="Protein Sequence">
      <data key="d0">Protein Sequence</data>
      <data key="d1">data</data>
      <data key="d2">A protein sequence is the input data for researchers to obtain structural information using AlphaFold2 within days or hours.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004146</data>
      <data key="d6" />
    </node>
    <node id="Genome Sequencing Results">
      <data key="d0">Genome Sequencing Results</data>
      <data key="d1">data</data>
      <data key="d2">Genome sequencing results are cited as an example of big data in current scientific development.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004146</data>
      <data key="d6" />
    </node>
    <node id="Massive Papers">
      <data key="d0">Massive Papers</data>
      <data key="d1">data</data>
      <data key="d2">Massive papers are cited as an example of big data in current scientific development.</data>
      <data key="d3">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004146</data>
      <data key="d6" />
    </node>
    <node id="南开大学">
      <data key="d0">南开大学</data>
      <data key="d1">organization</data>
      <data key="d2">南开大学是研究论文的发表单位，其统计与数据科学学院的研究团队开发了D-I-TASSER算法。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004234</data>
      <data key="d6" />
    </node>
    <node id="郑伟">
      <data key="d0">郑伟</data>
      <data key="d1">person</data>
      <data key="d2">郑伟是南开大学统计与数据科学学院的教授，是论文的第一作者，长期从事生物分子结构预测研究，开发了D-I-TASSER等算法。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004234</data>
      <data key="d6" />
    </node>
    <node id="张阳">
      <data key="d0">张阳</data>
      <data key="d1">person</data>
      <data key="d2">张阳是新加坡国立大学的教授，是论文的通讯作者之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004226</data>
      <data key="d6" />
    </node>
    <node id="Lydia Freddolino">
      <data key="d0">Lydia Freddolino</data>
      <data key="d1">person</data>
      <data key="d2">Lydia Freddolino是密歇根大学的副教授，是论文的通讯作者之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004227</data>
      <data key="d6" />
    </node>
    <node id="Nature Biotechnology">
      <data key="d0">Nature Biotechnology</data>
      <data key="d1">content</data>
      <data key="d2">Nature Biotechnology是国际生物技术领域的顶尖期刊，是Nature系列期刊之一，发表了关于D-I-TASSER算法的研究论文。&lt;SEP&gt;An authoritative biomedical journal where dozens of papers have been published.</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8&lt;SEP&gt;chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004227</data>
      <data key="d6" />
    </node>
    <node id="D-I-TASSER">
      <data key="d0">D-I-TASSER</data>
      <data key="d1">method</data>
      <data key="d2">D-I-TASSER是一种融合深度学习空间约束与统计能量函数的蛋白质结构预测算法，旨在解决孤儿蛋白和多结构域蛋白的预测难题。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004227</data>
      <data key="d6" />
    </node>
    <node id="AlphaFold3">
      <data key="d0">AlphaFold3</data>
      <data key="d1">method</data>
      <data key="d2">AlphaFold3是一种深度学习方法，在蛋白质结构预测领域取得了突破性进展，但其对孤儿蛋白和多结构域蛋白的预测存在短板。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004228</data>
      <data key="d6" />
    </node>
    <node id="CASP">
      <data key="d0">CASP</data>
      <data key="d1">organization</data>
      <data key="d2">CASP是国际公认的世界级蛋白质结构预测权威竞赛，被誉为“蛋白质结构预测的奥林匹克竞赛”，D-I-TASSER在第15届比赛中获得两项第一。&lt;SEP&gt;CASP is an organization that issued press releases regarding AlphaFold 2's success.</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8&lt;SEP&gt;chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004295</data>
      <data key="d6" />
    </node>
    <node id="孤儿蛋白">
      <data key="d0">孤儿蛋白</data>
      <data key="d1">concept</data>
      <data key="d2">孤儿蛋白是指同源序列较少的蛋白质，其结构预测对AlphaFold系列算法来说是一个挑战。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004229</data>
      <data key="d6" />
    </node>
    <node id="多结构域蛋白">
      <data key="d0">多结构域蛋白</data>
      <data key="d1">concept</data>
      <data key="d2">多结构域蛋白是由多个结构域组成的复杂蛋白质，其结构预测对AlphaFold系列算法来说是一个挑战。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004229</data>
      <data key="d6" />
    </node>
    <node id="前沿交叉学科研究院">
      <data key="d0">前沿交叉学科研究院</data>
      <data key="d1">organization</data>
      <data key="d2">前沿交叉学科研究院是南开大学下属的研究机构，为本研究提供了支持。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004229</data>
      <data key="d6" />
    </node>
    <node id="传染病溯源预警与智能决策全国重点实验室">
      <data key="d0">传染病溯源预警与智能决策全国重点实验室</data>
      <data key="d1">organization</data>
      <data key="d2">该实验室是全国重点实验室，为本研究提供了支持。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004230</data>
      <data key="d6" />
    </node>
    <node id="自然科学基金委">
      <data key="d0">自然科学基金委</data>
      <data key="d1">organization</data>
      <data key="d2">自然科学基金委是中国的科研资助机构，为本研究提供了支持。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004230</data>
      <data key="d6" />
    </node>
    <node id="统计与数据科学学院">
      <data key="d0">统计与数据科学学院</data>
      <data key="d1">organization</data>
      <data key="d2">统计与数据科学学院是南开大学下属的学院，郑伟教授在此任职，是D-I-TASSER算法的开发单位。&lt;SEP&gt;统计与数据科学学院是河北金融学院的学院之一，是本研究作者韩祝华的工作单位。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8&lt;SEP&gt;chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006318</data>
      <data key="d6" />
    </node>
    <node id="新加坡国立大学">
      <data key="d0">新加坡国立大学</data>
      <data key="d1">organization</data>
      <data key="d2">新加坡国立大学是通讯作者张阳教授所在的机构。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004231</data>
      <data key="d6" />
    </node>
    <node id="密歇根大学">
      <data key="d0">密歇根大学</data>
      <data key="d1">organization</data>
      <data key="d2">密歇根大学是通讯作者Lydia Freddolino副教授所在的机构。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004231</data>
      <data key="d6" />
    </node>
    <node id="DMFold">
      <data key="d0">DMFold</data>
      <data key="d1">method</data>
      <data key="d2">DMFold是郑伟教授开发的一系列结构预测算法之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004231</data>
      <data key="d6" />
    </node>
    <node id="人类基因组">
      <data key="d0">人类基因组</data>
      <data key="d1">data</data>
      <data key="d2">人类基因组是D-I-TASSER算法进行蛋白质结构和功能预测的对象。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004231</data>
      <data key="d6" />
    </node>
    <node id="GO标签">
      <data key="d0">GO标签</data>
      <data key="d1">concept</data>
      <data key="d2">GO标签是基因本体论标签，是D-I-TASSER算法预测的蛋白质功能之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004239</data>
      <data key="d6" />
    </node>
    <node id="酶分类">
      <data key="d0">酶分类</data>
      <data key="d1">concept</data>
      <data key="d2">酶分类是D-I-TASSER算法预测的蛋白质功能之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004239</data>
      <data key="d6" />
    </node>
    <node id="小分子结合位点">
      <data key="d0">小分子结合位点</data>
      <data key="d1">concept</data>
      <data key="d2">小分子结合位点是D-I-TASSER算法预测的蛋白质功能之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004232</data>
      <data key="d6" />
    </node>
    <node id="抗体筛选与优化">
      <data key="d0">抗体筛选与优化</data>
      <data key="d1">concept</data>
      <data key="d2">抗体筛选与优化是D-I-TASSER算法取得初步进展的应用任务之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004232</data>
      <data key="d6" />
    </node>
    <node id="罕见病致病基因识别">
      <data key="d0">罕见病致病基因识别</data>
      <data key="d1">concept</data>
      <data key="d2">罕见病致病基因识别是D-I-TASSER算法取得初步进展的应用任务之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004232</data>
      <data key="d6" />
    </node>
    <node id="病毒感染性预测">
      <data key="d0">病毒感染性预测</data>
      <data key="d1">concept</data>
      <data key="d2">病毒感染性预测是D-I-TASSER算法取得初步进展的应用任务之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004232</data>
      <data key="d6" />
    </node>
    <node id="辅助冷冻电镜结构解析">
      <data key="d0">辅助冷冻电镜结构解析</data>
      <data key="d1">concept</data>
      <data key="d2">辅助冷冻电镜结构解析是D-I-TASSER算法取得初步进展的应用任务之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004233</data>
      <data key="d6" />
    </node>
    <node id="Nature Methods">
      <data key="d0">Nature Methods</data>
      <data key="d1">content</data>
      <data key="d2">Nature Methods is a high-level SCI journal where over 50 articles have been published.&lt;SEP&gt;Nature Methods是郑伟教授发表过文章的高水平SCI期刊之一。&lt;SEP&gt;Nature Methods is a journal that named protein structure prediction as its 2021 Method of the Year.</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8&lt;SEP&gt;chunk-95ce0b0b365782f95d313a054721a437&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004498</data>
      <data key="d6" />
    </node>
    <node id="Nature Communications">
      <data key="d0">Nature Communications</data>
      <data key="d1">content</data>
      <data key="d2">Nature Communications is a high-level SCI journal where over 50 articles have been published.&lt;SEP&gt;Nature Communications是郑伟教授发表过文章的高水平SCI期刊之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8&lt;SEP&gt;chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004233</data>
      <data key="d6" />
    </node>
    <node id="PNAS">
      <data key="d0">PNAS</data>
      <data key="d1">content</data>
      <data key="d2">PNAS is a high-level SCI journal where over 50 articles have been published.&lt;SEP&gt;PNAS是郑伟教授发表过文章的高水平SCI期刊之一。</data>
      <data key="d3">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8&lt;SEP&gt;chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004233</data>
      <data key="d6" />
    </node>
    <node id="Structural Prediction Algorithm">
      <data key="d0">Structural Prediction Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">A developed algorithm that has served nearly 100,000 users from over 100 countries.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004234</data>
      <data key="d6" />
    </node>
    <node id="Nankai Statistics">
      <data key="d0">Nankai Statistics</data>
      <data key="d1">organization</data>
      <data key="d2">An academic unit at Nankai University focusing on interdisciplinary biomedical research.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004234</data>
      <data key="d6" />
    </node>
    <node id="Biomedical Interdisciplinary Field">
      <data key="d0">Biomedical Interdisciplinary Field</data>
      <data key="d1">concept</data>
      <data key="d2">A research area where Nankai Statistics is actively involved.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004235</data>
      <data key="d6" />
    </node>
    <node id="Biostatistics">
      <data key="d0">Biostatistics</data>
      <data key="d1">concept</data>
      <data key="d2">A research direction covered by Nankai Statistics.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004235</data>
      <data key="d6" />
    </node>
    <node id="Bioinformatics">
      <data key="d0">Bioinformatics</data>
      <data key="d1">concept</data>
      <data key="d2">A research direction covered by Nankai Statistics.&lt;SEP&gt;Bioinformatics is a field combined with deep learning in AlphaFold's core technology.&lt;SEP&gt;Bioinformatics is the field or domain of study mentioned in the document metadata.&lt;SEP&gt;Bioinformatics is the domain or field of study mentioned in the document metadata.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437&lt;SEP&gt;chunk-5899806c994fc2f391826abc901a8669&lt;SEP&gt;chunk-82b403277dd4d1f793acce70ac7e2f82&lt;SEP&gt;chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004543</data>
      <data key="d6" />
    </node>
    <node id="Mathematical Epidemiology">
      <data key="d0">Mathematical Epidemiology</data>
      <data key="d1">concept</data>
      <data key="d2">A research direction covered by Nankai Statistics.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004235</data>
      <data key="d6" />
    </node>
    <node id="Nature Cancer">
      <data key="d0">Nature Cancer</data>
      <data key="d1">content</data>
      <data key="d2">An authoritative biomedical journal where dozens of papers have been published.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004236</data>
      <data key="d6" />
    </node>
    <node id="Circulation">
      <data key="d0">Circulation</data>
      <data key="d1">content</data>
      <data key="d2">An authoritative biomedical journal where dozens of papers have been published.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004236</data>
      <data key="d6" />
    </node>
    <node id="Gut">
      <data key="d0">Gut</data>
      <data key="d1">content</data>
      <data key="d2">An authoritative biomedical journal where dozens of papers have been published.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004244</data>
      <data key="d6" />
    </node>
    <node id="Epidemic Situation Analysis Reports">
      <data key="d0">Epidemic Situation Analysis Reports</data>
      <data key="d1">content</data>
      <data key="d2">Multiple reports that have received instructions from national leaders.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004244</data>
      <data key="d6" />
    </node>
    <node id="International Protein Structure And Function Prediction Competitions">
      <data key="d0">International Protein Structure And Function Prediction Competitions</data>
      <data key="d1">event</data>
      <data key="d2">Competitions where Nankai Statistics has won the championship multiple times over the years.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004237</data>
      <data key="d6" />
    </node>
    <node id="Nankai University">
      <data key="d0">Nankai University</data>
      <data key="d1">organization</data>
      <data key="d2">The university associated with Nankai Statistics and the news center.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004237</data>
      <data key="d6" />
    </node>
    <node id="Nankai University News Center">
      <data key="d0">Nankai University News Center</data>
      <data key="d1">organization</data>
      <data key="d2">The unit responsible for designing and maintaining the website.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004237</data>
      <data key="d6" />
    </node>
    <node id="Nature Communication">
      <data key="d0">Nature Communication</data>
      <data key="d1">content</data>
      <data key="d2">Nature Communication is an authoritative biomedical journal where dozens of papers have been published.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004237</data>
      <data key="d6" />
    </node>
    <node id="Over 50 Articles">
      <data key="d0">Over 50 Articles</data>
      <data key="d1">data</data>
      <data key="d2">Over 50 articles have been published in high-level SCI journals.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004237</data>
      <data key="d6" />
    </node>
    <node id="Cumulative Citations Of 3500+">
      <data key="d0">Cumulative Citations Of 3500+</data>
      <data key="d1">data</data>
      <data key="d2">The published articles have received over 3500 cumulative citations.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004238</data>
      <data key="d6" />
    </node>
    <node id="Nearly 100,000 Users">
      <data key="d0">Nearly 100,000 Users</data>
      <data key="d1">data</data>
      <data key="d2">The structural prediction algorithm has served nearly 100,000 users.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004238</data>
      <data key="d6" />
    </node>
    <node id="Over 100 Countries">
      <data key="d0">Over 100 Countries</data>
      <data key="d1">data</data>
      <data key="d2">Users of the structural prediction algorithm come from over 100 countries.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004238</data>
      <data key="d6" />
    </node>
    <node id="Dozens Of Papers">
      <data key="d0">Dozens Of Papers</data>
      <data key="d1">data</data>
      <data key="d2">Dozens of papers have been published in authoritative biomedical journals.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004238</data>
      <data key="d6" />
    </node>
    <node id="Multiple Championships">
      <data key="d0">Multiple Championships</data>
      <data key="d1">data</data>
      <data key="d2">Nankai Statistics has won the championship multiple times in international competitions.</data>
      <data key="d3">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004238</data>
      <data key="d6" />
    </node>
    <node id="AlphaFold 2">
      <data key="d0">AlphaFold 2</data>
      <data key="d1">method</data>
      <data key="d2">AlphaFold 2 is an AI algorithm that successfully predicts protein structures based on amino acid sequences, solving a long-standing biological challenge.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004295</data>
      <data key="d6" />
    </node>
    <node id="Science">
      <data key="d0">Science</data>
      <data key="d1">content</data>
      <data key="d2">Science is a specialist science press publication that covered the story of AlphaFold 2's success.&lt;SEP&gt;Science is a weekly journal that selected the achievement of AlphaFold2 as the top scientific breakthrough of 2021.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004497</data>
      <data key="d6" />
    </node>
    <node id="MIT Technology Review">
      <data key="d0">MIT Technology Review</data>
      <data key="d1">content</data>
      <data key="d2">MIT Technology Review is a specialist science press publication that covered the story of AlphaFold 2's success, noting its significance.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004297</data>
      <data key="d6" />
    </node>
    <node id="New Scientist">
      <data key="d0">New Scientist</data>
      <data key="d1">content</data>
      <data key="d2">New Scientist is a specialist science press publication that covered the story of AlphaFold 2's success.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004296</data>
      <data key="d6" />
    </node>
    <node id="Fortune">
      <data key="d0">Fortune</data>
      <data key="d1">content</data>
      <data key="d2">Fortune is a general news-service or weekly publication that covered the story of AlphaFold 2's success.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004297</data>
      <data key="d6" />
    </node>
    <node id="The Economist">
      <data key="d0">The Economist</data>
      <data key="d1">content</data>
      <data key="d2">The Economist is a general news-service or weekly publication that covered the story of AlphaFold 2's success.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004297</data>
      <data key="d6" />
    </node>
    <node id="Bloomberg">
      <data key="d0">Bloomberg</data>
      <data key="d1">organization</data>
      <data key="d2">Bloomberg is a general news-service or weekly publication that covered the story of AlphaFold 2's success.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004298</data>
      <data key="d6" />
    </node>
    <node id="Der Spiegel">
      <data key="d0">Der Spiegel</data>
      <data key="d1">content</data>
      <data key="d2">Der Spiegel is a general news-service or weekly publication that covered the story of AlphaFold 2's success.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004298</data>
      <data key="d6" />
    </node>
    <node id="The Spectator">
      <data key="d0">The Spectator</data>
      <data key="d1">content</data>
      <data key="d2">The Spectator is a general news-service or weekly publication that covered the story of AlphaFold 2's success.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004298</data>
      <data key="d6" />
    </node>
    <node id="The Times">
      <data key="d0">The Times</data>
      <data key="d1">content</data>
      <data key="d2">The Times is a major national newspaper in London that made the AlphaFold 2 story its front-page photo lead with extensive coverage.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004298</data>
      <data key="d6" />
    </node>
    <node id="Protein Structure Prediction">
      <data key="d0">Protein Structure Prediction</data>
      <data key="d1">concept</data>
      <data key="d2">Protein structure prediction is the ability to accurately predict protein structures based on amino acid sequences, expected to benefit life sciences.&lt;SEP&gt;Protein structure prediction is a scientific problem that AlphaFold2 solved, representing a significant breakthrough for life sciences research.&lt;SEP&gt;Protein structure prediction is a field of research focused on determining the three-dimensional structure of proteins from their amino acid sequences.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2&lt;SEP&gt;chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004711</data>
      <data key="d6" />
    </node>
    <node id="Life Sciences">
      <data key="d0">Life Sciences</data>
      <data key="d1">concept</data>
      <data key="d2">Life sciences is a field expected to benefit widely from accurate protein structure prediction, including drug discovery and disease understanding.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004299</data>
      <data key="d6" />
    </node>
    <node id="Drug Discovery">
      <data key="d0">Drug Discovery</data>
      <data key="d1">concept</data>
      <data key="d2">Drug discovery is an area within life sciences that is expected to be accelerated by accurate protein structure prediction.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004299</data>
      <data key="d6" />
    </node>
    <node id="Disease Understanding">
      <data key="d0">Disease Understanding</data>
      <data key="d1">concept</data>
      <data key="d2">Disease understanding is an area within life sciences that is expected to be improved by accurate protein structure prediction.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004299</data>
      <data key="d6" />
    </node>
    <node id="Fifty-Year Old Grand Challenge Of Biology">
      <data key="d0">Fifty-Year Old Grand Challenge Of Biology</data>
      <data key="d1">concept</data>
      <data key="d2">The fifty-year old grand challenge of biology refers to the long-standing problem of predicting protein structures, which AlphaFold 2 solved.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004300</data>
      <data key="d6" />
    </node>
    <node id="London">
      <data key="d0">London</data>
      <data key="d1">location</data>
      <data key="d2">London is the city where The Times newspaper is based, which featured the AlphaFold 2 story prominently.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004300</data>
      <data key="d6" />
    </node>
    <node id="Amino Acid Sequence">
      <data key="d0">Amino Acid Sequence</data>
      <data key="d1">concept</data>
      <data key="d2">Amino acid sequence is the constituent sequence upon which protein structure prediction is based.</data>
      <data key="d3">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004300</data>
      <data key="d6" />
    </node>
    <node id="深度学习技术">
      <data key="d0">深度学习技术</data>
      <data key="d1">method</data>
      <data key="d2">深度学习技术是一种用于增强基因组数据分析准确性和处理能力的人工智能方法。&lt;SEP&gt;Deep learning technology employed by traders for data exploration, model development, scoring, and consumption.&lt;SEP&gt;Deep learning technology is a method that has achieved breakthroughs in the field of image processing.</data>
      <data key="d3">chunk-8ac6b800c024bfc59d45d5769abdcb86&lt;SEP&gt;chunk-858e73004375c211a45ff338fb81b219&lt;SEP&gt;chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009445</data>
      <data key="d6" />
    </node>
    <node id="基因组数据分析">
      <data key="d0">基因组数据分析</data>
      <data key="d1">data</data>
      <data key="d2">基因组数据分析涉及对基因组序列信息的处理和解读，其准确性和处理能力是生物信息学研究的核心。</data>
      <data key="d3">chunk-8ac6b800c024bfc59d45d5769abdcb86</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004315</data>
      <data key="d6" />
    </node>
    <node id="概念性框架">
      <data key="d0">概念性框架</data>
      <data key="d1">concept</data>
      <data key="d2">概念性框架是一个用于指导畜禽基因组学研究策略发展的理论结构。</data>
      <data key="d3">chunk-8ac6b800c024bfc59d45d5769abdcb86</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004316</data>
      <data key="d6" />
    </node>
    <node id="畜禽基因组学研究">
      <data key="d0">畜禽基因组学研究</data>
      <data key="d1">concept</data>
      <data key="d2">畜禽基因组学研究是针对家畜和家禽基因组进行的研究，旨在发展相关策略和应用。</data>
      <data key="d3">chunk-8ac6b800c024bfc59d45d5769abdcb86</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004316</data>
      <data key="d6" />
    </node>
    <node id="MIT 6.874">
      <data key="d0">MIT 6.874</data>
      <data key="d1">content</data>
      <data key="d2">麻省理工学院开设的一门交叉专业课程，内容涵盖生命科学与计算机科学。</data>
      <data key="d3">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004337</data>
      <data key="d6" />
    </node>
    <node id="麻省理工学院">
      <data key="d0">麻省理工学院</data>
      <data key="d1">organization</data>
      <data key="d2">全球顶尖大学，开设了MIT 6.874课程。</data>
      <data key="d3">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004337</data>
      <data key="d6" />
    </node>
    <node id="生命科学">
      <data key="d0">生命科学</data>
      <data key="d1">concept</data>
      <data key="d2">一个科学领域，与计算机科学交叉，是MIT 6.874课程的核心内容之一。</data>
      <data key="d3">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004337</data>
      <data key="d6" />
    </node>
    <node id="基因组学">
      <data key="d0">基因组学</data>
      <data key="d1">concept</data>
      <data key="d2">生命科学领域中的一个分支，在MIT 6.874课程中被广泛介绍。</data>
      <data key="d3">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004337</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning In Life Sciences">
      <data key="d0">Deep Learning In Life Sciences</data>
      <data key="d1">content</data>
      <data key="d2">Deep Learning in Life Sciences is a lecture series, specifically Lecture 07 on Regulatory Genomics.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004373</data>
      <data key="d6" />
    </node>
    <node id="Regulatory Genomics">
      <data key="d0">Regulatory Genomics</data>
      <data key="d1">concept</data>
      <data key="d2">Regulatory Genomics is the subject of Lecture 07 within the Deep Learning in Life Sciences series.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004373</data>
      <data key="d6" />
    </node>
    <node id="Spring 2021">
      <data key="d0">Spring 2021</data>
      <data key="d1">event</data>
      <data key="d2">Spring 2021 is the semester during which the lecture series Deep Learning in Life Sciences was offered.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004373</data>
      <data key="d6" />
    </node>
    <node id="20.390">
      <data key="d0">20.390</data>
      <data key="d1">content</data>
      <data key="d2">20.390 is a course number associated with the lecture series Deep Learning in Life Sciences.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004373</data>
      <data key="d6" />
    </node>
    <node id="20.490">
      <data key="d0">20.490</data>
      <data key="d1">content</data>
      <data key="d2">20.490 is a course number associated with the lecture series Deep Learning in Life Sciences.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004373</data>
      <data key="d6" />
    </node>
    <node id="HST.506">
      <data key="d0">HST.506</data>
      <data key="d1">content</data>
      <data key="d2">HST.506 is a course number associated with the lecture series Deep Learning in Life Sciences.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004374</data>
      <data key="d6" />
    </node>
    <node id="Prof.">
      <data key="d0">Prof.</data>
      <data key="d1">person</data>
      <data key="d2">Prof. is the instructor for the lecture series Deep Learning in Life Sciences in Spring 2021.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004374</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-18295298">
      <data key="d0">DOC_ID: chunk-18295298</data>
      <data key="d1">data</data>
      <data key="d2">DOC_ID: chunk-18295298 is a document identifier for the text segment.</data>
      <data key="d3">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004374</data>
      <data key="d6" />
    </node>
    <node id="Deep Neural Network">
      <data key="d0">Deep Neural Network</data>
      <data key="d1">method</data>
      <data key="d2">A deep neural network is a trained model used to predict protein properties from gene sequences.</data>
      <data key="d3">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004395</data>
      <data key="d6" />
    </node>
    <node id="Gene Sequence">
      <data key="d0">Gene Sequence</data>
      <data key="d1">data</data>
      <data key="d2">A gene sequence is the input data from which protein properties are predicted.</data>
      <data key="d3">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004395</data>
      <data key="d6" />
    </node>
    <node id="Protein">
      <data key="d0">Protein</data>
      <data key="d1">naturalobject</data>
      <data key="d2">A protein is a biological molecule whose properties are predicted by the neural network models.</data>
      <data key="d3">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004395</data>
      <data key="d6" />
    </node>
    <node id="Protein Property">
      <data key="d0">Protein Property</data>
      <data key="d1">concept</data>
      <data key="d2">Protein properties are the attributes predicted by the neural networks from gene sequences.</data>
      <data key="d3">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004395</data>
      <data key="d6" />
    </node>
    <node id="Sequence">
      <data key="d0">Sequence</data>
      <data key="d1">concept</data>
      <data key="d2">Sequence refers to the linear arrangement of biological molecules, such as amino acids in proteins.</data>
      <data key="d3">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004421</data>
      <data key="d6" />
    </node>
    <node id="Structure">
      <data key="d0">Structure</data>
      <data key="d1">concept</data>
      <data key="d2">Structure refers to the three-dimensional conformation of biological molecules, such as proteins.</data>
      <data key="d3">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004422</data>
      <data key="d6" />
    </node>
    <node id="Multiple Sequence Alignment (MSA)">
      <data key="d0">Multiple Sequence Alignment (MSA)</data>
      <data key="d1">method</data>
      <data key="d2">Multiple Sequence Alignment (MSA) is a bioinformatics method used for comparing and aligning multiple biological sequences.</data>
      <data key="d3">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004422</data>
      <data key="d6" />
    </node>
    <node id="Traditional Tools">
      <data key="d0">Traditional Tools</data>
      <data key="d1">method</data>
      <data key="d2">Traditional tools are methods in bioinformatics that often rely on physical models or simple machine learning.</data>
      <data key="d3">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004422</data>
      <data key="d6" />
    </node>
    <node id="Physical Model">
      <data key="d0">Physical Model</data>
      <data key="d1">method</data>
      <data key="d2">Physical model is a type of method used in traditional bioinformatics tools to understand molecular structures.</data>
      <data key="d3">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004422</data>
      <data key="d6" />
    </node>
    <node id="Simple Machine Learning">
      <data key="d0">Simple Machine Learning</data>
      <data key="d1">method</data>
      <data key="d2">Simple machine learning refers to basic computational learning techniques used in some traditional bioinformatics tools.</data>
      <data key="d3">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004422</data>
      <data key="d6" />
    </node>
    <node id="Protein Sequences">
      <data key="d0">Protein Sequences</data>
      <data key="d1">data</data>
      <data key="d2">Protein sequences are a type of data analyzed by AlphaFold.</data>
      <data key="d3">chunk-5899806c994fc2f391826abc901a8669</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004441</data>
      <data key="d6" />
    </node>
    <node id="Protein Structures">
      <data key="d0">Protein Structures</data>
      <data key="d1">data</data>
      <data key="d2">Protein structures are a type of data analyzed by AlphaFold.</data>
      <data key="d3">chunk-5899806c994fc2f391826abc901a8669</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004441</data>
      <data key="d6" />
    </node>
    <node id="序列与结构之间的关系">
      <data key="d0">序列与结构之间的关系</data>
      <data key="d1">concept</data>
      <data key="d2">序列与结构之间的关系是AlphaFold通过学习大量蛋白质序列和结构数据所要掌握的核心知识。</data>
      <data key="d3">chunk-5899806c994fc2f391826abc901a8669</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004441</data>
      <data key="d6" />
    </node>
    <node id="Jiang Po">
      <data key="d0">Jiang Po</data>
      <data key="d1">person</data>
      <data key="d2">Jiang Po led a young team to re-examine and comprehensively adjust and improve the initial version of AlphaFold.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004504</data>
      <data key="d6" />
    </node>
    <node id="CASP Competition">
      <data key="d0">CASP Competition</data>
      <data key="d1">event</data>
      <data key="d2">The CASP (Critical Assessment of protein Structure Prediction) competition is an event where AlphaFold2 demonstrated superior performance with high GDT scores.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004496</data>
      <data key="d6" />
    </node>
    <node id="GDT Score">
      <data key="d0">GDT Score</data>
      <data key="d1">data</data>
      <data key="d2">GDT (Global Distance Test) score is a metric used to evaluate the accuracy of protein structure predictions, with AlphaFold2 achieving an average of 92.4.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004499</data>
      <data key="d6" />
    </node>
    <node id="Young Team">
      <data key="d0">Young Team</data>
      <data key="d1">organization</data>
      <data key="d2">A young team led by Jiang Po that re-examined and improved the initial version of AlphaFold.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004500</data>
      <data key="d6" />
    </node>
    <node id="Algorithm">
      <data key="d0">Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">The algorithm for AlphaFold2 was made freely available by DeepMind for global researchers to use.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004501</data>
      <data key="d6" />
    </node>
    <node id="Paper">
      <data key="d0">Paper</data>
      <data key="d1">content</data>
      <data key="d2">The paper detailing AlphaFold2, published in Nature, has been cited nearly ten thousand times.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004501</data>
      <data key="d6" />
    </node>
    <node id="Life Sciences Research">
      <data key="d0">Life Sciences Research</data>
      <data key="d1">concept</data>
      <data key="d2">Life sciences research is a field that benefited immensely from the AlphaFold2 breakthrough, as it drastically reduced the time and cost to obtain protein structures.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004501</data>
      <data key="d6" />
    </node>
    <node id="Big Data">
      <data key="d0">Big Data</data>
      <data key="d1">concept</data>
      <data key="d2">Big data, such as genome sequencing results and massive volumes of papers, is an important feature of current scientific development.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004502</data>
      <data key="d6" />
    </node>
    <node id="AI Tools">
      <data key="d0">AI Tools</data>
      <data key="d1">concept</data>
      <data key="d2">AI tools represent an important direction for solving life science problems, as exemplified by AlphaFold.</data>
      <data key="d3">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004502</data>
      <data key="d6" />
    </node>
    <node id="Google DeepMind">
      <data key="d0">Google DeepMind</data>
      <data key="d1">organization</data>
      <data key="d2">Google DeepMind is an organization that trained a reinforcement learning agent called AlphaDev.&lt;SEP&gt;Google DeepMind is an organization that develops and tests innovative technologies, including the Gemini model, which are integrated into Google Cloud.</data>
      <data key="d3">chunk-82b403277dd4d1f793acce70ac7e2f82&lt;SEP&gt;chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009396</data>
      <data key="d6" />
    </node>
    <node id="AlphaDev">
      <data key="d0">AlphaDev</data>
      <data key="d1">artifact</data>
      <data key="d2">AlphaDev is a reinforcement learning agent trained by Google DeepMind to find better sorting programs.</data>
      <data key="d3">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004523</data>
      <data key="d6" />
    </node>
    <node id="Reinforcement Learning Agent">
      <data key="d0">Reinforcement Learning Agent</data>
      <data key="d1">concept</data>
      <data key="d2">A reinforcement learning agent is a type of artificial intelligence system that learns to make decisions through trial and error.</data>
      <data key="d3">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004523</data>
      <data key="d6" />
    </node>
    <node id="Sorting Program">
      <data key="d0">Sorting Program</data>
      <data key="d1">artifact</data>
      <data key="d2">A sorting program is a computer algorithm designed to arrange data in a specific order.</data>
      <data key="d3">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004524</data>
      <data key="d6" />
    </node>
    <node id="Small Sorting Algorithm">
      <data key="d0">Small Sorting Algorithm</data>
      <data key="d1">artifact</data>
      <data key="d2">Small sorting algorithms are compact computer programs for arranging data, discovered from scratch by AlphaDev.</data>
      <data key="d3">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004524</data>
      <data key="d6" />
    </node>
    <node id="Human Benchmark">
      <data key="d0">Human Benchmark</data>
      <data key="d1">concept</data>
      <data key="d2">Human benchmarks refer to previously known performance standards set by human-designed algorithms.</data>
      <data key="d3">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004524</data>
      <data key="d6" />
    </node>
    <node id="David Baker">
      <data key="d0">David Baker</data>
      <data key="d1">person</data>
      <data key="d2">David Baker is a professor at the University of Washington and a world-renowned expert in protein design, having published over 700 research papers in the field of proteins.</data>
      <data key="d3">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004543</data>
      <data key="d6" />
    </node>
    <node id="University Of Washington">
      <data key="d0">University Of Washington</data>
      <data key="d1">organization</data>
      <data key="d2">The University of Washington is an American university where David Baker serves as a professor.</data>
      <data key="d3">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004543</data>
      <data key="d6" />
    </node>
    <node id="Protein Design">
      <data key="d0">Protein Design</data>
      <data key="d1">concept</data>
      <data key="d2">Protein design is a field of bioinformatics and scientific research.</data>
      <data key="d3">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004543</data>
      <data key="d6" />
    </node>
    <node id="Research Papers">
      <data key="d0">Research Papers</data>
      <data key="d1">content</data>
      <data key="d2">Research papers are scholarly publications; David Baker has published over 700 of them in the field of proteins.</data>
      <data key="d3">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004543</data>
      <data key="d6" />
    </node>
    <node id="Citations">
      <data key="d0">Citations</data>
      <data key="d1">data</data>
      <data key="d2">Citations refer to the cumulative number of times David Baker's research work has been referenced by others.</data>
      <data key="d3">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004543</data>
      <data key="d6" />
    </node>
    <node id="多序列比对">
      <data key="d0">多序列比对</data>
      <data key="d1">method</data>
      <data key="d2">Multiple sequence alignment is a method used in bioinformatics and is part of the input for AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004669</data>
      <data key="d6" />
    </node>
    <node id="预测距离分布">
      <data key="d0">预测距离分布</data>
      <data key="d1">concept</data>
      <data key="d2">Predicted distance distribution is a type of information used in protein structure prediction.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004669</data>
      <data key="d6" />
    </node>
    <node id="二面角分布">
      <data key="d0">二面角分布</data>
      <data key="d1">concept</data>
      <data key="d2">Dihedral angle distribution is a type of information used in protein structure prediction.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004663</data>
      <data key="d6" />
    </node>
    <node id="结构优化">
      <data key="d0">结构优化</data>
      <data key="d1">method</data>
      <data key="d2">Structure optimization is a process involved in refining protein models.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004663</data>
      <data key="d6" />
    </node>
    <node id="Alphafold2">
      <data key="d0">Alphafold2</data>
      <data key="d1">method</data>
      <data key="d2">AlphaFold2 is an end-to-end deep learning model for protein structure prediction, featuring attention mechanisms and 3D equivariance.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004663</data>
      <data key="d6" />
    </node>
    <node id="End-to-end架构">
      <data key="d0">End-to-end架构</data>
      <data key="d1">concept</data>
      <data key="d2">End-to-end architecture refers to a model design where input is directly mapped to output without intermediate manual steps.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004664</data>
      <data key="d6" />
    </node>
    <node id="3D Equivariant Structure Module">
      <data key="d0">3D Equivariant Structure Module</data>
      <data key="d1">method</data>
      <data key="d2">The 3D Equivariant Structure Module is a component of AlphaFold2 that outputs atomic coordinates with rotational and translational invariance.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004665</data>
      <data key="d6" />
    </node>
    <node id="CASP14">
      <data key="d0">CASP14</data>
      <data key="d1">event</data>
      <data key="d2">CASP14 is the 14th Critical Assessment of protein Structure Prediction competition where AlphaFold2 was presented.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004665</data>
      <data key="d6" />
    </node>
    <node id="Jumper, J">
      <data key="d0">Jumper, J</data>
      <data key="d1">person</data>
      <data key="d2">Jumper, J is an author of the 2021 Nature paper detailing the AlphaFold2 architecture.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004666</data>
      <data key="d6" />
    </node>
    <node id="Protein backbone">
      <data key="d0">Protein backbone</data>
      <data key="d1">concept</data>
      <data key="d2">The protein backbone refers to the main chain of atoms (N-Cα-C) in a protein's structure.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004666</data>
      <data key="d6" />
    </node>
    <node id="IPA (Invariant Point Attention)">
      <data key="d0">IPA (Invariant Point Attention)</data>
      <data key="d1">method</data>
      <data key="d2">Invariant Point Attention is a key architecture within the Structure Module that achieves 3D equivariance.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004667</data>
      <data key="d6" />
    </node>
    <node id="Residue Gas">
      <data key="d0">Residue Gas</data>
      <data key="d1">concept</data>
      <data key="d2">Residue Gas is a representation used for the protein structure, modeling it as a gas of 3D rigid bodies.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004667</data>
      <data key="d6" />
    </node>
    <node id="序列信息">
      <data key="d0">序列信息</data>
      <data key="d1">data</data>
      <data key="d2">Sequence information refers to the amino acid sequence of the target protein, used as input to AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004667</data>
      <data key="d6" />
    </node>
    <node id="Distance Map信息">
      <data key="d0">Distance Map信息</data>
      <data key="d1">data</data>
      <data key="d2">Distance map information contains pairwise distance constraints between residues, used as input to AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004674</data>
      <data key="d6" />
    </node>
    <node id="蛋白质骨架初始Residue Gas">
      <data key="d0">蛋白质骨架初始Residue Gas</data>
      <data key="d1">data</data>
      <data key="d2">The initial Residue Gas for the protein backbone is the starting 3D representation input to the Structure Module.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004667</data>
      <data key="d6" />
    </node>
    <node id="全原子的位置坐标">
      <data key="d0">全原子的位置坐标</data>
      <data key="d1">data</data>
      <data key="d2">Full atomic position coordinates are the 3D coordinates of all atoms in the predicted protein structure, output by AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004667</data>
      <data key="d6" />
    </node>
    <node id="lDDT-Cα">
      <data key="d0">lDDT-Cα</data>
      <data key="d1">data</data>
      <data key="d2">lDDT-Cα is a metric used to evaluate the modeling accuracy of the predicted protein structure.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004668</data>
      <data key="d6" />
    </node>
    <node id="Evoformer">
      <data key="d0">Evoformer</data>
      <data key="d1">method</data>
      <data key="d2">Evoformer is an attention-based architecture within AlphaFold2 used for processing MSA and template information.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004668</data>
      <data key="d6" />
    </node>
    <node id="Recycling多轮迭代">
      <data key="d0">Recycling多轮迭代</data>
      <data key="d1">method</data>
      <data key="d2">Recycling multi-round iteration is a process in AlphaFold2 where the model refines its predictions through multiple cycles.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004668</data>
      <data key="d6" />
    </node>
    <node id="2020">
      <data key="d0">2020</data>
      <data key="d1">data</data>
      <data key="d2">2020 is the publication year of a Nature paper discussing AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004669</data>
      <data key="d6" />
    </node>
    <node id="577(7792): 706-710">
      <data key="d0">577(7792): 706-710</data>
      <data key="d1">data</data>
      <data key="d2">577(7792): 706-710 is the volume, issue, and page range for the 2020 Nature publication.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004669</data>
      <data key="d6" />
    </node>
    <node id="Chapter1">
      <data key="d0">Chapter1</data>
      <data key="d1">content</data>
      <data key="d2">Chapter1 is a section heading in the document discussing the overall architecture of AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004670</data>
      <data key="d6" />
    </node>
    <node id="Picture taken from DeepMind slides in CASP14">
      <data key="d0">Picture taken from DeepMind slides in CASP14</data>
      <data key="d1">content</data>
      <data key="d2">This is a caption for an image sourced from DeepMind's presentation at CASP14.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004670</data>
      <data key="d6" />
    </node>
    <node id="主要特点">
      <data key="d0">主要特点</data>
      <data key="d1">concept</data>
      <data key="d2">Key features are the listed characteristics of AlphaFold2's architecture.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004671</data>
      <data key="d6" />
    </node>
    <node id="1D与2D信息">
      <data key="d0">1D与2D信息</data>
      <data key="d1">data</data>
      <data key="d2">1D and 2D information refers to sequence and pairwise interaction data used by AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004671</data>
      <data key="d6" />
    </node>
    <node id="Chapter2">
      <data key="d0">Chapter2</data>
      <data key="d1">content</data>
      <data key="d2">Chapter2 is a section heading in the document detailing the AlphaFold model architecture.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004671</data>
      <data key="d6" />
    </node>
    <node id="2021">
      <data key="d0">2021</data>
      <data key="d1">data</data>
      <data key="d2">2021 is the publication year of the detailed Nature paper on AlphaFold2 by Jumper et al.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004671</data>
      <data key="d6" />
    </node>
    <node id="整体架构的精彩之四">
      <data key="d0">整体架构的精彩之四</data>
      <data key="d1">concept</data>
      <data key="d2">This is a sub-heading highlighting the fourth key aspect of the overall architecture.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004671</data>
      <data key="d6" />
    </node>
    <node id="Protein backbone = gas of 3-D rigid bodies">
      <data key="d0">Protein backbone = gas of 3-D rigid bodies</data>
      <data key="d1">concept</data>
      <data key="d2">This is a conceptual equation describing the Residue Gas representation of a protein.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004672</data>
      <data key="d6" />
    </node>
    <node id="重要架构">
      <data key="d0">重要架构</data>
      <data key="d1">concept</data>
      <data key="d2">Important architecture refers to key components like IPA and Residue Gas.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004672</data>
      <data key="d6" />
    </node>
    <node id="输入">
      <data key="d0">输入</data>
      <data key="d1">concept</data>
      <data key="d2">Input refers to the data fed into the Structure Module of AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004672</data>
      <data key="d6" />
    </node>
    <node id="输出">
      <data key="d0">输出</data>
      <data key="d1">concept</data>
      <data key="d2">Output refers to the results produced by the Structure Module of AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004672</data>
      <data key="d6" />
    </node>
    <node id="更强大的MSA &amp; Templates">
      <data key="d0">更强大的MSA &amp; Templates</data>
      <data key="d1">concept</data>
      <data key="d2">More powerful MSA &amp; Templates refers to enhanced input features for AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004672</data>
      <data key="d6" />
    </node>
    <node id="用于结构预测的Attention架构">
      <data key="d0">用于结构预测的Attention架构</data>
      <data key="d1">concept</data>
      <data key="d2">Attention architecture for structure prediction describes the Evoformer module.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004672</data>
      <data key="d6" />
    </node>
    <node id="多输出">
      <data key="d0">多输出</data>
      <data key="d1">concept</data>
      <data key="d2">Multiple outputs refers to the various predictions (coordinates, scores) made by AlphaFold2.</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004673</data>
      <data key="d6" />
    </node>
    <node id="DeepMind slides">
      <data key="d0">DeepMind slides</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d2">The slides containing the picture were presented by DeepMind at the CASP14 event.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004678</data>
      <data key="d6" />
    </node>
    <node id="Alphafold模型架构">
      <data key="d0">Alphafold模型架构</data>
      <data key="d3">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d2">Chapter2 of the document provides a detailed explanation of the AlphaFold model architecture.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004679</data>
      <data key="d6" />
    </node>
    <node id="Patent Data">
      <data key="d0">Patent Data</data>
      <data key="d1">data</data>
      <data key="d2">Patent data refers to the collection of published patent documents used as a source for analyzing technological trends and developments.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004711</data>
      <data key="d6" />
    </node>
    <node id="Application Trends">
      <data key="d0">Application Trends</data>
      <data key="d1">concept</data>
      <data key="d2">Application trends refer to the patterns and directions in which patent applications in a specific field are filed over time.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004711</data>
      <data key="d6" />
    </node>
    <node id="Regional Distribution">
      <data key="d0">Regional Distribution</data>
      <data key="d1">concept</data>
      <data key="d2">Regional distribution refers to the geographical spread of patent applications or research activities across different countries or areas.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004712</data>
      <data key="d6" />
    </node>
    <node id="Major Applicants">
      <data key="d0">Major Applicants</data>
      <data key="d1">concept</data>
      <data key="d2">Major applicants are the primary individuals or organizations that file a significant number of patents in a given field.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004712</data>
      <data key="d6" />
    </node>
    <node id="Technological Evolution">
      <data key="d0">Technological Evolution</data>
      <data key="d1">concept</data>
      <data key="d2">Technological evolution describes the progression and changes in the core technologies and methods within a research field over time.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004712</data>
      <data key="d6" />
    </node>
    <node id="Opportunities And Challenges">
      <data key="d0">Opportunities And Challenges</data>
      <data key="d1">concept</data>
      <data key="d2">Opportunities and challenges refer to the potential future developments and the existing difficulties or obstacles within an industry or research area.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004720</data>
      <data key="d6" />
    </node>
    <node id="High-Quality Development">
      <data key="d0">High-Quality Development</data>
      <data key="d1">concept</data>
      <data key="d2">High-quality development refers to the strategic goal of advancing an industry in a scientifically sound, efficient, and sustainable manner.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004712</data>
      <data key="d6" />
    </node>
    <node id="This Paper">
      <data key="d0">This Paper</data>
      <data key="d1">content</data>
      <data key="d2">This paper is a research document that analyzes the global status of protein structure prediction using patent data.</data>
      <data key="d3">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004713</data>
      <data key="d6" />
    </node>
    <node id="Deep-Algotrading">
      <data key="d0">Deep-Algotrading</data>
      <data key="d1">content</data>
      <data key="d2">Deep-Algotrading is a resource repository for learners covering topics from simple regression analysis to complex time series forecasting techniques.</data>
      <data key="d3">chunk-201fcd200de194e722ae83a479174b8b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004748</data>
      <data key="d6" />
    </node>
    <node id="Regression Analysis">
      <data key="d0">Regression Analysis</data>
      <data key="d1">method</data>
      <data key="d2">Regression analysis is a statistical method for estimating the relationships among variables, mentioned as a foundational topic covered by the resource.</data>
      <data key="d3">chunk-201fcd200de194e722ae83a479174b8b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004748</data>
      <data key="d6" />
    </node>
    <node id="Time Series Forecasting">
      <data key="d0">Time Series Forecasting</data>
      <data key="d1">method</data>
      <data key="d2">Time series forecasting is a technique for predicting future values based on previously observed values, covered as a complex topic in the resource.</data>
      <data key="d3">chunk-201fcd200de194e722ae83a479174b8b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004749</data>
      <data key="d6" />
    </node>
    <node id="LSTM">
      <data key="d0">LSTM</data>
      <data key="d1">method</data>
      <data key="d2">LSTM (Long Short-Term Memory) is a type of recurrent neural network architecture used for time series forecasting.&lt;SEP&gt;Long Short-Term Memory networks, capable of learning long-range context, which is very helpful for recognition tasks.&lt;SEP&gt;一种用于处理序列依赖或长时间依赖特征的神经网络模型。&lt;SEP&gt;LSTM是一种深度学习模型，能够捕捉长距离的上下文特征，帮助解决语义理解问题。</data>
      <data key="d3">chunk-201fcd200de194e722ae83a479174b8b&lt;SEP&gt;chunk-432af570193bd3df6d564434ee8bfbbb&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006832</data>
      <data key="d6" />
    </node>
    <node id="Reinforcement Learning">
      <data key="d0">Reinforcement Learning</data>
      <data key="d1">method</data>
      <data key="d2">Reinforcement learning is a machine learning paradigm where an agent learns to make decisions by interacting with an environment, mentioned as a method utilizing financial data.&lt;SEP&gt;A machine learning paradigm where an agent learns by interacting with an environment to maximize reward.&lt;SEP&gt;A type of machine learning where an agent learns by interacting with an environment.</data>
      <data key="d3">chunk-201fcd200de194e722ae83a479174b8b&lt;SEP&gt;chunk-0724c887b70d220c530dcfaee28003c1&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009206</data>
      <data key="d6" />
    </node>
    <node id="Financial Data">
      <data key="d0">Financial Data</data>
      <data key="d1">data</data>
      <data key="d2">Financial data refers to datasets used in quantitative finance and algorithmic trading, serving as input for the methods described.&lt;SEP&gt;Financial Data contains 'Three Invisible Traps' that can cause models to fail in the stock market.</data>
      <data key="d3">chunk-201fcd200de194e722ae83a479174b8b&lt;SEP&gt;chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004950</data>
      <data key="d6" />
    </node>
    <node id="Market Participants">
      <data key="d0">Market Participants</data>
      <data key="d1">organization</data>
      <data key="d2">Entities involved in financial markets who have a widespread demand for algorithmic trading.</data>
      <data key="d3">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004769</data>
      <data key="d6" />
    </node>
    <node id="Algorithmic Trading">
      <data key="d0">Algorithmic Trading</data>
      <data key="d1">concept</data>
      <data key="d2">The use of computer algorithms to automate trading decisions in financial markets.</data>
      <data key="d3">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004769</data>
      <data key="d6" />
    </node>
    <node id="Deep Reinforcement Learning (DRL)">
      <data key="d0">Deep Reinforcement Learning (DRL)</data>
      <data key="d1">method</data>
      <data key="d2">A machine learning approach that combines deep learning with reinforcement learning, used here as a perspective for analyzing algorithmic trading.</data>
      <data key="d3">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004769</data>
      <data key="d6" />
    </node>
    <node id="Strategy Inputs And Outputs">
      <data key="d0">Strategy Inputs And Outputs</data>
      <data key="d1">concept</data>
      <data key="d2">Components of an algorithmic trading strategy, referring to the data fed into the model and the trading decisions it generates.</data>
      <data key="d3">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004769</data>
      <data key="d6" />
    </node>
    <node id="Incentive Function">
      <data key="d0">Incentive Function</data>
      <data key="d1">concept</data>
      <data key="d2">A function within a reinforcement learning framework that defines the rewards or penalties to guide the learning of an algorithmic trading strategy.</data>
      <data key="d3">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004770</data>
      <data key="d6" />
    </node>
    <node id="Financial Studies">
      <data key="d0">Financial Studies</data>
      <data key="d1">concept</data>
      <data key="d2">The academic domain or field of study to which the document belongs, as indicated by the document metadata.</data>
      <data key="d3">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004770</data>
      <data key="d6" />
    </node>
    <node id="Back-Testing Results">
      <data key="d0">Back-Testing Results</data>
      <data key="d1">data</data>
      <data key="d2">Back-testing results are performance metrics for trading strategies, including number of trades, win rate, average profit, average loss, profit-loss ratio, and expected return.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004802</data>
      <data key="d6" />
    </node>
    <node id="High-Frequency Trading Strategy">
      <data key="d0">High-Frequency Trading Strategy</data>
      <data key="d1">method</data>
      <data key="d2">A high-frequency trading strategy is a method that executes a large number of trades at very high speeds, based on algorithmic models.&lt;SEP&gt;A trading strategy where ultra-low latency is crucial, presenting high technical and cost barriers for deploying deep learning models.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3&lt;SEP&gt;chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004942</data>
      <data key="d6" />
    </node>
    <node id="ANN">
      <data key="d0">ANN</data>
      <data key="d1">method</data>
      <data key="d2">ANN (Artificial Neural Network) is a computational model used as the basis for a high-frequency trading strategy.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004802</data>
      <data key="d6" />
    </node>
    <node id="交易次数">
      <data key="d0">交易次数</data>
      <data key="d1">data</data>
      <data key="d2">交易次数is a metric in back-testing results representing the number of trades executed.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004803</data>
      <data key="d6" />
    </node>
    <node id="胜率">
      <data key="d0">胜率</data>
      <data key="d1">data</data>
      <data key="d2">胜率is a metric in back-testing results representing the win rate of the trading strategy.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004804</data>
      <data key="d6" />
    </node>
    <node id="平均盈利">
      <data key="d0">平均盈利</data>
      <data key="d1">data</data>
      <data key="d2">平均盈利is a metric in back-testing results representing the average profit per trade.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004804</data>
      <data key="d6" />
    </node>
    <node id="平均亏损">
      <data key="d0">平均亏损</data>
      <data key="d1">data</data>
      <data key="d2">平均亏损is a metric in back-testing results representing the average loss per trade.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004804</data>
      <data key="d6" />
    </node>
    <node id="盈亏比">
      <data key="d0">盈亏比</data>
      <data key="d1">data</data>
      <data key="d2">盈亏比is a metric in back-testing results representing the profit-to-loss ratio.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004805</data>
      <data key="d6" />
    </node>
    <node id="期望收益">
      <data key="d0">期望收益</data>
      <data key="d1">data</data>
      <data key="d2">期望收益is a metric in back-testing results representing the expected return of the strategy.</data>
      <data key="d3">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004805</data>
      <data key="d6" />
    </node>
    <node id="高頻交易">
      <data key="d0">高頻交易</data>
      <data key="d1">concept</data>
      <data key="d2">High-frequency trading (HFT) is a field characterized by extremely large data volumes and rapid changes.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004915</data>
      <data key="d6" />
    </node>
    <node id="深度學習模型">
      <data key="d0">深度學習模型</data>
      <data key="d1">concept</data>
      <data key="d2">Deep learning models, such as CNN and RNN, are capable of processing massive amounts of micro-market structure data.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004915</data>
      <data key="d6" />
    </node>
    <node id="微觀市場結構數據">
      <data key="d0">微觀市場結構數據</data>
      <data key="d1">data</data>
      <data key="d2">Micro-market structure data includes changes in order book depth, bid-ask spread fluctuations, and instantaneous trading volume.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004917</data>
      <data key="d6" />
    </node>
    <node id="訂單簿">
      <data key="d0">訂單簿</data>
      <data key="d1">concept</data>
      <data key="d2">The order book is a record of outstanding buy and sell orders for a security.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004917</data>
      <data key="d6" />
    </node>
    <node id="買賣價差">
      <data key="d0">買賣價差</data>
      <data key="d1">concept</data>
      <data key="d2">The bid-ask spread is the difference between the highest price a buyer is willing to pay and the lowest price a seller is willing to accept.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004917</data>
      <data key="d6" />
    </node>
    <node id="多因子模型">
      <data key="d0">多因子模型</data>
      <data key="d1">method</data>
      <data key="d2">Multi-factor models are quantitative strategies where the effectiveness of individual factors is not constant.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004918</data>
      <data key="d6" />
    </node>
    <node id="因子">
      <data key="d0">因子</data>
      <data key="d1">data</data>
      <data key="d2">A factor, such as value, momentum, or low volatility, is a characteristic used to explain asset returns.&lt;SEP&gt;因子是用于量化模型分析的特征或变量，文中提到中低频因子数量少，而高频日内因子可达上百个。</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859&lt;SEP&gt;chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005144</data>
      <data key="d6" />
    </node>
    <node id="自動編碼器">
      <data key="d0">自動編碼器</data>
      <data key="d1">method</data>
      <data key="d2">Autoencoder is an unsupervised learning model used for learning compressed representations of data, applicable in risk management for anomaly detection.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004918</data>
      <data key="d6" />
    </node>
    <node id="風險管理">
      <data key="d0">風險管理</data>
      <data key="d1">concept</data>
      <data key="d2">Risk management is a cornerstone of quantitative trading, involving volatility forecasting, credit risk assessment, and market anomaly detection.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004918</data>
      <data key="d6" />
    </node>
    <node id="投資組合">
      <data key="d0">投資組合</data>
      <data key="d1">concept</data>
      <data key="d2">A portfolio is a collection of financial assets. Portfolio optimization involves building and optimizing the entire collection for better risk-return ratios.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004919</data>
      <data key="d6" />
    </node>
    <node id="另類數據">
      <data key="d0">另類數據</data>
      <data key="d1">data</data>
      <data key="d2">Alternative data includes non-traditional sources like news sentiment, social media sentiment, satellite imagery, and supply chain data.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004919</data>
      <data key="d6" />
    </node>
    <node id="自然語言處理">
      <data key="d0">自然語言處理</data>
      <data key="d1">method</data>
      <data key="d2">Natural Language Processing (NLP) is a branch of deep learning used to extract information like market sentiment and industry trends from unstructured text data.&lt;SEP&gt;自然語言處理是一種建立在深度學習上的機制，用於理解上下文、進行情感分析，並提高消費者情感分析的精確度。</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859&lt;SEP&gt;chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006586</data>
      <data key="d6" />
    </node>
    <node id="長短期記憶網路">
      <data key="d0">長短期記憶網路</data>
      <data key="d1">method</data>
      <data key="d2">Long Short-Term Memory (LSTM) network is an improved type of RNN particularly adept at processing and predicting time series data, effectively capturing long-term dependencies.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004919</data>
      <data key="d6" />
    </node>
    <node id="注意力機制">
      <data key="d0">注意力機制</data>
      <data key="d1">concept</data>
      <data key="d2">Attention Mechanism is a component of the Transformer model that allows it to focus on the most important parts of a sequence during prediction.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004920</data>
      <data key="d6" />
    </node>
    <node id="時間序列數據">
      <data key="d0">時間序列數據</data>
      <data key="d1">data</data>
      <data key="d2">Time series data is sequential data points indexed in time order, which LSTM and Transformer models are designed to process and predict.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004920</data>
      <data key="d6" />
    </node>
    <node id="金融時間序列預測">
      <data key="d0">金融時間序列預測</data>
      <data key="d1">concept</data>
      <data key="d2">Financial time series prediction involves forecasting future values of financial data sequences, such as stock and futures prices.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004921</data>
      <data key="d6" />
    </node>
    <node id="套利機會">
      <data key="d0">套利機會</data>
      <data key="d1">concept</data>
      <data key="d2">Arbitrage opportunities are fleeting chances to profit from price discrepancies in the market.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004922</data>
      <data key="d6" />
    </node>
    <node id="K線圖">
      <data key="d0">K線圖</data>
      <data key="d1">data</data>
      <data key="d2">Candlestick charts are a type of financial chart used to represent price movements of securities.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004922</data>
      <data key="d6" />
    </node>
    <node id="技術指標">
      <data key="d0">技術指標</data>
      <data key="d1">data</data>
      <data key="d2">Technical indicators are calculations based on the price, volume, or open interest of a security used to predict future price movements.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004922</data>
      <data key="d6" />
    </node>
    <node id="頭肩頂">
      <data key="d0">頭肩頂</data>
      <data key="d1">concept</data>
      <data key="d2">Head and shoulders top is a classic technical chart pattern indicating a potential trend reversal.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004922</data>
      <data key="d6" />
    </node>
    <node id="雙底">
      <data key="d0">雙底</data>
      <data key="d1">concept</data>
      <data key="d2">Double bottom is a classic technical chart pattern indicating a potential trend reversal.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004923</data>
      <data key="d6" />
    </node>
    <node id="梯度消失/爆炸問題">
      <data key="d0">梯度消失/爆炸問題</data>
      <data key="d1">concept</data>
      <data key="d2">The vanishing/exploding gradient problem is an issue in training traditional RNNs that LSTM's gating mechanism helps to mitigate.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004923</data>
      <data key="d6" />
    </node>
    <node id="資料品質">
      <data key="d0">資料品質</data>
      <data key="d1">concept</data>
      <data key="d2">Data quality refers to the condition of a dataset, with high-quality data being essential for training effective deep learning models.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004930</data>
      <data key="d6" />
    </node>
    <node id="樣本數限制">
      <data key="d0">樣本數限制</data>
      <data key="d1">concept</data>
      <data key="d2">Sample size limitation refers to the challenge of having insufficient data points to effectively train deep learning models.</data>
      <data key="d3">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004923</data>
      <data key="d6" />
    </node>
    <node id="量化交易">
      <data key="d0">量化交易</data>
      <data key="d1">concept</data>
      <data key="d2">Quantitative trading is a field in finance that traditionally relies on technical indicators, fundamental analysis, or statistical models to make trading decisions.&lt;SEP&gt;量化交易是一种使用数学模型和计算机程序进行金融交易的方法，文中讨论了机器学习在其中不同频率的应用。&lt;SEP&gt;Quantitative trading, using mathematical models and algorithms for trading decisions.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-0ff265f7709913907a277247870f20cc&lt;SEP&gt;chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005140</data>
      <data key="d6" />
    </node>
    <node id="深度神经网络">
      <data key="d0">深度神经网络</data>
      <data key="d1">method</data>
      <data key="d2">Deep neural networks possess powerful learning and pattern recognition capabilities, offering new perspectives and tools for quantitative trading.&lt;SEP&gt;一种用于构建大语言模型的网络结构。&lt;SEP&gt;深度神经网络是一种用于处理遥感图像分类、目标检测、语义分割和变化检测等任务的人工智能方法。</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-3678971988880bb3960a90e15878444d&lt;SEP&gt;chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009480</data>
      <data key="d6" />
    </node>
    <node id="长短期记忆网络">
      <data key="d0">长短期记忆网络</data>
      <data key="d1">method</data>
      <data key="d2">Long Short-Term Memory networks (LSTM) are a variant of RNNs that are particularly effective for capturing complex nonlinear relationships and long-term dependencies in time series data.&lt;SEP&gt;长短期记忆网络是一种深度学习模型，能够记忆长距离和短距离的语义信息，对特征选择和模型输出有帮助。</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006989</data>
      <data key="d6" />
    </node>
    <node id="金融领域">
      <data key="d0">金融领域</data>
      <data key="d1">concept</data>
      <data key="d2">The finance sector is an industry being transformed by technologies like deep learning, specifically within quantitative trading.&lt;SEP&gt;The financial sector, where the presented method shows broad future prospects.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006140</data>
      <data key="d6" />
    </node>
    <node id="时间序列数据">
      <data key="d0">时间序列数据</data>
      <data key="d1">data</data>
      <data key="d2">Time series data, such as historical price data, contains complex nonlinear relationships that models like RNN and LSTM are designed to capture.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004927</data>
      <data key="d6" />
    </node>
    <node id="特征工程">
      <data key="d0">特征工程</data>
      <data key="d1">method</data>
      <data key="d2">Feature engineering is the traditional, manual process of selecting and designing predictive indicators, which is simplified by deep learning's automatic feature extraction.&lt;SEP&gt;传统机器学习中花费大量时间的过程，涉及根据TF-IDF、互信息、信息增益等方式计算特征值或对特征进行过滤排序。&lt;SEP&gt;特征工程是传统机器学习中的关键步骤，涉及从原始数据中手动创建、选择和转换特征，通常耗时很长。</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006870</data>
      <data key="d6" />
    </node>
    <node id="高维数据">
      <data key="d0">高维数据</data>
      <data key="d1">data</data>
      <data key="d2">High-dimensional data in quantitative trading involves massive information from different asset classes and time scales, which deep learning models can process effectively.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004928</data>
      <data key="d6" />
    </node>
    <node id="维度灾难">
      <data key="d0">维度灾难</data>
      <data key="d1">concept</data>
      <data key="d2">The "curse of dimensionality" is a problem often encountered by traditional statistical methods in high-dimensional spaces, which deep learning helps to avoid.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004928</data>
      <data key="d6" />
    </node>
    <node id="经典因子模型">
      <data key="d0">经典因子模型</data>
      <data key="d1">method</data>
      <data key="d2">Classical factor models, such as value and momentum factors, can be seamlessly integrated with deep learning models to form composite trading strategies.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004929</data>
      <data key="d6" />
    </node>
    <node id="价格预测">
      <data key="d0">价格预测</data>
      <data key="d1">method</data>
      <data key="d2">Price prediction is a direct application of deep learning in quantitative trading, using models like LSTM and Transformer to forecast future price movements.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004929</data>
      <data key="d6" />
    </node>
    <node id="方向判断">
      <data key="d0">方向判断</data>
      <data key="d1">method</data>
      <data key="d2">Direction judgment involves using deep learning models to determine the short-term direction of price movements.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004929</data>
      <data key="d6" />
    </node>
    <node id="高频交易">
      <data key="d0">高频交易</data>
      <data key="d1">concept</data>
      <data key="d2">High-frequency trading (HFT) is a field involving extremely large and rapidly changing data volumes, where deep learning models like CNN and RNN can process micro-market structure data.&lt;SEP&gt;High-frequency trading, involving rapid execution of a large number of orders using complex algorithms.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005157</data>
      <data key="d6" />
    </node>
    <node id="订单簿">
      <data key="d0">订单簿</data>
      <data key="d1">data</data>
      <data key="d2">The order book, containing data on depth changes, bid-ask spread fluctuations, and instantaneous volume, is an example of micro-market structure data processed in high-frequency trading.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004929</data>
      <data key="d6" />
    </node>
    <node id="K线图">
      <data key="d0">K线图</data>
      <data key="d1">content</data>
      <data key="d2">K-line charts are visual patterns from which deep learning models like CNN can automatically learn and extract features for prediction.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004930</data>
      <data key="d6" />
    </node>
    <node id="统计套利策略">
      <data key="d0">统计套利策略</data>
      <data key="d1">method</data>
      <data key="d2">Statistical arbitrage strategies can be seamlessly combined with deep learning models as part of a composite trading strategy.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004930</data>
      <data key="d6" />
    </node>
    <node id="资金分配模型">
      <data key="d0">资金分配模型</data>
      <data key="d1">method</data>
      <data key="d2">Traditional capital allocation models are responsible for optimizing investment portfolios in hybrid strategies that incorporate deep learning.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004930</data>
      <data key="d6" />
    </node>
    <node id="混合式方法">
      <data key="d0">混合式方法</data>
      <data key="d1">method</data>
      <data key="d2">A hybrid approach combines deep learning models for generating precise trading signals with traditional models for portfolio optimization to achieve better overall results.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004931</data>
      <data key="d6" />
    </node>
    <node id="市场环境">
      <data key="d0">市场环境</data>
      <data key="d1">concept</data>
      <data key="d2">The market environment is dynamic and constantly changing, requiring models to have adaptability, which deep learning models can achieve through continuous training.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004931</data>
      <data key="d6" />
    </node>
    <node id="技术指标">
      <data key="d0">技术指标</data>
      <data key="d1">data</data>
      <data key="d2">Technical indicators, such as moving averages and RSI, are examples of features traditionally engineered manually for quantitative trading strategies.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004931</data>
      <data key="d6" />
    </node>
    <node id="基本面分析">
      <data key="d0">基本面分析</data>
      <data key="d1">method</data>
      <data key="d2">Fundamental analysis is a traditional method used in quantitative trading strategies.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004932</data>
      <data key="d6" />
    </node>
    <node id="统计模型">
      <data key="d0">统计模型</data>
      <data key="d1">method</data>
      <data key="d2">Statistical models are traditional methods used in quantitative trading strategies.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004932</data>
      <data key="d6" />
    </node>
    <node id="移动平均线">
      <data key="d0">移动平均线</data>
      <data key="d1">data</data>
      <data key="d2">Moving average is an example of a technical indicator used in traditional feature engineering for quantitative trading.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004933</data>
      <data key="d6" />
    </node>
    <node id="RSI">
      <data key="d0">RSI</data>
      <data key="d1">data</data>
      <data key="d2">RSI (Relative Strength Index) is an example of a technical indicator used in traditional feature engineering for quantitative trading.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004940</data>
      <data key="d6" />
    </node>
    <node id="价值因子">
      <data key="d0">价值因子</data>
      <data key="d1">data</data>
      <data key="d2">The value factor is an example of a classical factor that can be integrated with deep learning models.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004940</data>
      <data key="d6" />
    </node>
    <node id="动量因子">
      <data key="d0">动量因子</data>
      <data key="d1">data</data>
      <data key="d2">The momentum factor is an example of a classical factor that can be integrated with deep learning models.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004933</data>
      <data key="d6" />
    </node>
    <node id="历史价格数据">
      <data key="d0">历史价格数据</data>
      <data key="d1">data</data>
      <data key="d2">Historical price data is raw data from which deep learning models can automatically extract features.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004933</data>
      <data key="d6" />
    </node>
    <node id="自订指标">
      <data key="d0">自订指标</data>
      <data key="d1">data</data>
      <data key="d2">Custom indicators are a type of raw data from which deep learning models can automatically extract features.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004933</data>
      <data key="d6" />
    </node>
    <node id="开盘价">
      <data key="d0">开盘价</data>
      <data key="d1">data</data>
      <data key="d2">Opening price is a component of historical price time series data used for price prediction.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004933</data>
      <data key="d6" />
    </node>
    <node id="收盘价">
      <data key="d0">收盘价</data>
      <data key="d1">data</data>
      <data key="d2">Closing price is a component of historical price time series data used for price prediction.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004933</data>
      <data key="d6" />
    </node>
    <node id="最高价">
      <data key="d0">最高价</data>
      <data key="d1">data</data>
      <data key="d2">Highest price is a component of historical price time series data used for price prediction.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004934</data>
      <data key="d6" />
    </node>
    <node id="最低价">
      <data key="d0">最低价</data>
      <data key="d1">data</data>
      <data key="d2">Lowest price is a component of historical price time series data used for price prediction.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004934</data>
      <data key="d6" />
    </node>
    <node id="成交量">
      <data key="d0">成交量</data>
      <data key="d1">data</data>
      <data key="d2">Trading volume is a component of historical price time series data used for price prediction.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004935</data>
      <data key="d6" />
    </node>
    <node id="买入信号">
      <data key="d0">买入信号</data>
      <data key="d1">concept</data>
      <data key="d2">A buy signal is a potential trading signal that can be identified by analyzing K-line chart patterns using models like CNN.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004935</data>
      <data key="d6" />
    </node>
    <node id="卖出信号">
      <data key="d0">卖出信号</data>
      <data key="d1">concept</data>
      <data key="d2">A sell signal is a potential trading signal that can be identified by analyzing K-line chart patterns using models like CNN.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004935</data>
      <data key="d6" />
    </node>
    <node id="短期交易策略">
      <data key="d0">短期交易策略</data>
      <data key="d1">method</data>
      <data key="d2">Short-term trading strategies can utilize signals identified from K-line chart analysis by models like CNN.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004935</data>
      <data key="d6" />
    </node>
    <node id="买卖价差">
      <data key="d0">买卖价差</data>
      <data key="d1">data</data>
      <data key="d2">Bid-ask spread is an example of micro-market structure data processed in high-frequency trading.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004935</data>
      <data key="d6" />
    </node>
    <node id="瞬时成交量">
      <data key="d0">瞬时成交量</data>
      <data key="d1">data</data>
      <data key="d2">Instantaneous volume is an example of micro-market structure data processed in high-frequency trading.</data>
      <data key="d3">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004936</data>
      <data key="d6" />
    </node>
    <node id="Autoencoder">
      <data key="d0">Autoencoder</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning model used in risk management modules to detect anomalies by analyzing reconstruction errors, identifying potential market risks or fraudulent behavior.&lt;SEP&gt;A type of artificial neural network used for unsupervised learning.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009183</data>
      <data key="d6" />
    </node>
    <node id="Risk Management Module">
      <data key="d0">Risk Management Module</data>
      <data key="d1">concept</data>
      <data key="d2">A component within a system where Autoencoder is applied to detect data anomalies for identifying market risks or fraud.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004937</data>
      <data key="d6" />
    </node>
    <node id="Market Risk">
      <data key="d0">Market Risk</data>
      <data key="d1">concept</data>
      <data key="d2">A type of financial risk that Autoencoder helps identify through anomaly detection in data.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004937</data>
      <data key="d6" />
    </node>
    <node id="Fraudulent Behavior">
      <data key="d0">Fraudulent Behavior</data>
      <data key="d1">concept</data>
      <data key="d2">Deceptive activities that Autoencoder can help detect by identifying anomalies in data.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004937</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning Model">
      <data key="d0">Deep Learning Model</data>
      <data key="d1">concept</data>
      <data key="d2">A complex AI model requiring large, high-quality datasets for training, facing challenges like data noise, overfitting, and lack of interpretability in financial applications.&lt;SEP&gt;Deep learning model is a type of model to which the Transformer belongs.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4&lt;SEP&gt;chunk-778f83860f7db1907e0da6e0cb412723</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007735</data>
      <data key="d6" />
    </node>
    <node id="Financial Market Data">
      <data key="d0">Financial Market Data</data>
      <data key="d1">data</data>
      <data key="d2">Data from financial markets often containing noise, missing values, and scarcity of high-quality labeled data, posing challenges for training deep learning models.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004938</data>
      <data key="d6" />
    </node>
    <node id="Cross-Validation">
      <data key="d0">Cross-Validation</data>
      <data key="d1">method</data>
      <data key="d2">A rigorous testing method crucial for mitigating overfitting in deep learning models applied to finance.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004938</data>
      <data key="d6" />
    </node>
    <node id="Out-Of-Sample Testing">
      <data key="d0">Out-Of-Sample Testing</data>
      <data key="d1">method</data>
      <data key="d2">A testing method involving data not used during model training, essential for validating the performance of deep learning models in finance.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004938</data>
      <data key="d6" />
    </node>
    <node id="Multiple Backtesting">
      <data key="d0">Multiple Backtesting</data>
      <data key="d1">method</data>
      <data key="d2">A rigorous testing process involving multiple historical periods to validate the robustness of trading strategies using deep learning.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004939</data>
      <data key="d6" />
    </node>
    <node id="Black Box Problem">
      <data key="d0">Black Box Problem</data>
      <data key="d1">concept</data>
      <data key="d2">The challenge of interpreting the internal decision-making process of complex deep learning models, a significant issue in regulated industries like finance.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004939</data>
      <data key="d6" />
    </node>
    <node id="Real-Time Trading">
      <data key="d0">Real-Time Trading</data>
      <data key="d1">concept</data>
      <data key="d2">A trading environment where prediction speed and execution latency are critical, posing high computational resource demands for deep learning models.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004940</data>
      <data key="d6" />
    </node>
    <node id="Market Non-Stationarity">
      <data key="d0">Market Non-Stationarity</data>
      <data key="d1">concept</data>
      <data key="d2">The dynamic and evolving nature of financial markets, where past patterns may not reliably predict the future, requiring continuous model monitoring and retraining.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004942</data>
      <data key="d6" />
    </node>
    <node id="Hybrid Strategy">
      <data key="d0">Hybrid Strategy</data>
      <data key="d1">method</data>
      <data key="d2">A robust trading approach that combines deep learning model predictions with traditional quantitative strategies or manual analysis.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004943</data>
      <data key="d6" />
    </node>
    <node id="Modular Strategy Architecture">
      <data key="d0">Modular Strategy Architecture</data>
      <data key="d1">method</data>
      <data key="d2">A design that decomposes a quantitative strategy into independent modules, such as a 'signal generation module' powered by deep learning and a 'capital allocation module' using traditional methods.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004943</data>
      <data key="d6" />
    </node>
    <node id="Signal Generation Module">
      <data key="d0">Signal Generation Module</data>
      <data key="d1">concept</data>
      <data key="d2">A component within a modular strategy architecture responsible for generating trading signals, potentially using deep learning models.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004943</data>
      <data key="d6" />
    </node>
    <node id="Capital Allocation Module">
      <data key="d0">Capital Allocation Module</data>
      <data key="d1">concept</data>
      <data key="d2">A component within a modular strategy architecture responsible for allocating funds, potentially using traditional optimization methods.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004944</data>
      <data key="d6" />
    </node>
    <node id="Backtesting">
      <data key="d0">Backtesting</data>
      <data key="d1">method</data>
      <data key="d2">A validation process testing a strategy on historical data.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004944</data>
      <data key="d6" />
    </node>
    <node id="Forward Testing">
      <data key="d0">Forward Testing</data>
      <data key="d1">method</data>
      <data key="d2">A validation process testing a model or strategy in a simulated real-time environment.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004944</data>
      <data key="d6" />
    </node>
    <node id="Model Monitoring Mechanism">
      <data key="d0">Model Monitoring Mechanism</data>
      <data key="d1">method</data>
      <data key="d2">A system implemented to ensure the stability and effectiveness of a model after deployment.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004944</data>
      <data key="d6" />
    </node>
    <node id="Explainable AI (XAI)">
      <data key="d0">Explainable AI (XAI)</data>
      <data key="d1">concept</data>
      <data key="d2">A field of AI technology aimed at improving the interpretability and transparency of complex models like deep learning networks.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004945</data>
      <data key="d6" />
    </node>
    <node id="Multi-Modal Learning">
      <data key="d0">Multi-Modal Learning</data>
      <data key="d1">method</data>
      <data key="d2">Multi-Modal Learning is a method that combines various types of data such as numerical, text, and images to build a more comprehensive market view.&lt;SEP&gt;A future development direction in deep learning for quantitative trading that combines numerical, text, image, and other data types to build a comprehensive market view.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4&lt;SEP&gt;chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004945</data>
      <data key="d6" />
    </node>
    <node id="Federated Learning">
      <data key="d0">Federated Learning</data>
      <data key="d1">method</data>
      <data key="d2">Federated Learning is a technology that protects data privacy and is important for collaboration among financial institutions.&lt;SEP&gt;A privacy-preserving machine learning technique that may facilitate collaboration between financial institutions by training models across decentralized data sources.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4&lt;SEP&gt;chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004945</data>
      <data key="d6" />
    </node>
    <node id="Quantitative Trading Team">
      <data key="d0">Quantitative Trading Team</data>
      <data key="d1">organization</data>
      <data key="d2">Teams, often small to medium-sized, that face high technical and cost barriers when implementing deep learning models for trading strategies.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004946</data>
      <data key="d6" />
    </node>
    <node id="Financial Industry">
      <data key="d0">Financial Industry</data>
      <data key="d1">organization</data>
      <data key="d2">A regulated sector where the lack of interpretability in deep learning models poses significant challenges for compliance and transparency.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004946</data>
      <data key="d6" />
    </node>
    <node id="Financial Institution">
      <data key="d0">Financial Institution</data>
      <data key="d1">organization</data>
      <data key="d2">Organizations that may collaborate using privacy-preserving techniques like Federated Learning.</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004947</data>
      <data key="d6" />
    </node>
    <node id="Quantitative Trading">
      <data key="d0">Quantitative Trading</data>
      <data key="d1">concept</data>
      <data key="d2">Quantitative Trading is a field being reshaped by deep learning, offering advanced tools for market analysis and investment decisions.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004947</data>
      <data key="d6" />
    </node>
    <node id="Arthur">
      <data key="d0">Arthur</data>
      <data key="d1">person</data>
      <data key="d2">Arthur is the author of the documentation piece discussing the future of quantitative trading technologies.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004947</data>
      <data key="d6" />
    </node>
    <node id="Documentation">
      <data key="d0">Documentation</data>
      <data key="d1">content</data>
      <data key="d2">Documentation is the category under which the article discussing multi-modal learning, federated learning, and deep learning in finance is published.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004948</data>
      <data key="d6" />
    </node>
    <node id="Dollar Bars">
      <data key="d0">Dollar Bars</data>
      <data key="d1">method</data>
      <data key="d2">Dollar Bars is a data sampling method mentioned in the context of quantitative trading strategies.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004948</data>
      <data key="d6" />
    </node>
    <node id="Triple Barrier Method">
      <data key="d0">Triple Barrier Method</data>
      <data key="d1">method</data>
      <data key="d2">The Triple Barrier Method is a technique used to address data sampling pitfalls in quantitative trading.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004949</data>
      <data key="d6" />
    </node>
    <node id="Fractional Differentiation">
      <data key="d0">Fractional Differentiation</data>
      <data key="d1">method</data>
      <data key="d2">Fractional Differentiation is a method discussed for solving model memory loss and cheating in quantitative trading.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004949</data>
      <data key="d6" />
    </node>
    <node id="Rolling Validation">
      <data key="d0">Rolling Validation</data>
      <data key="d1">method</data>
      <data key="d2">Rolling Validation is a validation technique mentioned in the context of quantitative trading models.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004949</data>
      <data key="d6" />
    </node>
    <node id="Feature Engineering">
      <data key="d0">Feature Engineering</data>
      <data key="d1">task</data>
      <data key="d2">Feature Engineering involves the 'Three Major Schools' and key transformation tools for taming financial data.&lt;SEP&gt;The process performed by Bi-LSTM in the described model structure to extract features from input sequences.</data>
      <data key="d3">chunk-d9ecda3ea425b03f3129938c0ba44219&lt;SEP&gt;chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006946</data>
      <data key="d6" />
    </node>
    <node id="Reconstruction Error">
      <data key="d0">Reconstruction Error</data>
      <data key="d3">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d2">Autoencoder uses reconstruction error as a metric to judge whether data is anomalous.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769004970</data>
      <data key="d6" />
    </node>
    <node id="Gpu">
      <data key="d0">Gpu</data>
      <data key="d1">artifact</data>
      <data key="d2">Advanced GPU technology used in financial trading for data processing and model execution.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005001</data>
      <data key="d6" />
    </node>
    <node id="交易员">
      <data key="d0">交易员</data>
      <data key="d1">person</data>
      <data key="d2">Traders who utilize GPU and deep learning technology on a high-intensity computing platform.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005001</data>
      <data key="d6" />
    </node>
    <node id="Kinetica数据库">
      <data key="d0">Kinetica数据库</data>
      <data key="d1">artifact</data>
      <data key="d2">Kinetica database, a component of the high-intensity computing platform used for financial data tasks.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005002</data>
      <data key="d6" />
    </node>
    <node id="Nvidia Gpu">
      <data key="d0">Nvidia Gpu</data>
      <data key="d1">artifact</data>
      <data key="d2">NVIDIA GPU, a specific hardware component of the computing platform used for intensive calculations.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005002</data>
      <data key="d6" />
    </node>
    <node id="高强度计算平台">
      <data key="d0">高强度计算平台</data>
      <data key="d1">artifact</data>
      <data key="d2">A single, high-intensity computing platform that integrates database and GPU hardware for financial analysis.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005002</data>
      <data key="d6" />
    </node>
    <node id="数据探索">
      <data key="d0">数据探索</data>
      <data key="d1">method</data>
      <data key="d2">The process of data exploration performed by traders on the computing platform.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005003</data>
      <data key="d6" />
    </node>
    <node id="模型开发/评分">
      <data key="d0">模型开发/评分</data>
      <data key="d1">method</data>
      <data key="d2">The combined activities of model development and scoring conducted on the computing platform.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005003</data>
      <data key="d6" />
    </node>
    <node id="模型消耗">
      <data key="d0">模型消耗</data>
      <data key="d1">method</data>
      <data key="d2">The process of model consumption executed on the computing platform.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005003</data>
      <data key="d6" />
    </node>
    <node id="金融学">
      <data key="d0">金融学</data>
      <data key="d1">concept</data>
      <data key="d2">The domain of finance, which is the context for the described technological applications.&lt;SEP&gt;本发明所属的学术或应用领域。&lt;SEP&gt;金融学是AI Agent风控模型所属的学科领域。&lt;SEP&gt;The domain or field of study to which the guide belongs.</data>
      <data key="d3">chunk-858e73004375c211a45ff338fb81b219&lt;SEP&gt;chunk-ead8239d6c7d35f7d27952face0dd715&lt;SEP&gt;chunk-c00652dd3948d32546676fffc8064300&lt;SEP&gt;chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005877</data>
      <data key="d6" />
    </node>
    <node id="量化投资">
      <data key="d0">量化投资</data>
      <data key="d1">concept</data>
      <data key="d2">量化投资是作者的个人职业领域，涉及使用量化方法进行投资决策。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005141</data>
      <data key="d6" />
    </node>
    <node id="中低频量化">
      <data key="d0">中低频量化</data>
      <data key="d1">method</data>
      <data key="d2">中低频量化是作者早期从事的量化交易策略，其特点是交易频率较低，文中指出机器学习在此场景下效果不佳。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005143</data>
      <data key="d6" />
    </node>
    <node id="高频量化">
      <data key="d0">高频量化</data>
      <data key="d1">method</data>
      <data key="d2">高频量化是作者近两年转向的量化交易策略，特指日内的T0交易，文中指出机器学习在此场景下展现了较大优势。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005150</data>
      <data key="d6" />
    </node>
    <node id="日内T0">
      <data key="d0">日内T0</data>
      <data key="d1">method</data>
      <data key="d2">日内T0是一种高频交易策略，在单个交易日内完成建仓和平仓，文中是机器学习应用的成功场景。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005150</data>
      <data key="d6" />
    </node>
    <node id="Barra模型">
      <data key="d0">Barra模型</data>
      <data key="d1">method</data>
      <data key="d2">Barra模型是一套基于线性模型的量化分析框架，主要用于风险控制，是作者学习的起点和比较基准。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005143</data>
      <data key="d6" />
    </node>
    <node id="线性模型">
      <data key="d0">线性模型</data>
      <data key="d1">method</data>
      <data key="d2">线性模型是传统的量化建模方法，文中指出在中低频量化中，其表现优于尝试过的各种机器学习模型。&lt;SEP&gt;A branch of machine learning suitable for small-sample, low-frequency data.</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc&lt;SEP&gt;chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005144</data>
      <data key="d6" />
    </node>
    <node id="股票打分">
      <data key="d0">股票打分</data>
      <data key="d1">method</data>
      <data key="d2">股票打分是一种应用机器学习于量化投资的设想方法，即用模型为股票评级，但文中尝试后宣告失败。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005144</data>
      <data key="d6" />
    </node>
    <node id="信噪比">
      <data key="d0">信噪比</data>
      <data key="d1">concept</data>
      <data key="d2">信噪比是衡量信号中有效信息与噪声比例的指标，文中指出中低频量化信噪比低是机器学习效果差的原因之一，而高频量化信噪比较高。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005145</data>
      <data key="d6" />
    </node>
    <node id="数据量">
      <data key="d0">数据量</data>
      <data key="d1">concept</data>
      <data key="d2">数据量指可用于模型训练的数据规模，文中指出中低频数据量少是机器学习效果差的另一个原因，而高频数据量巨大。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005145</data>
      <data key="d6" />
    </node>
    <node id="Tick数据">
      <data key="d0">Tick数据</data>
      <data key="d1">data</data>
      <data key="d2">Tick数据是记录证券每一笔交易的价格和成交量等信息的最高频数据，是高频量化机器学习的主要数据源。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005145</data>
      <data key="d6" />
    </node>
    <node id="互联网行业">
      <data key="d0">互联网行业</data>
      <data key="d1">organization</data>
      <data key="d2">互联网行业是广泛应用机器学习和深度学习的领域，文中以其推荐、反欺诈等应用为例，说明算法适用的前提。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005146</data>
      <data key="d6" />
    </node>
    <node id="反欺诈">
      <data key="d0">反欺诈</data>
      <data key="d1">method</data>
      <data key="d2">反欺诈是互联网行业中机器学习/深度学习的另一个应用领域。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005146</data>
      <data key="d6" />
    </node>
    <node id="人工智障">
      <data key="d0">人工智障</data>
      <data key="d1">concept</data>
      <data key="d2">“人工智障”是文中对机器学习模型表现不佳的戏谑说法，意指如果人眼都能发现的机会模型却学不到，则模型能力低下。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005147</data>
      <data key="d6" />
    </node>
    <node id="基股传声">
      <data key="d0">基股传声</data>
      <data key="d1">person</data>
      <data key="d2">“基股传声”是雪球App上本文的作者。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005147</data>
      <data key="d6" />
    </node>
    <node id="雪球">
      <data key="d0">雪球</data>
      <data key="d1">organization</data>
      <data key="d2">雪球是一个投资社交网络平台，本文的发布和讨论平台。</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005147</data>
      <data key="d6" />
    </node>
    <node id="Barra">
      <data key="d0">Barra</data>
      <data key="d1">method</data>
      <data key="d2">Barra is a specific quantitative analysis framework based on linear models, primarily used for risk control, which the author initially studied.</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005148</data>
      <data key="d6" />
    </node>
    <node id="工程师">
      <data key="d0">工程师</data>
      <data key="d1">person</data>
      <data key="d2">Engineers are professionals mentioned in the context of the internet industry who can manually perform tasks like personalized recommendations, but their limited numbers necessitate the use of machine learning algorithms.</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005148</data>
      <data key="d6" />
    </node>
    <node id="主观的研究员">
      <data key="d0">主观的研究员</data>
      <data key="d1">person</data>
      <data key="d2">Subjective researchers are investment professionals mentioned as an example of individuals who cannot achieve high win rates and low drawdowns in medium-to-low frequency investing, indicating the difficulty of the task.</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005149</data>
      <data key="d6" />
    </node>
    <node id="基金经理">
      <data key="d0">基金经理</data>
      <data key="d1">person</data>
      <data key="d2">Fund managers are investment professionals mentioned as an example of individuals who cannot achieve high win rates and low drawdowns in medium-to-low frequency investing, indicating the difficulty of the task.</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005149</data>
      <data key="d6" />
    </node>
    <node id="客服">
      <data key="d0">客服</data>
      <data key="d1">person</data>
      <data key="d2">Customer service representatives are mentioned hypothetically; if their numbers were infinite, they could provide better recommendations than machine learning algorithms.</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005149</data>
      <data key="d6" />
    </node>
    <node id="quant-computer">
      <data key="d0">quant-computer</data>
      <data key="d1">person</data>
      <data key="d2">A user who graduated in 2017, worked in quantitative finance until 2018, then left to consider transitioning to machine learning, and later switched to deep learning (image processing).&lt;SEP&gt;"quant-computer" is a user who posted a comment on the article discussing their career shift from quantitative finance to deep learning (image processing).</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc&lt;SEP&gt;chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005150</data>
      <data key="d6" />
    </node>
    <node id="站内推荐">
      <data key="d0">站内推荐</data>
      <data key="d1">concept</data>
      <data key="d2">A feature that allows discussions to be visible only under the current post when the "Discuss only under the main text" option is selected.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005150</data>
      <data key="d6" />
    </node>
    <node id="仅在正文下讨论">
      <data key="d0">仅在正文下讨论</data>
      <data key="d1">concept</data>
      <data key="d2">A function that restricts the visibility of discussion content to the discussion area under the current post.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005151</data>
      <data key="d6" />
    </node>
    <node id="江苏">
      <data key="d0">江苏</data>
      <data key="d1">location</data>
      <data key="d2">A province in China, mentioned as the location of the user 'quant-computer'.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005151</data>
      <data key="d6" />
    </node>
    <node id="量化">
      <data key="d0">量化</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to quantitative finance or quantitative trading, involving mathematical and statistical modeling for financial markets.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005152</data>
      <data key="d6" />
    </node>
    <node id="angl1799">
      <data key="d0">angl1799</data>
      <data key="d1">person</data>
      <data key="d2">A user who participated in the discussion.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005152</data>
      <data key="d6" />
    </node>
    <node id="厚积薄发磨一剑">
      <data key="d0">厚积薄发磨一剑</data>
      <data key="d1">person</data>
      <data key="d2">A user who commented on the challenges in quantitative finance due to excessive noise (invalid data) and the need for professional expertise in data preprocessing.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005161</data>
      <data key="d6" />
    </node>
    <node id="噪音">
      <data key="d0">噪音</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to invalid or irrelevant data that complicates analysis in quantitative finance, mentioned as a major challenge.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005153</data>
      <data key="d6" />
    </node>
    <node id="数据清洗预处理">
      <data key="d0">数据清洗预处理</data>
      <data key="d1">method</data>
      <data key="d2">The process of cleaning and preparing raw data for analysis, requiring professional experience.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005153</data>
      <data key="d6" />
    </node>
    <node id="股票">
      <data key="d0">股票</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to equities or shares in companies, mentioned in the context of market analysis and noise factors.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005154</data>
      <data key="d6" />
    </node>
    <node id="美股">
      <data key="d0">美股</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the US stock market, mentioned as a source of market volatility (大涨大跌).</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005154</data>
      <data key="d6" />
    </node>
    <node id="周末假期效应">
      <data key="d0">周末假期效应</data>
      <data key="d1">concept</data>
      <data key="d2">A market anomaly where stock prices are affected before or after weekends and holidays.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005154</data>
      <data key="d6" />
    </node>
    <node id="个股利好利空">
      <data key="d0">个股利好利空</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to positive (利好) or negative (利空) news affecting individual stocks.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005154</data>
      <data key="d6" />
    </node>
    <node id="大盘板块大涨大跌">
      <data key="d0">大盘板块大涨大跌</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to significant rises or falls in major market indices or sectors, impacting individual stocks.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005155</data>
      <data key="d6" />
    </node>
    <node id="敬畏常识">
      <data key="d0">敬畏常识</data>
      <data key="d1">person</data>
      <data key="d2">A user who commented that much stock information cannot be quantified, leading to model input distortion, and that machine learning is merely a modifier of knowledge.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005155</data>
      <data key="d6" />
    </node>
    <node id="模型">
      <data key="d0">模型</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to mathematical or statistical models used in quantitative finance and machine learning.&lt;SEP&gt;用来帮助我们更好地理解和预测所描述对象的简化“影子”或“替身”，可以是实体的或虚拟的，是人工智能系统的核心。</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008430</data>
      <data key="d6" />
    </node>
    <node id="Panel_Trader">
      <data key="d0">Panel_Trader</data>
      <data key="d1">person</data>
      <data key="d2">A user with a达人认证(expert certification) who commented on the branches of machine learning suitable for different data frequencies.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005156</data>
      <data key="d6" />
    </node>
    <node id="小样本低频数据">
      <data key="d0">小样本低频数据</data>
      <data key="d1">data</data>
      <data key="d2">Data characterized by a small number of samples and low frequency, suitable for linear models.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005156</data>
      <data key="d6" />
    </node>
    <node id="大样本高频数据">
      <data key="d0">大样本高频数据</data>
      <data key="d1">data</data>
      <data key="d2">Data characterized by a large number of samples and high frequency, suitable for deep learning.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005156</data>
      <data key="d6" />
    </node>
    <node id="中频数据">
      <data key="d0">中频数据</data>
      <data key="d1">data</data>
      <data key="d2">Data with medium frequency, suitable for other machine learning methods between linear models and deep learning.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005157</data>
      <data key="d6" />
    </node>
    <node id="象牙山李宝库">
      <data key="d0">象牙山李宝库</data>
      <data key="d1">person</data>
      <data key="d2">A user who discussed quantitative trading at Goldman Sachs, high-frequency trading, fundamental quantitative investing, and the use of Python for data analysis.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005157</data>
      <data key="d6" />
    </node>
    <node id="高盛">
      <data key="d0">高盛</data>
      <data key="d1">organization</data>
      <data key="d2">Goldman Sachs, an investment bank where a friend works on quantitative trading.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005157</data>
      <data key="d6" />
    </node>
    <node id="海量数据">
      <data key="d0">海量数据</data>
      <data key="d1">data</data>
      <data key="d2">Extremely large volumes of data, mentioned in the context of high-frequency trading.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005157</data>
      <data key="d6" />
    </node>
    <node id="数学建模能力">
      <data key="d0">数学建模能力</data>
      <data key="d1">concept</data>
      <data key="d2">Mathematical modeling skills, described as extremely demanding for high-frequency trading teams.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005157</data>
      <data key="d6" />
    </node>
    <node id="基本面量化投资">
      <data key="d0">基本面量化投资</data>
      <data key="d1">concept</data>
      <data key="d2">Fundamental quantitative investing, which uses quantitative analysis on fundamental data and has been popular for years.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005158</data>
      <data key="d6" />
    </node>
    <node id="公募">
      <data key="d0">公募</data>
      <data key="d1">organization</data>
      <data key="d2">Public offering funds, such as mutual funds, engaged in fundamental quantitative investing.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005158</data>
      <data key="d6" />
    </node>
    <node id="私募">
      <data key="d0">私募</data>
      <data key="d1">organization</data>
      <data key="d2">Private equity funds, also engaged in fundamental quantitative investing.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005159</data>
      <data key="d6" />
    </node>
    <node id="超额收益">
      <data key="d0">超额收益</data>
      <data key="d1">concept</data>
      <data key="d2">Excess return, mentioned as still relatively high for fundamental quantitative investing.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005159</data>
      <data key="d6" />
    </node>
    <node id="财务分析">
      <data key="d0">财务分析</data>
      <data key="d1">method</data>
      <data key="d2">Financial analysis, traditionally done manually by analysts but now accelerated through quantitative data analysis.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005159</data>
      <data key="d6" />
    </node>
    <node id="研究员">
      <data key="d0">研究员</data>
      <data key="d1">person</data>
      <data key="d2">A research analyst who traditionally spent hours analyzing a listed company.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005160</data>
      <data key="d6" />
    </node>
    <node id="上市公司">
      <data key="d0">上市公司</data>
      <data key="d1">organization</data>
      <data key="d2">Listed companies, whose financial data is analyzed.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005160</data>
      <data key="d6" />
    </node>
    <node id="量化数据分析">
      <data key="d0">量化数据分析</data>
      <data key="d1">method</data>
      <data key="d2">Quantitative data analysis, which can produce results in minutes compared to traditional methods.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005160</data>
      <data key="d6" />
    </node>
    <node id="非标数据">
      <data key="d0">非标数据</data>
      <data key="d1">data</data>
      <data key="d2">Non-standard data, mentioned as the frontier of quantitative research and analysis.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005160</data>
      <data key="d6" />
    </node>
    <node id="股票市盈率估值">
      <data key="d0">股票市盈率估值</data>
      <data key="d1">concept</data>
      <data key="d2">Price-to-earnings (P/E) ratio valuation of stocks, given as an example of low valuation metrics.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005160</data>
      <data key="d6" />
    </node>
    <node id="森林里的男人">
      <data key="d0">森林里的男人</data>
      <data key="d1">person</data>
      <data key="d2">A user who commented that ultimately, it (likely referring to quantitative trading) does not make money.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005161</data>
      <data key="d6" />
    </node>
    <node id="讨论区">
      <data key="d0">讨论区</data>
      <data key="d1">concept</data>
      <data key="d2">The area under a post where discussions take place, visibility of which can be controlled by the "仅在正文下讨论" function.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005161</data>
      <data key="d6" />
    </node>
    <node id="正文">
      <data key="d0">正文</data>
      <data key="d1">content</data>
      <data key="d2">The main text of a post, under which discussions can be restricted.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005161</data>
      <data key="d6" />
    </node>
    <node id="无效数据">
      <data key="d0">无效数据</data>
      <data key="d1">data</data>
      <data key="d2">Synonymous with "噪音", refers to data that is irrelevant or misleading for analysis.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005162</data>
      <data key="d6" />
    </node>
    <node id="专业经验">
      <data key="d0">专业经验</data>
      <data key="d1">concept</data>
      <data key="d2">Professional expertise required for tasks like data cleaning and preprocessing in quantitative finance.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005162</data>
      <data key="d6" />
    </node>
    <node id="懂股票又懂机器学习的人">
      <data key="d0">懂股票又懂机器学习的人</data>
      <data key="d1">person</data>
      <data key="d2">Individuals with expertise in both stock markets and machine learning, described as being scarce.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005162</data>
      <data key="d6" />
    </node>
    <node id="大盘">
      <data key="d0">大盘</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the overall stock market index, whose movements affect individual stocks.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005162</data>
      <data key="d6" />
    </node>
    <node id="板块">
      <data key="d0">板块</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to specific industry sectors within the stock market, whose movements affect individual stocks.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005163</data>
      <data key="d6" />
    </node>
    <node id="知识的修饰器">
      <data key="d0">知识的修饰器</data>
      <data key="d1">concept</data>
      <data key="d2">A metaphor used to describe machine learning as a tool that modifies existing knowledge rather than creating it.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005163</data>
      <data key="d6" />
    </node>
    <node id="达人认证">
      <data key="d0">达人认证</data>
      <data key="d1">concept</data>
      <data key="d2">An expert certification held by the user 'Panel_Trader'.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005163</data>
      <data key="d6" />
    </node>
    <node id="其它机器学习方法">
      <data key="d0">其它机器学习方法</data>
      <data key="d1">method</data>
      <data key="d2">Other machine learning methods suitable for medium-frequency data, positioned between linear models and deep learning.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005163</data>
      <data key="d6" />
    </node>
    <node id="几十人团队">
      <data key="d0">几十人团队</data>
      <data key="d1">organization</data>
      <data key="d2">A team of dozens of people working on high-frequency trading at Goldman Sachs, as mentioned by the user.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005163</data>
      <data key="d6" />
    </node>
    <node id="基础分析">
      <data key="d0">基础分析</data>
      <data key="d1">method</data>
      <data key="d2">Basic analysis performed using Python programs to scrape data, distinguished from machine learning.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005164</data>
      <data key="d6" />
    </node>
    <node id="几分钟">
      <data key="d0">几分钟</data>
      <data key="d1">data</data>
      <data key="d2">The short time (a few minutes) it takes to produce results using quantitative data analysis for financial analysis.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005164</data>
      <data key="d6" />
    </node>
    <node id="几个小时">
      <data key="d0">几个小时</data>
      <data key="d1">data</data>
      <data key="d2">The longer time (several hours) it traditionally took a research analyst to analyze a listed company.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005164</data>
      <data key="d6" />
    </node>
    <node id="举个简单例子">
      <data key="d0">举个简单例子</data>
      <data key="d1">content</data>
      <data key="d2">A phrase introducing a simple example, specifically about low P/E ratio valuations.</data>
      <data key="d3">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005165</data>
      <data key="d6" />
    </node>
    <node id="Image 64">
      <data key="d0">Image 64</data>
      <data key="d1">artifact</data>
      <data key="d2">Image 64 is a digital image file, specifically a screenshot of the enterprise communication software "企业微信".</data>
      <data key="d3">chunk-7b1e8c21b7d64e83d4ee433e43a86a4b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005165</data>
      <data key="d6" />
    </node>
    <node id="Image 65">
      <data key="d0">Image 65</data>
      <data key="d1">artifact</data>
      <data key="d2">Image 65 is a digital image file, specifically a screenshot of a QR code.</data>
      <data key="d3">chunk-7b1e8c21b7d64e83d4ee433e43a86a4b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005165</data>
      <data key="d6" />
    </node>
    <node id="企业微信">
      <data key="d0">企业微信</data>
      <data key="d1">artifact</data>
      <data key="d2">企业微信is an enterprise communication and collaboration software, appearing as the subject of Image 64.</data>
      <data key="d3">chunk-7b1e8c21b7d64e83d4ee433e43a86a4b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005165</data>
      <data key="d6" />
    </node>
    <node id="二维码">
      <data key="d0">二维码</data>
      <data key="d1">artifact</data>
      <data key="d2">二维码is a QR code, appearing as the subject of Image 65.</data>
      <data key="d3">chunk-7b1e8c21b7d64e83d4ee433e43a86a4b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005165</data>
      <data key="d6" />
    </node>
    <node id="讨论">
      <data key="d0">讨论</data>
      <data key="d1">event</data>
      <data key="d2">Discussion is an event or activity indicated by the text.</data>
      <data key="d3">chunk-7b1e8c21b7d64e83d4ee433e43a86a4b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005166</data>
      <data key="d6" />
    </node>
    <node id="风险控制">
      <data key="d0">风险控制</data>
      <data key="d3">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d2">The Barra framework is primarily considered from a risk control perspective.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005170</data>
      <data key="d6" />
    </node>
    <node id="风控建模方法">
      <data key="d0">风控建模方法</data>
      <data key="d1">method</data>
      <data key="d2">一种基于深度学习的金融风险控制建模方法，包含从云端数据库获取并处理用户数据的步骤。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005212</data>
      <data key="d6" />
    </node>
    <node id="云端数据库">
      <data key="d0">云端数据库</data>
      <data key="d1">artifact</data>
      <data key="d2">存储用户数据的远程数据库系统，是本发明方法的数据来源。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005213</data>
      <data key="d6" />
    </node>
    <node id="用户数据">
      <data key="d0">用户数据</data>
      <data key="d1">data</data>
      <data key="d2">本发明方法处理的核心数据对象，包括结构化数据和非结构化数据。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005216</data>
      <data key="d6" />
    </node>
    <node id="结构化数据">
      <data key="d0">结构化数据</data>
      <data key="d1">data</data>
      <data key="d2">用户数据的一种类型，具有预定义格式和组织方式。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005216</data>
      <data key="d6" />
    </node>
    <node id="非结构化数据">
      <data key="d0">非结构化数据</data>
      <data key="d1">data</data>
      <data key="d2">用户数据的一种类型，没有预定义格式或模型。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005216</data>
      <data key="d6" />
    </node>
    <node id="初步筛选">
      <data key="d0">初步筛选</data>
      <data key="d1">method</data>
      <data key="d2">对用户数据进行初始处理或过滤的步骤。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005216</data>
      <data key="d6" />
    </node>
    <node id="S1">
      <data key="d0">S1</data>
      <data key="d1">method</data>
      <data key="d2">风控建模方法的第一步，涉及从云端数据库获取用户数据并进行初步筛选。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005216</data>
      <data key="d6" />
    </node>
    <node id="S2">
      <data key="d0">S2</data>
      <data key="d1">method</data>
      <data key="d2">风控建模方法的第二步，在输入文本中仅被提及，具体内容未展开。</data>
      <data key="d3">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005217</data>
      <data key="d6" />
    </node>
    <node id="Corporate Bond Credit Risk">
      <data key="d0">Corporate Bond Credit Risk</data>
      <data key="d1">concept</data>
      <data key="d2">Corporate Bond Credit Risk is the main subject of the research paper "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005249</data>
      <data key="d6" />
    </node>
    <node id="Fuwei Jiang">
      <data key="d0">Fuwei Jiang</data>
      <data key="d1">person</data>
      <data key="d2">Fuwei Jiang is an author of the research paper "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005249</data>
      <data key="d6" />
    </node>
    <node id="Bailin Chai">
      <data key="d0">Bailin Chai</data>
      <data key="d1">person</data>
      <data key="d2">Bailin Chai is an author of the research paper "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005251</data>
      <data key="d6" />
    </node>
    <node id="Yihao Lin">
      <data key="d0">Yihao Lin</data>
      <data key="d1">person</data>
      <data key="d2">Yihao Lin is an author of the research paper "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005251</data>
      <data key="d6" />
    </node>
    <node id="China Journal of Econometrics">
      <data key="d0">China Journal of Econometrics</data>
      <data key="d1">content</data>
      <data key="d2">China Journal of Econometrics is the journal where the paper "Deep Learning and Corporate Bond Credit Risk" is published.</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005251</data>
      <data key="d6" />
    </node>
    <node id="DOI 10.12012/CJoE2024-0092">
      <data key="d0">DOI 10.12012/CJoE2024-0092</data>
      <data key="d1">data</data>
      <data key="d2">DOI 10.12012/CJoE2024-0092 is the Digital Object Identifier for the research paper "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005252</data>
      <data key="d6" />
    </node>
    <node id="ISSN 2097-2326">
      <data key="d0">ISSN 2097-2326</data>
      <data key="d1">data</data>
      <data key="d2">ISSN 2097-2326 is the International Standard Serial Number for the online version of the journal.</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005252</data>
      <data key="d6" />
    </node>
    <node id="ISSN 2096-9732">
      <data key="d0">ISSN 2096-9732</data>
      <data key="d1">data</data>
      <data key="d2">ISSN 2096-9732 is the International Standard Serial Number for the print version of the journal.</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005253</data>
      <data key="d6" />
    </node>
    <node id="CN 10-1738/F">
      <data key="d0">CN 10-1738/F</data>
      <data key="d1">data</data>
      <data key="d2">CN 10-1738/F is the China serial number for the journal.</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005253</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning and Corporate Bond Credit Risk">
      <data key="d0">Deep Learning and Corporate Bond Credit Risk</data>
      <data key="d1">content</data>
      <data key="d2">Deep Learning and Corporate Bond Credit Risk is the title of the research paper authored by Fuwei Jiang, Bailin Chai, and Yihao Lin.</data>
      <data key="d3">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005253</data>
      <data key="d6" />
    </node>
    <node id="Cox Proportional Hazards Regression Model">
      <data key="d0">Cox Proportional Hazards Regression Model</data>
      <data key="d1">method</data>
      <data key="d2">A traditional statistical model used for disease risk prediction, also referred to as the Cox model.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005334</data>
      <data key="d6" />
    </node>
    <node id="Logistic Regression Model">
      <data key="d0">Logistic Regression Model</data>
      <data key="d1">method</data>
      <data key="d2">A traditional statistical model used for disease risk prediction.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005334</data>
      <data key="d6" />
    </node>
    <node id="Wang et al.">
      <data key="d0">Wang et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers who evaluated a stroke prediction model, considering calibration and discrimination.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005336</data>
      <data key="d6" />
    </node>
    <node id="Stroke Prediction Model">
      <data key="d0">Stroke Prediction Model</data>
      <data key="d1">method</data>
      <data key="d2">A model for predicting stroke risk, evaluated using calibration and discrimination metrics.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005338</data>
      <data key="d6" />
    </node>
    <node id="Calibration">
      <data key="d0">Calibration</data>
      <data key="d1">concept</data>
      <data key="d2">A metric referring to the consistency between predicted and actual outcomes, evaluated using the Hosmer-Lemeshow statistic.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005338</data>
      <data key="d6" />
    </node>
    <node id="Discrimination">
      <data key="d0">Discrimination</data>
      <data key="d1">concept</data>
      <data key="d2">A metric evaluated using the c-statistic, which is the area under the ROC curve (AUC).</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005339</data>
      <data key="d6" />
    </node>
    <node id="Hosmer-Lemeshow Statistic">
      <data key="d0">Hosmer-Lemeshow Statistic</data>
      <data key="d1">method</data>
      <data key="d2">A statistical test used to evaluate the calibration of a prediction model.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005340</data>
      <data key="d6" />
    </node>
    <node id="C-Statistic">
      <data key="d0">C-Statistic</data>
      <data key="d1">method</data>
      <data key="d2">A metric for model discrimination, equivalent to the area under the ROC curve (AUC).</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005341</data>
      <data key="d6" />
    </node>
    <node id="Receiver Operating Characteristic Curve">
      <data key="d0">Receiver Operating Characteristic Curve</data>
      <data key="d1">method</data>
      <data key="d2">A graphical plot used to evaluate the diagnostic ability of a binary classifier, also known as the ROC curve.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005343</data>
      <data key="d6" />
    </node>
    <node id="Area Under The Curve">
      <data key="d0">Area Under The Curve</data>
      <data key="d1">method</data>
      <data key="d2">A metric representing the area under the ROC curve, used to measure model discrimination.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005345</data>
      <data key="d6" />
    </node>
    <node id="Stroke Or Death Prediction Model">
      <data key="d0">Stroke Or Death Prediction Model</data>
      <data key="d1">method</data>
      <data key="d2">A model for predicting the risk of stroke or death.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005345</data>
      <data key="d6" />
    </node>
    <node id="Khosla et al.">
      <data key="d0">Khosla et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers who published a paper at KDD 2010, exploring methods like SVM and margin-based censored regression for prediction.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005347</data>
      <data key="d6" />
    </node>
    <node id="Support Vector Machine">
      <data key="d0">Support Vector Machine</data>
      <data key="d1">method</data>
      <data key="d2">A machine learning algorithm used for classification and regression, abbreviated as SVM.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005347</data>
      <data key="d6" />
    </node>
    <node id="Margin-Based Censored Regression">
      <data key="d0">Margin-Based Censored Regression</data>
      <data key="d1">method</data>
      <data key="d2">A regression method used in the context of survival analysis or censored data.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005349</data>
      <data key="d6" />
    </node>
    <node id="L1 Regularized Logistic Regression">
      <data key="d0">L1 Regularized Logistic Regression</data>
      <data key="d1">method</data>
      <data key="d2">A logistic regression model with L1 regularization used for feature selection.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005349</data>
      <data key="d6" />
    </node>
    <node id="10-Fold Cross-Validation">
      <data key="d0">10-Fold Cross-Validation</data>
      <data key="d1">method</data>
      <data key="d2">A resampling procedure used to evaluate machine learning models by partitioning data into 10 subsets.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005351</data>
      <data key="d6" />
    </node>
    <node id="Electronic Health Records">
      <data key="d0">Electronic Health Records</data>
      <data key="d1">data</data>
      <data key="d2">Digital versions of patient paper charts, used as data sources for building disease risk prediction models.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005353</data>
      <data key="d6" />
    </node>
    <node id="Recurrent Neural Network">
      <data key="d0">Recurrent Neural Network</data>
      <data key="d1">method</data>
      <data key="d2">A class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence, abbreviated as RNN.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005354</data>
      <data key="d6" />
    </node>
    <node id="Chio et al.">
      <data key="d0">Chio et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers who in 2016 pioneered the use of RNN-based methods for heart failure prediction using EHR data.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005355</data>
      <data key="d6" />
    </node>
    <node id="Heart Failure">
      <data key="d0">Heart Failure</data>
      <data key="d1">concept</data>
      <data key="d2">A chronic condition where the heart doesn't pump blood as well as it should, abbreviated as HF.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005358</data>
      <data key="d6" />
    </node>
    <node id="One-Hot Vector">
      <data key="d0">One-Hot Vector</data>
      <data key="d1">method</data>
      <data key="d2">A common representation in natural language understanding where categorical variables are converted into a binary vector.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005358</data>
      <data key="d6" />
    </node>
    <node id="Gated Recurrent Unit">
      <data key="d0">Gated Recurrent Unit</data>
      <data key="d1">method</data>
      <data key="d2">A type of recurrent neural network, similar to an LSTM, but with a simpler structure, abbreviated as GRU.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005360</data>
      <data key="d6" />
    </node>
    <node id="K-Nearest Neighbors">
      <data key="d0">K-Nearest Neighbors</data>
      <data key="d1">method</data>
      <data key="d2">A simple, instance-based learning algorithm used for classification and regression, abbreviated as KNN.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005360</data>
      <data key="d6" />
    </node>
    <node id="KDD">
      <data key="d0">KDD</data>
      <data key="d1">event</data>
      <data key="d2">An international conference on Knowledge Discovery and Data Mining where Khosla et al. published their paper in 2010.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005362</data>
      <data key="d6" />
    </node>
    <node id="Framingham Heart Study">
      <data key="d0">Framingham Heart Study</data>
      <data key="d1">organization</data>
      <data key="d2">A long-term, ongoing cardiovascular cohort study that developed a risk score for predicting stroke or death in individuals with new-onset atrial fibrillation.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005362</data>
      <data key="d6" />
    </node>
    <node id="Wang TJ">
      <data key="d0">Wang TJ</data>
      <data key="d1">person</data>
      <data key="d2">An author of the 2003 study "A risk score for predicting stroke or death in individuals with new-onset atrial fibrillation in the community: the Framingham Heart Study."</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005362</data>
      <data key="d6" />
    </node>
    <node id="Temporal Relation">
      <data key="d0">Temporal Relation</data>
      <data key="d1">concept</data>
      <data key="d2">The sequential timing relationships between clinical events in electronic health records, which RNN methods are used to analyze.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005367</data>
      <data key="d6" />
    </node>
    <node id="Interpretability">
      <data key="d0">Interpretability</data>
      <data key="d1">concept</data>
      <data key="d2">The ease with which a model's decisions can be understood by humans; deep learning methods are noted to reduce this aspect.</data>
      <data key="d3">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005367</data>
      <data key="d6" />
    </node>
    <node id="模型风险管理">
      <data key="d0">模型风险管理</data>
      <data key="d1">concept</data>
      <data key="d2">Model risk management (MRM) is a critical factor for enterprises, involving the management of risks arising from the use of models in financial services such as pricing, valuation, fraud detection, and anti-money laundering.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005480</data>
      <data key="d6" />
    </node>
    <node id="金融机构">
      <data key="d0">金融机构</data>
      <data key="d1">organization</data>
      <data key="d2">Financial institutions rely on a series of models for pricing, valuation, fraud and money laundering detection, and other financial services.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005480</data>
      <data key="d6" />
    </node>
    <node id="人工智能模型">
      <data key="d0">人工智能模型</data>
      <data key="d1">artifact</data>
      <data key="d2">AI models, if trained on datasets not evaluated for bias, can produce results that reflect and perpetuate inherent biases in the data.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005481</data>
      <data key="d6" />
    </node>
    <node id="美联储">
      <data key="d0">美联储</data>
      <data key="d1">organization</data>
      <data key="d2">The Federal Reserve, along with the OCC, issued the Model Risk Management Supervisory Guidance as a benchmark for MRM frameworks in the United States.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005484</data>
      <data key="d6" />
    </node>
    <node id="货币监理署">
      <data key="d0">货币监理署</data>
      <data key="d1">organization</data>
      <data key="d2">The Office of the Comptroller of the Currency (OCC), along with the Federal Reserve, issued the Model Risk Management Supervisory Guidance as a benchmark for MRM frameworks in the United States.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005485</data>
      <data key="d6" />
    </node>
    <node id="模型风险管理监管指南">
      <data key="d0">模型风险管理监管指南</data>
      <data key="d1">content</data>
      <data key="d2">The Model Risk Management Supervisory Guidance, issued by the Federal Reserve and OCC, serves as a benchmark for MRM frameworks.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005486</data>
      <data key="d6" />
    </node>
    <node id="模型验证">
      <data key="d0">模型验证</data>
      <data key="d1">method</data>
      <data key="d2">Model validation is a process in MRM, such as stress testing market models, where AI and machine learning can be applied.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005489</data>
      <data key="d6" />
    </node>
    <node id="模型监控">
      <data key="d0">模型监控</data>
      <data key="d1">method</data>
      <data key="d2">Real-time model monitoring is a process in MRM where AI and machine learning can be applied.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005491</data>
      <data key="d6" />
    </node>
    <node id="模型风险管理软件">
      <data key="d0">模型风险管理软件</data>
      <data key="d1">artifact</data>
      <data key="d2">Model risk management software helps organizations manage model risk more effectively by providing features like model inventory, tracking, mapping metrics, and supporting regulatory compliance.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005491</data>
      <data key="d6" />
    </node>
    <node id="求职者筛选系统">
      <data key="d0">求职者筛选系统</data>
      <data key="d1">artifact</data>
      <data key="d2">A job applicant screening system is an example of an AI model that may favor male or younger applicants if not evaluated for bias.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005492</data>
      <data key="d6" />
    </node>
    <node id="医疗保健预测软件">
      <data key="d0">医疗保健预测软件</data>
      <data key="d1">artifact</data>
      <data key="d2">Healthcare prediction software is an example of an AI model that may exhibit racial bias when prioritizing patients needing immediate care if not evaluated for bias.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005494</data>
      <data key="d6" />
    </node>
    <node id="训练数据集">
      <data key="d0">训练数据集</data>
      <data key="d1">data</data>
      <data key="d2">Training datasets for AI models must be evaluated for bias to prevent the models from producing biased results.&lt;SEP&gt;用于训练深度学习模型的数据集，由数值天气预报产品和天气现象观测数据构建而成。</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309&lt;SEP&gt;chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010181</data>
      <data key="d6" />
    </node>
    <node id="IBM Cloud Pak For Business Automation">
      <data key="d0">IBM Cloud Pak For Business Automation</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM Cloud Pak for Business Automation is a modular set of integrated software components for operational management and automation.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005501</data>
      <data key="d6" />
    </node>
    <node id="IBM Openpages">
      <data key="d0">IBM Openpages</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM OpenPages is a solution implemented by the IBM CIO organization to unify governance, risk, and compliance management, simplify audit processes, and enhance visibility across business units.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005503</data>
      <data key="d6" />
    </node>
    <node id="Generative AI For Business">
      <data key="d0">Generative AI For Business</data>
      <data key="d1">concept</data>
      <data key="d2">The rise of generative AI for enterprises is a trend discussed, including its use in building practical virtual agents and driving innovation.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005504</data>
      <data key="d6" />
    </node>
    <node id="Virtual Agent">
      <data key="d0">Virtual Agent</data>
      <data key="d1">artifact</data>
      <data key="d2">Virtual agents, powered by generative AI, are becoming faster and more accurate, potentially replacing humans in some roles.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005504</data>
      <data key="d6" />
    </node>
    <node id="CEO">
      <data key="d0">CEO</data>
      <data key="d1">person</data>
      <data key="d2">CEOs are mentioned as utilizing generative AI and application modernization to drive innovation and maintain competitiveness.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005499</data>
      <data key="d6" />
    </node>
    <node id="IBM CIO Organization">
      <data key="d0">IBM CIO Organization</data>
      <data key="d1">organization</data>
      <data key="d2">The IBM CIO organization implemented IBM OpenPages to achieve enterprise-level governance, risk, and compliance management.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005500</data>
      <data key="d6" />
    </node>
    <node id="SR 11-7">
      <data key="d0">SR 11-7</data>
      <data key="d1">content</data>
      <data key="d2">SR 11-7: Guidance on Model Risk Management is a document published by the Federal Reserve on April 4, 2011.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005500</data>
      <data key="d6" />
    </node>
    <node id="Cambridge Journal Of Economics">
      <data key="d0">Cambridge Journal Of Economics</data>
      <data key="d1">content</data>
      <data key="d2">The Cambridge Journal of Economics published an article on July 1, 2009, titled "Structural causes of the global financial crisis: a critical assessment of the 'new financial architecture'".</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005501</data>
      <data key="d6" />
    </node>
    <node id="British Actuarial Journal">
      <data key="d0">British Actuarial Journal</data>
      <data key="d1">content</data>
      <data key="d2">The British Actuarial Journal published an article in December 2015 titled "Model risk – daring to open up the black box".</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005502</data>
      <data key="d6" />
    </node>
    <node id="Zillow">
      <data key="d0">Zillow</data>
      <data key="d1">organization</data>
      <data key="d2">Zillow experienced a home-buying debacle that illustrates the difficulty of using AI to value real estate.</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005505</data>
      <data key="d6" />
    </node>
    <node id="金融预测">
      <data key="d0">金融预测</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d2">Generative AI may not be suitable for financial forecasting as other mature models can perform the task with less effort and lower cost.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005508</data>
      <data key="d6" />
    </node>
    <node id="Federal Reserve">
      <data key="d0">Federal Reserve</data>
      <data key="d3">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d2">The Federal Reserve published the SR 11-7 guidance document on model risk management.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005525</data>
      <data key="d6" />
    </node>
    <node id="Machine Learning Algorithm">
      <data key="d0">Machine Learning Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">A method that repeats tasks, adjusting its approach each time to achieve better results, similar to how humans learn from experience.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005588</data>
      <data key="d6" />
    </node>
    <node id="Supervisory Machine Learning Algorithm">
      <data key="d0">Supervisory Machine Learning Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">A category of machine learning algorithms, each with its own advantages and limitations, used for tasks like supervised learning.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005588</data>
      <data key="d6" />
    </node>
    <node id="Deep Neural Network (DNN)">
      <data key="d0">Deep Neural Network (DNN)</data>
      <data key="d1">method</data>
      <data key="d2">An advanced machine learning technique used to identify loans that may be downgraded, often applied to complex real-world problems like fraud detection, image recognition, and natural language processing.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005596</data>
      <data key="d6" />
    </node>
    <node id="Data Processing Procedure">
      <data key="d0">Data Processing Procedure</data>
      <data key="d1">method</data>
      <data key="d2">A procedure that requires immense computational power, typically beyond the capability of a standard desktop computer, and can be completed in minutes using specialized infrastructure.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005591</data>
      <data key="d6" />
    </node>
    <node id="Training Phase">
      <data key="d0">Training Phase</data>
      <data key="d1">concept</data>
      <data key="d2">The phase where a machine learning algorithm randomly selects observations from a 'training set', builds a model to explain the output, and evaluates the model's performance with another batch of randomly selected data.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005591</data>
      <data key="d6" />
    </node>
    <node id="Model Parameters">
      <data key="d0">Model Parameters</data>
      <data key="d1">concept</data>
      <data key="d2">Parameters that are further fine-tuned with each repetition of the training process until the model's performance can no longer be improved.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005592</data>
      <data key="d6" />
    </node>
    <node id="Binary Classification Problem">
      <data key="d0">Binary Classification Problem</data>
      <data key="d1">concept</data>
      <data key="d2">A model's task of classifying whether a loan will be downgraded or not.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005594</data>
      <data key="d6" />
    </node>
    <node id="Area Under the Curve of Receiver Operating Characteristic (AUC)">
      <data key="d0">Area Under the Curve of Receiver Operating Characteristic (AUC)</data>
      <data key="d1">concept</data>
      <data key="d2">A metric used to evaluate the performance of a model, particularly for binary classification problems.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005595</data>
      <data key="d6" />
    </node>
    <node id="Hong Kong Monetary Authority (HKMA)">
      <data key="d0">Hong Kong Monetary Authority (HKMA)</data>
      <data key="d1">organization</data>
      <data key="d2">The organization under whose 'Digitalisation Programme' an internal data science laboratory was developed.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005596</data>
      <data key="d6" />
    </node>
    <node id="Internal Data Science Laboratory">
      <data key="d0">Internal Data Science Laboratory</data>
      <data key="d1">organization</data>
      <data key="d2">A facility, akin to a supercomputer, developed under the HKMA's 'Digitalisation Programme' to handle massive computational tasks.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005599</data>
      <data key="d6" />
    </node>
    <node id="Test Set">
      <data key="d0">Test Set</data>
      <data key="d1">data</data>
      <data key="d2">A subset of the dataset, constituting 20% (582,655 observations) of the total data, used to evaluate the performance of the fully trained model.&lt;SEP&gt;A test set comprising 25% of the data was used to evaluate the Deep Auto-Encoder model in Experiment Two.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3&lt;SEP&gt;chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006127</data>
      <data key="d6" />
    </node>
    <node id="Loan">
      <data key="d0">Loan</data>
      <data key="d1">concept</data>
      <data key="d2">The subject of the study, specifically focusing on identifying loans that may be downgraded.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005603</data>
      <data key="d6" />
    </node>
    <node id="Empirical Results">
      <data key="d0">Empirical Results</data>
      <data key="d1">content</data>
      <data key="d2">The section of the study detailing the dataset preparation and model evaluation process.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005603</data>
      <data key="d6" />
    </node>
    <node id="Benchmark Model">
      <data key="d0">Benchmark Model</data>
      <data key="d1">concept</data>
      <data key="d2">A model whose performance is compared against the trained DNN model in the study.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005605</data>
      <data key="d6" />
    </node>
    <node id="Figure 2">
      <data key="d0">Figure 2</data>
      <data key="d1">content</data>
      <data key="d2">A figure in the study that compares the performance of the trained DNN model with the benchmark model.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005606</data>
      <data key="d6" />
    </node>
    <node id="Digitalisation Programme">
      <data key="d0">Digitalisation Programme</data>
      <data key="d1">concept</data>
      <data key="d2">A program under the Hong Kong Monetary Authority (HKMA) that facilitated the development of the internal data science laboratory.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005608</data>
      <data key="d6" />
    </node>
    <node id="Hosmer et al.">
      <data key="d0">Hosmer et al.</data>
      <data key="d1">content</data>
      <data key="d2">A referenced work or authors mentioned in the context of comparing model performance.</data>
      <data key="d3">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005608</data>
      <data key="d6" />
    </node>
    <node id="金融行业">
      <data key="d0">金融行业</data>
      <data key="d1">organization</data>
      <data key="d2">The financial industry is the sector that deals with the detection of transaction fraud risks.</data>
      <data key="d3">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005647</data>
      <data key="d6" />
    </node>
    <node id="交易欺诈风险">
      <data key="d0">交易欺诈风险</data>
      <data key="d1">concept</data>
      <data key="d2">Transaction fraud risk is the type of risk that the financial industry aims to detect.</data>
      <data key="d3">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005647</data>
      <data key="d6" />
    </node>
    <node id="基于规则的方法">
      <data key="d0">基于规则的方法</data>
      <data key="d1">method</data>
      <data key="d2">The rule-based method involves continuously establishing and updating a rule library based on transaction behavior characteristics.</data>
      <data key="d3">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005649</data>
      <data key="d6" />
    </node>
    <node id="规则库">
      <data key="d0">规则库</data>
      <data key="d1">artifact</data>
      <data key="d2">The rule library is a collection of rules based on transaction behavior characteristics that is updated and applied during transactions.</data>
      <data key="d3">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005650</data>
      <data key="d6" />
    </node>
    <node id="交易行为特征">
      <data key="d0">交易行为特征</data>
      <data key="d1">concept</data>
      <data key="d2">Transaction behavior characteristics are the features used to build and update the rule library for fraud detection.</data>
      <data key="d3">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005650</data>
      <data key="d6" />
    </node>
    <node id="基于机器学习算法的方法">
      <data key="d0">基于机器学习算法的方法</data>
      <data key="d1">method</data>
      <data key="d2">The machine learning algorithm-based method is another primary approach for detecting transaction fraud risks.</data>
      <data key="d3">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005650</data>
      <data key="d6" />
    </node>
    <node id="基于机器学习算法">
      <data key="d0">基于机器学习算法</data>
      <data key="d1">method</data>
      <data key="d2">The machine learning algorithm-based method is another primary approach for detecting transaction fraud risks.</data>
      <data key="d3">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005652</data>
      <data key="d6" />
    </node>
    <node id="欺诈应用检测方法">
      <data key="d0">欺诈应用检测方法</data>
      <data key="d1">method</data>
      <data key="d2">A detection method for fraudulent applications, specifically based on deep learning techniques.</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005685</data>
      <data key="d6" />
    </node>
    <node id="移动广告数据">
      <data key="d0">移动广告数据</data>
      <data key="d1">data</data>
      <data key="d2">Data obtained from mobile advertising, which undergoes preprocessing as part of the detection method.</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005685</data>
      <data key="d6" />
    </node>
    <node id="结构数据">
      <data key="d0">结构数据</data>
      <data key="d1">data</data>
      <data key="d2">Structural data extracted from the mobile advertising data for further processing.</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005688</data>
      <data key="d6" />
    </node>
    <node id="样本数据">
      <data key="d0">样本数据</data>
      <data key="d1">data</data>
      <data key="d2">Sample data extracted alongside structural data for analysis.</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005688</data>
      <data key="d6" />
    </node>
    <node id="图">
      <data key="d0">图</data>
      <data key="d1">artifact</data>
      <data key="d2">A graph constructed based on the structural data to represent relationships.</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005689</data>
      <data key="d6" />
    </node>
    <node id="图嵌入特征">
      <data key="d0">图嵌入特征</data>
      <data key="d1">data</data>
      <data key="d2">Graph embedding features obtained from the constructed graph, used in the detection process.</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005690</data>
      <data key="d6" />
    </node>
    <node id="预处理">
      <data key="d0">预处理</data>
      <data key="d1">concept</data>
      <data key="d2">A step involving the preparation and cleaning of mobile advertising data before further analysis.&lt;SEP&gt;数据处理的重要步骤，涉及数据清洗，例如将字、词转换为各种ID。</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006906</data>
      <data key="d6" />
    </node>
    <node id="本发明">
      <data key="d0">本发明</data>
      <data key="d1">artifact</data>
      <data key="d2">Refers to the invention or patent being disclosed, which describes a fraud application detection method.&lt;SEP&gt;一项公开的专利或发明，内容涉及天气现象预报方法。</data>
      <data key="d3">chunk-a6a52780a97b8eca9204ad8ed2f86840&lt;SEP&gt;chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010183</data>
      <data key="d6" />
    </node>
    <node id="AI Agent风控模型">
      <data key="d0">AI Agent风控模型</data>
      <data key="d1">method</data>
      <data key="d2">AI Agent风控模型是一种基于深度学习的实时欺诈检测算法实现。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005772</data>
      <data key="d6" />
    </node>
    <node id="实时欺诈检测算法">
      <data key="d0">实时欺诈检测算法</data>
      <data key="d1">method</data>
      <data key="d2">实时欺诈检测算法是一种能够即时识别欺诈行为的技术，是AI Agent风控模型的核心功能。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005773</data>
      <data key="d6" />
    </node>
    <node id="用户行为">
      <data key="d0">用户行为</data>
      <data key="d1">data</data>
      <data key="d2">用户行为是AI Agent风控模型分析的数据类型之一，用于识别潜在的欺诈行为。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005777</data>
      <data key="d6" />
    </node>
    <node id="交易模式">
      <data key="d0">交易模式</data>
      <data key="d1">data</data>
      <data key="d2">交易模式是AI Agent风控模型分析的数据类型之一，用于识别潜在的欺诈行为。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005777</data>
      <data key="d6" />
    </node>
    <node id="历史数据">
      <data key="d0">历史数据</data>
      <data key="d1">data</data>
      <data key="d2">历史数据是AI Agent风控模型分析的数据类型之一，用于识别潜在的欺诈行为。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005778</data>
      <data key="d6" />
    </node>
    <node id="潜在欺诈行为">
      <data key="d0">潜在欺诈行为</data>
      <data key="d1">concept</data>
      <data key="d2">潜在欺诈行为是AI Agent风控模型旨在识别的风险概念。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005786</data>
      <data key="d6" />
    </node>
    <node id="企业">
      <data key="d0">企业</data>
      <data key="d1">organization</data>
      <data key="d2">企业是AI Agent风控模型旨在保护其资产和信誉的组织。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005786</data>
      <data key="d6" />
    </node>
    <node id="资产">
      <data key="d0">资产</data>
      <data key="d1">concept</data>
      <data key="d2">资产是企业拥有的资源，AI Agent风控模型旨在对其进行保护。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005783</data>
      <data key="d6" />
    </node>
    <node id="信誉">
      <data key="d0">信誉</data>
      <data key="d1">concept</data>
      <data key="d2">信誉是企业的声誉，AI Agent风控模型旨在对其进行保护。</data>
      <data key="d3">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005791</data>
      <data key="d6" />
    </node>
    <node id="Fraud Detection">
      <data key="d0">Fraud Detection</data>
      <data key="d1">concept</data>
      <data key="d2">Fraud detection is the process of identifying fraudulent activities.</data>
      <data key="d3">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005828</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning Models">
      <data key="d0">Deep Learning Models</data>
      <data key="d1">method</data>
      <data key="d2">Deep learning models are highly scalable and improve the accuracy of detecting fraudulent activities.</data>
      <data key="d3">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005831</data>
      <data key="d6" />
    </node>
    <node id="Business Impact">
      <data key="d0">Business Impact</data>
      <data key="d1">concept</data>
      <data key="d2">Business impact refers to the significant effect of transitioning from machine learning to deep learning for fraud detection.</data>
      <data key="d3">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005833</data>
      <data key="d6" />
    </node>
    <node id="Real-Time Detection">
      <data key="d0">Real-Time Detection</data>
      <data key="d1">concept</data>
      <data key="d2">Real-time detection is a capability enabled by deep learning models for identifying fraudulent activities as they occur.</data>
      <data key="d3">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005834</data>
      <data key="d6" />
    </node>
    <node id="False Positives">
      <data key="d0">False Positives</data>
      <data key="d1">concept</data>
      <data key="d2">False positives are incorrect fraud alerts that are reduced by using deep learning models.</data>
      <data key="d3">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005834</data>
      <data key="d6" />
    </node>
    <node id="Scalability">
      <data key="d0">Scalability</data>
      <data key="d1">concept</data>
      <data key="d2">Scalability refers to the high degree to which deep learning models can be expanded or adapted.</data>
      <data key="d3">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005835</data>
      <data key="d6" />
    </node>
    <node id="深度学习图神经网络">
      <data key="d0">深度学习图神经网络</data>
      <data key="d1">method</data>
      <data key="d2">一种基于深度学习的图神经网络方法，用于构建端到端、近乎实时的反欺诈系统。</data>
      <data key="d3">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005868</data>
      <data key="d6" />
    </node>
    <node id="端到端近乎实时反欺诈系统">
      <data key="d0">端到端近乎实时反欺诈系统</data>
      <data key="d1">method</data>
      <data key="d2">一种利用深度学习图神经网络构建的、能够近乎实时运作的反欺诈系统架构。</data>
      <data key="d3">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005868</data>
      <data key="d6" />
    </node>
    <node id="蓝图架构">
      <data key="d0">蓝图架构</data>
      <data key="d1">method</data>
      <data key="d2">一种使用深度图库(DGL)根据表格数据构造异构图，并训练图神经网络(GNN)模型以检测欺诈的系统设计蓝图。</data>
      <data key="d3">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005869</data>
      <data key="d6" />
    </node>
    <node id="深度图库">
      <data key="d0">深度图库</data>
      <data key="d1">method</data>
      <data key="d2">用于根据表格数据构造异构图的软件库。</data>
      <data key="d3">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005872</data>
      <data key="d6" />
    </node>
    <node id="表格数据">
      <data key="d0">表格数据</data>
      <data key="d1">data</data>
      <data key="d2">用于构造异构图的原始数据形式。</data>
      <data key="d3">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005872</data>
      <data key="d6" />
    </node>
    <node id="异构图">
      <data key="d0">异构图</data>
      <data key="d1">data</data>
      <data key="d2">由深度图库(DGL)根据表格数据构造的、包含多种类型节点和边的图结构数据。</data>
      <data key="d3">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005873</data>
      <data key="d6" />
    </node>
    <node id="图神经网络模型">
      <data key="d0">图神经网络模型</data>
      <data key="d1">method</data>
      <data key="d2">一种用于在异构图数据上进行训练，以检测欺诈的神经网络模型。</data>
      <data key="d3">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005873</data>
      <data key="d6" />
    </node>
    <node id="Amazon Web Services">
      <data key="d0">Amazon Web Services</data>
      <data key="d1">organization</data>
      <data key="d2">Amazon Web Services is a cloud computing platform mentioned as the deployment environment for the real-time anti-fraud solution.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005910</data>
      <data key="d6" />
    </node>
    <node id="Real-Time Anti-Fraud Solution">
      <data key="d0">Real-Time Anti-Fraud Solution</data>
      <data key="d1">method</data>
      <data key="d2">The Real-Time Anti-Fraud Solution is a system designed to detect fraudulent activities in real-time using deep learning graph neural networks.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005910</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning Graph Neural Networks">
      <data key="d0">Deep Learning Graph Neural Networks</data>
      <data key="d1">method</data>
      <data key="d2">Deep Learning Graph Neural Networks are a type of artificial intelligence model used for analyzing graph-structured data, applied here for fraud detection.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005911</data>
      <data key="d6" />
    </node>
    <node id="Graph Database">
      <data key="d0">Graph Database</data>
      <data key="d1">artifact</data>
      <data key="d2">A Graph Database is a type of database that uses graph structures for data representation, used here to support real-time anti-fraud detection.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005914</data>
      <data key="d6" />
    </node>
    <node id="Implementation Guide">
      <data key="d0">Implementation Guide</data>
      <data key="d1">content</data>
      <data key="d2">The Implementation Guide is a document that details the architectural considerations and configuration steps for deploying the anti-fraud solution on AWS.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005914</data>
      <data key="d6" />
    </node>
    <node id="AWS">
      <data key="d0">AWS</data>
      <data key="d1">organization</data>
      <data key="d2">AWS is a cloud computing platform, mentioned as the deployment environment for the real-time anti-fraud solution.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005923</data>
      <data key="d6" />
    </node>
    <node id="Architectural Considerations">
      <data key="d0">Architectural Considerations</data>
      <data key="d1">concept</data>
      <data key="d2">Architectural Considerations are the design and structural factors discussed in the implementation guide for deploying the solution.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005923</data>
      <data key="d6" />
    </node>
    <node id="Configuration Steps">
      <data key="d0">Configuration Steps</data>
      <data key="d1">method</data>
      <data key="d2">Configuration Steps are the specific procedural instructions provided in the implementation guide for setting up the solution.</data>
      <data key="d3">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005924</data>
      <data key="d6" />
    </node>
    <node id="深度学习欺诈侦测模型">
      <data key="d0">深度学习欺诈侦测模型</data>
      <data key="d1">method</data>
      <data key="d2">一种用于检测欺诈行为的深度学习模型，针对银行和保险业务中的伪卡欺诈和骗保检测等场景。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005967</data>
      <data key="d6" />
    </node>
    <node id="伪卡欺诈侦测">
      <data key="d0">伪卡欺诈侦测</data>
      <data key="d1">concept</data>
      <data key="d2">银行和保险业务中常见的应用场景，指检测伪造银行卡的欺诈行为。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005967</data>
      <data key="d6" />
    </node>
    <node id="骗保检测">
      <data key="d0">骗保检测</data>
      <data key="d1">concept</data>
      <data key="d2">保险业务中常见的应用场景，指检测保险欺诈行为。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005968</data>
      <data key="d6" />
    </node>
    <node id="银行">
      <data key="d0">银行</data>
      <data key="d1">organization</data>
      <data key="d2">提供金融服务的机构，是欺诈侦测模型的应用场景之一。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005970</data>
      <data key="d6" />
    </node>
    <node id="保险业务">
      <data key="d0">保险业务</data>
      <data key="d1">organization</data>
      <data key="d2">提供保险服务的业务领域，是欺诈侦测模型的应用场景之一。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005970</data>
      <data key="d6" />
    </node>
    <node id="真实数据">
      <data key="d0">真实数据</data>
      <data key="d1">data</data>
      <data key="d2">用于仿真验证模型性能的实际业务数据。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005972</data>
      <data key="d6" />
    </node>
    <node id="仿真验证">
      <data key="d0">仿真验证</data>
      <data key="d1">method</data>
      <data key="d2">使用真实数据对模型进行模拟测试和验证的过程。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005973</data>
      <data key="d6" />
    </node>
    <node id="GBDT→GRU→RF三明治结构">
      <data key="d0">GBDT→GRU→RF三明治结构</data>
      <data key="d1">method</data>
      <data key="d2">一种结合了梯度提升决策树、门控循环单元和随机森林的复合模型结构，用于欺诈侦测。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005975</data>
      <data key="d6" />
    </node>
    <node id="三方工程师">
      <data key="d0">三方工程师</data>
      <data key="d1">person</data>
      <data key="d2">Three-party engineers who conducted simulation verification for the new deep learning fraud detection model using real data.</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005976</data>
      <data key="d6" />
    </node>
    <node id="GBDT">
      <data key="d0">GBDT</data>
      <data key="d1">method</data>
      <data key="d2">Gradient Boosting Decision Tree, a component of the GBDT→GRU→RF sandwich structure used in the fraud detection model.</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005977</data>
      <data key="d6" />
    </node>
    <node id="GRU">
      <data key="d0">GRU</data>
      <data key="d1">method</data>
      <data key="d2">Gated Recurrent Unit, a component of the GBDT→GRU→RF sandwich structure used in the fraud detection model.&lt;SEP&gt;一种比LSTM稍简单的循环神经网络单元，在层次深或复杂时运算效率更高，但精度可能稍差。</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006915</data>
      <data key="d6" />
    </node>
    <node id="RF">
      <data key="d0">RF</data>
      <data key="d1">method</data>
      <data key="d2">Random Forest, a component of the GBDT→GRU→RF sandwich structure used in the fraud detection model.</data>
      <data key="d3">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769005987</data>
      <data key="d6" />
    </node>
    <node id="Moonlight">
      <data key="d0">Moonlight</data>
      <data key="d1">artifact</data>
      <data key="d2">Moonlight is an AI research assistant tool that helps users understand academic papers by providing text and image explanations, AI dialogue, smart citations, translation, auto-highlighting, external link analysis, annotation features, and academic search.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006094</data>
      <data key="d6" />
    </node>
    <node id="Credit Card Fraud Detection: A Deep Learning Approach">
      <data key="d0">Credit Card Fraud Detection: A Deep Learning Approach</data>
      <data key="d1">content</data>
      <data key="d2">This is an academic paper that proposes using deep learning methods to detect credit card fraud, addressing challenges like concept drift, class imbalance, and verification latency in financial transactions.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006094</data>
      <data key="d6" />
    </node>
    <node id="Multi-layer Feed-forward Neural Network">
      <data key="d0">Multi-layer Feed-forward Neural Network</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning model used for credit card fraud detection that feeds input data through layers, using non-linear transformations to learn hierarchical features from the data.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006095</data>
      <data key="d6" />
    </node>
    <node id="Deep Auto-Encoders">
      <data key="d0">Deep Auto-Encoders</data>
      <data key="d1">method</data>
      <data key="d2">An unsupervised learning method introduced for fraud detection that learns normal user transaction patterns without labels to identify anomalous patterns, particularly useful for severely imbalanced data.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006098</data>
      <data key="d6" />
    </node>
    <node id="Bat Algorithm">
      <data key="d0">Bat Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">A nature-inspired optimization algorithm that simulates bat echolocation behavior, used for feature selection and reducing training costs in the deep learning fraud detection model.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006098</data>
      <data key="d6" />
    </node>
    <node id="Kaggle Credit Card Fraud Detection Dataset">
      <data key="d0">Kaggle Credit Card Fraud Detection Dataset</data>
      <data key="d1">data</data>
      <data key="d2">A dataset containing 284,807 instances and 31 features, used for training and testing the proposed fraud detection models.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006099</data>
      <data key="d6" />
    </node>
    <node id="Z-score Standardization">
      <data key="d0">Z-score Standardization</data>
      <data key="d1">method</data>
      <data key="d2">A data standardization method used in the experiments, found to perform well when combined with the Tanh activation function.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006100</data>
      <data key="d6" />
    </node>
    <node id="Min-max Standardization">
      <data key="d0">Min-max Standardization</data>
      <data key="d1">method</data>
      <data key="d2">A data normalization method used alongside Z-score standardization in the model implementation phase.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006101</data>
      <data key="d6" />
    </node>
    <node id="Tanh Function">
      <data key="d0">Tanh Function</data>
      <data key="d1">method</data>
      <data key="d2">An activation function used in the neural network experiments, which outperformed the Logistic Sigmoid function when combined with Z-score standardization.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006103</data>
      <data key="d6" />
    </node>
    <node id="Logistic Sigmoid Function">
      <data key="d0">Logistic Sigmoid Function</data>
      <data key="d1">method</data>
      <data key="d2">An activation function compared against the Tanh function in the experiments for the fraud detection model.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006105</data>
      <data key="d6" />
    </node>
    <node id="Mean Squared Error (MSE)">
      <data key="d0">Mean Squared Error (MSE)</data>
      <data key="d1">method</data>
      <data key="d2">The loss function used in training the Deep Auto-Encoder model to reconstruct data and identify anomalies.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006105</data>
      <data key="d6" />
    </node>
    <node id="Scikit-learn">
      <data key="d0">Scikit-learn</data>
      <data key="d1">artifact</data>
      <data key="d2">A machine learning library whose algorithms were compared against the proposed deep learning methods using metrics like AUC score and confusion matrix.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006108</data>
      <data key="d6" />
    </node>
    <node id="AUC Score">
      <data key="d0">AUC Score</data>
      <data key="d1">data</data>
      <data key="d2">A performance metric used to evaluate and compare the fraud detection models, with the optimized model achieving a high score.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006108</data>
      <data key="d6" />
    </node>
    <node id="Confusion Matrix">
      <data key="d0">Confusion Matrix</data>
      <data key="d1">method</data>
      <data key="d2">An evaluation tool used to compare the performance of different classification algorithms for fraud detection.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006110</data>
      <data key="d6" />
    </node>
    <node id="Over-sampling">
      <data key="d0">Over-sampling</data>
      <data key="d1">method</data>
      <data key="d2">A technique used to handle class imbalance in the dataset by increasing the number of instances in the minority class.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006110</data>
      <data key="d6" />
    </node>
    <node id="Under-sampling">
      <data key="d0">Under-sampling</data>
      <data key="d1">method</data>
      <data key="d2">A technique used to handle class imbalance in the dataset by decreasing the number of instances in the majority class.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006112</data>
      <data key="d6" />
    </node>
    <node id="Concept Drift">
      <data key="d0">Concept Drift</data>
      <data key="d1">concept</data>
      <data key="d2">A challenge in fraud detection where the statistical properties of the target variable change over time, which traditional systems struggle with.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006112</data>
      <data key="d6" />
    </node>
    <node id="Class Imbalance">
      <data key="d0">Class Imbalance</data>
      <data key="d1">concept</data>
      <data key="d2">A challenge in fraud detection where fraudulent transactions are significantly outnumbered by legitimate ones, complicating model training.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006122</data>
      <data key="d6" />
    </node>
    <node id="Verification Latency">
      <data key="d0">Verification Latency</data>
      <data key="d1">concept</data>
      <data key="d2">A challenge in fraud detection referring to the delay between a transaction occurring and its label (fraudulent or legitimate) being confirmed.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006116</data>
      <data key="d6" />
    </node>
    <node id="Financial Transactions">
      <data key="d0">Financial Transactions</data>
      <data key="d1">concept</data>
      <data key="d2">Financial transactions are the processes involving the exchange of funds, which are susceptible to fraudulent activities leading to high costs.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006119</data>
      <data key="d6" />
    </node>
    <node id="Traditional Fraud Detection Systems">
      <data key="d0">Traditional Fraud Detection Systems</data>
      <data key="d1">concept</data>
      <data key="d2">Traditional fraud detection systems are existing methods that face challenges like concept drift, class imbalance, and verification latency in identifying fraudulent activities.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006119</data>
      <data key="d6" />
    </node>
    <node id="Fuzzy Logic">
      <data key="d0">Fuzzy Logic</data>
      <data key="d1">concept</data>
      <data key="d2">Fuzzy Logic is a computational approach used in some current fraud detection systems.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006121</data>
      <data key="d6" />
    </node>
    <node id="Validation Set">
      <data key="d0">Validation Set</data>
      <data key="d1">data</data>
      <data key="d2">A validation set is a subset of data used in Experiment One to determine the best standardization method and activation function for the neural network.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006124</data>
      <data key="d6" />
    </node>
    <node id="Reconstruction Method">
      <data key="d0">Reconstruction Method</data>
      <data key="d1">method</data>
      <data key="d2">The reconstruction method is the technique used by the Deep Auto-Encoder to identify anomalous data by attempting to reconstruct input data.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006127</data>
      <data key="d6" />
    </node>
    <node id="Global Best Position">
      <data key="d0">Global Best Position</data>
      <data key="d1">concept</data>
      <data key="d2">The global best position is the optimal solution found by the Bat Algorithm through updating bat positions and velocities during the optimization process.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006130</data>
      <data key="d6" />
    </node>
    <node id="Financial Field">
      <data key="d0">Financial Field</data>
      <data key="d1">concept</data>
      <data key="d2">The financial field is the application domain where the proposed deep learning fraud detection method shows broad future prospects, especially with big data and deep learning development.</data>
      <data key="d3">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006133</data>
      <data key="d6" />
    </node>
    <node id="检测方法">
      <data key="d0">检测方法</data>
      <data key="d1">method</data>
      <data key="d2">A method that significantly improves performance and remains effective even without sufficient labeled data.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006133</data>
      <data key="d6" />
    </node>
    <node id="系统">
      <data key="d0">系统</data>
      <data key="d1">artifact</data>
      <data key="d2">A system that enables a higher degree of automation, reducing the time, cost, and false positive rates associated with manual intervention while enhancing fraud detection capabilities.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006136</data>
      <data key="d6" />
    </node>
    <node id="本文的方法">
      <data key="d0">本文的方法</data>
      <data key="d1">method</data>
      <data key="d2">The method presented in the text, which shows broad future prospects in the financial sector.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006139</data>
      <data key="d6" />
    </node>
    <node id="免费AI PDF查看器">
      <data key="d0">免费AI PDF查看器</data>
      <data key="d1">artifact</data>
      <data key="d2">A free AI PDF viewer that revolutionizes the way papers are read.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006140</data>
      <data key="d6" />
    </node>
    <node id="CEO Younghyun Chung">
      <data key="d0">CEO Younghyun Chung</data>
      <data key="d1">person</data>
      <data key="d2">Younghyun Chung, the CEO of Corca, Inc.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006144</data>
      <data key="d6" />
    </node>
    <node id="Corca, Inc.">
      <data key="d0">Corca, Inc.</data>
      <data key="d1">organization</data>
      <data key="d2">Corca, Inc., a company with the business registration number 271-86-02206.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006145</data>
      <data key="d6" />
    </node>
    <node id="6F, 11-8 Teheran-ro 77-gil, Gangnam-gu, Seoul, Republic of Korea, 06159">
      <data key="d0">6F, 11-8 Teheran-ro 77-gil, Gangnam-gu, Seoul, Republic of Korea, 06159</data>
      <data key="d1">location</data>
      <data key="d2">The office address of Corca, Inc., located in Gangnam-gu, Seoul, Republic of Korea.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006148</data>
      <data key="d6" />
    </node>
    <node id="Contact 02-6925-6978">
      <data key="d0">Contact 02-6925-6978</data>
      <data key="d1">data</data>
      <data key="d2">The contact phone number for Corca, Inc.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006149</data>
      <data key="d6" />
    </node>
    <node id="E-mail: moonlight@corca.ai">
      <data key="d0">E-mail: moonlight@corca.ai</data>
      <data key="d1">data</data>
      <data key="d2">The email address for contacting Corca, Inc.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006149</data>
      <data key="d6" />
    </node>
    <node id="Business Registration Number 271-86-02206">
      <data key="d0">Business Registration Number 271-86-02206</data>
      <data key="d1">data</data>
      <data key="d2">The business registration number for Corca, Inc.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006152</data>
      <data key="d6" />
    </node>
    <node id="© 2026 Corca, Inc. All rights reserved.">
      <data key="d0">© 2026 Corca, Inc. All rights reserved.</data>
      <data key="d1">content</data>
      <data key="d2">A copyright notice indicating Corca, Inc. holds rights to its materials in 2026.</data>
      <data key="d3">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006152</data>
      <data key="d6" />
    </node>
    <node id="李峰">
      <data key="d0">李峰</data>
      <data key="d1">person</data>
      <data key="d2">李峰是河北金融学院的研究人员，是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的作者之一。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006310</data>
      <data key="d6" />
    </node>
    <node id="李惠先">
      <data key="d0">李惠先</data>
      <data key="d1">person</data>
      <data key="d2">李惠先是河北金融学院的研究人员，是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的作者之一。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006310</data>
      <data key="d6" />
    </node>
    <node id="陈雪">
      <data key="d0">陈雪</data>
      <data key="d1">person</data>
      <data key="d2">陈雪是河北金融学院的研究人员，是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的作者之一。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006311</data>
      <data key="d6" />
    </node>
    <node id="韩祝华">
      <data key="d0">韩祝华</data>
      <data key="d1">person</data>
      <data key="d2">韩祝华是河北金融学院的研究人员，是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的通讯作者。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006314</data>
      <data key="d6" />
    </node>
    <node id="河北金融学院">
      <data key="d0">河北金融学院</data>
      <data key="d1">organization</data>
      <data key="d2">河北金融学院是位于河北保定的教育机构，其下属的河北省金融科技应用重点实验室、金融科技学院和统计与数据科学学院参与了本研究。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006314</data>
      <data key="d6" />
    </node>
    <node id="河北省金融科技应用重点实验室">
      <data key="d0">河北省金融科技应用重点实验室</data>
      <data key="d1">organization</data>
      <data key="d2">河北省金融科技应用重点实验室是隶属于河北金融学院的研究机构，是本研究作者李峰的工作单位之一。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006315</data>
      <data key="d6" />
    </node>
    <node id="金融科技学院">
      <data key="d0">金融科技学院</data>
      <data key="d1">organization</data>
      <data key="d2">金融科技学院是河北金融学院的学院之一，是本研究作者李峰、李惠先和陈雪的工作单位。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006316</data>
      <data key="d6" />
    </node>
    <node id="保定">
      <data key="d0">保定</data>
      <data key="d1">location</data>
      <data key="d2">保定是河北省的城市，是河北金融学院及其相关实验室和学院的所在地。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006319</data>
      <data key="d6" />
    </node>
    <node id="信用卡欺诈">
      <data key="d0">信用卡欺诈</data>
      <data key="d1">concept</data>
      <data key="d2">信用卡欺诈是金融科技领域面临的重大挑战，是本文研究的核心问题。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006322</data>
      <data key="d6" />
    </node>
    <node id="动态时序图神经网络模型">
      <data key="d0">动态时序图神经网络模型</data>
      <data key="d1">method</data>
      <data key="d2">动态时序图神经网络模型是本文提出的一种新模型，用于信用卡欺诈检测，采用连续时间动态图范式。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006322</data>
      <data key="d6" />
    </node>
    <node id="DTGNN-FD">
      <data key="d0">DTGNN-FD</data>
      <data key="d1">method</data>
      <data key="d2">DTGNN-FD是本文提出的动态时序图神经网络模型的简称，用于实时信用卡欺诈检测。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006325</data>
      <data key="d6" />
    </node>
    <node id="图神经网络">
      <data key="d0">图神经网络</data>
      <data key="d1">method</data>
      <data key="d2">图神经网络是一种用于欺诈检测的方法，现有基于静态快照的方法难以捕捉动态演化模式。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006325</data>
      <data key="d6" />
    </node>
    <node id="静态快照">
      <data key="d0">静态快照</data>
      <data key="d1">concept</data>
      <data key="d2">静态快照是现有图神经网络方法中处理交易数据的一种方式，将动态交易流离散化，可能导致时序信息丢失。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006327</data>
      <data key="d6" />
    </node>
    <node id="连续时间动态图">
      <data key="d0">连续时间动态图</data>
      <data key="d1">concept</data>
      <data key="d2">连续时间动态图是DTGNN-FD模型采用的范式，用于对流式交易进行实时风险建模。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006327</data>
      <data key="d6" />
    </node>
    <node id="门控记忆机制">
      <data key="d0">门控记忆机制</data>
      <data key="d1">method</data>
      <data key="d2">门控记忆机制是DTGNN-FD模型采用的组件之一，用于持续更新用户表征。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006330</data>
      <data key="d6" />
    </node>
    <node id="时间感知注意力">
      <data key="d0">时间感知注意力</data>
      <data key="d1">method</data>
      <data key="d2">时间感知注意力是DTGNN-FD模型采用的组件之一，用于持续更新用户表征。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006330</data>
      <data key="d6" />
    </node>
    <node id="用户表征">
      <data key="d0">用户表征</data>
      <data key="d1">concept</data>
      <data key="d2">用户表征是DTGNN-FD模型在流式交易中持续更新的对象，用于进行实时风险建模。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006332</data>
      <data key="d6" />
    </node>
    <node id="流式交易">
      <data key="d0">流式交易</data>
      <data key="d1">concept</data>
      <data key="d2">流式交易是DTGNN-FD模型进行实时风险建模的对象。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006332</data>
      <data key="d6" />
    </node>
    <node id="实时风险建模">
      <data key="d0">实时风险建模</data>
      <data key="d1">concept</data>
      <data key="d2">实时风险建模是DTGNN-FD模型的目标，旨在对信用卡交易进行实时欺诈检测。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006335</data>
      <data key="d6" />
    </node>
    <node id="金融欺诈数据集">
      <data key="d0">金融欺诈数据集</data>
      <data key="d1">data</data>
      <data key="d2">金融欺诈数据集是用于评估DTGNN-FD模型性能的真实数据，实验在两个此类数据集上进行。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006335</data>
      <data key="d6" />
    </node>
    <node id="F1-Score">
      <data key="d0">F1-Score</data>
      <data key="d1">data</data>
      <data key="d2">F1-Score是评估欺诈检测模型性能的关键指标之一，本文所提模型在该指标上优于基线模型。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006337</data>
      <data key="d6" />
    </node>
    <node id="Recall">
      <data key="d0">Recall</data>
      <data key="d1">data</data>
      <data key="d2">Recall是评估欺诈检测模型性能的关键指标之一，本文所提模型在该指标上优于基线模型。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006337</data>
      <data key="d6" />
    </node>
    <node id="基线模型">
      <data key="d0">基线模型</data>
      <data key="d1">concept</data>
      <data key="d2">基线模型是用于与本文提出的DTGNN-FD模型进行比较的其他多种模型。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006340</data>
      <data key="d6" />
    </node>
    <node id="复杂时序模式">
      <data key="d0">复杂时序模式</data>
      <data key="d1">concept</data>
      <data key="d2">复杂时序模式是欺诈行为可能表现出的特征，本文所提模型表现出识别此类模式的潜力。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006340</data>
      <data key="d6" />
    </node>
    <node id="实时信用卡欺诈检测">
      <data key="d0">实时信用卡欺诈检测</data>
      <data key="d1">concept</data>
      <data key="d2">实时信用卡欺诈检测是本文研究旨在提供有效解决方案的目标领域。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006342</data>
      <data key="d6" />
    </node>
    <node id="DOI: 10.12677/csa.2025.1511295">
      <data key="d0">DOI: 10.12677/csa.2025.1511295</data>
      <data key="d1">data</data>
      <data key="d2">DOI: 10.12677/csa.2025.1511295是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的数字对象标识符。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006342</data>
      <data key="d6" />
    </node>
    <node id="基于动态时序图神经网络的信用卡欺诈检测方法研究">
      <data key="d0">基于动态时序图神经网络的信用卡欺诈检测方法研究</data>
      <data key="d1">content</data>
      <data key="d2">《基于动态时序图神经网络的信用卡欺诈检测方法研究》是本文研究的论文标题。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006345</data>
      <data key="d6" />
    </node>
    <node id="Credit Card Fraud Detection Approach Based on a Dynamic Temporal Graph Neural Network">
      <data key="d0">Credit Card Fraud Detection Approach Based on a Dynamic Temporal Graph Neural Network</data>
      <data key="d1">content</data>
      <data key="d2">Credit Card Fraud Detection Approach Based on a Dynamic Temporal Graph Neural Network是论文的英文标题。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006345</data>
      <data key="d6" />
    </node>
    <node id="计算机科学与应用">
      <data key="d0">计算机科学与应用</data>
      <data key="d1">content</data>
      <data key="d2">计算机科学与应用是发表本文的期刊或出版物名称。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006347</data>
      <data key="d6" />
    </node>
    <node id="收稿日期：2025年10月12日">
      <data key="d0">收稿日期：2025年10月12日</data>
      <data key="d1">data</data>
      <data key="d2">收稿日期：2025年10月12日是论文被接收的日期。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006347</data>
      <data key="d6" />
    </node>
    <node id="录用日期：2025年11月12日">
      <data key="d0">录用日期：2025年11月12日</data>
      <data key="d1">data</data>
      <data key="d2">录用日期：2025年11月12日是论文被录用的日期。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006357</data>
      <data key="d6" />
    </node>
    <node id="发布日期：2025年11月24日">
      <data key="d0">发布日期：2025年11月24日</data>
      <data key="d1">data</data>
      <data key="d2">发布日期：2025年11月24日是论文被发布的日期。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006357</data>
      <data key="d6" />
    </node>
    <node id="金融科技">
      <data key="d0">金融科技</data>
      <data key="d1">concept</data>
      <data key="d2">金融科技是信用卡欺诈问题所在的领域，也是本文研究的背景领域。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006352</data>
      <data key="d6" />
    </node>
    <node id="时序信息丢失">
      <data key="d0">时序信息丢失</data>
      <data key="d1">concept</data>
      <data key="d2">时序信息丢失是现有静态快照方法在处理动态交易流时导致的问题之一。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006352</data>
      <data key="d6" />
    </node>
    <node id="检测延迟">
      <data key="d0">检测延迟</data>
      <data key="d1">concept</data>
      <data key="d2">检测延迟是现有静态快照方法在处理动态交易流时导致的问题之一。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006355</data>
      <data key="d6" />
    </node>
    <node id="循环记忆模块">
      <data key="d0">循环记忆模块</data>
      <data key="d1">method</data>
      <data key="d2">循环记忆模块是论文关键词中提到的模型组件，可能与门控记忆机制相关。</data>
      <data key="d3">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006355</data>
      <data key="d6" />
    </node>
    <node id="自然语言">
      <data key="d0">自然语言</data>
      <data key="d1">concept</data>
      <data key="d2">自然语言是人类使用的语言，是深度学习模型处理的对象。</data>
      <data key="d3">chunk-fd544a0511ae2b1911f2ec7bdc2235ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006392</data>
      <data key="d6" />
    </node>
    <node id="NNLM模型">
      <data key="d0">NNLM模型</data>
      <data key="d1">method</data>
      <data key="d2">NNLM模型是一种使用神经网络建模语言的经典范例，其思路与统计语言模型保持一致。</data>
      <data key="d3">chunk-fd544a0511ae2b1911f2ec7bdc2235ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006393</data>
      <data key="d6" />
    </node>
    <node id="统计语言模型">
      <data key="d0">统计语言模型</data>
      <data key="d1">method</data>
      <data key="d2">统计语言模型是一种建模语言的方法，NNLM模型的思路与其保持一致。</data>
      <data key="d3">chunk-fd544a0511ae2b1911f2ec7bdc2235ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006393</data>
      <data key="d6" />
    </node>
    <node id="研究者">
      <data key="d0">研究者</data>
      <data key="d1">person</data>
      <data key="d2">研究者是使用深度学习模型处理自然语言的人，他们在2013年左右重新发掘了NNLM模型。</data>
      <data key="d3">chunk-fd544a0511ae2b1911f2ec7bdc2235ae</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006393</data>
      <data key="d6" />
    </node>
    <node id="深度学习工程师">
      <data key="d0">深度学习工程师</data>
      <data key="d1">person</data>
      <data key="d2">Deep learning engineers are professionals who can easily combine multiple neural networks to create end-to-end designs.</data>
      <data key="d3">chunk-1eb9c8a9254475c3a6672347d5ac549f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006409</data>
      <data key="d6" />
    </node>
    <node id="端到端设计">
      <data key="d0">端到端设计</data>
      <data key="d1">concept</data>
      <data key="d2">End-to-end design is a methodology that allows for the seamless combination of multiple neural networks.</data>
      <data key="d3">chunk-1eb9c8a9254475c3a6672347d5ac549f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006410</data>
      <data key="d6" />
    </node>
    <node id="情感分析案例">
      <data key="d0">情感分析案例</data>
      <data key="d1">content</data>
      <data key="d2">The sentiment analysis case is an example previously discussed to illustrate the application of neural network combinations.</data>
      <data key="d3">chunk-1eb9c8a9254475c3a6672347d5ac549f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006410</data>
      <data key="d6" />
    </node>
    <node id="向量">
      <data key="d0">向量</data>
      <data key="d1">concept</data>
      <data key="d2">Vectors are the "language of communication" between layers of a neural network and between different neural networks.</data>
      <data key="d3">chunk-1eb9c8a9254475c3a6672347d5ac549f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006410</data>
      <data key="d6" />
    </node>
    <node id="自然语言处理">
      <data key="d0">自然语言处理</data>
      <data key="d1">concept</data>
      <data key="d2">自然语言处理（Natural Language Processing，NLP）是人工智能和计算机科学的一个关键子领域。它专注于研究计算机与人类之间使用自然语言进行的交互，旨在让机器能够理解、解释、生成并处理人类语言。该领域结合了计算语言学、预测性人工智能以及深度学习模型等多种技术，以辨别和应对人类语言中的细微差异，从而改变人工智能理解人类思想与行为的方式。

从技术构成上看，自然语言处理通常包含两个核心组成部分：自然语言理解（NLU）和自然语言生成（NLG）。其应用范围广泛，涵盖了智能问答、机器翻译、文本分析等多个重要方向。本质上，它是通过机器学习等方法，使计算机具备与人类进行有效语言交流的能力。</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e&lt;SEP&gt;chunk-5ec46d561fc83169cc4cb16171e4b90d&lt;SEP&gt;chunk-b572e7e95c9e5e07043de0b3cb587187&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008437</data>
      <data key="d6" />
    </node>
    <node id="词元">
      <data key="d0">词元</data>
      <data key="d1">concept</data>
      <data key="d2">A token is a unit of text, such as a word or subword, that can be pre-trained using models like word2vec, GloVe, or subword embedding models.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006465</data>
      <data key="d6" />
    </node>
    <node id="Word2vec">
      <data key="d0">Word2vec</data>
      <data key="d1">method</data>
      <data key="d2">Word2vec is a model used for pre-training token representations on large corpora.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006466</data>
      <data key="d6" />
    </node>
    <node id="GloVe">
      <data key="d0">GloVe</data>
      <data key="d1">method</data>
      <data key="d2">GloVe is a model used for pre-training token representations on large corpora.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006466</data>
      <data key="d6" />
    </node>
    <node id="子词嵌入模型">
      <data key="d0">子词嵌入模型</data>
      <data key="d1">method</data>
      <data key="d2">Subword embedding models are used for pre-training token representations on large corpora.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006466</data>
      <data key="d6" />
    </node>
    <node id="Transformer编码器">
      <data key="d0">Transformer编码器</data>
      <data key="d1">method</data>
      <data key="d2">The Transformer encoder is a deeper self-supervised model architecture.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006466</data>
      <data key="d6" />
    </node>
    <node id="文本表示">
      <data key="d0">文本表示</data>
      <data key="d1">concept</data>
      <data key="d2">Text representation is the vector form of tokens learned through pre-training, which can be used in various deep learning architectures.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006467</data>
      <data key="d6" />
    </node>
    <node id="深度学习架构">
      <data key="d0">深度学习架构</data>
      <data key="d1">concept</data>
      <data key="d2">Deep learning architectures are frameworks into which pre-trained text representations can be placed for different natural language processing tasks.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006467</data>
      <data key="d6" />
    </node>
    <node id="自然语言处理任务">
      <data key="d0">自然语言处理任务</data>
      <data key="d1">concept</data>
      <data key="d2">Natural language processing tasks are various applications, such as those mentioned in section 15, where pre-trained text representations are used.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006467</data>
      <data key="d6" />
    </node>
    <node id="大型语料库">
      <data key="d0">大型语料库</data>
      <data key="d1">data</data>
      <data key="d2">Large corpora are extensive collections of text sequences used as the source data for pre-training text representations.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006468</data>
      <data key="d6" />
    </node>
    <node id="海量文本数据">
      <data key="d0">海量文本数据</data>
      <data key="d1">data</data>
      <data key="d2">Massive text data refers to the vast amount of textual information used for supervised learning in pre-training models without expensive labeling.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006468</data>
      <data key="d6" />
    </node>
    <node id="图14.1">
      <data key="d0">图14.1</data>
      <data key="d1">content</data>
      <data key="d2">Figure 14.1 illustrates how pre-trained text representations can be placed into various deep learning architectures for different natural language processing tasks.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006469</data>
      <data key="d6" />
    </node>
    <node id="8.3节">
      <data key="d0">8.3节</data>
      <data key="d1">content</data>
      <data key="d2">Section 8.3 discusses language models as an example of using natural language processing techniques.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006469</data>
      <data key="d6" />
    </node>
    <node id="9.5节">
      <data key="d0">9.5节</data>
      <data key="d1">content</data>
      <data key="d2">Section 9.5 discusses machine translation models as an example of using natural language processing techniques.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006469</data>
      <data key="d6" />
    </node>
    <node id="15节">
      <data key="d0">15节</data>
      <data key="d1">content</data>
      <data key="d2">Section 15 introduces various deep learning architectures for different natural language processing tasks that utilize pre-trained text representations.</data>
      <data key="d3">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006469</data>
      <data key="d6" />
    </node>
    <node id="孙民">
      <data key="d0">孙民</data>
      <data key="d1">person</data>
      <data key="d2">孙民是Appier的首席人工智能科学家，对传统NLP方法的局限性和深度学习的优势发表了见解。</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006554</data>
      <data key="d6" />
    </node>
    <node id="Appier">
      <data key="d0">Appier</data>
      <data key="d1">organization</data>
      <data key="d2">Appier is a company that provides AI solutions and maintains a blog covering marketing technology trends, automation, industry insights, best practices, and its own perspectives.&lt;SEP&gt;Appier是一家公司，其首席人工智能科学家孙民在文中被引用。&lt;SEP&gt;Appier is a company that publishes whitepapers and blogs about marketing technology trends and AI applications.</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d&lt;SEP&gt;chunk-93d921ef5f299976a4f4ffe79dfe7521&lt;SEP&gt;chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006559</data>
      <data key="d6" />
    </node>
    <node id="传统方法">
      <data key="d0">传统方法</data>
      <data key="d1">method</data>
      <data key="d2">传统方法是一种依赖高度人为干预来定义词汇含义和关系的自然语言处理方法，其学习过程偏向“死记硬背”，缺乏可扩展性。</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006559</data>
      <data key="d6" />
    </node>
    <node id="词向量">
      <data key="d0">词向量</data>
      <data key="d1">concept</data>
      <data key="d2">词向量是将相似单词映射到向量空间中的概念，用于判断在同一上下文中的不同单词在语义上是否相近。</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006560</data>
      <data key="d6" />
    </node>
    <node id="语料库">
      <data key="d0">语料库</data>
      <data key="d1">data</data>
      <data key="d2">语料库是用于语言学习的大量文本集合，通常来自新闻网站、维基百科和Reddit等来源。&lt;SEP&gt;语料库是大量文本数据的集合，用于训练和评估自然语言处理模型，其质量对统计模型的效果至关重要。</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006860</data>
      <data key="d6" />
    </node>
    <node id="Reddit">
      <data key="d0">Reddit</data>
      <data key="d1">organization</data>
      <data key="d2">Reddit是一个网站，其上的评论是构建专门知识库和语料库的来源之一。</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006563</data>
      <data key="d6" />
    </node>
    <node id="关键词营销">
      <data key="d0">关键词营销</data>
      <data key="d1">concept</data>
      <data key="d2">关键词营销是一种营销方式，在深度学习的帮助下，可以通过向量空间寻找相似的种子关键词来优化。</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006565</data>
      <data key="d6" />
    </node>
    <node id="Plaster">
      <data key="d0">Plaster</data>
      <data key="d1">concept</data>
      <data key="d2">Plaster is an English word with multiple meanings, such as a coating for walls or an adhesive bandage, used as an example to illustrate the challenge of disambiguation for AI.</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006567</data>
      <data key="d6" />
    </node>
    <node id="Clear Plaster">
      <data key="d0">Clear Plaster</data>
      <data key="d1">concept</data>
      <data key="d2">Clear Plaster is a search query example ("clear plaster") used to demonstrate that AI trained with deep learning can correctly interpret it as a first-aid item rather than a decoration material.</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006567</data>
      <data key="d6" />
    </node>
    <node id="Seed Data">
      <data key="d0">Seed Data</data>
      <data key="d1">concept</data>
      <data key="d2">Seed data are initial inputs provided to an AI system in deep learning, which then finds similar keywords in the vector space for applications like keyword marketing.</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006568</data>
      <data key="d6" />
    </node>
    <node id="Vector Space">
      <data key="d0">Vector Space</data>
      <data key="d1">concept</data>
      <data key="d2">Vector space is a mathematical construct where word vectors are mapped, allowing the measurement of semantic similarity between words based on their proximity.</data>
      <data key="d3">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006568</data>
      <data key="d6" />
    </node>
    <node id="Appier Blog">
      <data key="d0">Appier Blog</data>
      <data key="d1">content</data>
      <data key="d2">The Appier Blog is a subscription-based content source that delivers the latest trends in marketing technology, automated marketing, industry trends, best practice cases, and Appier's viewpoints.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006569</data>
      <data key="d6" />
    </node>
    <node id="Contextual Advertising">
      <data key="d0">Contextual Advertising</data>
      <data key="d1">concept</data>
      <data key="d2">Contextual Advertising is a form of targeted advertising where ads are placed based on the content of a webpage or the context of a user's activity.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006572</data>
      <data key="d6" />
    </node>
    <node id="AI Solution">
      <data key="d0">AI Solution</data>
      <data key="d1">concept</data>
      <data key="d2">An AI solution that is described as being more proactive in thinking, planning, and acting than chatbots and Co-pilots.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006573</data>
      <data key="d6" />
    </node>
    <node id="Chatbot">
      <data key="d0">Chatbot</data>
      <data key="d1">artifact</data>
      <data key="d2">A type of conversational AI agent, mentioned as a point of comparison for a more proactive AI solution.&lt;SEP&gt;A software application designed to simulate conversation with human users.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009186</data>
      <data key="d6" />
    </node>
    <node id="Co-pilot">
      <data key="d0">Co-pilot</data>
      <data key="d1">concept</data>
      <data key="d2">An AI assistant tool, mentioned as a point of comparison for a more proactive AI solution.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006577</data>
      <data key="d6" />
    </node>
    <node id="Marketing Technology Trends">
      <data key="d0">Marketing Technology Trends</data>
      <data key="d1">concept</data>
      <data key="d2">Marketing technology trends are a key topic covered by the Appier Blog.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006579</data>
      <data key="d6" />
    </node>
    <node id="Automated Marketing">
      <data key="d0">Automated Marketing</data>
      <data key="d1">concept</data>
      <data key="d2">Automated marketing is a key topic covered by the Appier Blog.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006579</data>
      <data key="d6" />
    </node>
    <node id="Industry Trends">
      <data key="d0">Industry Trends</data>
      <data key="d1">concept</data>
      <data key="d2">Industry trends are a key topic covered by the Appier Blog.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006580</data>
      <data key="d6" />
    </node>
    <node id="Best Practice Cases">
      <data key="d0">Best Practice Cases</data>
      <data key="d1">concept</data>
      <data key="d2">Best practice cases are a key topic covered by the Appier Blog.</data>
      <data key="d3">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006581</data>
      <data key="d6" />
    </node>
    <node id="深度學習">
      <data key="d0">深度學習</data>
      <data key="d1">method</data>
      <data key="d2">深度學習是一種人工智慧方法，可以幫助企業從種子資料中尋找相似關鍵字，並進行更精準的情感分析。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006583</data>
      <data key="d6" />
    </node>
    <node id="人工智慧">
      <data key="d0">人工智慧</data>
      <data key="d1">method</data>
      <data key="d2">人工智慧是一種工具，可以處理自然語言，用於關鍵字擴展、情感分析和目標受眾識別。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006583</data>
      <data key="d6" />
    </node>
    <node id="關鍵字清單">
      <data key="d0">關鍵字清單</data>
      <data key="d1">content</data>
      <data key="d2">關鍵字清單是行銷人根據行銷目標預先構思的詞語集合，用於定義目標市場和觸及潛在顧客。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006586</data>
      <data key="d6" />
    </node>
    <node id="種子資料">
      <data key="d0">種子資料</data>
      <data key="d1">data</data>
      <data key="d2">種子資料是企業輸入到人工智慧中的初始資料，用於在向量空間中尋找相似的關鍵字。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006588</data>
      <data key="d6" />
    </node>
    <node id="向量空間">
      <data key="d0">向量空間</data>
      <data key="d1">concept</data>
      <data key="d2">向量空間是一個數學概念，人工智慧在其中根據種子資料尋找語義相似的關鍵字。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006598</data>
      <data key="d6" />
    </node>
    <node id="情感分析">
      <data key="d0">情感分析</data>
      <data key="d1">method</data>
      <data key="d2">情感分析是自然語言處理的一項功能，能根據關鍵字判斷使用者在搜尋當下的正面或負面感受。&lt;SEP&gt;情感分析是一种深度学习应用，用于分析文本序列所表达的情感倾向，属于多对一问题。&lt;SEP&gt;深度学习的一个应用方向。&lt;SEP&gt;情感分析是从文本中提取主观特质(如态度、情感)的技术。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007377</data>
      <data key="d6" />
    </node>
    <node id="詞向量">
      <data key="d0">詞向量</data>
      <data key="d1">concept</data>
      <data key="d2">詞向量是自然語言處理中的一種應用，可以幫助避免錯失與使用特定關鍵字的消費者互動的機會。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006593</data>
      <data key="d6" />
    </node>
    <node id="文本生成">
      <data key="d0">文本生成</data>
      <data key="d1">method</data>
      <data key="d2">文本生成是自然語言處理技術的一部分，目前在語言生成方面的表現不如語言理解穩定，有時會產出預想之外的內容。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006593</data>
      <data key="d6" />
    </node>
    <node id="聊天機器人">
      <data key="d0">聊天機器人</data>
      <data key="d1">artifact</data>
      <data key="d2">聊天機器人是一種人工智慧應用，未來有望處理更複雜的查詢問題並推動行銷自動化。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006594</data>
      <data key="d6" />
    </node>
    <node id="行銷自動化">
      <data key="d0">行銷自動化</data>
      <data key="d1">concept</data>
      <data key="d2">行銷自動化是未來人工智慧發展的目標之一，旨在減少人為干預，使行銷工作更具可擴充性。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006595</data>
      <data key="d6" />
    </node>
    <node id="孫民">
      <data key="d0">孫民</data>
      <data key="d1">person</data>
      <data key="d2">孫民是一位專家，他提到深度學習和人工智慧在行銷中的應用，包括關鍵字擴展、情感分析的優勢以及當前技術的不足之處。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006598</data>
      <data key="d6" />
    </node>
    <node id="旅遊公司">
      <data key="d0">旅遊公司</data>
      <data key="d1">organization</data>
      <data key="d2">旅遊公司是一個企業例子，它會針對潛在顧客擬定包含「度假」、「班機」等詞語的關鍵字清單。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006598</data>
      <data key="d6" />
    </node>
    <node id="宿霧">
      <data key="d0">宿霧</data>
      <data key="d1">location</data>
      <data key="d2">宿霧是一個地點，在行銷案例中與「菲律賓」、「潛水」或「地震」等關鍵字一同被搜尋，用於判斷使用者意圖。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006608</data>
      <data key="d6" />
    </node>
    <node id="菲律賓">
      <data key="d0">菲律賓</data>
      <data key="d1">location</data>
      <data key="d2">菲律賓是一個國家，在行銷案例中與「宿霧」一同被搜尋，人工智慧工具會從上下文中判定使用者是否有意旅行。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006600</data>
      <data key="d6" />
    </node>
    <node id="白皮書">
      <data key="d0">白皮書</data>
      <data key="d1">content</data>
      <data key="d2">白皮書是Appier發布的一份文件，標題為「鎖定高價值應用程式使用者: 運用深度學習提高獲取新客的行銷成效」，提供關於深度學習在行銷應用的深入洞察。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006602</data>
      <data key="d6" />
    </node>
    <node id="高價值應用程式使用者">
      <data key="d0">高價值應用程式使用者</data>
      <data key="d1">concept</data>
      <data key="d2">高價值應用程式使用者是Appier白皮書中提到的目標受眾概念，指可以通過深度學習行銷策略獲取的重要客戶群體。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006603</data>
      <data key="d6" />
    </node>
    <node id="獲取新客">
      <data key="d0">獲取新客</data>
      <data key="d1">concept</data>
      <data key="d2">獲取新客是行銷的一個核心目標，Appier的白皮書探討如何運用深度學習來提高達成此目標的行銷成效。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006604</data>
      <data key="d6" />
    </node>
    <node id="廣告創意素材">
      <data key="d0">廣告創意素材</data>
      <data key="d1">content</data>
      <data key="d2">廣告創意素材是行銷中用於實現「千人千面」顧客旅程的內容，可以通過AI進行個性化打造。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006607</data>
      <data key="d6" />
    </node>
    <node id="千人千面">
      <data key="d0">千人千面</data>
      <data key="d1">concept</data>
      <data key="d2">千人千面是一種行銷概念，指為不同的顧客提供高度個性化的體驗和旅程。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006608</data>
      <data key="d6" />
    </node>
    <node id="Agentic AI">
      <data key="d0">Agentic AI</data>
      <data key="d1">concept</data>
      <data key="d2">Agentic AI是一種比聊天機器人和Co-pilot更先進的人工智慧解決方案，具備主動思考、計畫與行動的能力。&lt;SEP&gt;A concept in artificial intelligence focusing on autonomous agents.</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009181</data>
      <data key="d6" />
    </node>
    <node id="內容相關廣告">
      <data key="d0">內容相關廣告</data>
      <data key="d1">concept</data>
      <data key="d2">內容相關廣告是一種廣告形式，其內容與用戶正在瀏覽的網頁上下文相關。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006611</data>
      <data key="d6" />
    </node>
    <node id="Appier部落格">
      <data key="d0">Appier部落格</data>
      <data key="d1">content</data>
      <data key="d2">Appier部落格是一個內容平台，提供最新行銷科技趨勢、自動化行銷、產業趨勢、最佳實踐案例以及Appier觀點。</data>
      <data key="d3">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006611</data>
      <data key="d6" />
    </node>
    <node id="NLP预处理">
      <data key="d0">NLP预处理</data>
      <data key="d1">method</data>
      <data key="d2">NLP预处理是将原始文本准备好以供程序或机器学习模型分析的过程，旨在将文本转换成深度学习模型更容易分析的格式。</data>
      <data key="d3">chunk-38b1076024c94a070f64f72dcaea1102</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006678</data>
      <data key="d6" />
    </node>
    <node id="原始文本">
      <data key="d0">原始文本</data>
      <data key="d1">data</data>
      <data key="d2">原始文本是未经处理的文本数据，是NLP预处理的输入对象。&lt;SEP&gt;原始文本是未经处理的文本数据，是文本预处理的输入。</data>
      <data key="d3">chunk-38b1076024c94a070f64f72dcaea1102&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007433</data>
      <data key="d6" />
    </node>
    <node id="程序">
      <data key="d0">程序</data>
      <data key="d1">artifact</data>
      <data key="d2">程序是用于分析经过NLP预处理后的文本的软件工具。</data>
      <data key="d3">chunk-38b1076024c94a070f64f72dcaea1102</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006688</data>
      <data key="d6" />
    </node>
    <node id="机器学习模型">
      <data key="d0">机器学习模型</data>
      <data key="d1">concept</data>
      <data key="d2">机器学习模型是用于分析经过NLP预处理后的文本的算法模型。&lt;SEP&gt;Machine learning models, such as LLMs, are systems that can generate text, summarize content, translate, rewrite, classify, and analyze.</data>
      <data key="d3">chunk-38b1076024c94a070f64f72dcaea1102&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008988</data>
      <data key="d6" />
    </node>
    <node id="语言学">
      <data key="d0">语言学</data>
      <data key="d1">concept</data>
      <data key="d2">语言学是文本所属的学术领域，为NLP预处理提供了应用背景。&lt;SEP&gt;语言学是本次课程内容所属的学术领域。</data>
      <data key="d3">chunk-38b1076024c94a070f64f72dcaea1102&lt;SEP&gt;chunk-e77bf0e5ecd6a42625cc947b20dfaca8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007756</data>
      <data key="d6" />
    </node>
    <node id="计算语言学">
      <data key="d0">计算语言学</data>
      <data key="d1">concept</data>
      <data key="d2">A scientific discipline that uses computers and software tools to understand and build models of human language.&lt;SEP&gt;计算语言学是基于规则的人类语言建模，是自然语言处理的一个组成部分。</data>
      <data key="d3">chunk-b572e7e95c9e5e07043de0b3cb587187&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007347</data>
      <data key="d6" />
    </node>
    <node id="人类语言">
      <data key="d0">人类语言</data>
      <data key="d1">concept</data>
      <data key="d2">Human language is the subject of study and processing in both natural language processing and computational linguistics.</data>
      <data key="d3">chunk-b572e7e95c9e5e07043de0b3cb587187</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006717</data>
      <data key="d6" />
    </node>
    <node id="对抗网络">
      <data key="d0">对抗网络</data>
      <data key="d1">method</data>
      <data key="d2">对抗网络是一种前沿技术，属于机器学习领域。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006832</data>
      <data key="d6" />
    </node>
    <node id="达观数据">
      <data key="d0">达观数据</data>
      <data key="d1">organization</data>
      <data key="d2">达观数据是一个组织，原创发布了本文。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006835</data>
      <data key="d6" />
    </node>
    <node id="人人都是产品经理">
      <data key="d0">人人都是产品经理</data>
      <data key="d1">organization</data>
      <data key="d2">人人都是产品经理是一个平台，本文在该平台发布。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006836</data>
      <data key="d6" />
    </node>
    <node id="原告律师">
      <data key="d0">原告律师</data>
      <data key="d1">concept</data>
      <data key="d2">原告律师是一个需要从文本中抽取的语义概念，其识别依赖于对较远上下文(如“原告”二字)的理解。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006837</data>
      <data key="d6" />
    </node>
    <node id="被告律师">
      <data key="d0">被告律师</data>
      <data key="d1">concept</data>
      <data key="d2">被告律师是一个需要从文本中抽取的语义概念。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006848</data>
      <data key="d6" />
    </node>
    <node id="原告刘德华">
      <data key="d0">原告刘德华</data>
      <data key="d1">concept</data>
      <data key="d2">原告刘德华是一个需要从文本中抽取的语义概念，其识别依赖于对较远上下文(如“原告”二字)的理解。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006848</data>
      <data key="d6" />
    </node>
    <node id="委托律师张学友">
      <data key="d0">委托律师张学友</data>
      <data key="d1">concept</data>
      <data key="d2">委托律师张学友是一个需要从文本中抽取的语义概念，其识别依赖于对较远上下文(如“原告”二字)的理解。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006843</data>
      <data key="d6" />
    </node>
    <node id="上下文特征">
      <data key="d0">上下文特征</data>
      <data key="d1">concept</data>
      <data key="d2">上下文特征是深度学习LSTM模型能够学习的特征，用于解决长距离语义依赖问题。</data>
      <data key="d3">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006843</data>
      <data key="d6" />
    </node>
    <node id="AlphaGo项目">
      <data key="d0">AlphaGo项目</data>
      <data key="d1">event</data>
      <data key="d2">AlphaGo项目是一个著名的人工智能项目，其主要负责人David Silver曾提出“深度学习+强化学习=人工智能”的观点。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006848</data>
      <data key="d6" />
    </node>
    <node id="David Silver">
      <data key="d0">David Silver</data>
      <data key="d1">person</data>
      <data key="d2">David Silver是AlphaGo项目的主要负责人，他发表了关于深度学习与强化学习结合构成人工智能的言论。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006850</data>
      <data key="d6" />
    </node>
    <node id="文本挖掘">
      <data key="d0">文本挖掘</data>
      <data key="d1">method</data>
      <data key="d2">文本挖掘是从非结构化文本数据中提取有价值信息和模式的过程，是自然语言处理的一个应用方向。&lt;SEP&gt;文本挖掘是从非结构化文本数据中提取信息和发现模式的技术。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007375</data>
      <data key="d6" />
    </node>
    <node id="机器翻译">
      <data key="d0">机器翻译</data>
      <data key="d1">concept</data>
      <data key="d2">机器翻译是一种深度学习应用，属于异步的多对多序列到序列问题，需要根据上下文进行翻译。&lt;SEP&gt;深度学习的一个应用方向。&lt;SEP&gt;机器翻译是使用计算机将文本或语音从一种语言自动翻译成另一种语言的技术，是自然语言处理的早期应用之一。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006855</data>
      <data key="d6" />
    </node>
    <node id="规则引擎">
      <data key="d0">规则引擎</data>
      <data key="d1">method</data>
      <data key="d2">规则引擎是一种基于预定义人工规则的系统，在自然语言处理早期被用于实现问答、翻译等功能。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006856</data>
      <data key="d6" />
    </node>
    <node id="统计机器学习">
      <data key="d0">统计机器学习</data>
      <data key="d1">method</data>
      <data key="d2">统计机器学习是一种基于统计模型的机器学习方法，在上世纪九十年代推动了自然语言处理技术的革新。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006857</data>
      <data key="d6" />
    </node>
    <node id="中文分词">
      <data key="d0">中文分词</data>
      <data key="d1">method</data>
      <data key="d2">深度学习的一个应用方向。&lt;SEP&gt;中文分词是将连续的中文文本序列切分成单独词语的过程，是中文自然语言处理的基础任务。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006860</data>
      <data key="d6" />
    </node>
    <node id="命名实体识别">
      <data key="d0">命名实体识别</data>
      <data key="d1">method</data>
      <data key="d2">深度学习的一个应用方向。&lt;SEP&gt;命名实体识别是识别文本中具有特定意义的实体(如人名、地名、组织名)并分类的技术。&lt;SEP&gt;命名实体识别是识别文本中特定类型实体(如人名、地名)的任务。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007380</data>
      <data key="d6" />
    </node>
    <node id="依存文法分析">
      <data key="d0">依存文法分析</data>
      <data key="d1">method</data>
      <data key="d2">依存文法分析是分析句子中词语之间的语法依存关系的一种方法。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006862</data>
      <data key="d6" />
    </node>
    <node id="语义归一化">
      <data key="d0">语义归一化</data>
      <data key="d1">method</data>
      <data key="d2">语义归一化是将不同表达但含义相同的文本映射到统一标准形式的技术。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006865</data>
      <data key="d6" />
    </node>
    <node id="文本纠错">
      <data key="d0">文本纠错</data>
      <data key="d1">method</data>
      <data key="d2">文本纠错是检测并修正文本中拼写、语法等错误的技术。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006865</data>
      <data key="d6" />
    </node>
    <node id="TF-IDF">
      <data key="d0">TF-IDF</data>
      <data key="d1">method</data>
      <data key="d2">一种用于计算特征值或进行特征过滤排序的方式。&lt;SEP&gt;TF-IDF是一种用于信息检索与文本挖掘的常用加权技术，用以评估一个词语对于一个文件集或一个语料库中的其中一份文件的重要程度。&lt;SEP&gt;TF-IDF是一种评估单词在文档集合中重要性的特征提取技术。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007389</data>
      <data key="d6" />
    </node>
    <node id="互信息">
      <data key="d0">互信息</data>
      <data key="d1">method</data>
      <data key="d2">一种用于计算特征值或进行特征过滤排序的方式。&lt;SEP&gt;互信息是信息论中衡量两个变量之间相互依赖性的度量，可用于特征选择。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006870</data>
      <data key="d6" />
    </node>
    <node id="信息增益">
      <data key="d0">信息增益</data>
      <data key="d1">method</data>
      <data key="d2">一种用于计算特征值或进行特征过滤排序的方式。&lt;SEP&gt;信息增益是决策树算法中用于选择特征的一种指标，基于熵的概念，衡量特征为分类系统带来多少信息。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006874</data>
      <data key="d6" />
    </node>
    <node id="Logistics Regression">
      <data key="d0">Logistics Regression</data>
      <data key="d1">method</data>
      <data key="d2">逻辑回归是一种用于解决分类问题的经典统计机器学习算法。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006886</data>
      <data key="d6" />
    </node>
    <node id="知识图谱">
      <data key="d0">知识图谱</data>
      <data key="d1">concept</data>
      <data key="d2">知识图谱是一种用图模型来描述知识和建模万物之间关联关系的技术，是自然语言处理中的重要应用。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006887</data>
      <data key="d6" />
    </node>
    <node id="达观">
      <data key="d0">达观</data>
      <data key="d1">organization</data>
      <data key="d2">达观是一家公司，在文本中将其自然语言处理的技术层级称为“篇章”级应用。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006890</data>
      <data key="d6" />
    </node>
    <node id="字词句篇与达标训练">
      <data key="d0">字词句篇与达标训练</data>
      <data key="d1">content</data>
      <data key="d2">《字词句篇与达标训练》是一本小学语文辅导书，内容涉及字、词、句、篇的学习。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006890</data>
      <data key="d6" />
    </node>
    <node id="篇章">
      <data key="d0">篇章</data>
      <data key="d1">concept</data>
      <data key="d2">篇章是自然语言处理中的一个应用层级，指对整篇文章或长文本进行处理和分析，涉及分类、主题建模等高层次应用。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006896</data>
      <data key="d6" />
    </node>
    <node id="互联网时代">
      <data key="d0">互联网时代</data>
      <data key="d1">event</data>
      <data key="d2">互联网时代是上个世纪末开始的时期，其特征是大量数据的电子化，为深度学习的发展提供了数据基础。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006896</data>
      <data key="d6" />
    </node>
    <node id="并行计算">
      <data key="d0">并行计算</data>
      <data key="d1">concept</data>
      <data key="d2">并行计算是一种计算类型，其中许多计算或进程同时执行，GPU是实现并行计算的关键硬件，显著加速了深度学习算法的训练。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006891</data>
      <data key="d6" />
    </node>
    <node id="听觉">
      <data key="d0">听觉</data>
      <data key="d1">concept</data>
      <data key="d2">听觉是人类感官之一，在人工智能中对应语音识别技术。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006891</data>
      <data key="d6" />
    </node>
    <node id="视觉">
      <data key="d0">视觉</data>
      <data key="d1">concept</data>
      <data key="d2">视觉是人类感官之一，在人工智能中对应计算机视觉技术。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006893</data>
      <data key="d6" />
    </node>
    <node id="Knowledge Base">
      <data key="d0">Knowledge Base</data>
      <data key="d1">data</data>
      <data key="d2">知识数据库是一种人工智能形式，它可能不那么智能，但属于AI的范畴。&lt;SEP&gt;A Knowledge Base is an external repository of information from which RAG retrieves relevant data to inform its answer generation.&lt;SEP&gt;An external repository of information used in the Retrieval-Augmented Generation technique to retrieve relevant data.</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-0222ac86b3d60100ac5d03d88a69654e&lt;SEP&gt;chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008727</data>
      <data key="d6" />
    </node>
    <node id="词位置分析">
      <data key="d0">词位置分析</data>
      <data key="d1">method</data>
      <data key="d2">词位置分析是分析词语在文本中位置信息的技术，属于段落级别的自然语言处理方法。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006894</data>
      <data key="d6" />
    </node>
    <node id="主题模型">
      <data key="d0">主题模型</data>
      <data key="d1">method</data>
      <data key="d2">主题模型是一种用于发现文档集合中抽象主题的统计模型，属于篇章级别的自然语言处理应用。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006898</data>
      <data key="d6" />
    </node>
    <node id="文章建模">
      <data key="d0">文章建模</data>
      <data key="d1">method</data>
      <data key="d2">文章建模是对整篇文章进行表示和建模的技术，属于篇章级别的自然语言处理应用。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006898</data>
      <data key="d6" />
    </node>
    <node id="开源工具">
      <data key="d0">开源工具</data>
      <data key="d1">artifact</data>
      <data key="d2">开源工具是公开源代码的软件工具，在自然语言处理中，有很好的中文分词等工具可供使用。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006900</data>
      <data key="d6" />
    </node>
    <node id="商用工具">
      <data key="d0">商用工具</data>
      <data key="d1">artifact</data>
      <data key="d2">商用工具是商业公司提供的软件工具，在自然语言处理中可以达到一定的精度要求。</data>
      <data key="d3">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006900</data>
      <data key="d6" />
    </node>
    <node id="传统机器学习">
      <data key="d0">传统机器学习</data>
      <data key="d1">concept</data>
      <data key="d2">传统机器学习方法需要大量特征工程，定制化程度高，不同领域间模型迁移困难，但某些领域效果很好。&lt;SEP&gt;一种机器学习范式，其90%的时间会花在特征工程上。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006902</data>
      <data key="d6" />
    </node>
    <node id="经典机器学习">
      <data key="d0">经典机器学习</data>
      <data key="d1">concept</data>
      <data key="d2">一种机器学习范式，其90%的时间会花在特征工程上。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006904</data>
      <data key="d6" />
    </node>
    <node id="N元语法模型">
      <data key="d0">N元语法模型</data>
      <data key="d1">method</data>
      <data key="d2">一种用于提取局部文本特征的模型。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006904</data>
      <data key="d6" />
    </node>
    <node id="后处理">
      <data key="d0">后处理</data>
      <data key="d1">concept</data>
      <data key="d2">模型输出后的处理过程，例如根据业务需要将分类结果转换为通过或不通过。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006906</data>
      <data key="d6" />
    </node>
    <node id="文本分类">
      <data key="d0">文本分类</data>
      <data key="d1">concept</data>
      <data key="d2">文本分类是一种深度学习应用，输入一个文本序列后输出其类别，属于多对一问题。&lt;SEP&gt;深度学习的一个应用方向。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006907</data>
      <data key="d6" />
    </node>
    <node id="Word2Vec">
      <data key="d0">Word2Vec</data>
      <data key="d1">method</data>
      <data key="d2">深度学习在NLP领域火起来之前最有代表性的工作，将字或词表示为向量。&lt;SEP&gt;Word2Vec is an advanced word embedding method that represents words as dense vectors in a continuous space to capture semantic relationships.</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007318</data>
      <data key="d6" />
    </node>
    <node id="One-Hot编码">
      <data key="d0">One-Hot编码</data>
      <data key="d1">method</data>
      <data key="d2">一种以词为单位的表示方式，使用稀疏的高维向量，不能有效计算相似度。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006918</data>
      <data key="d6" />
    </node>
    <node id="表示学习">
      <data key="d0">表示学习</data>
      <data key="d1">concept</data>
      <data key="d2">通过Word2Vec等方法学习词的向量表示。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006914</data>
      <data key="d6" />
    </node>
    <node id="Bi-LSTM">
      <data key="d0">Bi-LSTM</data>
      <data key="d1">method</data>
      <data key="d2">Bidirectional LSTM, considered a very good and relatively mature approach for practical or industrial applications, balancing overall effectiveness and complexity.&lt;SEP&gt;一种双向的LSTM，可以学习前后上下文的特征和语义。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006915</data>
      <data key="d6" />
    </node>
    <node id="卷积">
      <data key="d0">卷积</data>
      <data key="d1">concept</data>
      <data key="d2">卷积是一种在图像和文本处理中用于特征提取的数学运算，通过层层过滤选出最佳特征结果。&lt;SEP&gt;CNN中的核心操作，使用过滤器(如九宫格)在输入(如图像或文本)上滑动并进行矩阵相乘以提取特征。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006915</data>
      <data key="d6" />
    </node>
    <node id="过滤器">
      <data key="d0">过滤器</data>
      <data key="d1">artifact</data>
      <data key="d2">卷积操作中使用的模板(如九宫格)，用于与输入数据相乘以提取特征。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006919</data>
      <data key="d6" />
    </node>
    <node id="步长">
      <data key="d0">步长</data>
      <data key="d1">concept</data>
      <data key="d2">卷积操作中过滤器平移的间隔，通常选择一步一步平移。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006919</data>
      <data key="d6" />
    </node>
    <node id="图像识别网络">
      <data key="d0">图像识别网络</data>
      <data key="d1">concept</data>
      <data key="d2">一种应用CNN的网络，网络越深效果越好，通过层层学习浓缩特征。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006920</data>
      <data key="d6" />
    </node>
    <node id="达观杯算法大赛">
      <data key="d0">达观杯算法大赛</data>
      <data key="d1">event</data>
      <data key="d2">达观杯算法大赛是一个比赛，许多参赛者使用传统方法和基线模型，其中基线模型表现较高。&lt;SEP&gt;一个算法比赛，其数据经过了清洗预处理。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006921</data>
      <data key="d6" />
    </node>
    <node id="威海">
      <data key="d0">威海</data>
      <data key="d1">location</data>
      <data key="d2">一个城市，在Word2Vec向量空间中与潍坊、枣庄等城市距离相近。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006924</data>
      <data key="d6" />
    </node>
    <node id="潍坊">
      <data key="d0">潍坊</data>
      <data key="d1">location</data>
      <data key="d2">一个城市，在Word2Vec向量空间中与威海、枣庄等城市距离相近。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006925</data>
      <data key="d6" />
    </node>
    <node id="枣庄">
      <data key="d0">枣庄</data>
      <data key="d1">location</data>
      <data key="d2">一个城市，在Word2Vec向量空间中与威海、潍坊等城市距离相近。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006925</data>
      <data key="d6" />
    </node>
    <node id="山东">
      <data key="d0">山东</data>
      <data key="d1">location</data>
      <data key="d2">一个省份，在语义计算中，山东-威海的关系约等于广东-佛山。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006926</data>
      <data key="d6" />
    </node>
    <node id="广东">
      <data key="d0">广东</data>
      <data key="d1">location</data>
      <data key="d2">一个省份，在语义计算中，广东-佛山的关系约等于山东-威海。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006928</data>
      <data key="d6" />
    </node>
    <node id="佛山">
      <data key="d0">佛山</data>
      <data key="d1">location</data>
      <data key="d2">一个城市，在语义计算中，广东-佛山的关系约等于山东-威海。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006929</data>
      <data key="d6" />
    </node>
    <node id="语义计算">
      <data key="d0">语义计算</data>
      <data key="d1">concept</data>
      <data key="d2">利用Word2Vec等向量表示进行语义关系推断的能力，例如判断山东-威海约等于广东-佛山。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006930</data>
      <data key="d6" />
    </node>
    <node id="泛化能力">
      <data key="d0">泛化能力</data>
      <data key="d1">concept</data>
      <data key="d2">Word2Vec等表示学习方法带来的好处，通过低维稠密向量增强模型的泛化能力。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006930</data>
      <data key="d6" />
    </node>
    <node id="向量相似度">
      <data key="d0">向量相似度</data>
      <data key="d1">concept</data>
      <data key="d2">通过计算向量之间的距离或相似度来判断词或实体之间的语义关系。</data>
      <data key="d3">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006933</data>
      <data key="d6" />
    </node>
    <node id="Deep Pyramid CNN">
      <data key="d0">Deep Pyramid CNN</data>
      <data key="d1">method</data>
      <data key="d2">A deep CNN characterized by a simple structure. It consists of multiple identical blocks (except the first layer), each performing a pooling operation to halve dimensions, followed by two convolutions of equal width, outputting 250 dimensions. Stacking multiple layers allows it to learn accurate semantics.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006935</data>
      <data key="d6" />
    </node>
    <node id="Embedding">
      <data key="d0">Embedding</data>
      <data key="d1">concept</data>
      <data key="d2">A technique used at the word level, involving various embedding methods to transform words into vector representations for input to the next hierarchical level.&lt;SEP&gt;Embedding is the process of converting discrete tokens (like words) into continuous vector representations, serving as the input to the Transformer.&lt;SEP&gt;A process referenced in the TransformerEncoder's forward and call methods where input tokens are converted into vectors, which are then scaled before being combined with positional encoding.&lt;SEP&gt;A numerical representation of a token, which is processed and transformed within the model.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f&lt;SEP&gt;chunk-3ac3b580cca11b5e1d0122810a6ec5f5&lt;SEP&gt;chunk-ad8f11550a8a8807684e7ecc93a2a801&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008153</data>
      <data key="d6" />
    </node>
    <node id="HNN">
      <data key="d0">HNN</data>
      <data key="d1">method</data>
      <data key="d2">A neural network model mentioned alongside Deep Pyramid CNN. Online implementations may differ from the original paper.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006938</data>
      <data key="d6" />
    </node>
    <node id="Sequence Labeling">
      <data key="d0">Sequence Labeling</data>
      <data key="d1">task</data>
      <data key="d2">A task involving two main components: defining a tag system and applying models like CRF or deep learning for prediction.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006939</data>
      <data key="d6" />
    </node>
    <node id="BMES">
      <data key="d0">BMES</data>
      <data key="d1">method</data>
      <data key="d2">A classic and commonly used tag system for sequence labeling, representing Begin, Middle, End, and Single character tags.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006941</data>
      <data key="d6" />
    </node>
    <node id="IO">
      <data key="d0">IO</data>
      <data key="d1">method</data>
      <data key="d2">A simpler tag system for sequence labeling.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006942</data>
      <data key="d6" />
    </node>
    <node id="BIO">
      <data key="d0">BIO</data>
      <data key="d1">method</data>
      <data key="d2">A more complex tag system for sequence labeling.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006943</data>
      <data key="d6" />
    </node>
    <node id="CRF">
      <data key="d0">CRF</data>
      <data key="d1">method</data>
      <data key="d2">Conditional Random Fields, a traditional model that performs well for sequence labeling tasks.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006944</data>
      <data key="d6" />
    </node>
    <node id="Char-Level Embedding">
      <data key="d0">Char-Level Embedding</data>
      <data key="d1">method</data>
      <data key="d2">In the context of an English model, character-level information is processed using RNN or CNN to create embeddings, learning relationships at the character level.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006946</data>
      <data key="d6" />
    </node>
    <node id="Word-Level Embedding">
      <data key="d0">Word-Level Embedding</data>
      <data key="d1">method</data>
      <data key="d2">Word vector representations (e.g., red-colored word vectors) that are concatenated with other features in the model.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006947</data>
      <data key="d6" />
    </node>
    <node id="Manual Features">
      <data key="d0">Manual Features</data>
      <data key="d1">data</data>
      <data key="d2">Handcrafted features (represented as gray-colored vectors) that can be added to the model based on individual design choices.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006949</data>
      <data key="d6" />
    </node>
    <node id="Generative Summarization">
      <data key="d0">Generative Summarization</data>
      <data key="d1">task</data>
      <data key="d2">A difficult task where the training set requires human-written summaries for articles, making annotation more challenging than tasks like word segmentation or classification.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006949</data>
      <data key="d6" />
    </node>
    <node id="BLEU">
      <data key="d0">BLEU</data>
      <data key="d1">method</data>
      <data key="d2">An evaluation metric used for tasks like text summarization.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006959</data>
      <data key="d6" />
    </node>
    <node id="Extractive Summarization">
      <data key="d0">Extractive Summarization</data>
      <data key="d1">task</data>
      <data key="d2">A method more commonly used in industry, which involves identifying and extracting the most important sentences from an article.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006952</data>
      <data key="d6" />
    </node>
    <node id="Beam Search">
      <data key="d0">Beam Search</data>
      <data key="d1">method</data>
      <data key="d2">A search algorithm used during decoding to find the best output sequence, such as in generative headline creation.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006955</data>
      <data key="d6" />
    </node>
    <node id="Text Classification">
      <data key="d0">Text Classification</data>
      <data key="d1">task</data>
      <data key="d2">A task where models like HNN and Deep Pyramid CNN, which are "many to one" architectures, are widely used.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006964</data>
      <data key="d6" />
    </node>
    <node id="Text Mining">
      <data key="d0">Text Mining</data>
      <data key="d1">task</data>
      <data key="d2">The overarching field involving the extraction of knowledge from text, encompassing tasks like classification, sequence labeling, and summarization.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006964</data>
      <data key="d6" />
    </node>
    <node id="Max-Pooling">
      <data key="d0">Max-Pooling</data>
      <data key="d1">method</data>
      <data key="d2">Max-pooling is an operation used in convolutional neural networks to select the maximum feature from each feature map as the final output.&lt;SEP&gt;A technique used in the CNN model to extract the largest feature from each feature map as the final output.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f&lt;SEP&gt;chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006958</data>
      <data key="d6" />
    </node>
    <node id="Block N">
      <data key="d0">Block N</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the repeated, identical structural blocks (except the first) that constitute the Deep Pyramid CNN architecture.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006960</data>
      <data key="d6" />
    </node>
    <node id="Word Level">
      <data key="d0">Word Level</data>
      <data key="d1">concept</data>
      <data key="d2">A hierarchical level in text processing where operations like Embedding and Attention are applied to individual words.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006962</data>
      <data key="d6" />
    </node>
    <node id="Sentence Level">
      <data key="d0">Sentence Level</data>
      <data key="d1">concept</data>
      <data key="d2">A hierarchical level in text processing that follows the word level, where Attention is used to identify important sentences.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006964</data>
      <data key="d6" />
    </node>
    <node id="Semantic Level">
      <data key="d0">Semantic Level</data>
      <data key="d1">concept</data>
      <data key="d2">A level of understanding where the Deep Pyramid CNN model can identify which semantics contribute most to classification, indicated by color intensity.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006965</data>
      <data key="d6" />
    </node>
    <node id="Label System">
      <data key="d0">Label System</data>
      <data key="d1">concept</data>
      <data key="d2">The first component of sequence labeling, involving the definition of a tagging scheme such as BMES, IO, or BIO.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006967</data>
      <data key="d6" />
    </node>
    <node id="Context">
      <data key="d0">Context</data>
      <data key="d1">concept</data>
      <data key="d2">Information from surrounding text that models like LSTM and Bi-LSTM are designed to capture, which is crucial for tasks like sequence labeling.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006967</data>
      <data key="d6" />
    </node>
    <node id="Sequence Dependency">
      <data key="d0">Sequence Dependency</data>
      <data key="d1">concept</data>
      <data key="d2">The relationship between output labels in sequence labeling, which pure Bi-LSTM models lack but is handled by combining Bi-LSTM with CRF.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006969</data>
      <data key="d6" />
    </node>
    <node id="News Headline Generation">
      <data key="d0">News Headline Generation</data>
      <data key="d1">task</data>
      <data key="d2">A specific application of generative text models, using the first paragraph of a news article as input to generate a title, sharing the core idea of generative summarization.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006970</data>
      <data key="d6" />
    </node>
    <node id="News Website">
      <data key="d0">News Website</data>
      <data key="d1">organization</data>
      <data key="d2">A source from which news articles and their first paragraphs can be crawled for training generative models like headline generators.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006979</data>
      <data key="d6" />
    </node>
    <node id="Decoding">
      <data key="d0">Decoding</data>
      <data key="d1">task</data>
      <data key="d2">The process in generative models where the output sequence (e.g., a headline) is produced, often utilizing mechanisms like Attention and search algorithms like beam search.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006980</data>
      <data key="d6" />
    </node>
    <node id="Plaintiff Lawyer">
      <data key="d0">Plaintiff Lawyer</data>
      <data key="d1">concept</data>
      <data key="d2">An example entity type mentioned in the context of a semantic extraction challenge, where identifying "原告" (plaintiff) from long-range context is necessary to correctly classify a "lawyer".</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006981</data>
      <data key="d6" />
    </node>
    <node id="Defendant Lawyer">
      <data key="d0">Defendant Lawyer</data>
      <data key="d1">concept</data>
      <data key="d2">An example entity type mentioned in the context of a semantic extraction challenge.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006982</data>
      <data key="d6" />
    </node>
    <node id="Plaintiff Liu Dehua">
      <data key="d0">Plaintiff Liu Dehua</data>
      <data key="d1">person</data>
      <data key="d2">An example name ("刘德华") used in a scenario to illustrate the need for capturing long-range context to determine that a mentioned "lawyer" is associated with the plaintiff.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006984</data>
      <data key="d6" />
    </node>
    <node id="Entrusted Lawyer Zhang Xueyou">
      <data key="d0">Entrusted Lawyer Zhang Xueyou</data>
      <data key="d1">person</data>
      <data key="d2">An example name ("张学友") used in a scenario to illustrate the challenge of determining a lawyer's role (e.g., plaintiff's lawyer) without sufficient context.</data>
      <data key="d3">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006986</data>
      <data key="d6" />
    </node>
    <node id="细胞状态">
      <data key="d0">细胞状态</data>
      <data key="d1">concept</data>
      <data key="d2">细胞状态是长短期记忆网络中用于存储长期信息的一种状态，通常称为“cell”。</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006988</data>
      <data key="d6" />
    </node>
    <node id="图像描述">
      <data key="d0">图像描述</data>
      <data key="d1">method</data>
      <data key="d2">图像描述是一种深度学习应用，输入一张图像后输出对该图像内容的文字描述，属于一对多问题。</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006991</data>
      <data key="d6" />
    </node>
    <node id="序列标注">
      <data key="d0">序列标注</data>
      <data key="d1">method</data>
      <data key="d2">序列标注是一种深度学习应用，属于同步的多对多序列到序列问题，常见于自然语言处理任务。</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006991</data>
      <data key="d6" />
    </node>
    <node id="单层CNN">
      <data key="d0">单层CNN</data>
      <data key="d1">method</data>
      <data key="d2">单层卷积神经网络是一种结构简单的深度学习模型，使用几种卷积类型生成特征图并通过最大池化输出特征。</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006994</data>
      <data key="d6" />
    </node>
    <node id="Deep Pyramin CNN">
      <data key="d0">Deep Pyramin CNN</data>
      <data key="d1">method</data>
      <data key="d2">深度金字塔卷积神经网络是一种深度卷积网络，其结构特点尚在描述中。</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006993</data>
      <data key="d6" />
    </node>
    <node id="Ht-1">
      <data key="d0">Ht-1</data>
      <data key="d1">concept</data>
      <data key="d2">Ht-1 is the hidden state output from the previous time step in a recurrent neural network cell.</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006993</data>
      <data key="d6" />
    </node>
    <node id="Xt">
      <data key="d0">Xt</data>
      <data key="d1">concept</data>
      <data key="d2">Xt is the current input at time step t in a recurrent neural network.</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006989</data>
      <data key="d6" />
    </node>
    <node id="Ct-1">
      <data key="d0">Ct-1</data>
      <data key="d1">concept</data>
      <data key="d2">Ct-1 is the cell state from the previous time step in a long short-term memory network.</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006991</data>
      <data key="d6" />
    </node>
    <node id="Ct">
      <data key="d0">Ct</data>
      <data key="d1">concept</data>
      <data key="d2">Ct is the updated cell state in a long short-term memory network, calculated by combining retained old information and new information.</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006991</data>
      <data key="d6" />
    </node>
    <node id="Ht">
      <data key="d0">Ht</data>
      <data key="d1">concept</data>
      <data key="d2">Ht is the hidden layer output at time step t, which is externally visible and similar to RNN output but involves an internal update process.</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006991</data>
      <data key="d6" />
    </node>
    <node id="Baseline">
      <data key="d0">Baseline</data>
      <data key="d1">concept</data>
      <data key="d2">Baseline refers to a basic reference model used in the "达观杯" algorithm competition, which performed well without special optimization.</data>
      <data key="d3">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769006991</data>
      <data key="d6" />
    </node>
    <node id="Stemming">
      <data key="d0">Stemming</data>
      <data key="d1">method</data>
      <data key="d2">Stemming is a text preprocessing technique that reduces words to their root form, such as converting "running" to "run," to group different forms of the same word.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007311</data>
      <data key="d6" />
    </node>
    <node id="Text Cleaning">
      <data key="d0">Text Cleaning</data>
      <data key="d1">method</data>
      <data key="d2">Text cleaning is a preprocessing step that removes unwanted elements like punctuation, special characters, and numbers to prevent confusion in analysis.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007311</data>
      <data key="d6" />
    </node>
    <node id="Feature Extraction">
      <data key="d0">Feature Extraction</data>
      <data key="d1">method</data>
      <data key="d2">Feature extraction is the process of converting raw text into numerical representations that machines can analyze, using techniques like Bag of Words and TF-IDF.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007315</data>
      <data key="d6" />
    </node>
    <node id="Bag Of Words">
      <data key="d0">Bag Of Words</data>
      <data key="d1">method</data>
      <data key="d2">Bag of Words is an NLP technique for feature extraction that quantifies the presence of words in a document.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007315</data>
      <data key="d6" />
    </node>
    <node id="Tf-Idf">
      <data key="d0">Tf-Idf</data>
      <data key="d1">method</data>
      <data key="d2">TF-IDF is an NLP technique for feature extraction that quantifies the importance of words in a document.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007316</data>
      <data key="d6" />
    </node>
    <node id="Glove">
      <data key="d0">Glove</data>
      <data key="d1">method</data>
      <data key="d2">GloVe is an advanced word embedding method that represents words as dense vectors in a continuous space to capture semantic relationships.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007318</data>
      <data key="d6" />
    </node>
    <node id="Contextual Embeddings">
      <data key="d0">Contextual Embeddings</data>
      <data key="d1">method</data>
      <data key="d2">Contextual embeddings enhance word representations by considering the context in which words appear, enabling richer and more nuanced meaning capture.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007319</data>
      <data key="d6" />
    </node>
    <node id="Text Analysis">
      <data key="d0">Text Analysis</data>
      <data key="d1">concept</data>
      <data key="d2">Text analysis involves interpreting and extracting meaningful information from text data using various computational techniques.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007322</data>
      <data key="d6" />
    </node>
    <node id="Part-Of-Speech Tagging">
      <data key="d0">Part-Of-Speech Tagging</data>
      <data key="d1">method</data>
      <data key="d2">Part-of-speech (POS) tagging is a text analysis task that identifies the grammatical role of words in a sentence.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007322</data>
      <data key="d6" />
    </node>
    <node id="Named Entity Recognition">
      <data key="d0">Named Entity Recognition</data>
      <data key="d1">method</data>
      <data key="d2">Named Entity Recognition (NER) is a text analysis task that detects specific entities such as names, locations, and dates in text.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007324</data>
      <data key="d6" />
    </node>
    <node id="Dependency Parsing">
      <data key="d0">Dependency Parsing</data>
      <data key="d1">method</data>
      <data key="d2">Dependency parsing is a text analysis task that analyzes grammatical relationships between words to understand sentence structure.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007324</data>
      <data key="d6" />
    </node>
    <node id="Sentiment Analysis">
      <data key="d0">Sentiment Analysis</data>
      <data key="d1">method</data>
      <data key="d2">Sentiment analysis is a text analysis task that determines the emotional tone of text, assessing whether it is positive, negative, or neutral.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007324</data>
      <data key="d6" />
    </node>
    <node id="Topic Modeling">
      <data key="d0">Topic Modeling</data>
      <data key="d1">method</data>
      <data key="d2">Topic modeling is a text analysis technique used to identify latent topics or themes within a text or a corpus of documents.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007327</data>
      <data key="d6" />
    </node>
    <node id="Natural Language Understanding">
      <data key="d0">Natural Language Understanding</data>
      <data key="d1">concept</data>
      <data key="d2">Natural Language Understanding (NLU) is a subset of NLP focused on analyzing the meaning behind sentences, enabling software to find similar meanings across different sentences.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007329</data>
      <data key="d6" />
    </node>
    <node id="Natural Language Toolkit">
      <data key="d0">Natural Language Toolkit</data>
      <data key="d1">artifact</data>
      <data key="d2">Natural Language Toolkit (NLTK) is a suite of libraries and programs written in Python for English, supporting tasks like text classification, tokenization, stemming, tagging, parsing, and semantic reasoning.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007329</data>
      <data key="d6" />
    </node>
    <node id="Tensorflow">
      <data key="d0">Tensorflow</data>
      <data key="d1">artifact</data>
      <data key="d2">TensorFlow is a free, open-source software library for machine learning and AI, used for training models for NLP applications.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007330</data>
      <data key="d6" />
    </node>
    <node id="Nlp Models">
      <data key="d0">Nlp Models</data>
      <data key="d1">concept</data>
      <data key="d2">NLP models are advanced AI systems designed to process and understand human language, though they are not perfect and face challenges like ambiguity.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007331</data>
      <data key="d6" />
    </node>
    <node id="Human Language">
      <data key="d0">Human Language</data>
      <data key="d1">concept</data>
      <data key="d2">Human language is complex and full of ambiguity, making it difficult for programmers to teach software to accurately determine intended meaning.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007332</data>
      <data key="d6" />
    </node>
    <node id="Ibm Granite">
      <data key="d0">Ibm Granite</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM® Granite is a series of open, high-performance, trustworthy AI models tailored for enterprises and optimized to help scale AI applications.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007335</data>
      <data key="d6" />
    </node>
    <node id="Ibm Embedded Ai">
      <data key="d0">Ibm Embedded Ai</data>
      <data key="d1">concept</data>
      <data key="d2">IBM Embedded AI refers to AI capabilities integrated into applications to enhance their functionality.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007335</data>
      <data key="d6" />
    </node>
    <node id="Healthcare Industry">
      <data key="d0">Healthcare Industry</data>
      <data key="d1">organization</data>
      <data key="d2">The healthcare industry can use NLP-based tools to analyze health records and medical research papers for better decision-making and disease detection.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007337</data>
      <data key="d6" />
    </node>
    <node id="Insurance Industry">
      <data key="d0">Insurance Industry</data>
      <data key="d1">organization</data>
      <data key="d2">The insurance industry can use NLP to analyze claims, identify patterns, and discover inefficiencies in claims processing.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007338</data>
      <data key="d6" />
    </node>
    <node id="Ibm">
      <data key="d0">Ibm</data>
      <data key="d1">organization</data>
      <data key="d2">IBM is the company that developed the Granite AI model series and conducted a survey of 2,000 organizations regarding their AI initiatives.</data>
      <data key="d3">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007341</data>
      <data key="d6" />
    </node>
    <node id="统计建模">
      <data key="d0">统计建模</data>
      <data key="d1">method</data>
      <data key="d2">统计建模是使用统计方法对数据进行建模和分析，与机器学习结合用于自然语言处理。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007347</data>
      <data key="d6" />
    </node>
    <node id="大型语言模型">
      <data key="d0">大型语言模型</data>
      <data key="d1">method</data>
      <data key="d2">大型语言模型是基于大量文本数据训练的语言模型，具有强大的交流技巧。&lt;SEP&gt;Large Language Models are a type of AI technology mentioned as part of the widespread application of AI that challenges philosophical research practices.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010970</data>
      <data key="d6" />
    </node>
    <node id="图像生成模型">
      <data key="d0">图像生成模型</data>
      <data key="d1">artifact</data>
      <data key="d2">图像生成模型是能够根据请求生成图像的人工智能模型。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007354</data>
      <data key="d6" />
    </node>
    <node id="搜索引擎">
      <data key="d0">搜索引擎</data>
      <data key="d1">artifact</data>
      <data key="d2">搜索引擎是用于在互联网上查找信息的工具，自然语言处理为其提供支持。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007356</data>
      <data key="d6" />
    </node>
    <node id="聊天机器人">
      <data key="d0">聊天机器人</data>
      <data key="d1">artifact</data>
      <data key="d2">聊天机器人是能够与用户进行对话的软件程序，例如Amazon的Alexa、Apple的Siri和Microsoft的Cortana。&lt;SEP&gt;A chatbot is an example of an application that can be implemented using LLMs to provide 24/7 customer support.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009009</data>
      <data key="d6" />
    </node>
    <node id="Amazon Alexa">
      <data key="d0">Amazon Alexa</data>
      <data key="d1">artifact</data>
      <data key="d2">Amazon Alexa是亚马逊开发的语音助手，是一个聊天机器人的例子。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007365</data>
      <data key="d6" />
    </node>
    <node id="Apple Siri">
      <data key="d0">Apple Siri</data>
      <data key="d1">artifact</data>
      <data key="d2">Apple Siri是苹果公司开发的语音助手，是一个聊天机器人的例子。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007366</data>
      <data key="d6" />
    </node>
    <node id="Microsoft Cortana">
      <data key="d0">Microsoft Cortana</data>
      <data key="d1">artifact</data>
      <data key="d2">Microsoft Cortana是微软开发的语音助手，是一个聊天机器人的例子。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007368</data>
      <data key="d6" />
    </node>
    <node id="客户支持">
      <data key="d0">客户支持</data>
      <data key="d1">concept</data>
      <data key="d2">客户支持是企业为客户提供的帮助服务，自然语言处理可以自动化部分任务。&lt;SEP&gt;Customer support is a language-related task that LLMs can help supplement or fully undertake, potentially automating it.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008990</data>
      <data key="d6" />
    </node>
    <node id="数据输入">
      <data key="d0">数据输入</data>
      <data key="d1">concept</data>
      <data key="d2">数据输入是将信息录入系统的过程，自然语言处理可以部分自动化此过程。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007370</data>
      <data key="d6" />
    </node>
    <node id="文档处理">
      <data key="d0">文档处理</data>
      <data key="d1">concept</data>
      <data key="d2">文档处理是处理和分析文档的任务，自然语言处理工具可以自动分类、提取信息和汇总内容。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007373</data>
      <data key="d6" />
    </node>
    <node id="语言翻译">
      <data key="d0">语言翻译</data>
      <data key="d1">concept</data>
      <data key="d2">语言翻译是将文本从一种语言转换为另一种语言的过程，自然语言处理有助于此过程。&lt;SEP&gt;Language translation is a capability of LLMs that can facilitate cross-cultural communication.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009012</data>
      <data key="d6" />
    </node>
    <node id="意图理解">
      <data key="d0">意图理解</data>
      <data key="d1">concept</data>
      <data key="d2">意图理解是系统理解用户查询背后意图的能力，由自然语言处理提供支持。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007375</data>
      <data key="d6" />
    </node>
    <node id="GPT-4">
      <data key="d0">GPT-4</data>
      <data key="d1">artifact</data>
      <data key="d2">GPT-4是一个预训练的大型语言模型，能够根据提示生成类人文本。&lt;SEP&gt;A closed-source Large Language Model noted for its outstanding performance by the end of 2024.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008749</data>
      <data key="d6" />
    </node>
    <node id="句法分析">
      <data key="d0">句法分析</data>
      <data key="d1">method</data>
      <data key="d2">句法分析是通过解析语法来确定单词、短语或句子结构含义的分析方法。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007378</data>
      <data key="d6" />
    </node>
    <node id="语义分析">
      <data key="d0">语义分析</data>
      <data key="d1">method</data>
      <data key="d2">语义分析是从单词和句子结构中提取和解释含义的分析方法。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007373</data>
      <data key="d6" />
    </node>
    <node id="基于规则的NLP">
      <data key="d0">基于规则的NLP</data>
      <data key="d1">method</data>
      <data key="d2">基于规则的NLP是使用预先编程的语法规则来处理语言的方法。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007374</data>
      <data key="d6" />
    </node>
    <node id="统计NLP">
      <data key="d0">统计NLP</data>
      <data key="d1">method</data>
      <data key="d2">统计NLP是使用机器学习自动提取、分类和标记文本元素并分配统计可能性的方法。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007377</data>
      <data key="d6" />
    </node>
    <node id="词性标注">
      <data key="d0">词性标注</data>
      <data key="d1">method</data>
      <data key="d2">词性标注是为文本中的单词标注其词性(如名词、动词)的任务。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007377</data>
      <data key="d6" />
    </node>
    <node id="文本预处理">
      <data key="d0">文本预处理</data>
      <data key="d1">method</data>
      <data key="d2">文本预处理是将原始文本转换为机器更容易理解的格式的过程，包括标记化、小写转换等步骤。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007380</data>
      <data key="d6" />
    </node>
    <node id="标记化">
      <data key="d0">标记化</data>
      <data key="d1">method</data>
      <data key="d2">标记化是将文本拆分为更小单位(如单词、句子)的过程。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007380</data>
      <data key="d6" />
    </node>
    <node id="停用词删除">
      <data key="d0">停用词删除</data>
      <data key="d1">method</data>
      <data key="d2">停用词删除是过滤掉文本中常见但含义不重要的词(如“is”、“the”)的步骤。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007382</data>
      <data key="d6" />
    </node>
    <node id="词干提取">
      <data key="d0">词干提取</data>
      <data key="d1">method</data>
      <data key="d2">词干提取是将单词简化为其词根形式的过程。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007383</data>
      <data key="d6" />
    </node>
    <node id="词形还原">
      <data key="d0">词形还原</data>
      <data key="d1">method</data>
      <data key="d2">词形还原是将单词还原为其词典原形的过程。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007383</data>
      <data key="d6" />
    </node>
    <node id="Bag of Words">
      <data key="d0">Bag of Words</data>
      <data key="d1">method</data>
      <data key="d2">Bag of Words是一种将文本表示为单词出现频率的特征提取技术。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007394</data>
      <data key="d6" />
    </node>
    <node id="Apple">
      <data key="d0">Apple</data>
      <data key="d1">organization</data>
      <data key="d2">Apple is a technology company that developed the Siri voice assistant.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007391</data>
      <data key="d6" />
    </node>
    <node id="Microsoft">
      <data key="d0">Microsoft</data>
      <data key="d1">organization</data>
      <data key="d2">Microsoft is a technology company that developed the Cortana voice assistant.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007399</data>
      <data key="d6" />
    </node>
    <node id="语音命令">
      <data key="d0">语音命令</data>
      <data key="d1">concept</data>
      <data key="d2">语音命令是用户通过语音发出的指令，自然语言处理系统可以响应此类命令。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007393</data>
      <data key="d6" />
    </node>
    <node id="语音操作的GPS系统">
      <data key="d0">语音操作的GPS系统</data>
      <data key="d1">artifact</data>
      <data key="d2">语音操作的GPS系统是可以通过语音命令进行操作的导航设备。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007393</data>
      <data key="d6" />
    </node>
    <node id="问题解答数字助理">
      <data key="d0">问题解答数字助理</data>
      <data key="d1">artifact</data>
      <data key="d2">问题解答数字助理是智能手机上能够回答用户问题的软件助手。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007396</data>
      <data key="d6" />
    </node>
    <node id="数据">
      <data key="d0">数据</data>
      <data key="d1">data</data>
      <data key="d2">数据是信息的表现形式，自然语言处理用于分析和处理非结构化文本数据。&lt;SEP&gt;数据是AI模型发展离不开的支持，通过对大量数据的分析和学习，AI模型能够不断提升自身的性能和准确性。&lt;SEP&gt;人工智能系统处理、分析和解释以模拟人类智能行为的信息集合。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008433</data>
      <data key="d6" />
    </node>
    <node id="非结构化文本数据">
      <data key="d0">非结构化文本数据</data>
      <data key="d1">data</data>
      <data key="d2">非结构化文本数据是没有预定义格式的文本信息，如客户评论和社交媒体帖子。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007398</data>
      <data key="d6" />
    </node>
    <node id="客户评论">
      <data key="d0">客户评论</data>
      <data key="d1">content</data>
      <data key="d2">客户评论是用户对产品或服务的评价文本，是自然语言处理分析的数据来源之一。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007400</data>
      <data key="d6" />
    </node>
    <node id="社交媒体帖子">
      <data key="d0">社交媒体帖子</data>
      <data key="d1">content</data>
      <data key="d2">社交媒体帖子是在社交平台上发布的内容，是自然语言处理分析的数据来源之一。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007400</data>
      <data key="d6" />
    </node>
    <node id="新闻文章">
      <data key="d0">新闻文章</data>
      <data key="d1">content</data>
      <data key="d2">新闻文章是媒体报道的文本内容，是自然语言处理分析的数据来源之一。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007402</data>
      <data key="d6" />
    </node>
    <node id="模式">
      <data key="d0">模式</data>
      <data key="d1">concept</data>
      <data key="d2">模式是数据中重复出现的规律或结构，自然语言处理可以发现文本中的模式。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007402</data>
      <data key="d6" />
    </node>
    <node id="趋势">
      <data key="d0">趋势</data>
      <data key="d1">concept</data>
      <data key="d2">趋势是数据随时间变化的方向，自然语言处理可以从文本中识别趋势。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007402</data>
      <data key="d6" />
    </node>
    <node id="态度">
      <data key="d0">态度</data>
      <data key="d1">concept</data>
      <data key="d2">态度是个人对某事物的看法或立场，情感分析可以提取文本中的态度信息。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007404</data>
      <data key="d6" />
    </node>
    <node id="情感">
      <data key="d0">情感</data>
      <data key="d1">concept</data>
      <data key="d2">情感是个人体验的感觉或情绪，情感分析可以提取文本中的情感信息。&lt;SEP&gt;Emotion is mentioned by Wei Benqun as an aspect of human uniqueness that needs to be re-understood in the era of AI.</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011020</data>
      <data key="d6" />
    </node>
    <node id="讽刺">
      <data key="d0">讽刺</data>
      <data key="d1">concept</data>
      <data key="d2">讽刺是一种表达方式，情感分析可以识别文本中的讽刺。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007407</data>
      <data key="d6" />
    </node>
    <node id="困惑">
      <data key="d0">困惑</data>
      <data key="d1">concept</data>
      <data key="d2">困惑是一种心理状态，情感分析可以识别文本中表达的困惑。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007408</data>
      <data key="d6" />
    </node>
    <node id="怀疑">
      <data key="d0">怀疑</data>
      <data key="d1">concept</data>
      <data key="d2">怀疑是一种不确定或不相信的态度，情感分析可以识别文本中的怀疑。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007409</data>
      <data key="d6" />
    </node>
    <node id="通信路由">
      <data key="d0">通信路由</data>
      <data key="d1">concept</data>
      <data key="d2">通信路由是将信息或请求引导到适当系统或人员的过程。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007410</data>
      <data key="d6" />
    </node>
    <node id="用户查询">
      <data key="d0">用户查询</data>
      <data key="d1">data</data>
      <data key="d2">用户查询是用户向系统提出的问题或请求。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007411</data>
      <data key="d6" />
    </node>
    <node id="上下文">
      <data key="d0">上下文</data>
      <data key="d1">concept</data>
      <data key="d2">上下文是语言使用时的背景信息，自然语言处理用于理解查询的上下文。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007413</data>
      <data key="d6" />
    </node>
    <node id="关键字匹配">
      <data key="d0">关键字匹配</data>
      <data key="d1">method</data>
      <data key="d2">关键字匹配是搜索引擎中根据单词精确匹配查找信息的方法。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007413</data>
      <data key="d6" />
    </node>
    <node id="网络搜索">
      <data key="d0">网络搜索</data>
      <data key="d1">concept</data>
      <data key="d2">网络搜索是在互联网上查找信息的行为，自然语言处理可以改善其体验。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007414</data>
      <data key="d6" />
    </node>
    <node id="文档检索">
      <data key="d0">文档检索</data>
      <data key="d1">concept</data>
      <data key="d2">文档检索是从集合中查找相关文档的过程，自然语言处理可以改善其体验。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007417</data>
      <data key="d6" />
    </node>
    <node id="企业数据系统">
      <data key="d0">企业数据系统</data>
      <data key="d1">artifact</data>
      <data key="d2">企业数据系统是组织内用于存储和管理数据的软件系统。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007417</data>
      <data key="d6" />
    </node>
    <node id="报告">
      <data key="d0">报告</data>
      <data key="d1">content</data>
      <data key="d2">报告是正式的文件，GPT-4等模型可以生成报告。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007419</data>
      <data key="d6" />
    </node>
    <node id="营销文案">
      <data key="d0">营销文案</data>
      <data key="d1">content</data>
      <data key="d2">营销文案是用于推广产品或服务的文本，GPT-4等模型可以生成营销文案。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007419</data>
      <data key="d6" />
    </node>
    <node id="产品描述">
      <data key="d0">产品描述</data>
      <data key="d1">content</data>
      <data key="d2">产品描述是介绍产品特性的文本，GPT-4等模型可以生成产品描述。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007421</data>
      <data key="d6" />
    </node>
    <node id="创意写作内容">
      <data key="d0">创意写作内容</data>
      <data key="d1">content</data>
      <data key="d2">创意写作内容是具有艺术性的文本，GPT-4等模型可以生成创意写作内容。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007422</data>
      <data key="d6" />
    </node>
    <node id="电子邮件">
      <data key="d0">电子邮件</data>
      <data key="d1">content</data>
      <data key="d2">电子邮件是电子通信消息，自然语言处理工具可以协助起草电子邮件。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007423</data>
      <data key="d6" />
    </node>
    <node id="法律文书">
      <data key="d0">法律文书</data>
      <data key="d1">content</data>
      <data key="d2">法律文书是正式的法律文件，自然语言处理工具可以协助法律文书协作。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007426</data>
      <data key="d6" />
    </node>
    <node id="语气">
      <data key="d0">语气</data>
      <data key="d1">concept</data>
      <data key="d2">语气是文本表达的态度或风格，自然语言处理可以理解文本的语气。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007434</data>
      <data key="d6" />
    </node>
    <node id="风格">
      <data key="d0">风格</data>
      <data key="d1">concept</data>
      <data key="d2">风格是文本的独特表达方式，自然语言处理可以理解文本的风格。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007428</data>
      <data key="d6" />
    </node>
    <node id="连贯性">
      <data key="d0">连贯性</data>
      <data key="d1">concept</data>
      <data key="d2">连贯性是文本各部分逻辑连接的程度，自然语言处理确保生成内容的连贯性。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007428</data>
      <data key="d6" />
    </node>
    <node id="相关性">
      <data key="d0">相关性</data>
      <data key="d1">concept</data>
      <data key="d2">相关性是内容与主题或上下文的关联程度，自然语言处理确保生成内容的相关性。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007429</data>
      <data key="d6" />
    </node>
    <node id="数据科学">
      <data key="d0">数据科学</data>
      <data key="d1">concept</data>
      <data key="d2">数据科学是使用科学方法从数据中提取知识的领域，计算语言学利用数据科学分析语言。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007432</data>
      <data key="d6" />
    </node>
    <node id="语法规则">
      <data key="d0">语法规则</data>
      <data key="d1">concept</data>
      <data key="d2">语法规则是语言中单词组合成句子的规则，基于规则的NLP使用预先编程的语法规则。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007432</data>
      <data key="d6" />
    </node>
    <node id="小写转换">
      <data key="d0">小写转换</data>
      <data key="d1">method</data>
      <data key="d2">小写转换是将文本中所有字符转换为小写的标准化步骤。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007434</data>
      <data key="d6" />
    </node>
    <node id="文本清理">
      <data key="d0">文本清理</data>
      <data key="d1">method</data>
      <data key="d2">文本清理是删除标点符号、特殊字符和数字等不需要元素的步骤。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007435</data>
      <data key="d6" />
    </node>
    <node id="标点符号">
      <data key="d0">标点符号</data>
      <data key="d1">data</data>
      <data key="d2">标点符号是书写中使用的符号，在文本清理中可能被删除。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007437</data>
      <data key="d6" />
    </node>
    <node id="特殊字符">
      <data key="d0">特殊字符</data>
      <data key="d1">data</data>
      <data key="d2">特殊字符是非字母数字的符号，在文本清理中可能被删除。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007437</data>
      <data key="d6" />
    </node>
    <node id="数字">
      <data key="d0">数字</data>
      <data key="d1">data</data>
      <data key="d2">数字是数值字符，在文本清理中可能被删除。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007439</data>
      <data key="d6" />
    </node>
    <node id="数字表示">
      <data key="d0">数字表示</data>
      <data key="d1">data</data>
      <data key="d2">数字表示是文本经过特征提取后转换成的数值形式。</data>
      <data key="d3">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007439</data>
      <data key="d6" />
    </node>
    <node id="Encoder Block">
      <data key="d0">Encoder Block</data>
      <data key="d1">artifact</data>
      <data key="d2">Encoder Block is a component of the Transformer model, composed of Multi-Head Attention, Add &amp; Norm, and Feed Forward layers, processing input matrices.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007651</data>
      <data key="d6" />
    </node>
    <node id="Decoder Block">
      <data key="d0">Decoder Block</data>
      <data key="d1">artifact</data>
      <data key="d2">Decoder Block is a component of the Transformer model, containing two Multi-Head Attention layers (one with Masked attention) and processes sequences autoregressively.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007651</data>
      <data key="d6" />
    </node>
    <node id="Multi-Head Attention">
      <data key="d0">Multi-Head Attention</data>
      <data key="d1">method</data>
      <data key="d2">Multi-Head Attention is a mechanism within the Transformer, consisting of multiple Self-Attention heads, used to compute attention across different representation subspaces.&lt;SEP&gt;A technique used in transformer models where the attention mechanism is applied multiple times in parallel, allowing the model to jointly attend to information from different representation subspaces.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008139</data>
      <data key="d6" />
    </node>
    <node id="Self-Attention">
      <data key="d0">Self-Attention</data>
      <data key="d1">method</data>
      <data key="d2">Self-Attention is a core attention mechanism where elements of a sequence attend to all other elements in the same sequence to compute a weighted representation.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007655</data>
      <data key="d6" />
    </node>
    <node id="Add &amp; Norm Layer">
      <data key="d0">Add &amp; Norm Layer</data>
      <data key="d1">method</data>
      <data key="d2">Add &amp; Norm Layer combines a Residual Connection to prevent network degradation and Layer Normalization to normalize activation values in each layer.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007656</data>
      <data key="d6" />
    </node>
    <node id="Residual Connection">
      <data key="d0">Residual Connection</data>
      <data key="d1">method</data>
      <data key="d2">Residual Connection is a technique used in neural networks, represented by the 'Add' operation, to mitigate the vanishing gradient problem by adding the input of a layer to its output.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007657</data>
      <data key="d6" />
    </node>
    <node id="Layer Normalization">
      <data key="d0">Layer Normalization</data>
      <data key="d1">method</data>
      <data key="d2">Layer Normalization is a normalization technique, represented by the 'Norm' operation, applied to the activations of a layer to stabilize training.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007659</data>
      <data key="d6" />
    </node>
    <node id="Masked Multi-Head Attention">
      <data key="d0">Masked Multi-Head Attention</data>
      <data key="d1">method</data>
      <data key="d2">Masked Multi-Head Attention is a variant of Multi-Head Attention used in the Decoder block to prevent positions from attending to subsequent positions, ensuring autoregressive property.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007661</data>
      <data key="d6" />
    </node>
    <node id="Position Encoding">
      <data key="d0">Position Encoding</data>
      <data key="d1">method</data>
      <data key="d2">Position Encoding is a method to inject information about the position of tokens in a sequence into the model, as the Transformer itself has no inherent notion of order.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007663</data>
      <data key="d6" />
    </node>
    <node id="Linear Layer">
      <data key="d0">Linear Layer</data>
      <data key="d1">concept</data>
      <data key="d2">Linear Layer is a fully connected layer used in the Transformer to project the concatenated outputs from multiple attention heads into the final output dimension.&lt;SEP&gt;A neural network layer where each parallel subset has a unique weight matrix learned during pre-training.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008153</data>
      <data key="d6" />
    </node>
    <node id="Attention Mechanism">
      <data key="d0">Attention Mechanism</data>
      <data key="d1">concept</data>
      <data key="d2">Attention Mechanism is the core concept in Transformer models, allowing the model to focus on different parts of the input sequence when producing an output.&lt;SEP&gt;Attention mechanism is a technique that can be referenced for understanding Transformer models.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5&lt;SEP&gt;chunk-778f83860f7db1907e0da6e0cb412723</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007740</data>
      <data key="d6" />
    </node>
    <node id="Cross-Attention">
      <data key="d0">Cross-Attention</data>
      <data key="d1">method</data>
      <data key="d2">Cross-Attention is an attention mechanism in the Decoder block where queries come from the decoder's previous layer, and keys and values come from the Encoder's output.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007675</data>
      <data key="d6" />
    </node>
    <node id="Mask Matrix">
      <data key="d0">Mask Matrix</data>
      <data key="d1">artifact</data>
      <data key="d2">A Mask Matrix is a square matrix used in the Decoder's Masked Multi-Head Attention to prevent positions from attending to future positions, ensuring autoregressive generation.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007670</data>
      <data key="d6" />
    </node>
    <node id="Input Matrix X">
      <data key="d0">Input Matrix X</data>
      <data key="d1">data</data>
      <data key="d2">Input Matrix X is the initial numerical representation of the input sequence, with dimensions n×d, where n is the sequence length and d is the feature dimension.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007672</data>
      <data key="d6" />
    </node>
    <node id="Output Matrix O">
      <data key="d0">Output Matrix O</data>
      <data key="d1">data</data>
      <data key="d2">Output Matrix O is the final output of an Encoder block, with dimensions n×d, representing the processed features of the input sequence.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007673</data>
      <data key="d6" />
    </node>
    <node id="Output Matrices Z1 to Z8">
      <data key="d0">Output Matrices Z1 to Z8</data>
      <data key="d1">data</data>
      <data key="d2">Output Matrices Z1 to Z8 are the individual outputs from the multiple heads in a Multi-Head Attention mechanism before concatenation.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007675</data>
      <data key="d6" />
    </node>
    <node id="Final Output Z">
      <data key="d0">Final Output Z</data>
      <data key="d1">data</data>
      <data key="d2">Final Output Z is the result produced by the Multi-Head Attention layer after concatenating the outputs from multiple heads and passing them through a Linear layer.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007675</data>
      <data key="d6" />
    </node>
    <node id="Query (Q)">
      <data key="d0">Query (Q)</data>
      <data key="d1">data</data>
      <data key="d2">Query (Q) is a vector representation used in attention mechanisms, calculated from the Decoder's previous output or the input matrix, to retrieve information from keys.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007685</data>
      <data key="d6" />
    </node>
    <node id="Key (K)">
      <data key="d0">Key (K)</data>
      <data key="d1">data</data>
      <data key="d2">Key (K) is a vector representation used in attention mechanisms, calculated from the Encoder's output, to be matched against queries.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007678</data>
      <data key="d6" />
    </node>
    <node id="Value (V)">
      <data key="d0">Value (V)</data>
      <data key="d1">data</data>
      <data key="d2">Value (V) is a vector representation used in attention mechanisms, calculated from the Encoder's output, to produce the weighted sum output based on attention scores.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007680</data>
      <data key="d6" />
    </node>
    <node id="Concat (Concatenation)">
      <data key="d0">Concat (Concatenation)</data>
      <data key="d1">method</data>
      <data key="d2">Concat is the operation of combining the output matrices from multiple attention heads along the feature dimension before the final linear projection.</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007681</data>
      <data key="d6" />
    </node>
    <node id="Concat">
      <data key="d0">Concat</data>
      <data key="d3">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d2">Multi-Head Attention employs the Concat operation to combine the outputs from its multiple attention heads.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007713</data>
      <data key="d6" />
    </node>
    <node id="Self-Attention Mechanism">
      <data key="d0">Self-Attention Mechanism</data>
      <data key="d1">method</data>
      <data key="d2">Self-attention mechanism is the core component upon which the Transformer model is completely built.&lt;SEP&gt;The core functionality of the transformer model, enabling it to detect relationships or dependencies between different parts of an input sequence.</data>
      <data key="d3">chunk-778f83860f7db1907e0da6e0cb412723&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008136</data>
      <data key="d6" />
    </node>
    <node id="Article">
      <data key="d0">Article</data>
      <data key="d1">content</data>
      <data key="d2">An article that can be referenced for understanding the attention mechanism.</data>
      <data key="d3">chunk-778f83860f7db1907e0da6e0cb412723</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007735</data>
      <data key="d6" />
    </node>
    <node id="Transformer模型">
      <data key="d0">Transformer模型</data>
      <data key="d1">concept</data>
      <data key="d2">Transformer模型是本节课学习的核心内容，是一种用于处理序列数据的深度学习模型架构。</data>
      <data key="d3">chunk-e77bf0e5ecd6a42625cc947b20dfaca8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007754</data>
      <data key="d6" />
    </node>
    <node id="自注意力">
      <data key="d0">自注意力</data>
      <data key="d1">concept</data>
      <data key="d2">自注意力是Transformer模型的两个核心机制之一，是模型理解序列内部关系的关键组成部分。</data>
      <data key="d3">chunk-e77bf0e5ecd6a42625cc947b20dfaca8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007754</data>
      <data key="d6" />
    </node>
    <node id="多头注意力">
      <data key="d0">多头注意力</data>
      <data key="d1">concept</data>
      <data key="d2">多头注意力是Transformer模型的两个核心机制之一，是注意力机制的一种扩展形式，允许模型同时关注来自不同表示子空间的信息。</data>
      <data key="d3">chunk-e77bf0e5ecd6a42625cc947b20dfaca8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007755</data>
      <data key="d6" />
    </node>
    <node id="Input Sequence">
      <data key="d0">Input Sequence</data>
      <data key="d1">content</data>
      <data key="d2">The input sequence is the data that the Transformer architecture processes and transforms, such as the example "sky".</data>
      <data key="d3">chunk-f11a177649a52b5177411e9ce9bb9885</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007769</data>
      <data key="d6" />
    </node>
    <node id="Transformer Encoder Block">
      <data key="d0">Transformer Encoder Block</data>
      <data key="d1">artifact</data>
      <data key="d2">A component of a Transformer encoder, defined with parameters such as key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, and dropout.</data>
      <data key="d3">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007817</data>
      <data key="d6" />
    </node>
    <node id="Transformer Encoder">
      <data key="d0">Transformer Encoder</data>
      <data key="d1">artifact</data>
      <data key="d2">The encoder component of a Transformer model, initialized with vocabulary size and architectural parameters, and composed of multiple EncoderBlock layers. It processes input X and valid lengths using positional encoding.</data>
      <data key="d3">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007817</data>
      <data key="d6" />
    </node>
    <node id="EncoderBlock">
      <data key="d0">EncoderBlock</data>
      <data key="d1">artifact</data>
      <data key="d2">A building block used within the TransformerEncoder, containing mechanisms for attention and feed-forward processing, defined with parameters such as key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, and dropout.</data>
      <data key="d3">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007818</data>
      <data key="d6" />
    </node>
    <node id="Positional Encoding">
      <data key="d0">Positional Encoding</data>
      <data key="d1">method</data>
      <data key="d2">A technique used in Transformer models where embedding values are scaled by the square root of the embedding dimension and then added to positional encodings that range between -1 and 1.&lt;SEP&gt;A technique where a value vector is added to a token's embedding based on its relative position before it enters the attention mechanism, helping the model learn to pay more attention to nearby tokens.</data>
      <data key="d3">chunk-ad8f11550a8a8807684e7ecc93a2a801&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008141</data>
      <data key="d6" />
    </node>
    <node id="Forward Method">
      <data key="d0">Forward Method</data>
      <data key="d1">method</data>
      <data key="d2">A function defining the forward pass of a neural network module, such as in the TransformerEncoder, which processes input X and valid lengths.</data>
      <data key="d3">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007821</data>
      <data key="d6" />
    </node>
    <node id="Call Method">
      <data key="d0">Call Method</data>
      <data key="d1">method</data>
      <data key="d2">A function defining the call operation for a layer, as used in one variant of the TransformerEncoder to process input X and valid lengths.</data>
      <data key="d3">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007822</data>
      <data key="d6" />
    </node>
    <node id="Valid Lengths">
      <data key="d0">Valid Lengths</data>
      <data key="d1">data</data>
      <data key="d2">A parameter (valid_lens) passed to the forward and call methods of the TransformerEncoder and its blocks, used to handle variable sequence lengths, likely for masking.</data>
      <data key="d3">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007822</data>
      <data key="d6" />
    </node>
    <node id="Transformer (Deep Learning)">
      <data key="d0">Transformer (Deep Learning)</data>
      <data key="d1">concept</data>
      <data key="d2">A deep learning model architecture, referenced in English and Simple English Wikipedia entries.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007925</data>
      <data key="d6" />
    </node>
    <node id="Transformer (Machine Learning Model)">
      <data key="d0">Transformer (Machine Learning Model)</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning model architecture, referenced in a Simple English Wikipedia entry.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007925</data>
      <data key="d6" />
    </node>
    <node id="Transformator (Model Mašinskog Učenja)">
      <data key="d0">Transformator (Model Mašinskog Učenja)</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning model architecture, referenced in a Serbian language Wikipedia entry.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007926</data>
      <data key="d6" />
    </node>
    <node id="Supervised Learning">
      <data key="d0">Supervised Learning</data>
      <data key="d1">method</data>
      <data key="d2">A machine learning paradigm where models are trained on labeled data.&lt;SEP&gt;A machine learning paradigm where models are trained on labeled data.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009207</data>
      <data key="d6" />
    </node>
    <node id="Unsupervised Learning">
      <data key="d0">Unsupervised Learning</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning paradigm where models find patterns in unlabeled data.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007928</data>
      <data key="d6" />
    </node>
    <node id="Online Machine Learning">
      <data key="d0">Online Machine Learning</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning paradigm where models are updated continuously as new data arrives.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007929</data>
      <data key="d6" />
    </node>
    <node id="Meta-Learning (Computer Science)">
      <data key="d0">Meta-Learning (Computer Science)</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning paradigm focused on learning how to learn, referenced in an English Wikipedia entry.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007931</data>
      <data key="d6" />
    </node>
    <node id="Semi-Supervised Learning">
      <data key="d0">Semi-Supervised Learning</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning paradigm that uses a combination of labeled and unlabeled data.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007932</data>
      <data key="d6" />
    </node>
    <node id="Self-Supervised Learning">
      <data key="d0">Self-Supervised Learning</data>
      <data key="d1">method</data>
      <data key="d2">A machine learning paradigm where models generate their own supervisory signal from the data.&lt;SEP&gt;A learning paradigm where models generate their own labels from the data.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009208</data>
      <data key="d6" />
    </node>
    <node id="Rule-Based Machine Learning">
      <data key="d0">Rule-Based Machine Learning</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning paradigm based on learning or refining a set of rules.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007935</data>
      <data key="d6" />
    </node>
    <node id="Quantum Machine Learning">
      <data key="d0">Quantum Machine Learning</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning paradigm that utilizes quantum computing principles.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007938</data>
      <data key="d6" />
    </node>
    <node id="Active Learning (Machine Learning)">
      <data key="d0">Active Learning (Machine Learning)</data>
      <data key="d1">concept</data>
      <data key="d2">A machine learning paradigm where the algorithm can query a user to label new data points, referenced in an English Wikipedia entry.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007938</data>
      <data key="d6" />
    </node>
    <node id="Crowdsourcing">
      <data key="d0">Crowdsourcing</data>
      <data key="d1">concept</data>
      <data key="d2">A method of obtaining services, ideas, or content by soliciting contributions from a large group of people.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007938</data>
      <data key="d6" />
    </node>
    <node id="Human-In-The-Loop">
      <data key="d0">Human-In-The-Loop</data>
      <data key="d1">concept</data>
      <data key="d2">A paradigm in machine learning where human expertise is integrated into the model training or decision-making process.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007940</data>
      <data key="d6" />
    </node>
    <node id="Learning Curve (Machine Learning)">
      <data key="d0">Learning Curve (Machine Learning)</data>
      <data key="d1">concept</data>
      <data key="d2">A diagnostic tool in machine learning that plots model performance against experience, referenced in an English Wikipedia entry.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007941</data>
      <data key="d6" />
    </node>
    <node id="Machine Learning (Journal)">
      <data key="d0">Machine Learning (Journal)</data>
      <data key="d1">content</data>
      <data key="d2">An academic journal focused on machine learning research, referenced in an English Wikipedia entry.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007948</data>
      <data key="d6" />
    </node>
    <node id="Lili Chen">
      <data key="d0">Lili Chen</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007951</data>
      <data key="d6" />
    </node>
    <node id="Kevin Lu">
      <data key="d0">Kevin Lu</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007954</data>
      <data key="d6" />
    </node>
    <node id="Aravind Rajeswaran">
      <data key="d0">Aravind Rajeswaran</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007955</data>
      <data key="d6" />
    </node>
    <node id="Kimin Lee">
      <data key="d0">Kimin Lee</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007955</data>
      <data key="d6" />
    </node>
    <node id="Aditya Grover">
      <data key="d0">Aditya Grover</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007956</data>
      <data key="d6" />
    </node>
    <node id="Michael Laskin">
      <data key="d0">Michael Laskin</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007957</data>
      <data key="d6" />
    </node>
    <node id="Pieter Abbeel">
      <data key="d0">Pieter Abbeel</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007958</data>
      <data key="d6" />
    </node>
    <node id="Aravind Srinivas">
      <data key="d0">Aravind Srinivas</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007959</data>
      <data key="d6" />
    </node>
    <node id="Igor Mordatch">
      <data key="d0">Igor Mordatch</data>
      <data key="d1">person</data>
      <data key="d2">A researcher and co-author of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007959</data>
      <data key="d6" />
    </node>
    <node id="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d0">Decision Transformer: Reinforcement Learning via Sequence Modeling</data>
      <data key="d1">content</data>
      <data key="d2">A research paper authored by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch, published on arXiv in 2021.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007970</data>
      <data key="d6" />
    </node>
    <node id="arXiv">
      <data key="d0">arXiv</data>
      <data key="d1">organization</data>
      <data key="d2">An open-access repository for electronic preprints of scientific papers.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007964</data>
      <data key="d6" />
    </node>
    <node id="Paradigm">
      <data key="d0">Paradigm</data>
      <data key="d1">concept</data>
      <data key="d2">A fundamental style or approach to machine learning, such as supervised or unsupervised learning.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007965</data>
      <data key="d6" />
    </node>
    <node id="Model Diagnostics">
      <data key="d0">Model Diagnostics</data>
      <data key="d1">concept</data>
      <data key="d2">The process of evaluating and understanding the performance and behavior of machine learning models.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007965</data>
      <data key="d6" />
    </node>
    <node id="Conferences And Publications">
      <data key="d0">Conferences And Publications</data>
      <data key="d1">concept</data>
      <data key="d2">A category encompassing major academic events and journals in the field of machine learning.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007966</data>
      <data key="d6" />
    </node>
    <node id="arXiv:2106.01345">
      <data key="d0">arXiv:2106.01345</data>
      <data key="d1">data</data>
      <data key="d2">The unique identifier for the preprint of the paper "Decision Transformer: Reinforcement Learning via Sequence Modeling" on the arXiv server.</data>
      <data key="d3">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769007970</data>
      <data key="d6" />
    </node>
    <node id="Hugging Face">
      <data key="d0">Hugging Face</data>
      <data key="d1">organization</data>
      <data key="d2">Hugging Face is the organization that developed the Transformers package.</data>
      <data key="d3">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008016</data>
      <data key="d6" />
    </node>
    <node id="NLP">
      <data key="d0">NLP</data>
      <data key="d1">concept</data>
      <data key="d2">NLP (Natural Language Processing) is the field of study that the Transformers package supports.&lt;SEP&gt;Natural Language Processing, a field with which transformer models are commonly associated.&lt;SEP&gt;自然语言处理的缩写，是人工智能领域处理人类语言技术的统称。</data>
      <data key="d3">chunk-07c6d2ca0b23fef78261afa6105b1fe0&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008418</data>
      <data key="d6" />
    </node>
    <node id="GPT">
      <data key="d0">GPT</data>
      <data key="d1">method</data>
      <data key="d2">GPT is a large-scale language model whose rise has increased adoption of the Transformers library.&lt;SEP&gt;一种大型语言模型，在大量文本数据集上训练得到，具备理解和生成人类语言的能力，并能演变为进行多模态通信、推理、规划以及解决问题的综合性系统。&lt;SEP&gt;GPT是大语言模型的一种具体实现。&lt;SEP&gt;A common example of a Large Language Model.&lt;SEP&gt;A language model known as Generative Pre-trained Transformer.</data>
      <data key="d3">chunk-07c6d2ca0b23fef78261afa6105b1fe0&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-4f9864ecff092ef091c227f6ebb2d69f&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009186</data>
      <data key="d6" />
    </node>
    <node id="Transformers Library">
      <data key="d0">Transformers Library</data>
      <data key="d1">artifact</data>
      <data key="d2">The Transformers library is adopted by many companies and researchers following the rise of large language models.</data>
      <data key="d3">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008019</data>
      <data key="d6" />
    </node>
    <node id="Companies">
      <data key="d0">Companies</data>
      <data key="d1">organization</data>
      <data key="d2">Companies are adopting the Transformers library.</data>
      <data key="d3">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008021</data>
      <data key="d6" />
    </node>
    <node id="Researchers">
      <data key="d0">Researchers</data>
      <data key="d1">person</data>
      <data key="d2">Researchers are adopting the Transformers library.</data>
      <data key="d3">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008022</data>
      <data key="d6" />
    </node>
    <node id="Transformer Model">
      <data key="d0">Transformer Model</data>
      <data key="d1">concept</data>
      <data key="d2">A neural network architecture adept at processing sequential data, known for its association with large language models (LLMs) and its application in fields like computer vision, speech recognition, and time series prediction.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008132</data>
      <data key="d6" />
    </node>
    <node id="Large Language Model (LLM)">
      <data key="d0">Large Language Model (LLM)</data>
      <data key="d1">concept</data>
      <data key="d2">A type of AI model, often based on the transformer architecture, that is pre-trained on vast amounts of text data and can generate human-like text.&lt;SEP&gt;A Large Language Model (LLM) is trained on extensive text data using neural networks to generate text, translate, or perform other tasks, with performance improving with more data.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686&lt;SEP&gt;chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009406</data>
      <data key="d6" />
    </node>
    <node id="GPT-3">
      <data key="d0">GPT-3</data>
      <data key="d1">artifact</data>
      <data key="d2">A generative pre-trained transformer model developed by OpenAI, which catalyzed the modern era of generative AI and powered the release of ChatGPT.&lt;SEP&gt;GPT-3 is a specific large language model developed by OpenAI, known for its powerful text generation capabilities.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008482</data>
      <data key="d6" />
    </node>
    <node id="Token">
      <data key="d0">Token</data>
      <data key="d1">concept</data>
      <data key="d2">The smallest linguistic unit used by AI models, assigned an ID number, which facilitates efficient text processing by reducing computational requirements.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008138</data>
      <data key="d6" />
    </node>
    <node id="Tokenization">
      <data key="d0">Tokenization</data>
      <data key="d1">method</data>
      <data key="d2">The process of converting text into tokens, which significantly lowers the computational power required for processing text.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008138</data>
      <data key="d6" />
    </node>
    <node id="Query, Key, Value Vectors">
      <data key="d0">Query, Key, Value Vectors</data>
      <data key="d1">concept</data>
      <data key="d2">Three new vectors (Q, K, V) generated from the original token embedding by passing it through three parallel feedforward neural network layers, each with a unique weight matrix.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008141</data>
      <data key="d6" />
    </node>
    <node id="Attention Head">
      <data key="d0">Attention Head</data>
      <data key="d1">concept</data>
      <data key="d2">A component within an attention layer that processes a subset of the input embedding, consisting of parallel query, key, and value heads.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008143</data>
      <data key="d6" />
    </node>
    <node id="Machine Translation">
      <data key="d0">Machine Translation</data>
      <data key="d1">concept</data>
      <data key="d2">An initial use case for which the transformer architecture was developed.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008144</data>
      <data key="d6" />
    </node>
    <node id="OpenAI">
      <data key="d0">OpenAI</data>
      <data key="d1">organization</data>
      <data key="d2">The organization that developed the GPT series of models, including GPT-3.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008137</data>
      <data key="d6" />
    </node>
    <node id="Anthropic">
      <data key="d0">Anthropic</data>
      <data key="d1">organization</data>
      <data key="d2">The organization that developed the Claude model, a closed-source large language model.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008139</data>
      <data key="d6" />
    </node>
    <node id="Meta Llama">
      <data key="d0">Meta Llama</data>
      <data key="d1">artifact</data>
      <data key="d2">An open-source large language model.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008140</data>
      <data key="d6" />
    </node>
    <node id="ChatGPT">
      <data key="d0">ChatGPT</data>
      <data key="d1">artifact</data>
      <data key="d2">An AI chatbot released by OpenAI, powered by models like GPT-3.&lt;SEP&gt;ChatGPT是一个大语言模型的应用实例，用于智能客服和对话生成。&lt;SEP&gt;ChatGPT is an AI chatbot application based on a large language model, capable of conversational interactions.&lt;SEP&gt;ChatGPT is a popular AI application whose success brought widespread attention to large language models.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008457</data>
      <data key="d6" />
    </node>
    <node id="Claude">
      <data key="d0">Claude</data>
      <data key="d1">artifact</data>
      <data key="d2">A closed-source large language model developed by Anthropic.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008143</data>
      <data key="d6" />
    </node>
    <node id="Senior Staff Writer, AI Models">
      <data key="d0">Senior Staff Writer, AI Models</data>
      <data key="d1">person</data>
      <data key="d2">The author of the article, identified by their professional title.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008146</data>
      <data key="d6" />
    </node>
    <node id="Weight Matrix WQ">
      <data key="d0">Weight Matrix WQ</data>
      <data key="d1">concept</data>
      <data key="d2">A unique weight matrix used to generate the query vector (Q) from a token embedding.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008148</data>
      <data key="d6" />
    </node>
    <node id="Weight Matrix WK">
      <data key="d0">Weight Matrix WK</data>
      <data key="d1">concept</data>
      <data key="d2">A unique weight matrix used to generate the key vector (K) from a token embedding.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008149</data>
      <data key="d6" />
    </node>
    <node id="Weight Matrix WV">
      <data key="d0">Weight Matrix WV</data>
      <data key="d1">concept</data>
      <data key="d2">A unique weight matrix used to generate the value vector (V) from a token embedding.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008150</data>
      <data key="d6" />
    </node>
    <node id="Feedforward Neural Network Layer">
      <data key="d0">Feedforward Neural Network Layer</data>
      <data key="d1">concept</data>
      <data key="d2">A standard layer type used in the transformer architecture alongside attention layers.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008153</data>
      <data key="d6" />
    </node>
    <node id="Autoregressive Decoder-Only LLM">
      <data key="d0">Autoregressive Decoder-Only LLM</data>
      <data key="d1">concept</data>
      <data key="d2">A specific type of large language model architecture, exemplified by models like GPT-3 and Claude.</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008157</data>
      <data key="d6" />
    </node>
    <node id="IBM Watsonx.Ai">
      <data key="d0">IBM Watsonx.Ai</data>
      <data key="d1">artifact</data>
      <data key="d2">IBM Watsonx.Ai is an enterprise-grade development platform for AI builders, enabling the training, validation, tuning, and deployment of generative AI, foundation models, and machine learning capabilities.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008158</data>
      <data key="d6" />
    </node>
    <node id="Generative Ai">
      <data key="d0">Generative Ai</data>
      <data key="d1">concept</data>
      <data key="d2">Generative AI is a type of artificial intelligence capable of creating new content, solutions, and value, requiring investment and carrying associated risks.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008158</data>
      <data key="d6" />
    </node>
    <node id="Ai Investment">
      <data key="d0">Ai Investment</data>
      <data key="d1">concept</data>
      <data key="d2">AI Investment refers to the financial and resource allocation into artificial intelligence initiatives, with the goal of achieving a return on investment (ROI).</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008161</data>
      <data key="d6" />
    </node>
    <node id="Ceos">
      <data key="d0">Ceos</data>
      <data key="d1">person</data>
      <data key="d2">CEOs are chief executive officers who need to balance the value created by generative AI with the required investments and associated risks.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008164</data>
      <data key="d6" />
    </node>
    <node id="Ai Builders">
      <data key="d0">Ai Builders</data>
      <data key="d1">person</data>
      <data key="d2">AI Builders are individuals who construct and deliver innovative new solutions using AI technologies.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008165</data>
      <data key="d6" />
    </node>
    <node id="Survey Of 2,000 Organizations">
      <data key="d0">Survey Of 2,000 Organizations</data>
      <data key="d1">data</data>
      <data key="d2">A survey conducted on 2,000 organizations to understand their AI plans, identify effective and ineffective methods, and determine how to gain a lead.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008165</data>
      <data key="d6" />
    </node>
    <node id="Ai Development Lifecycle">
      <data key="d0">Ai Development Lifecycle</data>
      <data key="d1">concept</data>
      <data key="d2">The AI development lifecycle encompasses all stages from conception to deployment of AI solutions, accessible through a unified platform.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008169</data>
      <data key="d6" />
    </node>
    <node id="User-Friendly Interface">
      <data key="d0">User-Friendly Interface</data>
      <data key="d1">artifact</data>
      <data key="d2">A user-friendly interface is part of a development platform that simplifies the process of building AI solutions.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008170</data>
      <data key="d6" />
    </node>
    <node id="Industry Standard Apis And Sdks">
      <data key="d0">Industry Standard Apis And Sdks</data>
      <data key="d1">artifact</data>
      <data key="d2">Industry standard APIs and SDKs are tools provided by a platform to enable the creation of powerful AI solutions.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008170</data>
      <data key="d6" />
    </node>
    <node id="Report 2024 On Ai Practical Applications">
      <data key="d0">Report 2024 On Ai Practical Applications</data>
      <data key="d1">content</data>
      <data key="d2">A report detailing the practical applications of AI in 2024, based on a survey of organizations.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008173</data>
      <data key="d6" />
    </node>
    <node id="Ebook On Unlocking Generative Ai And Ml">
      <data key="d0">Ebook On Unlocking Generative Ai And Ml</data>
      <data key="d1">content</data>
      <data key="d2">An ebook focused on unlocking the powerful capabilities of generative AI and machine learning.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008175</data>
      <data key="d6" />
    </node>
    <node id="Guide For Ceos On Generative Ai">
      <data key="d0">Guide For Ceos On Generative Ai</data>
      <data key="d1">content</data>
      <data key="d2">A guide designed for CEOs to understand how to balance the value, investment, and risks of generative AI.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008176</data>
      <data key="d6" />
    </node>
    <node id="Guide On Maximizing Ai Roi">
      <data key="d0">Guide On Maximizing Ai Roi</data>
      <data key="d1">content</data>
      <data key="d2">A guide on making AI work effectively, focusing on using generative AI to improve return on investment.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008176</data>
      <data key="d6" />
    </node>
    <node id="Key Workflows And Operations">
      <data key="d0">Key Workflows And Operations</data>
      <data key="d1">concept</data>
      <data key="d2">Critical business processes and operations that can be transformed by AI to enhance experience, decision-making, and value.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008176</data>
      <data key="d6" />
    </node>
    <node id="Real-Time Decision-Making">
      <data key="d0">Real-Time Decision-Making</data>
      <data key="d1">concept</data>
      <data key="d2">The capability to make decisions instantly, which can be maximized through AI-powered workflow transformation.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008186</data>
      <data key="d6" />
    </node>
    <node id="Commercial Value">
      <data key="d0">Commercial Value</data>
      <data key="d1">concept</data>
      <data key="d2">The economic worth or benefit generated for a business, which AI aims to maximize.</data>
      <data key="d3">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008179</data>
      <data key="d6" />
    </node>
    <node id="Query Vector">
      <data key="d0">Query Vector</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d2">The weight matrix WQ is multiplied by the embedding value to calculate the query vector (Q).</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008211</data>
      <data key="d6" />
    </node>
    <node id="Key Vector">
      <data key="d0">Key Vector</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d2">The weight matrix WK is multiplied by the embedding value to calculate the key vector (K).</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008212</data>
      <data key="d6" />
    </node>
    <node id="Value Vector">
      <data key="d0">Value Vector</data>
      <data key="d3">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d2">The weight matrix WV is multiplied by the embedding value to calculate the value vector (V).</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008212</data>
      <data key="d6" />
    </node>
    <node id="Hung-yi Lee">
      <data key="d0">Hung-yi Lee</data>
      <data key="d1">person</data>
      <data key="d2">Hung-yi Lee is a professor who created and presented the lecture "【機器學習2021】Transformer (上)".</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008273</data>
      <data key="d6" />
    </node>
    <node id="Machine Learning 2021">
      <data key="d0">Machine Learning 2021</data>
      <data key="d1">content</data>
      <data key="d2">"Machine Learning 2021" is the name of a course for which the lecture on Transformer was presented.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008273</data>
      <data key="d6" />
    </node>
    <node id="Lecture Slides">
      <data key="d0">Lecture Slides</data>
      <data key="d1">artifact</data>
      <data key="d2">The lecture slides are a PDF document containing the presentation material for the Transformer lecture, hosted at a specific URL.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008278</data>
      <data key="d6" />
    </node>
    <node id="YouTube Channel">
      <data key="d0">YouTube Channel</data>
      <data key="d1">organization</data>
      <data key="d2">The YouTube channel belongs to Hung-yi Lee and has 354,000 subscribers, where the lecture video was published.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008278</data>
      <data key="d6" />
    </node>
    <node id="Lecture Video">
      <data key="d0">Lecture Video</data>
      <data key="d1">content</data>
      <data key="d2">The lecture video titled "【機器學習2021】Transformer (上)" was published on March 26, 2021, and has 283,126 views.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008279</data>
      <data key="d6" />
    </node>
    <node id="354000 Subscribers">
      <data key="d0">354000 Subscribers</data>
      <data key="d1">data</data>
      <data key="d2">354000 Subscribers is a numerical metric indicating the subscriber count of Hung-yi Lee's YouTube channel.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008280</data>
      <data key="d6" />
    </node>
    <node id="2878 Likes">
      <data key="d0">2878 Likes</data>
      <data key="d1">data</data>
      <data key="d2">2878 Likes is a numerical metric indicating the number of likes received by the lecture video.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008281</data>
      <data key="d6" />
    </node>
    <node id="283126 Views">
      <data key="d0">283126 Views</data>
      <data key="d1">data</data>
      <data key="d2">283126 Views is a numerical metric indicating the view count of the lecture video.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008283</data>
      <data key="d6" />
    </node>
    <node id="26 Mar 2021">
      <data key="d0">26 Mar 2021</data>
      <data key="d1">event</data>
      <data key="d2">26 Mar 2021 is the publication date of the lecture video on YouTube.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008284</data>
      <data key="d6" />
    </node>
    <node id="125 Comments">
      <data key="d0">125 Comments</data>
      <data key="d1">data</data>
      <data key="d2">125 Comments is a numerical metric indicating the number of comments on the lecture video.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008284</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-6db04701">
      <data key="d0">DOC_ID: chunk-6db04701</data>
      <data key="d1">data</data>
      <data key="d2">DOC_ID: chunk-6db04701 is a unique identifier for the document chunk being processed.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008286</data>
      <data key="d6" />
    </node>
    <node id="Linguistics">
      <data key="d0">Linguistics</data>
      <data key="d1">concept</data>
      <data key="d2">Linguistics is the domain or field of study mentioned in the document metadata.</data>
      <data key="d3">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008286</data>
      <data key="d6" />
    </node>
    <node id="大语言模型">
      <data key="d0">大语言模型</data>
      <data key="d1">concept</data>
      <data key="d2">大语言模型是基于Transformer架构、参数规模极大的神经网络语言模型，通过在海量文本数据上进行预训练来理解和生成自然语言，是人工智能领域的一个重要分支。&lt;SEP&gt;基于Transformer架构、参数规模极大的神经网络语言模型，通过在海量文本数据上进行预训练来理解和生成自然语言，是驱动智能化从“辅助工具”向“自主系统”演进的核心支柱之一。&lt;SEP&gt;大语言模型是深度学习技术的杰出应用之一，专为处理和生成自然语言文本而设计，通常包含庞大的参数规模，能够深刻理解和生成复杂语言结构。&lt;SEP&gt;一种由包含数百亿以上权重的深度神经网络构建的语言模型。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771&lt;SEP&gt;chunk-3678971988880bb3960a90e15878444d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008629</data>
      <data key="d6" />
    </node>
    <node id="智能体">
      <data key="d0">智能体</data>
      <data key="d1">concept</data>
      <data key="d2">与工作流、大语言模型并列为驱动智能化从“辅助工具”向“自主系统”演进的三个核心支柱之一，具备更广泛的认知与执行能力。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008407</data>
      <data key="d6" />
    </node>
    <node id="工作流">
      <data key="d0">工作流</data>
      <data key="d1">concept</data>
      <data key="d2">与智能体、大语言模型并列为驱动智能化从“辅助工具”向“自主系统”演进的三个核心支柱之一。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008410</data>
      <data key="d6" />
    </node>
    <node id="Transformer架构">
      <data key="d0">Transformer架构</data>
      <data key="d1">method</data>
      <data key="d2">Transformer架构是大语言模型所基于的神经网络架构，用于处理序列数据，特别是在理解和生成自然语言方面表现出色。&lt;SEP&gt;大语言模型所基于的神经网络架构。&lt;SEP&gt;Transformer architecture involves millions or billions of parameters, enabling it to capture complex language patterns and nuances.</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008974</data>
      <data key="d6" />
    </node>
    <node id="预训练">
      <data key="d0">预训练</data>
      <data key="d1">method</data>
      <data key="d2">大语言模型在海量文本数据上进行训练以理解语言的过程。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008421</data>
      <data key="d6" />
    </node>
    <node id="AIGC">
      <data key="d0">AIGC</data>
      <data key="d1">concept</data>
      <data key="d2">人工智能生成内容，是基于大模型技术演进的重要应用方向。&lt;SEP&gt;AIGC涉及到的领域和技术很广泛，其中自然语言处理是一项很重要的技术。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008417</data>
      <data key="d6" />
    </node>
    <node id="LLM">
      <data key="d0">LLM</data>
      <data key="d1">concept</data>
      <data key="d2">{"entities": ["大型语言模型", "人工智能", "GPT", "智能体", "工作流", "检索增强生成", "机器学习模型"]}</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771&lt;SEP&gt;chunk-3678971988880bb3960a90e15878444d&lt;SEP&gt;chunk-0222ac86b3d60100ac5d03d88a69654e&lt;SEP&gt;chunk-4d514ef014c3cb4cb7fc652928e9a4a4&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008974</data>
      <data key="d6" />
    </node>
    <node id="Agent">
      <data key="d0">Agent</data>
      <data key="d1">concept</data>
      <data key="d2">An Agent in AI refers to an entity that perceives its environment and takes actions to achieve goals, often involving learning and planning.&lt;SEP&gt;智能体的英文表述，与工作流、大语言模型并列为驱动智能化从“辅助工具”向“自主系统”演进的三个核心支柱之一。&lt;SEP&gt;Agent是人工智能领域的一个概念。&lt;SEP&gt;A development paradigm for large model applications, mentioned as part of a learning path and the subject of an article.</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009309</data>
      <data key="d6" />
    </node>
    <node id="Workflow">
      <data key="d0">Workflow</data>
      <data key="d1">concept</data>
      <data key="d2">工作流的英文表述，与智能体、大语言模型并列为驱动智能化从“辅助工具”向“自主系统”演进的三个核心支柱之一。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008427</data>
      <data key="d6" />
    </node>
    <node id="狭义AI">
      <data key="d0">狭义AI</data>
      <data key="d1">concept</data>
      <data key="d2">执行特定任务的人工智能发展范式。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008427</data>
      <data key="d6" />
    </node>
    <node id="通用AI">
      <data key="d0">通用AI</data>
      <data key="d1">concept</data>
      <data key="d2">具备更广泛认知与执行能力的人工智能发展范式。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008428</data>
      <data key="d6" />
    </node>
    <node id="具身人工智能">
      <data key="d0">具身人工智能</data>
      <data key="d1">concept</data>
      <data key="d2">大型语言模型对其发展具有推动作用和挑战的研究领域。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008434</data>
      <data key="d6" />
    </node>
    <node id="多模态通信">
      <data key="d0">多模态通信</data>
      <data key="d1">method</data>
      <data key="d2">大型语言模型如GPT演变后能够进行的综合性能力之一。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008438</data>
      <data key="d6" />
    </node>
    <node id="推理">
      <data key="d0">推理</data>
      <data key="d1">method</data>
      <data key="d2">大型语言模型如GPT演变后能够进行的综合性能力之一。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008439</data>
      <data key="d6" />
    </node>
    <node id="规划">
      <data key="d0">规划</data>
      <data key="d1">method</data>
      <data key="d2">大型语言模型如GPT演变后能够进行的综合性能力之一。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008441</data>
      <data key="d6" />
    </node>
    <node id="自然语言理解">
      <data key="d0">自然语言理解</data>
      <data key="d1">concept</data>
      <data key="d2">自然语言处理的一个组成部分，涉及计算机理解人类语言。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008443</data>
      <data key="d6" />
    </node>
    <node id="自然语言生成">
      <data key="d0">自然语言生成</data>
      <data key="d1">concept</data>
      <data key="d2">自然语言处理的一个组成部分，涉及计算机生成人类语言。</data>
      <data key="d3">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008444</data>
      <data key="d6" />
    </node>
    <node id="牛顿第二定律">
      <data key="d0">牛顿第二定律</data>
      <data key="d1">concept</data>
      <data key="d2">Newton's Second Law of Motion is a fundamental principle in physics used as an example case in the context of explaining machine learning methodology.&lt;SEP&gt;牛顿第二定律是一个用于说明机器学习方法论的案例。</data>
      <data key="d3">chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008444</data>
      <data key="d6" />
    </node>
    <node id="大模型">
      <data key="d0">大模型</data>
      <data key="d1">concept</data>
      <data key="d2">Large Models, particularly in natural language processing (e.g., GPT-3, BERT), are advanced machine learning models trained on massive datasets, demonstrating significant potential in complex tasks.&lt;SEP&gt;大模型是人工智能领域的一个概念，与深度学习结合用于模拟人类的语言理解过程。</data>
      <data key="d3">chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008445</data>
      <data key="d6" />
    </node>
    <node id="浙江大学人工智能教育教学研究中心">
      <data key="d0">浙江大学人工智能教育教学研究中心</data>
      <data key="d1">organization</data>
      <data key="d2">浙江大学人工智能教育教学研究中心是进行人工智能教育研究并展示相关研究成果的机构。</data>
      <data key="d3">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008448</data>
      <data key="d6" />
    </node>
    <node id="AI黑话揭秘">
      <data key="d0">AI黑话揭秘</data>
      <data key="d1">content</data>
      <data key="d2">AI黑话揭秘是一篇旨在解释人工智能相关概念之间关系的文章。</data>
      <data key="d3">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008449</data>
      <data key="d6" />
    </node>
    <node id="语言的重要性">
      <data key="d0">语言的重要性</data>
      <data key="d1">concept</data>
      <data key="d2">语言的重要性是一个知识点，强调语言在表达思想、情感和创造性运用方面的作用。</data>
      <data key="d3">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008450</data>
      <data key="d6" />
    </node>
    <node id="机器人技术">
      <data key="d0">机器人技术</data>
      <data key="d1">concept</data>
      <data key="d2">机器人技术是人工智能的一个子领域，涉及机器人的设计、建造和操作。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008453</data>
      <data key="d6" />
    </node>
    <node id="Scaling Law">
      <data key="d0">Scaling Law</data>
      <data key="d1">concept</data>
      <data key="d2">Scaling Law指模型性能随数据量和参数规模提升而提升的规律，是大语言模型兴起所依赖的法则。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008454</data>
      <data key="d6" />
    </node>
    <node id="GitHub Copilot">
      <data key="d0">GitHub Copilot</data>
      <data key="d1">artifact</data>
      <data key="d2">GitHub Copilot是一个大语言模型的应用实例，用于代码生成。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008457</data>
      <data key="d6" />
    </node>
    <node id="金融风控">
      <data key="d0">金融风控</data>
      <data key="d1">concept</data>
      <data key="d2">金融风控是机器学习的一个应用领域，例如使用逻辑回归算法。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008459</data>
      <data key="d6" />
    </node>
    <node id="医学影像识别">
      <data key="d0">医学影像识别</data>
      <data key="d1">concept</data>
      <data key="d2">医学影像识别是深度学习的一个应用领域，例如使用卷积神经网络。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008461</data>
      <data key="d6" />
    </node>
    <node id="语音助手">
      <data key="d0">语音助手</data>
      <data key="d1">concept</data>
      <data key="d2">语音助手是深度学习的一个应用领域，例如使用循环神经网络。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008461</data>
      <data key="d6" />
    </node>
    <node id="逻辑回归">
      <data key="d0">逻辑回归</data>
      <data key="d1">method</data>
      <data key="d2">逻辑回归是一种机器学习算法，应用于金融风控等领域。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008461</data>
      <data key="d6" />
    </node>
    <node id="协同过滤">
      <data key="d0">协同过滤</data>
      <data key="d1">method</data>
      <data key="d2">协同过滤是一种机器学习算法，应用于推荐系统等领域。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008465</data>
      <data key="d6" />
    </node>
    <node id="垂直模型">
      <data key="d0">垂直模型</data>
      <data key="d1">concept</data>
      <data key="d2">垂直模型是传统的AI模型，只会做特定领域的事情，例如翻译、下围棋或对话，无法像人类一样通用。&lt;SEP&gt;垂直模型是传统的AI模型，指只会做特定领域事情的模型，例如翻译、下围棋或对话。</data>
      <data key="d3">chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008467</data>
      <data key="d6" />
    </node>
    <node id="预训练-微调范式">
      <data key="d0">预训练-微调范式</data>
      <data key="d1">method</data>
      <data key="d2">The Pre-training and Fine-tuning paradigm involves first training a model on a large, general dataset and then adapting (fine-tuning) it to a specific task with a smaller, task-specific dataset.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008480</data>
      <data key="d6" />
    </node>
    <node id="文心一言">
      <data key="d0">文心一言</data>
      <data key="d1">artifact</data>
      <data key="d2">Wenxin Yiyan (文心一言) is a large language model and AI chatbot developed by Baidu.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008489</data>
      <data key="d6" />
    </node>
    <node id="通义千问">
      <data key="d0">通义千问</data>
      <data key="d1">artifact</data>
      <data key="d2">Tongyi Qianwen (通义千问) is a large language model and AI chatbot developed by Alibaba.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008490</data>
      <data key="d6" />
    </node>
    <node id="模型部署">
      <data key="d0">模型部署</data>
      <data key="d1">concept</data>
      <data key="d2">Model Deployment is the process of integrating a trained machine learning model into an existing production environment to make practical predictions.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008490</data>
      <data key="d6" />
    </node>
    <node id="学习路线">
      <data key="d0">学习路线</data>
      <data key="d1">content</data>
      <data key="d2">A Learning Path is a structured sequence of educational resources and activities designed to guide learners in acquiring specific knowledge or skills.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008493</data>
      <data key="d6" />
    </node>
    <node id="系统资料">
      <data key="d0">系统资料</data>
      <data key="d1">content</data>
      <data key="d2">Systematic Materials refer to organized and comprehensive learning resources provided to support a structured educational plan.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008493</data>
      <data key="d6" />
    </node>
    <node id="学习计划">
      <data key="d0">学习计划</data>
      <data key="d1">content</data>
      <data key="d2">A Study Plan is a customized schedule or strategy developed to achieve specific learning objectives within a given timeframe.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008494</data>
      <data key="d6" />
    </node>
    <node id="抖音推荐算法">
      <data key="d0">抖音推荐算法</data>
      <data key="d1">artifact</data>
      <data key="d2">Douyin's recommendation algorithm is a system used by the social media platform to personalize content for its users.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008495</data>
      <data key="d6" />
    </node>
    <node id="支付宝信用评分">
      <data key="d0">支付宝信用评分</data>
      <data key="d1">artifact</data>
      <data key="d2">Alipay Credit Score is a system used by the payment platform to assess user creditworthiness.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008496</data>
      <data key="d6" />
    </node>
    <node id="扫地机器人">
      <data key="d0">扫地机器人</data>
      <data key="d1">artifact</data>
      <data key="d2">A Robotic Vacuum Cleaner is an autonomous device that cleans floors, representing an application of AI in home appliances.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008498</data>
      <data key="d6" />
    </node>
    <node id="Siri">
      <data key="d0">Siri</data>
      <data key="d1">artifact</data>
      <data key="d2">Siri is a virtual assistant developed by Apple, representing an application of AI for voice interaction.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008500</data>
      <data key="d6" />
    </node>
    <node id="深度学习框架">
      <data key="d0">深度学习框架</data>
      <data key="d1">artifact</data>
      <data key="d2">Deep Learning Frameworks are standardized software tools and libraries that facilitate the development and deployment of deep learning models.</data>
      <data key="d3">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008501</data>
      <data key="d6" />
    </node>
    <node id="通用人工智能">
      <data key="d0">通用人工智能</data>
      <data key="d1">concept</data>
      <data key="d2">通用人工智能是让AI什么都能干的目标，是人工智能发展的一个方向。</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008503</data>
      <data key="d6" />
    </node>
    <node id="RL">
      <data key="d0">RL</data>
      <data key="d1">concept</data>
      <data key="d2">RL (Reinforcement Learning) is a method within machine learning that allows machines to automatically extract features from data.</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008505</data>
      <data key="d6" />
    </node>
    <node id="数据分析">
      <data key="d0">数据分析</data>
      <data key="d1">concept</data>
      <data key="d2">数据分析is the process of examining data to draw conclusions, supporting the performance improvement of AI models.&lt;SEP&gt;Data analysis is a language-related task that LLMs can help supplement or fully undertake, potentially automating it.</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008990</data>
      <data key="d6" />
    </node>
    <node id="谭铁牛">
      <data key="d0">谭铁牛</data>
      <data key="d1">person</data>
      <data key="d2">谭铁牛is an academician of the Chinese Academy of Sciences who provided a definition of artificial intelligence in an article published in "求实".</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008511</data>
      <data key="d6" />
    </node>
    <node id="求实">
      <data key="d0">求实</data>
      <data key="d1">content</data>
      <data key="d2">"求实" is a publication in which Academician Tan Tieniu published an article defining artificial intelligence.</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008501</data>
      <data key="d6" />
    </node>
    <node id="语言模型">
      <data key="d0">语言模型</data>
      <data key="d1">concept</data>
      <data key="d2">语言模型is a type of model that processes language, with large language models being a specific, advanced form.</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008502</data>
      <data key="d6" />
    </node>
    <node id="大数据模型">
      <data key="d0">大数据模型</data>
      <data key="d1">concept</data>
      <data key="d2">大数据模型is a type of model related to big data, often discussed in relation to AI models and large models.</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008503</data>
      <data key="d6" />
    </node>
    <node id="思维导图">
      <data key="d0">思维导图</data>
      <data key="d1">artifact</data>
      <data key="d2">思维导图is a visual tool used to organize information, mentioned as a resource for understanding the logical relationships between AI concepts.</data>
      <data key="d3">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008504</data>
      <data key="d6" />
    </node>
    <node id="自监督学习方法">
      <data key="d0">自监督学习方法</data>
      <data key="d1">method</data>
      <data key="d2">一种用于训练大语言模型的学习方法。</data>
      <data key="d3">chunk-3678971988880bb3960a90e15878444d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008631</data>
      <data key="d6" />
    </node>
    <node id="无标记文本">
      <data key="d0">无标记文本</data>
      <data key="d1">data</data>
      <data key="d2">用于训练大语言模型的大量文本数据。</data>
      <data key="d3">chunk-3678971988880bb3960a90e15878444d</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008632</data>
      <data key="d6" />
    </node>
    <node id="RAG">
      <data key="d0">RAG</data>
      <data key="d1">method</data>
      <data key="d2">RAG (Retrieval-Augmented Generation) is a technique that combines Large Language Models (LLMs) with external knowledge bases to generate precise answers by first retrieving relevant information.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008726</data>
      <data key="d6" />
    </node>
    <node id="Quantization">
      <data key="d0">Quantization</data>
      <data key="d1">method</data>
      <data key="d2">Quantization is a process that converts floating-point weights into integers using scaling and rounding, leading to some precision loss.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008729</data>
      <data key="d6" />
    </node>
    <node id="Llama.cpp">
      <data key="d0">Llama.cpp</data>
      <data key="d1">artifact</data>
      <data key="d2">Llama.cpp is a high-performance C++ implementation suitable for scenarios with high performance requirements.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008731</data>
      <data key="d6" />
    </node>
    <node id="Chatglm.cpp">
      <data key="d0">Chatglm.cpp</data>
      <data key="d1">artifact</data>
      <data key="d2">Chatglm.cpp is a high-performance C++ implementation suitable for scenarios with high performance requirements.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008732</data>
      <data key="d6" />
    </node>
    <node id="Qwen.cpp">
      <data key="d0">Qwen.cpp</data>
      <data key="d1">artifact</data>
      <data key="d2">Qwen.cpp is a high-performance C++ implementation suitable for scenarios with high performance requirements.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008733</data>
      <data key="d6" />
    </node>
    <node id="Softmax Function">
      <data key="d0">Softmax Function</data>
      <data key="d1">method</data>
      <data key="d2">The Softmax function converts a vector of numbers into a probability distribution, where larger input values correspond to higher probabilities.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008733</data>
      <data key="d6" />
    </node>
    <node id="Static KV-Cache">
      <data key="d0">Static KV-Cache</data>
      <data key="d1">method</data>
      <data key="d2">Static KV-Cache is an optimization technique that stores key-value pairs during LLM decoding to avoid recomputation, improving efficiency.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008737</data>
      <data key="d6" />
    </node>
    <node id="Torch.compile">
      <data key="d0">Torch.compile</data>
      <data key="d1">method</data>
      <data key="d2">Torch.compile is a PyTorch feature that, when combined with Static KV-Cache, can optimize performance by enabling static allocation.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008729</data>
      <data key="d6" />
    </node>
    <node id="Prompt Lookup Decoding">
      <data key="d0">Prompt Lookup Decoding</data>
      <data key="d1">method</data>
      <data key="d2">Prompt Lookup Decoding is a technique suitable for tasks with overlapping vocabulary between input and output; it generates candidate token sequences by string matching in the input prompt.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008730</data>
      <data key="d6" />
    </node>
    <node id="Fine-Tuning">
      <data key="d0">Fine-Tuning</data>
      <data key="d1">method</data>
      <data key="d2">Fine-Tuning is a model adaptation process that can be made more efficient by using techniques like torch.compile and padding-free data collation.&lt;SEP&gt;The process of adapting a pre-trained model to a specific task.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009201</data>
      <data key="d6" />
    </node>
    <node id="PyTorch Scaled Dot Product Attention">
      <data key="d0">PyTorch Scaled Dot Product Attention</data>
      <data key="d1">method</data>
      <data key="d2">PyTorch Scaled Dot Product Attention is an optimized computation mechanism that accelerates model training and inference through hardware acceleration.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008731</data>
      <data key="d6" />
    </node>
    <node id="Llama 2">
      <data key="d0">Llama 2</data>
      <data key="d1">artifact</data>
      <data key="d2">Llama 2 refers to open foundation and fine-tuned chat models.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008732</data>
      <data key="d6" />
    </node>
    <node id="Prompt Engineering">
      <data key="d0">Prompt Engineering</data>
      <data key="d1">concept</data>
      <data key="d2">Prompt Engineering is a technique for guiding model outputs, contrasted with Fine-tuning and RAG.&lt;SEP&gt;A common method for integrating proprietary and domain-specific data when building LLM applications.&lt;SEP&gt;The practice of designing and optimizing prompts for language models.&lt;SEP&gt;A development paradigm for large model applications, mentioned as a topic in learning paths and guides.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e&lt;SEP&gt;chunk-4f9864ecff092ef091c227f6ebb2d69f&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81&lt;SEP&gt;chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009307</data>
      <data key="d6" />
    </node>
    <node id="Precision Loss">
      <data key="d0">Precision Loss</data>
      <data key="d1">concept</data>
      <data key="d2">Precision Loss is the reduction in accuracy that occurs during the quantization process when floating-point values cannot be fully recovered.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008735</data>
      <data key="d6" />
    </node>
    <node id="Speculative Decoding">
      <data key="d0">Speculative Decoding</data>
      <data key="d1">method</data>
      <data key="d2">Speculative Decoding is a traditional decoding approach for which Prompt Lookup Decoding serves as an alternative.</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008737</data>
      <data key="d6" />
    </node>
    <node id="Large Language Model">
      <data key="d0">Large Language Model</data>
      <data key="d1">concept</data>
      <data key="d2">A type of deep learning model based on the Transformer architecture, primarily used for processing various natural language-related tasks such as text continuation, classification, summarization, rewriting, and translation.&lt;SEP&gt;A type of artificial intelligence model used for processing and generating human language.&lt;SEP&gt;A type of artificial intelligence model, central to the learning path and resources mentioned.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81&lt;SEP&gt;chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009324</data>
      <data key="d6" />
    </node>
    <node id="Transformer Architecture">
      <data key="d0">Transformer Architecture</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning model architecture that forms the basis for Large Language Models.&lt;SEP&gt;A deep learning model architecture based on self-attention mechanisms.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009212</data>
      <data key="d6" />
    </node>
    <node id="LLaMA">
      <data key="d0">LLaMA</data>
      <data key="d1">artifact</data>
      <data key="d2">A common example of a Large Language Model, introduced by Meta.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008740</data>
      <data key="d6" />
    </node>
    <node id="Meta">
      <data key="d0">Meta</data>
      <data key="d1">organization</data>
      <data key="d2">The organization that introduced the LLaMA model.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008740</data>
      <data key="d6" />
    </node>
    <node id="Mistral AI">
      <data key="d0">Mistral AI</data>
      <data key="d1">organization</data>
      <data key="d2">The organization that released the Mistral model.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008743</data>
      <data key="d6" />
    </node>
    <node id="Mistral Model">
      <data key="d0">Mistral Model</data>
      <data key="d1">artifact</data>
      <data key="d2">An open-source Large Language Model released by Mistral AI.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008744</data>
      <data key="d6" />
    </node>
    <node id="BigScience Team">
      <data key="d0">BigScience Team</data>
      <data key="d1">organization</data>
      <data key="d2">The team that introduced the BLOOM model.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008744</data>
      <data key="d6" />
    </node>
    <node id="BLOOM Model">
      <data key="d0">BLOOM Model</data>
      <data key="d1">artifact</data>
      <data key="d2">An open-source Large Language Model introduced by the BigScience team.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008748</data>
      <data key="d6" />
    </node>
    <node id="LLama 3.3">
      <data key="d0">LLama 3.3</data>
      <data key="d1">artifact</data>
      <data key="d2">An open-source Large Language Model highly recommended by the end of 2024.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008749</data>
      <data key="d6" />
    </node>
    <node id="LLama 3.2">
      <data key="d0">LLama 3.2</data>
      <data key="d1">artifact</data>
      <data key="d2">An open-source Large Language Model that outperforms GPT-4 in various benchmark tests but is noted as less excellent in practical applications.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008750</data>
      <data key="d6" />
    </node>
    <node id="Supervised Fine-Tuning">
      <data key="d0">Supervised Fine-Tuning</data>
      <data key="d1">method</data>
      <data key="d2">A method used to create conversational models.&lt;SEP&gt;A fine-tuning method that uses labeled data.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009201</data>
      <data key="d6" />
    </node>
    <node id="Reward Model Training">
      <data key="d0">Reward Model Training</data>
      <data key="d1">method</data>
      <data key="d2">A method used to train models capable of evaluating responses.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008752</data>
      <data key="d6" />
    </node>
    <node id="Encoder-Decoder Attention">
      <data key="d0">Encoder-Decoder Attention</data>
      <data key="d1">concept</data>
      <data key="d2">A mechanism where the decoder focuses on the encoder's output to understand the input sequence and generate more appropriate output.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008753</data>
      <data key="d6" />
    </node>
    <node id="Encoder-Only Model">
      <data key="d0">Encoder-Only Model</data>
      <data key="d1">concept</data>
      <data key="d2">A type of model used for extracting useful feature information from input data, focusing on understanding or representation learning, effective for tasks like text classification and sentiment analysis.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008754</data>
      <data key="d6" />
    </node>
    <node id="Decoder-Only Model">
      <data key="d0">Decoder-Only Model</data>
      <data key="d1">concept</data>
      <data key="d2">A type of model used for generative tasks, especially sequence generation like text generation and dialogue generation, applied in machine translation and code generation.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008754</data>
      <data key="d6" />
    </node>
    <node id="Encoder-Decoder Model">
      <data key="d0">Encoder-Decoder Model</data>
      <data key="d1">concept</data>
      <data key="d2">A model structure suitable for tasks that map an input sequence to an output sequence, such as machine translation and text summarization, consisting of an encoder for understanding and a decoder for generation.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008758</data>
      <data key="d6" />
    </node>
    <node id="Multimodal Large Language Models">
      <data key="d0">Multimodal Large Language Models</data>
      <data key="d1">concept</data>
      <data key="d2">A category of Large Language Models that handle multiple modalities.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008767</data>
      <data key="d6" />
    </node>
    <node id="Model Training and Fine-Tuning">
      <data key="d0">Model Training and Fine-Tuning</data>
      <data key="d1">method</data>
      <data key="d2">A common method for integrating proprietary and domain-specific data when building LLM applications.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008767</data>
      <data key="d6" />
    </node>
    <node id="Retrieval-Augmented Generation">
      <data key="d0">Retrieval-Augmented Generation</data>
      <data key="d1">method</data>
      <data key="d2">A technique that combines LLMs with external knowledge bases, where the LLM retrieves relevant information first before generating an answer.&lt;SEP&gt;A method that combines retrieval of information with generative models.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f&lt;SEP&gt;chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009204</data>
      <data key="d6" />
    </node>
    <node id="Zero-Shot Learning">
      <data key="d0">Zero-Shot Learning</data>
      <data key="d1">method</data>
      <data key="d2">A prompt strategy where the model generates answers without any examples, relying on pre-learned knowledge.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008761</data>
      <data key="d6" />
    </node>
    <node id="Few-Shot Learning">
      <data key="d0">Few-Shot Learning</data>
      <data key="d1">method</data>
      <data key="d2">A prompt strategy where the model is provided with a few examples to better understand the task requirements.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008761</data>
      <data key="d6" />
    </node>
    <node id="Modelscope-Classroom">
      <data key="d0">Modelscope-Classroom</data>
      <data key="d1">content</data>
      <data key="d2">A resource referenced for in-depth learning about Large Language Model fundamentals.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008765</data>
      <data key="d6" />
    </node>
    <node id="LLM Quantization">
      <data key="d0">LLM Quantization</data>
      <data key="d1">method</data>
      <data key="d2">A method mentioned alongside deployment and optimization in the context of Large Language Models.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008765</data>
      <data key="d6" />
    </node>
    <node id="LLM Deployment">
      <data key="d0">LLM Deployment</data>
      <data key="d1">method</data>
      <data key="d2">A method mentioned alongside quantization and optimization in the context of Large Language Models.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008767</data>
      <data key="d6" />
    </node>
    <node id="LLM Optimization">
      <data key="d0">LLM Optimization</data>
      <data key="d1">method</data>
      <data key="d2">A method mentioned alongside quantization and deployment in the context of Large Language Models.</data>
      <data key="d3">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008768</data>
      <data key="d6" />
    </node>
    <node id="Model Training">
      <data key="d0">Model Training</data>
      <data key="d3">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d2">PyTorch Scaled Dot Product Attention accelerates model training and inference through hardware-accelerated, optimized computation graphs.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008769</data>
      <data key="d6" />
    </node>
    <node id="红帽AI">
      <data key="d0">红帽AI</data>
      <data key="d1">organization</data>
      <data key="d2">红帽AI提供对第三方模型库的访问权限，这些模型经过验证，可以在其平台上高效运行。&lt;SEP&gt;Red Hat AI provides access to third-party model libraries that are verified to run efficiently on its platform, offering ready-made models for capacity planning scenarios.</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008967</data>
      <data key="d6" />
    </node>
    <node id="SLM">
      <data key="d0">SLM</data>
      <data key="d1">concept</data>
      <data key="d2">SLM是小语言模型，是语言模型的一种类型，常与LLM进行对比。&lt;SEP&gt;SLM (Small Language Model) is contrasted with LLM (Large Language Model) in terms of language model comparison.</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008969</data>
      <data key="d6" />
    </node>
    <node id="红帽® 企业Linux® AI">
      <data key="d0">红帽® 企业Linux® AI</data>
      <data key="d1">platform</data>
      <data key="d2">红帽® 企业Linux® AI是红帽的基础模型平台，用于开发、测试和运行Granite系列LLM。</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008970</data>
      <data key="d6" />
    </node>
    <node id="Granite系列LLM">
      <data key="d0">Granite系列LLM</data>
      <data key="d1">artifact</data>
      <data key="d2">Granite系列LLM是可以在红帽® 企业Linux® AI平台上运行的一系列大型语言模型。</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008970</data>
      <data key="d6" />
    </node>
    <node id="AI平台">
      <data key="d0">AI平台</data>
      <data key="d1">platform</data>
      <data key="d2">AI平台是提供LLM和AI工具访问的服务器环境，用于调整模型和构建生成式AI应用。</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008971</data>
      <data key="d6" />
    </node>
    <node id="模型上下文协议(MCP)">
      <data key="d0">模型上下文协议(MCP)</data>
      <data key="d1">concept</data>
      <data key="d2">模型上下文协议(MCP)是一种协议，可以将AI应用连接到外部数据源，以构建更智能的工作流。</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008972</data>
      <data key="d6" />
    </node>
    <node id="代理式AI">
      <data key="d0">代理式AI</data>
      <data key="d1">concept</data>
      <data key="d2">代理式AI是人工智能的一种类型，常与生成式AI进行对比。&lt;SEP&gt;Agent AI combines automation technology with the creativity of LLMs; its communication with tools involves orchestration, allowing LLMs to "reason" and determine the best way to answer questions.</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008972</data>
      <data key="d6" />
    </node>
    <node id="AI/ML用例">
      <data key="d0">AI/ML用例</data>
      <data key="d1">concept</data>
      <data key="d2">AI/ML用例指的是人工智能和机器学习在不同行业中的应用场景。</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008976</data>
      <data key="d6" />
    </node>
    <node id="容量指导规划">
      <data key="d0">容量指导规划</data>
      <data key="d1">concept</data>
      <data key="d2">容量指导规划是一种应用场景，可以使用红帽AI提供的现成模型来帮助针对特定领域的用例做出明智决策。&lt;SEP&gt;Capacity guidance planning is a scenario where ready-made models from platforms like Red Hat AI can be applied to help make informed decisions for domain-specific use cases.</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008979</data>
      <data key="d6" />
    </node>
    <node id="AI/ML相关资源">
      <data key="d0">AI/ML相关资源</data>
      <data key="d1">content</data>
      <data key="d2">AI/ML相关资源是一系列文章和指南的集合，包括代理式AI与生成式AI的区别、SLM与LLM的对比、AI平台介绍以及行业AI应用场景盘点。</data>
      <data key="d3">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008979</data>
      <data key="d6" />
    </node>
    <node id="数据准备">
      <data key="d0">数据准备</data>
      <data key="d1">method</data>
      <data key="d2">Data preparation involves collecting, cleaning, and organizing raw data for training LLMs, including steps like data cleaning, filtering, and tokenization.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008973</data>
      <data key="d6" />
    </node>
    <node id="llm-d">
      <data key="d0">llm-d</data>
      <data key="d1">artifact</data>
      <data key="d2">llm-d is an open-source AI framework that enables developers to meet the growing demands of complex large inference models like LLMs through technologies such as distributed inference.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008976</data>
      <data key="d6" />
    </node>
    <node id="分布式推理">
      <data key="d0">分布式推理</data>
      <data key="d1">method</data>
      <data key="d2">Distributed inference and llm-d use a modular architecture to distribute inference tasks across multiple hardware devices for collaborative processing, improving AI workload efficiency and model inference speed.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008978</data>
      <data key="d6" />
    </node>
    <node id="训练数据">
      <data key="d0">训练数据</data>
      <data key="d1">data</data>
      <data key="d2">Training data is the information used to train deep learning models; if it contains statistical biases or does not accurately represent the population, the output may be flawed.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008987</data>
      <data key="d6" />
    </node>
    <node id="检索增强生成(RAG)">
      <data key="d0">检索增强生成(RAG)</data>
      <data key="d1">method</data>
      <data key="d2">Retrieval-Augmented Generation (RAG) is an architecture that augments an LLM's knowledge base by integrating data from selected knowledge sources such as data warehouses, text collections, or existing documents.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008987</data>
      <data key="d6" />
    </node>
    <node id="GDPR">
      <data key="d0">GDPR</data>
      <data key="d1">concept</data>
      <data key="d2">GDPR is a data privacy law that organizations must comply with when deploying AI systems.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008982</data>
      <data key="d6" />
    </node>
    <node id="HIPAA">
      <data key="d0">HIPAA</data>
      <data key="d1">concept</data>
      <data key="d2">HIPAA is a data privacy law that organizations must comply with when deploying AI systems.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008982</data>
      <data key="d6" />
    </node>
    <node id="人机回圈">
      <data key="d0">人机回圈</data>
      <data key="d1">concept</data>
      <data key="d2">Human-in-the-loop is a strategy crucial for key decisions, establishing clear accountability frameworks for LLM performance and impact from development to deployment.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008983</data>
      <data key="d6" />
    </node>
    <node id="词元化">
      <data key="d0">词元化</data>
      <data key="d1">method</data>
      <data key="d2">Tokenization is the process of breaking down text into units that a model can understand, as part of data preparation for LLMs.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008984</data>
      <data key="d6" />
    </node>
    <node id="内容生成">
      <data key="d0">内容生成</data>
      <data key="d1">concept</data>
      <data key="d2">Content generation is a language-related task that LLMs can help supplement or fully undertake, potentially automating it.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008990</data>
      <data key="d6" />
    </node>
    <node id="运维成本">
      <data key="d0">运维成本</data>
      <data key="d1">concept</data>
      <data key="d2">Operational costs can be reduced through the automation of language-related tasks by LLMs.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008992</data>
      <data key="d6" />
    </node>
    <node id="市场趋势">
      <data key="d0">市场趋势</data>
      <data key="d1">concept</data>
      <data key="d2">Market trends are insights that businesses can better understand by using LLMs to quickly scan large volumes of text data from sources like social media and research papers.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008994</data>
      <data key="d6" />
    </node>
    <node id="客户反馈">
      <data key="d0">客户反馈</data>
      <data key="d1">data</data>
      <data key="d2">Customer feedback is information that businesses can better understand by using LLMs to quickly scan large volumes of text data from sources like social media and comments.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769008996</data>
      <data key="d6" />
    </node>
    <node id="个性化内容">
      <data key="d0">个性化内容</data>
      <data key="d1">content</data>
      <data key="d2">Personalized content is highly tailored material that LLMs can help businesses provide to customers, strengthening engagement and improving user experience.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009008</data>
      <data key="d6" />
    </node>
    <node id="营销信息">
      <data key="d0">营销信息</data>
      <data key="d1">content</data>
      <data key="d2">Marketing messages can be tailored to specific user personas using LLMs, facilitating personalized customer engagement.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009009</data>
      <data key="d6" />
    </node>
    <node id="跨文化交流">
      <data key="d0">跨文化交流</data>
      <data key="d1">concept</data>
      <data key="d2">Cross-cultural communication can be facilitated by LLMs through capabilities like language translation.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009012</data>
      <data key="d6" />
    </node>
    <node id="LLM提示词">
      <data key="d0">LLM提示词</data>
      <data key="d1">content</data>
      <data key="d2">LLM prompts are often complex and non-uniform, requiring significant computational resources and storage to process massive data.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009012</data>
      <data key="d6" />
    </node>
    <node id="计算资源">
      <data key="d0">计算资源</data>
      <data key="d1">concept</data>
      <data key="d2">Computational resources are required in large amounts to handle the massive data processing needs of LLMs.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009015</data>
      <data key="d6" />
    </node>
    <node id="存储支持">
      <data key="d0">存储支持</data>
      <data key="d1">concept</data>
      <data key="d2">Storage support is required in large amounts to handle the massive data processing needs of LLMs.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009017</data>
      <data key="d6" />
    </node>
    <node id="AI工作负载">
      <data key="d0">AI工作负载</data>
      <data key="d1">concept</data>
      <data key="d2">AI workloads refer to the computational tasks run by AI systems; distributed inference helps them run efficiently.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009017</data>
      <data key="d6" />
    </node>
    <node id="客户信息">
      <data key="d0">客户信息</data>
      <data key="d1">data</data>
      <data key="d2">Customer information is a type of data that LLMs may need to access, raising privacy and security concerns if handled by third-party providers.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009020</data>
      <data key="d6" />
    </node>
    <node id="专有的商业数据">
      <data key="d0">专有的商业数据</data>
      <data key="d1">data</data>
      <data key="d2">Proprietary business data is a type of information that LLMs may need to access, raising security concerns if handled by third-party providers.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009020</data>
      <data key="d6" />
    </node>
    <node id="第三方提供商">
      <data key="d0">第三方提供商</data>
      <data key="d1">organization</data>
      <data key="d2">Third-party providers are entities that may deploy or provide access to LLMs, necessitating caution regarding data security and privacy.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009022</data>
      <data key="d6" />
    </node>
    <node id="统计学上的偏差">
      <data key="d0">统计学上的偏差</data>
      <data key="d1">concept</data>
      <data key="d2">Statistical bias refers to flaws in training data that do not accurately represent the population, leading to defective AI outputs.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009022</data>
      <data key="d6" />
    </node>
    <node id="人类偏见">
      <data key="d0">人类偏见</data>
      <data key="d1">concept</data>
      <data key="d2">Human bias is an existing prejudice that can be transferred to AI systems, risking discriminatory algorithms and biased outputs.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009023</data>
      <data key="d6" />
    </node>
    <node id="歧视性算法">
      <data key="d0">歧视性算法</data>
      <data key="d1">concept</data>
      <data key="d2">Discriminatory algorithms are a risk when AI models are trained on biased data, leading to unfair or prejudiced outputs.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009025</data>
      <data key="d6" />
    </node>
    <node id="偏见输出">
      <data key="d0">偏见输出</data>
      <data key="d1">content</data>
      <data key="d2">Biased output is a risk when AI models are trained on biased data, leading to unfair or prejudiced results.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009025</data>
      <data key="d6" />
    </node>
    <node id="包容性">
      <data key="d0">包容性</data>
      <data key="d1">concept</data>
      <data key="d2">Inclusivity is a principle that must be upheld throughout the AI design process to help minimize bias.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009028</data>
      <data key="d6" />
    </node>
    <node id="多样性">
      <data key="d0">多样性</data>
      <data key="d1">concept</data>
      <data key="d2">Diversity is a consideration for the data collected to train AI models, ensuring it represents a broad population to minimize bias.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009030</data>
      <data key="d6" />
    </node>
    <node id="黑箱">
      <data key="d0">黑箱</data>
      <data key="d1">concept</data>
      <data key="d2">The "black box" nature of many LLMs hinders transparency and explainability in their decision-making processes.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009030</data>
      <data key="d6" />
    </node>
    <node id="透明度">
      <data key="d0">透明度</data>
      <data key="d1">concept</data>
      <data key="d2">Transparency is a quality hindered by the "black box" nature of many LLMs, affecting the explainability of their operations.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009032</data>
      <data key="d6" />
    </node>
    <node id="可解释性">
      <data key="d0">可解释性</data>
      <data key="d1">concept</data>
      <data key="d2">Explainability is a quality hindered by the "black box" nature of many LLMs, affecting the understanding of their decision-making.&lt;SEP&gt;Interpretability.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc&lt;SEP&gt;chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010199</data>
      <data key="d6" />
    </node>
    <node id="AI监管">
      <data key="d0">AI监管</data>
      <data key="d1">concept</data>
      <data key="d2">AI regulation is crucial for the responsible development and oversight of LLMs, ensuring they align with organizational values and legal requirements.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009033</data>
      <data key="d6" />
    </node>
    <node id="数据监管">
      <data key="d0">数据监管</data>
      <data key="d1">concept</data>
      <data key="d2">Data governance is a requirement under new AI-specific regulations for managing and overseeing data used in AI systems.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009035</data>
      <data key="d6" />
    </node>
    <node id="人工监督">
      <data key="d0">人工监督</data>
      <data key="d1">concept</data>
      <data key="d2">Human oversight is a requirement under new AI-specific regulations for monitoring AI system operations.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009036</data>
      <data key="d6" />
    </node>
    <node id="AI系统安全防护">
      <data key="d0">AI系统安全防护</data>
      <data key="d1">concept</data>
      <data key="d2">AI system security protection is a requirement under new AI-specific regulations to safeguard AI systems.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009037</data>
      <data key="d6" />
    </node>
    <node id="问责框架">
      <data key="d0">问责框架</data>
      <data key="d1">concept</data>
      <data key="d2">An accountability framework is crucial for defining responsibility for LLM performance and impact from development to deployment.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009038</data>
      <data key="d6" />
    </node>
    <node id="知识源">
      <data key="d0">知识源</data>
      <data key="d1">data</data>
      <data key="d2">Knowledge sources, such as data warehouses, text collections, or existing documents, are integrated by RAG to augment an LLM's knowledge base.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009041</data>
      <data key="d6" />
    </node>
    <node id="编排">
      <data key="d0">编排</data>
      <data key="d1">concept</data>
      <data key="d2">Orchestration is involved in the communication between Agent AI and tools, with specific processes or diagrams varying by framework.</data>
      <data key="d3">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009041</data>
      <data key="d6" />
    </node>
    <node id="NeOn-GPT">
      <data key="d0">NeOn-GPT</data>
      <data key="d1">method</data>
      <data key="d2">A large language model-powered pipeline for ontology learning.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009172</data>
      <data key="d6" />
    </node>
    <node id="Ontology Learning">
      <data key="d0">Ontology Learning</data>
      <data key="d1">concept</data>
      <data key="d2">The process of automatically or semi-automatically constructing ontologies from data.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009174</data>
      <data key="d6" />
    </node>
    <node id="DIKWP Research Group">
      <data key="d0">DIKWP Research Group</data>
      <data key="d1">organization</data>
      <data key="d2">A research group that conducts international standard evaluations for large language model biases.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009176</data>
      <data key="d6" />
    </node>
    <node id="Cultural Bias">
      <data key="d0">Cultural Bias</data>
      <data key="d1">concept</data>
      <data key="d2">A type of bias in large language models related to cultural perspectives.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009176</data>
      <data key="d6" />
    </node>
    <node id="Regional Bias">
      <data key="d0">Regional Bias</data>
      <data key="d1">concept</data>
      <data key="d2">A type of bias in large language models related to geographical regions.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009177</data>
      <data key="d6" />
    </node>
    <node id="Age Bias">
      <data key="d0">Age Bias</data>
      <data key="d1">concept</data>
      <data key="d2">A type of bias in large language models related to age groups.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009178</data>
      <data key="d6" />
    </node>
    <node id="Occupational Bias">
      <data key="d0">Occupational Bias</data>
      <data key="d1">concept</data>
      <data key="d2">A type of bias in large language models related to occupations.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009178</data>
      <data key="d6" />
    </node>
    <node id="Variational Autoencoder">
      <data key="d0">Variational Autoencoder</data>
      <data key="d1">method</data>
      <data key="d2">A generative model that is a variant of the autoencoder.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009183</data>
      <data key="d6" />
    </node>
    <node id="Generative Adversarial Network">
      <data key="d0">Generative Adversarial Network</data>
      <data key="d1">method</data>
      <data key="d2">A class of machine learning frameworks for generating new data.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009185</data>
      <data key="d6" />
    </node>
    <node id="Hallucination">
      <data key="d0">Hallucination</data>
      <data key="d1">concept</data>
      <data key="d2">A phenomenon in artificial intelligence where models generate incorrect or nonsensical information.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009186</data>
      <data key="d6" />
    </node>
    <node id="Model Collapse">
      <data key="d0">Model Collapse</data>
      <data key="d1">concept</data>
      <data key="d2">A degradation in model performance over time due to training on its own outputs.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009187</data>
      <data key="d6" />
    </node>
    <node id="Foundation Model">
      <data key="d0">Foundation Model</data>
      <data key="d1">concept</data>
      <data key="d2">A large-scale model trained on broad data that can be adapted to various tasks.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009199</data>
      <data key="d6" />
    </node>
    <node id="Reasoning Language Model">
      <data key="d0">Reasoning Language Model</data>
      <data key="d1">concept</data>
      <data key="d2">A type of language model designed for logical reasoning tasks.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009200</data>
      <data key="d6" />
    </node>
    <node id="Model Context Protocol">
      <data key="d0">Model Context Protocol</data>
      <data key="d1">concept</data>
      <data key="d2">A protocol related to the context management in language models.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009203</data>
      <data key="d6" />
    </node>
    <node id="Dialogue Program">
      <data key="d0">Dialogue Program</data>
      <data key="d1">artifact</data>
      <data key="d2">A program designed for conducting dialogues.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009205</data>
      <data key="d6" />
    </node>
    <node id="Ollama">
      <data key="d0">Ollama</data>
      <data key="d1">artifact</data>
      <data key="d2">A software tool or platform, listed among dialogue-related technologies.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009207</data>
      <data key="d6" />
    </node>
    <node id="Vision Transformer">
      <data key="d0">Vision Transformer</data>
      <data key="d1">method</data>
      <data key="d2">A transformer architecture adapted for computer vision tasks.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009213</data>
      <data key="d6" />
    </node>
    <node id="Vector Database">
      <data key="d0">Vector Database</data>
      <data key="d1">data</data>
      <data key="d2">A database optimized for storing and querying high-dimensional vector embeddings.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009215</data>
      <data key="d6" />
    </node>
    <node id="Word Embedding">
      <data key="d0">Word Embedding</data>
      <data key="d1">method</data>
      <data key="d2">A technique for representing words as vectors in a continuous space.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009216</data>
      <data key="d6" />
    </node>
    <node id="arXiv Papers">
      <data key="d0">arXiv Papers</data>
      <data key="d1">content</data>
      <data key="d2">A collection of 17,000 academic papers from the arXiv repository, analyzed for trends in topics, authors, and institutions within large language model research.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009216</data>
      <data key="d6" />
    </node>
    <node id="Topics, Authors, and Institutions">
      <data key="d0">Topics, Authors, and Institutions</data>
      <data key="d1">content</data>
      <data key="d2">The analyzed dimensions (topics, authors, institutions) from the study of 17,000 arXiv papers on large language model research.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009218</data>
      <data key="d6" />
    </node>
    <node id="International Standard Evaluation">
      <data key="d0">International Standard Evaluation</data>
      <data key="d1">method</data>
      <data key="d2">A standardized evaluation methodology used by the DIKWP Research Group for assessing biases in large language models.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009219</data>
      <data key="d6" />
    </node>
    <node id="PDF">
      <data key="d0">PDF</data>
      <data key="d1">artifact</data>
      <data key="d2">A document format, specifically referring to the PDF document of the NeOn-GPT paper.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009220</data>
      <data key="d6" />
    </node>
    <node id="List">
      <data key="d0">List</data>
      <data key="d1">content</data>
      <data key="d2">A catalog or enumeration, referenced in the context of chatbots and the Ollama tool.</data>
      <data key="d3">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009220</data>
      <data key="d6" />
    </node>
    <node id="Chatgpt Prompt Engineering For Developers">
      <data key="d0">Chatgpt Prompt Engineering For Developers</data>
      <data key="d1">content</data>
      <data key="d2">A resource for learning prompt engineering, described as relatively simple and suitable for beginners.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009294</data>
      <data key="d6" />
    </node>
    <node id="Openai Official Quickstart Documentation">
      <data key="d0">Openai Official Quickstart Documentation</data>
      <data key="d1">content</data>
      <data key="d2">Official documentation from OpenAI providing a quick start guide and API reference.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009294</data>
      <data key="d6" />
    </node>
    <node id="State Of Gpt">
      <data key="d0">State Of Gpt</data>
      <data key="d1">content</data>
      <data key="d2">A presentation by Andrej Karpathy that summarizes the training and application of GPT, highly recommended.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009295</data>
      <data key="d6" />
    </node>
    <node id="Deep Dive Into Llms Like Chatgpt">
      <data key="d0">Deep Dive Into Llms Like Chatgpt</data>
      <data key="d1">content</data>
      <data key="d2">A long introductory video by Andrej Karpathy, lasting three hours, highly recommended.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009298</data>
      <data key="d6" />
    </node>
    <node id="Building Systems With The Chatgpt Api">
      <data key="d0">Building Systems With The Chatgpt Api</data>
      <data key="d1">content</data>
      <data key="d2">A resource focused on building systems using the ChatGPT API.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009298</data>
      <data key="d6" />
    </node>
    <node id="Openai Cookbook">
      <data key="d0">Openai Cookbook</data>
      <data key="d1">content</data>
      <data key="d2">The official OpenAI Cookbook, a collection of resources and examples.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009299</data>
      <data key="d6" />
    </node>
    <node id="Brex's Prompt Engineering Guide">
      <data key="d0">Brex's Prompt Engineering Guide</data>
      <data key="d1">content</data>
      <data key="d2">An introductory guide to prompt engineering by Brex.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009300</data>
      <data key="d6" />
    </node>
    <node id="Build A Large Language Model (From Scratch)">
      <data key="d0">Build A Large Language Model (From Scratch)</data>
      <data key="d1">content</data>
      <data key="d2">A resource on building a large language model from scratch, highly recommended.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009301</data>
      <data key="d6" />
    </node>
    <node id="A Survey Of Prompt Engineering Methods In Large Language Models For Different Nlp Tasks">
      <data key="d0">A Survey Of Prompt Engineering Methods In Large Language Models For Different Nlp Tasks</data>
      <data key="d1">content</data>
      <data key="d2">A survey paper on prompt engineering methods for various NLP tasks.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009302</data>
      <data key="d6" />
    </node>
    <node id="Llm Powered Autonomous Agents">
      <data key="d0">Llm Powered Autonomous Agents</data>
      <data key="d1">content</data>
      <data key="d2">An early and notable article on autonomous agents powered by large language models.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009305</data>
      <data key="d6" />
    </node>
    <node id="Andrej Karpathy">
      <data key="d0">Andrej Karpathy</data>
      <data key="d1">person</data>
      <data key="d2">A person who created presentations and videos on GPT and LLMs, such as "State of GPT" and "Deep Dive into LLMs like ChatGPT".</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009305</data>
      <data key="d6" />
    </node>
    <node id="Rag">
      <data key="d0">Rag</data>
      <data key="d1">concept</data>
      <data key="d2">A development paradigm for large model applications, mentioned as part of a learning path.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009307</data>
      <data key="d6" />
    </node>
    <node id="Large Model Application Development">
      <data key="d0">Large Model Application Development</data>
      <data key="d1">concept</data>
      <data key="d2">The overarching field encompassing paradigms like Prompt Engineering, RAG, and Agent.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009309</data>
      <data key="d6" />
    </node>
    <node id="Nlp Tasks">
      <data key="d0">Nlp Tasks</data>
      <data key="d1">concept</data>
      <data key="d2">Natural Language Processing tasks, referenced in the context of a survey on prompt engineering methods.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009311</data>
      <data key="d6" />
    </node>
    <node id="Openai">
      <data key="d0">Openai</data>
      <data key="d1">organization</data>
      <data key="d2">An organization that provides official documentation, a cookbook, and an API for developers.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009312</data>
      <data key="d6" />
    </node>
    <node id="Brex">
      <data key="d0">Brex</data>
      <data key="d1">organization</data>
      <data key="d2">An organization that published a Prompt Engineering Guide.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009313</data>
      <data key="d6" />
    </node>
    <node id="Gpt">
      <data key="d0">Gpt</data>
      <data key="d1">concept</data>
      <data key="d2">A type of large language model, the subject of presentations and videos by Andrej Karpathy.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009314</data>
      <data key="d6" />
    </node>
    <node id="Api Reference">
      <data key="d0">Api Reference</data>
      <data key="d1">content</data>
      <data key="d2">Reference documentation for an API, mentioned alongside the OpenAI Official Quickstart Documentation.</data>
      <data key="d3">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009324</data>
      <data key="d6" />
    </node>
    <node id="Gemini">
      <data key="d0">Gemini</data>
      <data key="d1">artifact</data>
      <data key="d2">Gemini is a multimodal model developed by Google DeepMind, capable of understanding various inputs and generating outputs, accessible via Vertex AI.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009396</data>
      <data key="d6" />
    </node>
    <node id="Generative AI on Vertex AI">
      <data key="d0">Generative AI on Vertex AI</data>
      <data key="d1">service</data>
      <data key="d2">Generative AI on Vertex AI is a service that allows access to Google's large generative AI models for testing, tuning, and deployment in AI-driven applications.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009400</data>
      <data key="d6" />
    </node>
    <node id="Vertex AI Agent Builder">
      <data key="d0">Vertex AI Agent Builder</data>
      <data key="d1">service</data>
      <data key="d2">Vertex AI Agent Builder is a service that enables developers to build agents in an open manner and deploy enterprise-grade control features.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009400</data>
      <data key="d6" />
    </node>
    <node id="Customer Engagement Suite with Google AI">
      <data key="d0">Customer Engagement Suite with Google AI</data>
      <data key="d1">service</data>
      <data key="d2">Customer Engagement Suite with Google AI is an intelligent contact center solution that includes the conversational AI platform Dialogflow.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009401</data>
      <data key="d6" />
    </node>
    <node id="Dialogflow">
      <data key="d0">Dialogflow</data>
      <data key="d1">artifact</data>
      <data key="d2">Dialogflow is a conversational AI platform within the Customer Engagement Suite, featuring both intent-based and LLM capabilities.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009404</data>
      <data key="d6" />
    </node>
    <node id="Gemini API">
      <data key="d0">Gemini API</data>
      <data key="d1">artifact</data>
      <data key="d2">The Gemini API on Vertex AI allows users to provide prompts and execute tests using text, images, video, or code to leverage Gemini's advanced reasoning and generation capabilities.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009408</data>
      <data key="d6" />
    </node>
    <node id="Google AI">
      <data key="d0">Google AI</data>
      <data key="d1">organization</data>
      <data key="d2">Google AI is the advanced AI division that powers large language models, as mentioned in the context of Google Cloud's services.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009400</data>
      <data key="d6" />
    </node>
    <node id="AI-Driven Application">
      <data key="d0">AI-Driven Application</data>
      <data key="d1">concept</data>
      <data key="d2">AI-driven applications are next-generation applications built using advanced AI models like Gemini for tasks such as text extraction and image analysis.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009401</data>
      <data key="d6" />
    </node>
    <node id="Prompt">
      <data key="d0">Prompt</data>
      <data key="d1">concept</data>
      <data key="d2">A prompt is an input provided to models like Gemini on Vertex AI for testing and generating outputs using text, images, video, or code.&lt;SEP&gt;Prompt is mentioned as a means by which humans must interact to efficiently obtain information from AI, illustrating a paradox of human initiative and passivity.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440&lt;SEP&gt;chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010980</data>
      <data key="d6" />
    </node>
    <node id="Text Data">
      <data key="d0">Text Data</data>
      <data key="d1">data</data>
      <data key="d2">Text data is the large corpus of information used to train neural networks in Large Language Models (LLMs) to improve their performance and accuracy.</data>
      <data key="d3">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009404</data>
      <data key="d6" />
    </node>
    <node id="遥感图像分析">
      <data key="d0">遥感图像分析</data>
      <data key="d1">method</data>
      <data key="d2">Remote sensing image analysis is a method with broad application prospects in fields such as land resource management and marine monitoring.</data>
      <data key="d3">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009441</data>
      <data key="d6" />
    </node>
    <node id="国土资源管理">
      <data key="d0">国土资源管理</data>
      <data key="d1">concept</data>
      <data key="d2">Land resource management is a field where remote sensing image analysis is applied.</data>
      <data key="d3">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009441</data>
      <data key="d6" />
    </node>
    <node id="海洋监测">
      <data key="d0">海洋监测</data>
      <data key="d1">concept</data>
      <data key="d2">Marine monitoring is a field where remote sensing image analysis is applied.</data>
      <data key="d3">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009444</data>
      <data key="d6" />
    </node>
    <node id="遥感图像">
      <data key="d0">遥感图像</data>
      <data key="d1">data</data>
      <data key="d2">Remote sensing images are data characterized by large size, small and densely packed targets.</data>
      <data key="d3">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009445</data>
      <data key="d6" />
    </node>
    <node id="地球科学">
      <data key="d0">地球科学</data>
      <data key="d1">concept</data>
      <data key="d2">Earth science is the domain or field mentioned in the document metadata.&lt;SEP&gt;地球科学是本研究所属的领域，遥感技术是其重要的研究工具。&lt;SEP&gt;The domain or field of study to which the research summary belongs.</data>
      <data key="d3">chunk-70cc6b4326bedb7c4b61745cce643075&lt;SEP&gt;chunk-81494149ccc19d39342ca4e7f5dc4668&lt;SEP&gt;chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009582</data>
      <data key="d6" />
    </node>
    <node id="遥感图像分类">
      <data key="d0">遥感图像分类</data>
      <data key="d1">method</data>
      <data key="d2">遥感图像分类是利用算法对遥感图像中的地物进行识别和归类的关键任务。</data>
      <data key="d3">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009480</data>
      <data key="d6" />
    </node>
    <node id="目标检测">
      <data key="d0">目标检测</data>
      <data key="d1">method</data>
      <data key="d2">目标检测是识别遥感图像中特定目标(如建筑物、车辆)位置和类别的任务。</data>
      <data key="d3">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009480</data>
      <data key="d6" />
    </node>
    <node id="语义分割">
      <data key="d0">语义分割</data>
      <data key="d1">method</data>
      <data key="d2">语义分割是为遥感图像中的每个像素分配一个类别标签，以实现精细地物划分的任务。</data>
      <data key="d3">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009484</data>
      <data key="d6" />
    </node>
    <node id="变化检测">
      <data key="d0">变化检测</data>
      <data key="d1">method</data>
      <data key="d2">变化检测是通过比较不同时期的遥感图像来识别地表变化(如城市扩张、森林砍伐)的任务。</data>
      <data key="d3">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009484</data>
      <data key="d6" />
    </node>
    <node id="多模态数据">
      <data key="d0">多模态数据</data>
      <data key="d1">data</data>
      <data key="d2">多模态数据指融合了不同类型(如光学、雷达、激光雷达)的遥感数据，用于提升分析性能。</data>
      <data key="d3">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009493</data>
      <data key="d6" />
    </node>
    <node id="本研究">
      <data key="d0">本研究</data>
      <data key="d1">content</data>
      <data key="d2">本研究系统地综述了深度神经网络在遥感关键任务中的应用，并分析了国内外研究现状与进展。</data>
      <data key="d3">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009488</data>
      <data key="d6" />
    </node>
    <node id="国内外研究现状与进展">
      <data key="d0">国内外研究现状与进展</data>
      <data key="d1">content</data>
      <data key="d2">国内外研究现状与进展是本研究分析的对象，指深度神经网络在遥感应用领域的全球研究动态。</data>
      <data key="d3">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009490</data>
      <data key="d6" />
    </node>
    <node id="Imbalanced Learning-Based Automatic SAR Images Change Detection">
      <data key="d0">Imbalanced Learning-Based Automatic SAR Images Change Detection</data>
      <data key="d1">method</data>
      <data key="d2">A method for change detection in SAR images using morphological supervision and PCA-Net.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009526</data>
      <data key="d6" />
    </node>
    <node id="IEEE Geoscience and Remote Sensing Letters">
      <data key="d0">IEEE Geoscience and Remote Sensing Letters</data>
      <data key="d1">content</data>
      <data key="d2">A scientific journal that published the article on SAR image change detection.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009526</data>
      <data key="d6" />
    </node>
    <node id="Wang Y H">
      <data key="d0">Wang Y H</data>
      <data key="d1">person</data>
      <data key="d2">An author of the article on SAR image change detection.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009527</data>
      <data key="d6" />
    </node>
    <node id="Gao L R">
      <data key="d0">Gao L R</data>
      <data key="d1">person</data>
      <data key="d2">An author of the article on SAR image change detection.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009529</data>
      <data key="d6" />
    </node>
    <node id="Chen Z C">
      <data key="d0">Chen Z C</data>
      <data key="d1">person</data>
      <data key="d2">An author of the article on SAR image change detection.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009529</data>
      <data key="d6" />
    </node>
    <node id="Zhang B">
      <data key="d0">Zhang B</data>
      <data key="d1">person</data>
      <data key="d2">An author of the article on SAR image change detection.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009530</data>
      <data key="d6" />
    </node>
    <node id="SAR Images">
      <data key="d0">SAR Images</data>
      <data key="d1">data</data>
      <data key="d2">Synthetic Aperture Radar images, which are the subject of the change detection method.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009531</data>
      <data key="d6" />
    </node>
    <node id="Morphologically Supervised PCA-Net">
      <data key="d0">Morphologically Supervised PCA-Net</data>
      <data key="d1">method</data>
      <data key="d2">A neural network architecture used within the change detection method.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009532</data>
      <data key="d6" />
    </node>
    <node id="DOI: 10.1109/lgrs.2018.2878420">
      <data key="d0">DOI: 10.1109/lgrs.2018.2878420</data>
      <data key="d1">data</data>
      <data key="d2">The Digital Object Identifier for the published article.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009533</data>
      <data key="d6" />
    </node>
    <node id="Earth Science">
      <data key="d0">Earth Science</data>
      <data key="d1">concept</data>
      <data key="d2">The domain or field of study to which the document belongs.&lt;SEP&gt;Earth Science is the domain of the blog post, which discusses applications of deep learning in remote sensing.&lt;SEP&gt;The domain or field of study focused on the Earth and its processes.&lt;SEP&gt;The domain or field of study indicated by the document metadata.</data>
      <data key="d3">chunk-d03520804df199a76ce35edbbeca10f8&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1&lt;SEP&gt;chunk-333ff749c2940b520a06027eb3c17eac&lt;SEP&gt;chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010642</data>
      <data key="d6" />
    </node>
    <node id="遥感图像目标检测">
      <data key="d0">遥感图像目标检测</data>
      <data key="d1">method</data>
      <data key="d2">基于深度学习的遥感图像目标检测方法，从尺度不变性、旋转不变性、复杂背景干扰、样本量少和多波段数据检测5个角度进行总结。</data>
      <data key="d3">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009580</data>
      <data key="d6" />
    </node>
    <node id="尺度不变性">
      <data key="d0">尺度不变性</data>
      <data key="d1">concept</data>
      <data key="d2">遥感图像目标检测中需要考虑的一个角度，指检测方法应对目标尺度变化的能力。</data>
      <data key="d3">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009580</data>
      <data key="d6" />
    </node>
    <node id="旋转不变性">
      <data key="d0">旋转不变性</data>
      <data key="d1">concept</data>
      <data key="d2">遥感图像目标检测中需要考虑的一个角度，指检测方法应对目标旋转变化的能力。</data>
      <data key="d3">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009581</data>
      <data key="d6" />
    </node>
    <node id="复杂背景干扰">
      <data key="d0">复杂背景干扰</data>
      <data key="d1">concept</data>
      <data key="d2">遥感图像目标检测中需要考虑的一个角度，指检测方法应对复杂背景干扰的能力。</data>
      <data key="d3">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009584</data>
      <data key="d6" />
    </node>
    <node id="样本量少">
      <data key="d0">样本量少</data>
      <data key="d1">concept</data>
      <data key="d2">遥感图像目标检测中需要考虑的一个角度，指在训练样本数量有限的情况下进行检测的挑战。</data>
      <data key="d3">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009584</data>
      <data key="d6" />
    </node>
    <node id="多波段数据检测">
      <data key="d0">多波段数据检测</data>
      <data key="d1">concept</data>
      <data key="d2">遥感图像目标检测中需要考虑的一个角度，指利用遥感图像的多波段信息进行目标检测。</data>
      <data key="d3">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009585</data>
      <data key="d6" />
    </node>
    <node id="典型遥感图像目标">
      <data key="d0">典型遥感图像目标</data>
      <data key="d1">concept</data>
      <data key="d2">遥感图像中需要被检测的特定目标类别，其检测存在难点。</data>
      <data key="d3">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009586</data>
      <data key="d6" />
    </node>
    <node id="Global Features">
      <data key="d0">Global Features</data>
      <data key="d1">concept</data>
      <data key="d2">Features extracted by deep learning models for satellite remote sensing image retrieval and positioning, showing higher effectiveness compared to local features.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009652</data>
      <data key="d6" />
    </node>
    <node id="Satellite Remote Sensing Image Retrieval">
      <data key="d0">Satellite Remote Sensing Image Retrieval</data>
      <data key="d1">method</data>
      <data key="d2">The task of retrieving satellite remote sensing images, for which deep learning-derived global features provide a new approach.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009652</data>
      <data key="d6" />
    </node>
    <node id="Satellite Remote Sensing Image Positioning">
      <data key="d0">Satellite Remote Sensing Image Positioning</data>
      <data key="d1">method</data>
      <data key="d2">The task of positioning satellite remote sensing images, for which deep learning-derived global features provide a new approach.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009657</data>
      <data key="d6" />
    </node>
    <node id="Evaluation System">
      <data key="d0">Evaluation System</data>
      <data key="d1">method</data>
      <data key="d2">A system established to evaluate the feasibility of deep learning global features, quantifying Precision@K, average ranking, feature extraction time, similarity calculation time, and hardware consumption.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009657</data>
      <data key="d6" />
    </node>
    <node id="Precision@K">
      <data key="d0">Precision@K</data>
      <data key="d1">data</data>
      <data key="d2">A metric quantified by the evaluation system to measure the effectiveness of retrieval and positioning methods.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009658</data>
      <data key="d6" />
    </node>
    <node id="DenseNet">
      <data key="d0">DenseNet</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning model whose performance on test datasets is relatively better, with the highest Precision@K, indicating the highest success rate.&lt;SEP&gt;DenseNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009809</data>
      <data key="d6" />
    </node>
    <node id="ResNet-18">
      <data key="d0">ResNet-18</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning model whose performance on test datasets is relatively better.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009651</data>
      <data key="d6" />
    </node>
    <node id="VggNet">
      <data key="d0">VggNet</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning model whose performance on test datasets is relatively better.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009653</data>
      <data key="d6" />
    </node>
    <node id="Image Representation">
      <data key="d0">Image Representation</data>
      <data key="d1">concept</data>
      <data key="d2">The representation of images, for which global features extracted by deep learning models are used.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009654</data>
      <data key="d6" />
    </node>
    <node id="Local Features">
      <data key="d0">Local Features</data>
      <data key="d1">concept</data>
      <data key="d2">Features compared against global features in the study, with global features showing higher effectiveness for satellite remote sensing image retrieval and positioning.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009656</data>
      <data key="d6" />
    </node>
    <node id="Average Ranking">
      <data key="d0">Average Ranking</data>
      <data key="d1">data</data>
      <data key="d2">A metric quantified by the evaluation system to measure the effectiveness of retrieval and positioning methods.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009657</data>
      <data key="d6" />
    </node>
    <node id="Feature Extraction Time">
      <data key="d0">Feature Extraction Time</data>
      <data key="d1">data</data>
      <data key="d2">A metric quantified by the evaluation system to measure the efficiency of the methods.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009658</data>
      <data key="d6" />
    </node>
    <node id="Feature Similarity Calculation Time">
      <data key="d0">Feature Similarity Calculation Time</data>
      <data key="d1">data</data>
      <data key="d2">A metric quantified by the evaluation system to measure the efficiency of the methods.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009659</data>
      <data key="d6" />
    </node>
    <node id="Hardware Consumption">
      <data key="d0">Hardware Consumption</data>
      <data key="d1">data</data>
      <data key="d2">A metric quantified by the evaluation system to measure the efficiency of the methods.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009661</data>
      <data key="d6" />
    </node>
    <node id="Test Datasets">
      <data key="d0">Test Datasets</data>
      <data key="d1">data</data>
      <data key="d2">The datasets used to evaluate and compare the performance of deep learning models like DenseNet, ResNet-18, and VggNet.</data>
      <data key="d3">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009661</data>
      <data key="d6" />
    </node>
    <node id="Lavaan">
      <data key="d0">Lavaan</data>
      <data key="d1">method</data>
      <data key="d2">Lavaan is a software package used for structural equation modeling (SEM).</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009773</data>
      <data key="d6" />
    </node>
    <node id="Structural Equation Modeling (SEM)">
      <data key="d0">Structural Equation Modeling (SEM)</data>
      <data key="d1">method</data>
      <data key="d2">Structural equation modeling (SEM) is a statistical method used for testing and estimating causal relationships.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009773</data>
      <data key="d6" />
    </node>
    <node id="SWAP Agricultural Model">
      <data key="d0">SWAP Agricultural Model</data>
      <data key="d1">method</data>
      <data key="d2">The SWAP agricultural model is used for simulating water and solute transport in soil-plant-atmosphere systems.&lt;SEP&gt;The SWAP agricultural model is mentioned in the context of sensitivity analysis and climate change impact studies.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009774</data>
      <data key="d6" />
    </node>
    <node id="Climate Change">
      <data key="d0">Climate Change</data>
      <data key="d1">concept</data>
      <data key="d2">Climate change refers to long-term shifts in temperatures and weather patterns.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009776</data>
      <data key="d6" />
    </node>
    <node id="TRP Channel Protein">
      <data key="d0">TRP Channel Protein</data>
      <data key="d1">concept</data>
      <data key="d2">TRP channel proteins are a group of ion channels involved in various sensory processes.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009776</data>
      <data key="d6" />
    </node>
    <node id="Water Transport">
      <data key="d0">Water Transport</data>
      <data key="d1">concept</data>
      <data key="d2">Water transport refers to the movement of water within biological systems or the environment.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009778</data>
      <data key="d6" />
    </node>
    <node id="Single Atom Catalysis">
      <data key="d0">Single Atom Catalysis</data>
      <data key="d1">concept</data>
      <data key="d2">Single atom catalysis involves catalysts where isolated metal atoms are dispersed on a support material.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009779</data>
      <data key="d6" />
    </node>
    <node id="Sustainable Resources">
      <data key="d0">Sustainable Resources</data>
      <data key="d1">concept</data>
      <data key="d2">Sustainable resources are materials and energy sources that can be replenished naturally.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009780</data>
      <data key="d6" />
    </node>
    <node id="Biomedical New Materials">
      <data key="d0">Biomedical New Materials</data>
      <data key="d1">concept</data>
      <data key="d2">Biomedical new materials are advanced materials developed for medical applications.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009781</data>
      <data key="d6" />
    </node>
    <node id="Archiver">
      <data key="d0">Archiver</data>
      <data key="d1">organization</data>
      <data key="d2">Archiver is an organization or platform mentioned in the context.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009783</data>
      <data key="d6" />
    </node>
    <node id="Science Net">
      <data key="d0">Science Net</data>
      <data key="d1">organization</data>
      <data key="d2">Science Net is a website or platform, indicated by its ICP备案号(ICP Filing Number).</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009783</data>
      <data key="d6" />
    </node>
    <node id="GMT+8">
      <data key="d0">GMT+8</data>
      <data key="d1">location</data>
      <data key="d2">GMT+8 is a time zone, indicating a geographical location.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009785</data>
      <data key="d6" />
    </node>
    <node id="2026-1-20">
      <data key="d0">2026-1-20</data>
      <data key="d1">event</data>
      <data key="d2">2026-1-20 is a specific date mentioned in the text.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009785</data>
      <data key="d6" />
    </node>
    <node id="ICP Filing Number 07017567-12">
      <data key="d0">ICP Filing Number 07017567-12</data>
      <data key="d1">data</data>
      <data key="d2">ICP Filing Number 07017567-12 is a registration identifier for the website Science Net.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009787</data>
      <data key="d6" />
    </node>
    <node id="17:34">
      <data key="d0">17:34</data>
      <data key="d1">event</data>
      <data key="d2">17:34 is a specific time mentioned in the text.</data>
      <data key="d3">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009787</data>
      <data key="d6" />
    </node>
    <node id="Lv Xiangyang">
      <data key="d0">Lv Xiangyang</data>
      <data key="d1">person</data>
      <data key="d2">Lv Xiangyang is the author of a personal blog post discussing deep learning applications in remote sensing image processing.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009789</data>
      <data key="d6" />
    </node>
    <node id="Remote Sensing Image">
      <data key="d0">Remote Sensing Image</data>
      <data key="d1">data</data>
      <data key="d2">Remote Sensing Images are data used in applications like mineral exploration, precision agriculture, urban planning, and disaster monitoring, and are processed using deep learning techniques.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009791</data>
      <data key="d6" />
    </node>
    <node id="Image Segmentation">
      <data key="d0">Image Segmentation</data>
      <data key="d1">concept</data>
      <data key="d2">Image Segmentation is the process of partitioning an image into multiple segments, with models like FCN, SegNet, and U-Net mentioned for remote sensing applications.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009803</data>
      <data key="d6" />
    </node>
    <node id="YOLO">
      <data key="d0">YOLO</data>
      <data key="d1">method</data>
      <data key="d2">YOLO (You Only Look Once) is a one-stage object detection model series mentioned as a possibility for remote sensing applications.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009798</data>
      <data key="d6" />
    </node>
    <node id="FCN">
      <data key="d0">FCN</data>
      <data key="d1">method</data>
      <data key="d2">FCN (Fully Convolutional Network) is a model mentioned in the context of remote sensing image segmentation.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009799</data>
      <data key="d6" />
    </node>
    <node id="SegNet">
      <data key="d0">SegNet</data>
      <data key="d1">method</data>
      <data key="d2">SegNet is a model mentioned in the context of remote sensing image segmentation.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009808</data>
      <data key="d6" />
    </node>
    <node id="U-Net">
      <data key="d0">U-Net</data>
      <data key="d1">method</data>
      <data key="d2">U-Net is a model mentioned in the context of remote sensing image segmentation.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009808</data>
      <data key="d6" />
    </node>
    <node id="VGG">
      <data key="d0">VGG</data>
      <data key="d1">method</data>
      <data key="d2">VGG is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009804</data>
      <data key="d6" />
    </node>
    <node id="mAP">
      <data key="d0">mAP</data>
      <data key="d1">concept</data>
      <data key="d2">mAP (mean Average Precision) is a metric used to evaluate the accuracy of object detection models.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009808</data>
      <data key="d6" />
    </node>
    <node id="R Language">
      <data key="d0">R Language</data>
      <data key="d1">method</data>
      <data key="d2">The R language is mentioned in the context of implementing Bayesian models and structural equation models (SEM) for practical applications.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009810</data>
      <data key="d6" />
    </node>
    <node id="Structural Equation Model (SEM)">
      <data key="d0">Structural Equation Model (SEM)</data>
      <data key="d1">method</data>
      <data key="d2">Structural Equation Modeling is a statistical method mentioned as being implemented using the R package 'lavaan' for practical applications.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009819</data>
      <data key="d6" />
    </node>
    <node id="PLUS-InVEST Model">
      <data key="d0">PLUS-InVEST Model</data>
      <data key="d1">method</data>
      <data key="d2">The PLUS-InVEST model is mentioned for ecosystem service assessment and scenario simulation.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009821</data>
      <data key="d6" />
    </node>
    <node id="Visual MODFLOW Flex">
      <data key="d0">Visual MODFLOW Flex</data>
      <data key="d1">method</data>
      <data key="d2">Visual MODFLOW Flex is a software mentioned for groundwater modeling.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009823</data>
      <data key="d6" />
    </node>
    <node id="Mineral Exploration">
      <data key="d0">Mineral Exploration</data>
      <data key="d1">concept</data>
      <data key="d2">Mineral Exploration is one of the application areas mentioned for remote sensing images.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009824</data>
      <data key="d6" />
    </node>
    <node id="Precision Agriculture">
      <data key="d0">Precision Agriculture</data>
      <data key="d1">concept</data>
      <data key="d2">Precision Agriculture is one of the application areas mentioned for remote sensing images.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009826</data>
      <data key="d6" />
    </node>
    <node id="Urban Planning">
      <data key="d0">Urban Planning</data>
      <data key="d1">concept</data>
      <data key="d2">Urban Planning is one of the application areas mentioned for remote sensing images.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009827</data>
      <data key="d6" />
    </node>
    <node id="Disaster Monitoring">
      <data key="d0">Disaster Monitoring</data>
      <data key="d1">concept</data>
      <data key="d2">Disaster Monitoring is one of the application areas mentioned for remote sensing images.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009828</data>
      <data key="d6" />
    </node>
    <node id="R-CNN">
      <data key="d0">R-CNN</data>
      <data key="d1">method</data>
      <data key="d2">R-CNN is mentioned as a possible model in the evolution of two-stage object detectors for remote sensing.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009828</data>
      <data key="d6" />
    </node>
    <node id="Fast R-CNN">
      <data key="d0">Fast R-CNN</data>
      <data key="d1">method</data>
      <data key="d2">Fast R-CNN is mentioned as a possible model in the evolution of two-stage object detectors for remote sensing.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009832</data>
      <data key="d6" />
    </node>
    <node id="Bayesian Model">
      <data key="d0">Bayesian Model</data>
      <data key="d1">method</data>
      <data key="d2">Bayesian models are mentioned as being implemented using the R language for practical applications.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009833</data>
      <data key="d6" />
    </node>
    <node id="Forest Model">
      <data key="d0">Forest Model</data>
      <data key="d1">method</data>
      <data key="d2">Forest models and related computational methods are mentioned as topics for practical application.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009826</data>
      <data key="d6" />
    </node>
    <node id="Groundwater Modeling">
      <data key="d0">Groundwater Modeling</data>
      <data key="d1">concept</data>
      <data key="d2">Groundwater modeling is a topic mentioned in the context of using Visual MODFLOW Flex.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009826</data>
      <data key="d6" />
    </node>
    <node id="Sensitivity Analysis">
      <data key="d0">Sensitivity Analysis</data>
      <data key="d1">concept</data>
      <data key="d2">Sensitivity analysis is mentioned in the context of applying the SWAP agricultural model.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009828</data>
      <data key="d6" />
    </node>
    <node id="Climate Change Impact">
      <data key="d0">Climate Change Impact</data>
      <data key="d1">concept</data>
      <data key="d2">Climate change impact studies are mentioned in the context of applying the SWAP agricultural model.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009828</data>
      <data key="d6" />
    </node>
    <node id="Ecosystem Service Assessment">
      <data key="d0">Ecosystem Service Assessment</data>
      <data key="d1">concept</data>
      <data key="d2">Ecosystem service assessment is mentioned in the context of using the PLUS-InVEST model.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009830</data>
      <data key="d6" />
    </node>
    <node id="Scenario Simulation">
      <data key="d0">Scenario Simulation</data>
      <data key="d1">concept</data>
      <data key="d2">Scenario simulation is mentioned in the context of using the PLUS-InVEST model.</data>
      <data key="d3">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009830</data>
      <data key="d6" />
    </node>
    <node id="地球观测卫星">
      <data key="d0">地球观测卫星</data>
      <data key="d1">artifact</data>
      <data key="d2">Earth observation satellites are increasing in number and are used to collect climate data.</data>
      <data key="d3">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009892</data>
      <data key="d6" />
    </node>
    <node id="气候模型">
      <data key="d0">气候模型</data>
      <data key="d1">concept</data>
      <data key="d2">Climate models are becoming more abundant and are evolving into a data-related problem.</data>
      <data key="d3">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009892</data>
      <data key="d6" />
    </node>
    <node id="气候学">
      <data key="d0">气候学</data>
      <data key="d1">concept</data>
      <data key="d2">Climatology is the scientific field being combined with artificial intelligence for data analysis.</data>
      <data key="d3">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009895</data>
      <data key="d6" />
    </node>
    <node id="气候数据">
      <data key="d0">气候数据</data>
      <data key="d1">data</data>
      <data key="d2">Climate data is voluminous and is being analyzed to discover new models and improve weather forecasting.</data>
      <data key="d3">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009895</data>
      <data key="d6" />
    </node>
    <node id="研究人员">
      <data key="d0">研究人员</data>
      <data key="d1">person</data>
      <data key="d2">Researchers are attempting to integrate artificial intelligence with climatology.</data>
      <data key="d3">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009897</data>
      <data key="d6" />
    </node>
    <node id="天气">
      <data key="d0">天气</data>
      <data key="d1">concept</data>
      <data key="d2">Weather is the phenomenon that researchers aim to improve the forecasting of through data analysis.</data>
      <data key="d3">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009899</data>
      <data key="d6" />
    </node>
    <node id="DFS-M">
      <data key="d0">DFS-M</data>
      <data key="d1">method</data>
      <data key="d2">DFS-M is a model used for weather and climate forecasting.</data>
      <data key="d3">chunk-babf4b9b036bdc4286b6ed4dc016cba8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009922</data>
      <data key="d6" />
    </node>
    <node id="DFS-S">
      <data key="d0">DFS-S</data>
      <data key="d1">method</data>
      <data key="d2">DFS-S is a model used for weather and climate forecasting.</data>
      <data key="d3">chunk-babf4b9b036bdc4286b6ed4dc016cba8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009922</data>
      <data key="d6" />
    </node>
    <node id="Weather And Climate Forecasting">
      <data key="d0">Weather And Climate Forecasting</data>
      <data key="d1">concept</data>
      <data key="d2">Weather and climate forecasting is the process of predicting atmospheric conditions, which is the application domain of the study.</data>
      <data key="d3">chunk-babf4b9b036bdc4286b6ed4dc016cba8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009924</data>
      <data key="d6" />
    </node>
    <node id="This Study">
      <data key="d0">This Study</data>
      <data key="d1">content</data>
      <data key="d2">This study provides new ideas for selecting deep learning-based weather and climate forecasting methods.</data>
      <data key="d3">chunk-babf4b9b036bdc4286b6ed4dc016cba8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009924</data>
      <data key="d6" />
    </node>
    <node id="深度学习地球系统模型">
      <data key="d0">深度学习地球系统模型</data>
      <data key="d1">method</data>
      <data key="d2">A deep learning-based Earth system model (DLESyM) that uses two parallel neural networks to simulate the ocean and atmosphere, capable of accurate short-term predictions and simulating climate over a 1000-year period.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009999</data>
      <data key="d6" />
    </node>
    <node id="Cresswell-Clay">
      <data key="d0">Cresswell-Clay</data>
      <data key="d1">person</data>
      <data key="d2">The creator of the Deep Learning Earth System Model (DLESyM).</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769009999</data>
      <data key="d6" />
    </node>
    <node id="耦合模式比对计划第六阶段">
      <data key="d0">耦合模式比对计划第六阶段</data>
      <data key="d1">method</data>
      <data key="d2">The Coupled Model Intercomparison Project Phase 6 (CMIP6), a framework widely used in computational climate research for model comparison.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010005</data>
      <data key="d6" />
    </node>
    <node id="热带气旋">
      <data key="d0">热带气旋</data>
      <data key="d1">naturalobject</data>
      <data key="d2">A type of storm system that the DLESyM model excels at simulating compared to CMIP6 models.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010005</data>
      <data key="d6" />
    </node>
    <node id="印度夏季季风">
      <data key="d0">印度夏季季风</data>
      <data key="d1">naturalobject</data>
      <data key="d2">The Indian summer monsoon, a climate phenomenon that the DLESyM model simulates better than CMIP6 models.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010006</data>
      <data key="d6" />
    </node>
    <node id="北半球大气阻塞事件">
      <data key="d0">北半球大气阻塞事件</data>
      <data key="d1">event</data>
      <data key="d2">Atmospheric blocking events in the Northern Hemisphere that can lead to extreme weather, which DLESyM captures accurately.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010007</data>
      <data key="d6" />
    </node>
    <node id="东北风暴">
      <data key="d0">东北风暴</data>
      <data key="d1">naturalobject</data>
      <data key="d2">A nor'easter storm; the structure of one generated at the end of a 1000-year DLESyM simulation was very similar to one observed in 2018.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010008</data>
      <data key="d6" />
    </node>
    <node id="AGU Advances">
      <data key="d0">AGU Advances</data>
      <data key="d1">content</data>
      <data key="d2">A scientific journal that is the source of the article discussing the DLESyM model.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010011</data>
      <data key="d6" />
    </node>
    <node id="Wiley">
      <data key="d0">Wiley</data>
      <data key="d1">organization</data>
      <data key="d2">The organization responsible for providing the translation of the Eos article into Chinese.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010012</data>
      <data key="d6" />
    </node>
    <node id="传统模型">
      <data key="d0">传统模型</data>
      <data key="d1">method</data>
      <data key="d2">Traditional weather and climate models that are slower and less energy-efficient compared to machine learning-based models.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010012</data>
      <data key="d6" />
    </node>
    <node id="海洋">
      <data key="d0">海洋</data>
      <data key="d1">naturalobject</data>
      <data key="d2">The ocean, which is simulated by one of the neural networks in the DLESyM model, with its conditions updated every four model days.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010014</data>
      <data key="d6" />
    </node>
    <node id="大气">
      <data key="d0">大气</data>
      <data key="d1">naturalobject</data>
      <data key="d2">The atmosphere, which is simulated by one of the neural networks in the DLESyM model, with its predictions updated every 12 model hours due to faster evolution.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010006</data>
      <data key="d6" />
    </node>
    <node id="气候">
      <data key="d0">气候</data>
      <data key="d1">concept</data>
      <data key="d2">The long-term patterns of temperature, humidity, wind, etc., which the DLESyM model can accurately simulate over a 1000-year period.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010006</data>
      <data key="d6" />
    </node>
    <node id="年际变化">
      <data key="d0">年际变化</data>
      <data key="d1">concept</data>
      <data key="d2">Interannual variability in climate, which the DLESyM model can accurately simulate.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010008</data>
      <data key="d6" />
    </node>
    <node id="计算气候研究">
      <data key="d0">计算气候研究</data>
      <data key="d1">concept</data>
      <data key="d2">The field of computational climate research where models like CMIP6 are widely used.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010009</data>
      <data key="d6" />
    </node>
    <node id="极端天气">
      <data key="d0">极端天气</data>
      <data key="d1">event</data>
      <data key="d2">Extreme weather events that can be caused by atmospheric blocking events, which DLESyM helps to predict.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010009</data>
      <data key="d6" />
    </node>
    <node id="Eos">
      <data key="d0">Eos</data>
      <data key="d1">content</data>
      <data key="d2">The original article source that was translated, published by AGU.</data>
      <data key="d3">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010012</data>
      <data key="d6" />
    </node>
    <node id="Meteorological Elements Forecasting Method">
      <data key="d0">Meteorological Elements Forecasting Method</data>
      <data key="d1">method</data>
      <data key="d2">A forecasting method for meteorological elements that is based on deep learning techniques.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010096</data>
      <data key="d6" />
    </node>
    <node id="Long Short Term Memory">
      <data key="d0">Long Short Term Memory</data>
      <data key="d1">method</data>
      <data key="d2">A type of recurrent neural network architecture capable of learning long-term dependencies, mentioned as a key word.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010099</data>
      <data key="d6" />
    </node>
    <node id="Monthly Rainfall Forecasting">
      <data key="d0">Monthly Rainfall Forecasting</data>
      <data key="d1">method</data>
      <data key="d2">A specific application of forecasting that predicts monthly rainfall, utilizing a one-dimensional deep convolutional neural network.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010101</data>
      <data key="d6" />
    </node>
    <node id="One-Dimensional Deep Convolutional Neural Network">
      <data key="d0">One-Dimensional Deep Convolutional Neural Network</data>
      <data key="d1">method</data>
      <data key="d2">A neural network architecture using convolutional layers for processing one-dimensional data, applied to monthly rainfall forecasting.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010102</data>
      <data key="d6" />
    </node>
    <node id="Ensemble Of Neural Networks">
      <data key="d0">Ensemble Of Neural Networks</data>
      <data key="d1">method</data>
      <data key="d2">A method for weather forecasting that combines predictions from multiple neural network models.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010103</data>
      <data key="d6" />
    </node>
    <node id="Weather Forecasting">
      <data key="d0">Weather Forecasting</data>
      <data key="d1">concept</data>
      <data key="d2">The application of science and technology to predict atmospheric conditions, addressed by the ensemble neural network method.&lt;SEP&gt;The process of predicting future weather conditions.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0&lt;SEP&gt;chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010267</data>
      <data key="d6" />
    </node>
    <node id="Flood Forecasting">
      <data key="d0">Flood Forecasting</data>
      <data key="d1">concept</data>
      <data key="d2">The process of predicting the occurrence, magnitude, and timing of floods, for which input determination methods are discussed.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010106</data>
      <data key="d6" />
    </node>
    <node id="Copula Entropy Method">
      <data key="d0">Copula Entropy Method</data>
      <data key="d1">method</data>
      <data key="d2">A method used to determine input variables for artificial neural networks in the context of flood forecasting.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010109</data>
      <data key="d6" />
    </node>
    <node id="Prediction Interval">
      <data key="d0">Prediction Interval</data>
      <data key="d1">concept</data>
      <data key="d2">A range of values used to quantify the uncertainty of a prediction, with methods for its quantification in hydrological models being compared.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010109</data>
      <data key="d6" />
    </node>
    <node id="Artificial Neural Network Hydrologic Models">
      <data key="d0">Artificial Neural Network Hydrologic Models</data>
      <data key="d1">method</data>
      <data key="d2">Hydrological models that utilize artificial neural networks for simulation and prediction.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010111</data>
      <data key="d6" />
    </node>
    <node id="Rainfall-Runoff Process">
      <data key="d0">Rainfall-Runoff Process</data>
      <data key="d1">concept</data>
      <data key="d2">The physical process by which rainfall is transformed into runoff in a catchment area, which is modeled using artificial neural networks.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010111</data>
      <data key="d6" />
    </node>
    <node id="Deep Neural Network Modeling">
      <data key="d0">Deep Neural Network Modeling</data>
      <data key="d1">method</data>
      <data key="d2">The application of deep neural networks for creating models, specifically mentioned for big data weather forecasting.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010111</data>
      <data key="d6" />
    </node>
    <node id="Big Data Weather Forecasting">
      <data key="d0">Big Data Weather Forecasting</data>
      <data key="d1">concept</data>
      <data key="d2">Weather forecasting that leverages large and complex datasets, facilitated by deep neural network modeling.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010115</data>
      <data key="d6" />
    </node>
    <node id="Information Granularity">
      <data key="d0">Information Granularity</data>
      <data key="d1">concept</data>
      <data key="d2">A concept related to the level of detail or abstraction in data, mentioned in the context of big data and computational intelligence.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010124</data>
      <data key="d6" />
    </node>
    <node id="Computational Intelligence">
      <data key="d0">Computational Intelligence</data>
      <data key="d1">concept</data>
      <data key="d2">A branch of artificial intelligence involving adaptive mechanisms to facilitate intelligent behavior, mentioned alongside big data.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010124</data>
      <data key="d6" />
    </node>
    <node id="Hydrological Early Warning System">
      <data key="d0">Hydrological Early Warning System</data>
      <data key="d1">method</data>
      <data key="d2">A system designed to provide advance warning of hydrological hazards, based on a deep learning runoff model coupled with meteorological forecasts.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010119</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning Runoff Model">
      <data key="d0">Deep Learning Runoff Model</data>
      <data key="d1">method</data>
      <data key="d2">A model for predicting runoff using deep learning techniques, integrated into a hydrological early warning system.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010119</data>
      <data key="d6" />
    </node>
    <node id="Meteorological Forecast">
      <data key="d0">Meteorological Forecast</data>
      <data key="d1">concept</data>
      <data key="d2">A prediction of future atmospheric conditions, coupled with the runoff model in the early warning system.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010119</data>
      <data key="d6" />
    </node>
    <node id="Shi X J">
      <data key="d0">Shi X J</data>
      <data key="d1">person</data>
      <data key="d2">An author listed in the citation for a paper or work, likely a researcher in the field.&lt;SEP&gt;A researcher who co-authored a scientific paper in 2015.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0&lt;SEP&gt;chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010632</data>
      <data key="d6" />
    </node>
    <node id="Shi Z R">
      <data key="d0">Shi Z R</data>
      <data key="d1">person</data>
      <data key="d2">An author listed in the citation for a paper or work, likely a researcher in the field.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010123</data>
      <data key="d6" />
    </node>
    <node id="Wan H G">
      <data key="d0">Wan H G</data>
      <data key="d1">person</data>
      <data key="d2">An author listed in the citation for a paper or work, likely a researcher in the field.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010123</data>
      <data key="d6" />
    </node>
    <node id="Deep Learning In Neural Networks: An Overview">
      <data key="d0">Deep Learning In Neural Networks: An Overview</data>
      <data key="d1">content</data>
      <data key="d2">A cited paper or work that provides an overview of deep learning within neural networks.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010125</data>
      <data key="d6" />
    </node>
    <node id="J(x)">
      <data key="d0">J(x)</data>
      <data key="d1">method</data>
      <data key="d2">A mathematical cost function or objective function used in data assimilation or optimization, presented in the text with a specific formula.</data>
      <data key="d3">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010125</data>
      <data key="d6" />
    </node>
    <node id="数值天气预报">
      <data key="d0">数值天气预报</data>
      <data key="d1">method</data>
      <data key="d2">一种基于物理方程和数学模型的天气预报方法。</data>
      <data key="d3">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010175</data>
      <data key="d6" />
    </node>
    <node id="天气现象预报方法">
      <data key="d0">天气现象预报方法</data>
      <data key="d1">method</data>
      <data key="d2">一种结合深度学习和数值天气预报产品进行天气现象预测的方法。</data>
      <data key="d3">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010175</data>
      <data key="d6" />
    </node>
    <node id="数值天气预报产品">
      <data key="d0">数值天气预报产品</data>
      <data key="d1">data</data>
      <data key="d2">由数值天气预报模型生成的预报数据。</data>
      <data key="d3">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010180</data>
      <data key="d6" />
    </node>
    <node id="天气现象观测数据">
      <data key="d0">天气现象观测数据</data>
      <data key="d1">data</data>
      <data key="d2">对实际天气现象进行观测得到的数据。</data>
      <data key="d3">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010180</data>
      <data key="d6" />
    </node>
    <node id="深度学习网络模型">
      <data key="d0">深度学习网络模型</data>
      <data key="d1">method</data>
      <data key="d2">用于处理训练数据集并进行预测的深度学习模型架构。</data>
      <data key="d3">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010181</data>
      <data key="d6" />
    </node>
    <node id="气象预报应用领域">
      <data key="d0">气象预报应用领域</data>
      <data key="d1">concept</data>
      <data key="d2">The field of meteorological forecasting applications.</data>
      <data key="d3">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010204</data>
      <data key="d6" />
    </node>
    <node id="深度学习方法">
      <data key="d0">深度学习方法</data>
      <data key="d1">method</data>
      <data key="d2">Deep learning methods.</data>
      <data key="d3">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010204</data>
      <data key="d6" />
    </node>
    <node id="数值天气预报模式">
      <data key="d0">数值天气预报模式</data>
      <data key="d1">method</data>
      <data key="d2">Numerical weather prediction models.</data>
      <data key="d3">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010199</data>
      <data key="d6" />
    </node>
    <node id="气象科技进展">
      <data key="d0">气象科技进展</data>
      <data key="d1">content</data>
      <data key="d2">A publication titled "Advances in Meteorological Science and Technology".</data>
      <data key="d3">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010199</data>
      <data key="d6" />
    </node>
    <node id="学者">
      <data key="d0">学者</data>
      <data key="d1">person</data>
      <data key="d2">Scholars.</data>
      <data key="d3">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010200</data>
      <data key="d6" />
    </node>
    <node id="研究及挑战">
      <data key="d0">研究及挑战</data>
      <data key="d1">content</data>
      <data key="d2">Research and challenges.</data>
      <data key="d3">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010201</data>
      <data key="d6" />
    </node>
    <node id="直接预报模型">
      <data key="d0">直接预报模型</data>
      <data key="d1">method</data>
      <data key="d2">一种预报方法，在整体预报时段内的预报效果优于迭代预报模型，其RMSE比迭代预报模型低19%。</data>
      <data key="d3">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010223</data>
      <data key="d6" />
    </node>
    <node id="迭代预报模型">
      <data key="d0">迭代预报模型</data>
      <data key="d1">method</data>
      <data key="d2">一种预报方法，其预报误差会随着预报时次的增加而累积，在整体预报时段内的预报效果不如直接预报模型。</data>
      <data key="d3">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010223</data>
      <data key="d6" />
    </node>
    <node id="预报误差">
      <data key="d0">预报误差</data>
      <data key="d1">concept</data>
      <data key="d2">预报模型产生的误差，在迭代预报模型中会随着预报时次的增加而累积。</data>
      <data key="d3">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010226</data>
      <data key="d6" />
    </node>
    <node id="RMSE">
      <data key="d0">RMSE</data>
      <data key="d1">data</data>
      <data key="d2">均方根误差，用于衡量预报模型的精度，直接预报模型的RMSE比迭代预报模型低19%。</data>
      <data key="d3">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010226</data>
      <data key="d6" />
    </node>
    <node id="整体预报时段">
      <data key="d0">整体预报时段</data>
      <data key="d1">concept</data>
      <data key="d2">研究中所评估的预报效果所覆盖的整个时间范围。</data>
      <data key="d3">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010226</data>
      <data key="d6" />
    </node>
    <node id="LSTM Algorithm">
      <data key="d0">LSTM Algorithm</data>
      <data key="d1">method</data>
      <data key="d2">A specific type of recurrent neural network (RNN) architecture used for sequence prediction.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010269</data>
      <data key="d6" />
    </node>
    <node id="Historical Data">
      <data key="d0">Historical Data</data>
      <data key="d1">data</data>
      <data key="d2">Past weather data collected from various provinces across the country.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010269</data>
      <data key="d6" />
    </node>
    <node id="Real-Time Data">
      <data key="d0">Real-Time Data</data>
      <data key="d1">data</data>
      <data key="d2">Current and continuously updated weather data.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010272</data>
      <data key="d6" />
    </node>
    <node id="Weather Forecast">
      <data key="d0">Weather Forecast</data>
      <data key="d1">content</data>
      <data key="d2">Predictive information about future weather conditions.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010274</data>
      <data key="d6" />
    </node>
    <node id="Extreme Weather Warning">
      <data key="d0">Extreme Weather Warning</data>
      <data key="d1">content</data>
      <data key="d2">Alerts issued for hazardous weather conditions.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010277</data>
      <data key="d6" />
    </node>
    <node id="Life Index">
      <data key="d0">Life Index</data>
      <data key="d1">content</data>
      <data key="d2">Indices related to daily life and activities influenced by weather.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010277</data>
      <data key="d6" />
    </node>
    <node id="Visualization Dashboard">
      <data key="d0">Visualization Dashboard</data>
      <data key="d1">artifact</data>
      <data key="d2">A large screen or interface for displaying data in a visual format.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010277</data>
      <data key="d6" />
    </node>
    <node id="Hadoop">
      <data key="d0">Hadoop</data>
      <data key="d1">method</data>
      <data key="d2">A framework for distributed storage and processing of large data sets.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010280</data>
      <data key="d6" />
    </node>
    <node id="Spark">
      <data key="d0">Spark</data>
      <data key="d1">method</data>
      <data key="d2">A unified analytics engine for large-scale data processing.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010280</data>
      <data key="d6" />
    </node>
    <node id="Hive">
      <data key="d0">Hive</data>
      <data key="d1">method</data>
      <data key="d2">A data warehouse software for querying and managing large datasets.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010281</data>
      <data key="d6" />
    </node>
    <node id="全国各省">
      <data key="d0">全国各省</data>
      <data key="d1">location</data>
      <data key="d2">Refers to all provinces across the country, which are the geographical scope for data collection.</data>
      <data key="d3">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010281</data>
      <data key="d6" />
    </node>
    <node id="AARes-ConvLSTM">
      <data key="d0">AARes-ConvLSTM</data>
      <data key="d1">method</data>
      <data key="d2">A machine learning method mentioned in the context of intelligent climate prediction.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010422</data>
      <data key="d6" />
    </node>
    <node id="均方根误差">
      <data key="d0">均方根误差</data>
      <data key="d1">concept</data>
      <data key="d2">A statistical measure of error, likely used to evaluate climate prediction models.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010422</data>
      <data key="d6" />
    </node>
    <node id="预报技巧">
      <data key="d0">预报技巧</data>
      <data key="d1">concept</data>
      <data key="d2">A concept referring to the skill or accuracy of weather or climate forecasts.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010423</data>
      <data key="d6" />
    </node>
    <node id="智能气候预测">
      <data key="d0">智能气候预测</data>
      <data key="d1">concept</data>
      <data key="d2">The concept of intelligent climate prediction, involving the use of advanced methods like machine learning.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010426</data>
      <data key="d6" />
    </node>
    <node id="基于机器学习方法的中国降水预测">
      <data key="d0">基于机器学习方法的中国降水预测</data>
      <data key="d1">content</data>
      <data key="d2">A report or study content on precipitation prediction in China using machine learning methods.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010426</data>
      <data key="d6" />
    </node>
    <node id="基于中尺度气象同化预报和深度学习的风速预报">
      <data key="d0">基于中尺度气象同化预报和深度学习的风速预报</data>
      <data key="d1">content</data>
      <data key="d2">A report or study content on wind speed forecasting using mesoscale meteorological assimilation and deep learning.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010435</data>
      <data key="d6" />
    </node>
    <node id="光伏电站太阳辐射超短期预报">
      <data key="d0">光伏电站太阳辐射超短期预报</data>
      <data key="d1">content</data>
      <data key="d2">A report or study content on ultra-short-term solar radiation forecasting for photovoltaic power stations.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010428</data>
      <data key="d6" />
    </node>
    <node id="基于深度学习的北极地区格点化地表气温重建">
      <data key="d0">基于深度学习的北极地区格点化地表气温重建</data>
      <data key="d1">content</data>
      <data key="d2">A report or study content on reconstructing gridded surface air temperature in the Arctic region using deep learning.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010429</data>
      <data key="d6" />
    </node>
    <node id="气象人工智能未来发展思考">
      <data key="d0">气象人工智能未来发展思考</data>
      <data key="d1">content</data>
      <data key="d2">A report or study content discussing future developments in meteorological artificial intelligence.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010430</data>
      <data key="d6" />
    </node>
    <node id="极地缺测">
      <data key="d0">极地缺测</data>
      <data key="d1">concept</data>
      <data key="d2">The concept of missing observations in polar regions, which impacts the study of global temperature changes.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010441</data>
      <data key="d6" />
    </node>
    <node id="全球温度变化">
      <data key="d0">全球温度变化</data>
      <data key="d1">concept</data>
      <data key="d2">The concept of global temperature change, a key subject of climate research.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010441</data>
      <data key="d6" />
    </node>
    <node id="地表空气温度数据集">
      <data key="d0">地表空气温度数据集</data>
      <data key="d1">data</data>
      <data key="d2">A dataset of surface air temperature covering areas north of 30°N, created to address data gaps.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010443</data>
      <data key="d6" />
    </node>
    <node id="北极地区">
      <data key="d0">北极地区</data>
      <data key="d1">location</data>
      <data key="d2">The Arctic region, noted for having limited observational data.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010443</data>
      <data key="d6" />
    </node>
    <node id="格陵兰岛">
      <data key="d0">格陵兰岛</data>
      <data key="d1">location</data>
      <data key="d2">Greenland, identified as an area with particularly scarce data.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010445</data>
      <data key="d6" />
    </node>
    <node id="北冰洋">
      <data key="d0">北冰洋</data>
      <data key="d1">location</data>
      <data key="d2">The Arctic Ocean, identified as an area with particularly scarce data.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010445</data>
      <data key="d6" />
    </node>
    <node id="HadCRUT5">
      <data key="d0">HadCRUT5</data>
      <data key="d1">data</data>
      <data key="d2">A global gridded temperature dataset covering 1850-2020 with monthly resolution, combining land (CRUTEM5) and sea (HadSST4) data.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010446</data>
      <data key="d6" />
    </node>
    <node id="GISTEMP v4">
      <data key="d0">GISTEMP v4</data>
      <data key="d1">data</data>
      <data key="d2">A global temperature dataset covering 1880-2020 with monthly resolution, combining land (GHCN v4) and sea (ERSST v5) data.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010446</data>
      <data key="d6" />
    </node>
    <node id="NOAAGlobalTemp-Interim">
      <data key="d0">NOAAGlobalTemp-Interim</data>
      <data key="d1">data</data>
      <data key="d2">A global temperature dataset covering 1850-2020 with monthly resolution, combining land (GHCN v4) and sea (ERSST v5) data.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010449</data>
      <data key="d6" />
    </node>
    <node id="BEST">
      <data key="d0">BEST</data>
      <data key="d1">data</data>
      <data key="d2">A global temperature dataset covering 1850-2020 with monthly resolution, combining land (GHCN v4) and sea (ERSST v5) data.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010450</data>
      <data key="d6" />
    </node>
    <node id="20CRv3">
      <data key="d0">20CRv3</data>
      <data key="d1">data</data>
      <data key="d2">A global atmospheric reanalysis dataset covering 1836-2015 with sub-daily resolution.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010453</data>
      <data key="d6" />
    </node>
    <node id="ERA5">
      <data key="d0">ERA5</data>
      <data key="d1">data</data>
      <data key="d2">A global atmospheric reanalysis dataset covering 1979-present with hourly resolution.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010453</data>
      <data key="d6" />
    </node>
    <node id="CERA-20C">
      <data key="d0">CERA-20C</data>
      <data key="d1">data</data>
      <data key="d2">A coupled global reanalysis dataset covering 1901-2010 with 3-hourly resolution.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010446</data>
      <data key="d6" />
    </node>
    <node id="Berkeley Earth">
      <data key="d0">Berkeley Earth</data>
      <data key="d1">organization</data>
      <data key="d2">An organization producing the BEST global temperature dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010446</data>
      <data key="d6" />
    </node>
    <node id="ECMWF">
      <data key="d0">ECMWF</data>
      <data key="d1">organization</data>
      <data key="d2">The European Centre for Medium-Range Weather Forecasts, producer of the ERA5 and CERA-20C reanalysis datasets.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010448</data>
      <data key="d6" />
    </node>
    <node id="Huang et al.">
      <data key="d0">Huang et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers who published work on observation coverage, cited in the context of Arctic data limitations.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010448</data>
      <data key="d6" />
    </node>
    <node id="Morice et al.">
      <data key="d0">Morice et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with the HadCRUT5 dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010449</data>
      <data key="d6" />
    </node>
    <node id="Lenssen et al.">
      <data key="d0">Lenssen et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with the GISTEMP v4 dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010449</data>
      <data key="d6" />
    </node>
    <node id="Vose et al.">
      <data key="d0">Vose et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with the NOAAGlobalTemp-Interim dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010461</data>
      <data key="d6" />
    </node>
    <node id="Rohde et al.">
      <data key="d0">Rohde et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with the BEST dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010461</data>
      <data key="d6" />
    </node>
    <node id="Compo et al.">
      <data key="d0">Compo et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with the 20CRv3 dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010462</data>
      <data key="d6" />
    </node>
    <node id="Hersbach et al.">
      <data key="d0">Hersbach et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with the ERA5 dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010463</data>
      <data key="d6" />
    </node>
    <node id="Laloyaux et al.">
      <data key="d0">Laloyaux et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with the CERA-20C dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010465</data>
      <data key="d6" />
    </node>
    <node id="Kadow et al.">
      <data key="d0">Kadow et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with a dataset combining CRUTEM5 and HadSST4.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010467</data>
      <data key="d6" />
    </node>
    <node id="Vaccaro et al.">
      <data key="d0">Vaccaro et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with a dataset combining CRUTEM4 and HadSST3.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010467</data>
      <data key="d6" />
    </node>
    <node id="Dahlgren et al.">
      <data key="d0">Dahlgren et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with a dataset covering most of the Arctic from 2000-2012.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010469</data>
      <data key="d6" />
    </node>
    <node id="Rigor et al.">
      <data key="d0">Rigor et al.</data>
      <data key="d1">person</data>
      <data key="d2">Researchers associated with a method described as optimal interpolation.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010469</data>
      <data key="d6" />
    </node>
    <node id="报告内容">
      <data key="d0">报告内容</data>
      <data key="d1">content</data>
      <data key="d2">The general content of the report, encompassing various topics on intelligent climate prediction and case studies.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010470</data>
      <data key="d6" />
    </node>
    <node id="研究目的">
      <data key="d0">研究目的</data>
      <data key="d1">concept</data>
      <data key="d2">The research objective mentioned is to understand the situation and impact of missing data in the Arctic.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010471</data>
      <data key="d6" />
    </node>
    <node id="1850年至今HadCRUT5观测覆盖情况">
      <data key="d0">1850年至今HadCRUT5观测覆盖情况</data>
      <data key="d1">content</data>
      <data key="d2">A specific analysis or figure showing the observation coverage of the HadCRUT5 dataset from 1850 to the present.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010473</data>
      <data key="d6" />
    </node>
    <node id="全球格点温度资料">
      <data key="d0">全球格点温度资料</data>
      <data key="d1">concept</data>
      <data key="d2">The concept of global gridded temperature data, which is the subject of the listed datasets.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010474</data>
      <data key="d6" />
    </node>
    <node id="基于器测观测的全球温度资料">
      <data key="d0">基于器测观测的全球温度资料</data>
      <data key="d1">concept</data>
      <data key="d2">The concept of global temperature data based on instrumental observations.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010467</data>
      <data key="d6" />
    </node>
    <node id="序号">
      <data key="d0">序号</data>
      <data key="d1">concept</data>
      <data key="d2">A list number or sequence identifier used in the table of temperature datasets.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010467</data>
      <data key="d6" />
    </node>
    <node id="资料">
      <data key="d0">资料</data>
      <data key="d1">concept</data>
      <data key="d2">Refers to the dataset entries listed in the table.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010469</data>
      <data key="d6" />
    </node>
    <node id="起止时间">
      <data key="d0">起止时间</data>
      <data key="d1">concept</data>
      <data key="d2">The start and end time period for each dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010469</data>
      <data key="d6" />
    </node>
    <node id="时间分辨率">
      <data key="d0">时间分辨率</data>
      <data key="d1">concept</data>
      <data key="d2">The temporal resolution (e.g., monthly, hourly) of each dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010471</data>
      <data key="d6" />
    </node>
    <node id="陆地气温资料">
      <data key="d0">陆地气温资料</data>
      <data key="d1">concept</data>
      <data key="d2">The land temperature data component used in each global dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010472</data>
      <data key="d6" />
    </node>
    <node id="海表面温度">
      <data key="d0">海表面温度</data>
      <data key="d1">concept</data>
      <data key="d2">The sea surface temperature data component used in each global dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010472</data>
      <data key="d6" />
    </node>
    <node id="参考文献">
      <data key="d0">参考文献</data>
      <data key="d1">concept</data>
      <data key="d2">The reference citation for each dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010474</data>
      <data key="d6" />
    </node>
    <node id="CRUTEM5">
      <data key="d0">CRUTEM5</data>
      <data key="d1">data</data>
      <data key="d2">The land air temperature component used in datasets like HadCRUT5.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010476</data>
      <data key="d6" />
    </node>
    <node id="HadSST4">
      <data key="d0">HadSST4</data>
      <data key="d1">data</data>
      <data key="d2">The sea surface temperature component used in datasets like HadCRUT5.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010485</data>
      <data key="d6" />
    </node>
    <node id="GHCN v4">
      <data key="d0">GHCN v4</data>
      <data key="d1">data</data>
      <data key="d2">The Global Historical Climatology Network version 4, a land temperature data component.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010478</data>
      <data key="d6" />
    </node>
    <node id="ERSST v5">
      <data key="d0">ERSST v5</data>
      <data key="d1">data</data>
      <data key="d2">The Extended Reconstructed Sea Surface Temperature version 5, a sea surface temperature data component.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010478</data>
      <data key="d6" />
    </node>
    <node id="CRUTEM4">
      <data key="d0">CRUTEM4</data>
      <data key="d1">data</data>
      <data key="d2">An earlier version of the land air temperature component.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010480</data>
      <data key="d6" />
    </node>
    <node id="HadSST3">
      <data key="d0">HadSST3</data>
      <data key="d1">data</data>
      <data key="d2">An earlier version of the sea surface temperature component.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010480</data>
      <data key="d6" />
    </node>
    <node id="2000-2012">
      <data key="d0">2000-2012</data>
      <data key="d1">concept</data>
      <data key="d2">The time period covered by a specific Arctic dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010482</data>
      <data key="d6" />
    </node>
    <node id="Most of the Arctic">
      <data key="d0">Most of the Arctic</data>
      <data key="d1">location</data>
      <data key="d2">The geographical coverage of a specific dataset mentioned.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010482</data>
      <data key="d6" />
    </node>
    <node id="30 km, L71">
      <data key="d0">30 km, L71</data>
      <data key="d1">concept</data>
      <data key="d2">Spatial and vertical resolution details (likely 30 km horizontal, 71 levels) for a dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010482</data>
      <data key="d6" />
    </node>
    <node id="15 km, L71">
      <data key="d0">15 km, L71</data>
      <data key="d1">concept</data>
      <data key="d2">Spatial and vertical resolution details (likely 15 km horizontal, 71 levels) for a dataset.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010486</data>
      <data key="d6" />
    </node>
    <node id="optimal interpolation">
      <data key="d0">optimal interpolation</data>
      <data key="d1">method</data>
      <data key="d2">A data assimilation or reconstruction method mentioned in the context of Rigor et al.'s work.</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010486</data>
      <data key="d6" />
    </node>
    <node id="北极缺测">
      <data key="d0">北极缺测</data>
      <data key="d3">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d2">The research purpose is defined as understanding the Arctic data gap situation and its impact.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010510</data>
      <data key="d6" />
    </node>
    <node id="Zheng Y G">
      <data key="d0">Zheng Y G</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored scientific papers in 2016b and 2015.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010608</data>
      <data key="d6" />
    </node>
    <node id="Zhu W J">
      <data key="d0">Zhu W J</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Zheng Y G et al. in 2016b.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010608</data>
      <data key="d6" />
    </node>
    <node id="Yao D">
      <data key="d0">Yao D</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Zheng Y G et al. in 2016b.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010609</data>
      <data key="d6" />
    </node>
    <node id="Zhou K H">
      <data key="d0">Zhou K H</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Zheng Y G et al. in 2015.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010612</data>
      <data key="d6" />
    </node>
    <node id="Sheng J">
      <data key="d0">Sheng J</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Zheng Y G et al. in 2015.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010612</data>
      <data key="d6" />
    </node>
    <node id="Billet J">
      <data key="d0">Billet J</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper in 1997.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010612</data>
      <data key="d6" />
    </node>
    <node id="DeLisi M">
      <data key="d0">DeLisi M</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Billet J et al. in 1997.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010614</data>
      <data key="d6" />
    </node>
    <node id="Smith B G">
      <data key="d0">Smith B G</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Billet J et al. in 1997.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010615</data>
      <data key="d6" />
    </node>
    <node id="Gagne II D J">
      <data key="d0">Gagne II D J</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored scientific papers in 2017 and 2019.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010616</data>
      <data key="d6" />
    </node>
    <node id="McGovern A">
      <data key="d0">McGovern A</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored scientific papers in 2017 and 2019.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010618</data>
      <data key="d6" />
    </node>
    <node id="Haupt S E">
      <data key="d0">Haupt S E</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Gagne II D J et al. in 2017.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010618</data>
      <data key="d6" />
    </node>
    <node id="Kim M">
      <data key="d0">Kim M</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper in 2017a.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010621</data>
      <data key="d6" />
    </node>
    <node id="Im J">
      <data key="d0">Im J</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Kim M et al. in 2017a.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010621</data>
      <data key="d6" />
    </node>
    <node id="Park H">
      <data key="d0">Park H</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Kim M et al. in 2017a.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010623</data>
      <data key="d6" />
    </node>
    <node id="Elmore K L">
      <data key="d0">Elmore K L</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with McGovern A et al. in 2017.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010623</data>
      <data key="d6" />
    </node>
    <node id="Lagerquist R">
      <data key="d0">Lagerquist R</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with McGovern A et al. in 2019.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010624</data>
      <data key="d6" />
    </node>
    <node id="Mecikalski J R">
      <data key="d0">Mecikalski J R</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored scientific papers in 2013, 2010a, and 2010b.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010624</data>
      <data key="d6" />
    </node>
    <node id="Li X L">
      <data key="d0">Li X L</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Mecikalski J R et al. in 2013.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010626</data>
      <data key="d6" />
    </node>
    <node id="Carey L D">
      <data key="d0">Carey L D</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Mecikalski J R et al. in 2013.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010635</data>
      <data key="d6" />
    </node>
    <node id="Mackenzie W M Jr">
      <data key="d0">Mackenzie W M Jr</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored scientific papers with Mecikalski J R et al. in 2010a and 2010b.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010629</data>
      <data key="d6" />
    </node>
    <node id="Köenig M">
      <data key="d0">Köenig M</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Mecikalski J R et al. in 2010a.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010629</data>
      <data key="d6" />
    </node>
    <node id="König M">
      <data key="d0">König M</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Mecikalski J R et al. in 2010b.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010632</data>
      <data key="d6" />
    </node>
    <node id="Chen Z R">
      <data key="d0">Chen Z R</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Shi X J et al. in 2015.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010633</data>
      <data key="d6" />
    </node>
    <node id="Wang H">
      <data key="d0">Wang H</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Shi X J et al. in 2015.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010634</data>
      <data key="d6" />
    </node>
    <node id="Wang Y B">
      <data key="d0">Wang Y B</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper in 2017.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010635</data>
      <data key="d6" />
    </node>
    <node id="Long M S">
      <data key="d0">Long M S</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Wang Y B et al. in 2017.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010635</data>
      <data key="d6" />
    </node>
    <node id="Wang J M">
      <data key="d0">Wang J M</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Wang Y B et al. in 2017.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010638</data>
      <data key="d6" />
    </node>
    <node id="Wilson J W">
      <data key="d0">Wilson J W</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper in 2010.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010638</data>
      <data key="d6" />
    </node>
    <node id="Feng Y R">
      <data key="d0">Feng Y R</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Wilson J W et al. in 2010.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010640</data>
      <data key="d6" />
    </node>
    <node id="Chen M">
      <data key="d0">Chen M</data>
      <data key="d1">person</data>
      <data key="d2">A researcher who co-authored a scientific paper with Wilson J W et al. in 2010.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010642</data>
      <data key="d6" />
    </node>
    <node id="DOC_ID: chunk-5fe70e58">
      <data key="d0">DOC_ID: chunk-5fe70e58</data>
      <data key="d1">data</data>
      <data key="d2">A unique document identifier for the provided text chunk.</data>
      <data key="d3">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010643</data>
      <data key="d6" />
    </node>
    <node id="技术哲学">
      <data key="d0">技术哲学</data>
      <data key="d1">concept</data>
      <data key="d2">技术哲学是从哲学角度审视技术(如深度学习)的学科领域。&lt;SEP&gt;技术哲学是哲学中因人工智能普遍应用而可能兴起的新领域，专门研究技术如何塑造生活世界等基础议题，并与传统哲学领域并驾齐驱。&lt;SEP&gt;A broad field of philosophy that studies fundamental issues related to technology, such as how technology shapes the lifeworld and the relationship between humans and technology.</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011047</data>
      <data key="d6" />
    </node>
    <node id="杨媛">
      <data key="d0">杨媛</data>
      <data key="d1">person</data>
      <data key="d2">杨媛是华南师范大学马克思主义学院的学者，是论文《深度学习的技术路径与哲学审视》的作者。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010721</data>
      <data key="d6" />
    </node>
    <node id="华南师范大学马克思主义学院">
      <data key="d0">华南师范大学马克思主义学院</data>
      <data key="d1">organization</data>
      <data key="d2">华南师范大学马克思主义学院是杨媛所属的学术机构。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010721</data>
      <data key="d6" />
    </node>
    <node id="哲学进展">
      <data key="d0">哲学进展</data>
      <data key="d1">content</data>
      <data key="d2">《哲学进展》是发表论文《深度学习的技术路径与哲学审视》的期刊或出版物。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010722</data>
      <data key="d6" />
    </node>
    <node id="学习范式">
      <data key="d0">学习范式</data>
      <data key="d1">concept</data>
      <data key="d2">学习范式是深度学习的一个方面，本文从哲学角度对其进行了深入讨论。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010722</data>
      <data key="d6" />
    </node>
    <node id="技术演进">
      <data key="d0">技术演进</data>
      <data key="d1">concept</data>
      <data key="d2">技术演进是深度学习的发展脉络，本文对其进行了梳理。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010724</data>
      <data key="d6" />
    </node>
    <node id="DOI: 10.12677/acpp.2025.145279">
      <data key="d0">DOI: 10.12677/acpp.2025.145279</data>
      <data key="d1">data</data>
      <data key="d2">论文《深度学习的技术路径与哲学审视》的数字对象标识符。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010726</data>
      <data key="d6" />
    </node>
    <node id="广东广州">
      <data key="d0">广东广州</data>
      <data key="d1">location</data>
      <data key="d2">华南师范大学马克思主义学院所在的地理位置。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010735</data>
      <data key="d6" />
    </node>
    <node id="收稿日期：2025年5月1日">
      <data key="d0">收稿日期：2025年5月1日</data>
      <data key="d1">data</data>
      <data key="d2">论文被接收的日期。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010735</data>
      <data key="d6" />
    </node>
    <node id="录用日期：2025年5月23日">
      <data key="d0">录用日期：2025年5月23日</data>
      <data key="d1">data</data>
      <data key="d2">论文被录用的日期。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010728</data>
      <data key="d6" />
    </node>
    <node id="发布日期：2025年5月31日">
      <data key="d0">发布日期：2025年5月31日</data>
      <data key="d1">data</data>
      <data key="d2">论文被公开发布的日期。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010730</data>
      <data key="d6" />
    </node>
    <node id="关键词">
      <data key="d0">关键词</data>
      <data key="d1">concept</data>
      <data key="d2">论文中用于概括核心内容的术语列表，包括“深度学习”、“人工智能”、“技术哲学”。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010731</data>
      <data key="d6" />
    </node>
    <node id="Abstract">
      <data key="d0">Abstract</data>
      <data key="d1">content</data>
      <data key="d2">论文的英文摘要部分。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010731</data>
      <data key="d6" />
    </node>
    <node id="Technical Path and Philosophical Review of Deep Learning">
      <data key="d0">Technical Path and Philosophical Review of Deep Learning</data>
      <data key="d1">content</data>
      <data key="d2">论文的英文标题。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010734</data>
      <data key="d6" />
    </node>
    <node id="School of Marxism, South China Normal University">
      <data key="d0">School of Marxism, South China Normal University</data>
      <data key="d1">organization</data>
      <data key="d2">杨媛所属学术机构的英文名称。</data>
      <data key="d3">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010735</data>
      <data key="d6" />
    </node>
    <node id="Cameron J. Buckner">
      <data key="d0">Cameron J. Buckner</data>
      <data key="d1">person</data>
      <data key="d2">Cameron J. Buckner is the author of the book "From Deep Learning to Rational Machines".</data>
      <data key="d3">chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010780</data>
      <data key="d6" />
    </node>
    <node id="From Deep Learning to Rational Machines">
      <data key="d0">From Deep Learning to Rational Machines</data>
      <data key="d1">content</data>
      <data key="d2">"From Deep Learning to Rational Machines" is a book that discusses the philosophical implications of deep learning.</data>
      <data key="d3">chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010780</data>
      <data key="d6" />
    </node>
    <node id="Neural Networks">
      <data key="d0">Neural Networks</data>
      <data key="d1">concept</data>
      <data key="d2">Neural networks are a core technology within deep learning.</data>
      <data key="d3">chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010775</data>
      <data key="d6" />
    </node>
    <node id="2015">
      <data key="d0">2015</data>
      <data key="d1">event</data>
      <data key="d2">The year 2015 is mentioned as a starting point for fundamental changes in deep learning neural networks.</data>
      <data key="d3">chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010775</data>
      <data key="d6" />
    </node>
    <node id="张颖天">
      <data key="d0">张颖天</data>
      <data key="d1">person</data>
      <data key="d2">张颖天is a co-author of the article "Philosophical Reflections in the Age of Artificial Intelligence" published in the Guangming Daily.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010953</data>
      <data key="d6" />
    </node>
    <node id="戴宁馨">
      <data key="d0">戴宁馨</data>
      <data key="d1">person</data>
      <data key="d2">戴宁馨is a co-author of the article "Philosophical Reflections in the Age of Artificial Intelligence" published in the Guangming Daily.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010953</data>
      <data key="d6" />
    </node>
    <node id="光明日报">
      <data key="d0">光明日报</data>
      <data key="d1">organization</data>
      <data key="d2">Guangming Daily is the newspaper where the article "Philosophical Reflections in the Age of Artificial Intelligence" was published.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010955</data>
      <data key="d6" />
    </node>
    <node id="人工智能时代">
      <data key="d0">人工智能时代</data>
      <data key="d1">concept</data>
      <data key="d2">人工智能时代是人类历史发展的一个阶段，算法在其中狂飙突进，引发了社会生活、伦理规范与思想意识等方面的诸多争议。&lt;SEP&gt;The Age of Artificial Intelligence is the contemporary era characterized by the development and impact of AI, serving as the central context for the philosophical discussion.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010957</data>
      <data key="d6" />
    </node>
    <node id="哲学">
      <data key="d0">哲学</data>
      <data key="d1">concept</data>
      <data key="d2">哲学具有批判性反思的本质，能够与技术逻辑进行对话，关注意义、价值、复杂性和不可通约性，其思考具有不可替代性。&lt;SEP&gt;哲学在人工智能时代需要反思主体概念、技术安全性以及基础概念(如意识、理解)的内涵，其内部研究版图可能因技术哲学兴起而重组。&lt;SEP&gt;Philosophy is defined as the unity of worldview and methodology, and is the subject of reflection regarding its challenges and irreplaceability in the AI era.&lt;SEP&gt;Philosophy is described as a realm of pure thought, focusing on the laws of the thinking process itself, such as logic and dialectics. Its irreplaceability lies in its dialectical thinking method.&lt;SEP&gt;The discipline of human wisdom, involving critical thinking and meaning creation, whose internal landscape is being restructured in the age of AI.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010957</data>
      <data key="d6" />
    </node>
    <node id="哲学研究">
      <data key="d0">哲学研究</data>
      <data key="d1">concept</data>
      <data key="d2">Philosophical research is the activity of inquiry facing challenges from AI, particularly concerning human cognitive boundaries and the relationship between technology and the human future.&lt;SEP&gt;Philosophical research, which in the AI era must be "based on humans, centered on humans, and for humans," according to Zhao Li.&lt;SEP&gt;An activity that means human mental labor production.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010958</data>
      <data key="d6" />
    </node>
    <node id="王田">
      <data key="d0">王田</data>
      <data key="d1">person</data>
      <data key="d2">王田引用恩格斯的观点，认为哲学思考的不可替代性在于辩证思维方法，它既是科学思维方法的方法论前提，又能吸收和提升现代科学思维方法。&lt;SEP&gt;王田分析了人工智能发展对传统哲学主体概念带来的三大悖论挑战，以及人工智能引发的社会安全性、可靠性和公平性等哲学研究新视域。&lt;SEP&gt;王田is a lecturer in the Department of Philosophy and Culture at the Party School of the Beijing Municipal Committee of the CPC (Beijing Administrative College) and a participant in the discussion.&lt;SEP&gt;Wang Tian states that developing AI's "philosophy" first requires ensuring technological innovation is led by humans, not dominated by capital or technological logic. He cites Horkheimer and emphasizes considering social conditions and human scale.&lt;SEP&gt;A participant who discusses the tension between algorithmic value and philosophical value, arguing for a re-examination of labor theory of value in the AI era and the irreplaceable role of laborers.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010960</data>
      <data key="d6" />
    </node>
    <node id="中共北京市委党校〔北京行政学院〕哲学与文化教研部">
      <data key="d0">中共北京市委党校〔北京行政学院〕哲学与文化教研部</data>
      <data key="d1">organization</data>
      <data key="d2">This is the Department of Philosophy and Culture at the Party School of the Beijing Municipal Committee of the CPC (Beijing Administrative College), where王田works as a lecturer.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010962</data>
      <data key="d6" />
    </node>
    <node id="主持人">
      <data key="d0">主持人</data>
      <data key="d1">person</data>
      <data key="d2">主持人提出关于哲学思考不可替代性的问题，引导讨论聚焦于真问题。&lt;SEP&gt;The host moderates the discussion, posing questions about the challenges AI development brings to philosophical research, specifically regarding human subjectivity and creativity.&lt;SEP&gt;The moderator who raises a question about the tension between the algorithmic value and philosophical value of AI technology based on Marx's labor theory of value.&lt;SEP&gt;The host poses a question about the future development of philosophy and its role in sustainable human-machine collaboration, specifically asking how to develop human philosophy and AI's "philosophy" and what the starting point and standpoint for philosophical research in the AI era are.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010964</data>
      <data key="d6" />
    </node>
    <node id="深度学习算法">
      <data key="d0">深度学习算法</data>
      <data key="d1">method</data>
      <data key="d2">Deep Learning Algorithms are a type of AI technology mentioned as part of the widespread application of AI that challenges philosophical research practices.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010970</data>
      <data key="d6" />
    </node>
    <node id="哲学学者">
      <data key="d0">哲学学者</data>
      <data key="d1">person</data>
      <data key="d2">Philosophical scholars are researchers whose personal practice is challenged by AI's capabilities in information search, integration, and analysis, potentially leading to over-reliance and loss of originality.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010970</data>
      <data key="d6" />
    </node>
    <node id="主体性创造">
      <data key="d0">主体性创造</data>
      <data key="d1">concept</data>
      <data key="d2">Subjective creativity refers to the human capacity for original thought and creation in philosophy, which faces difficulties and challenges from the development of AI.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010972</data>
      <data key="d6" />
    </node>
    <node id="赵立">
      <data key="d0">赵立</data>
      <data key="d1">person</data>
      <data key="d2">赵立认为哲学思考的核心是批判性反思，必须基于实践真知和理论思维来锚定普遍性问题，以校准人工智能技术与哲学思考的发展方向。&lt;SEP&gt;赵立is a discussant who comments on the relationship between philosophy as a product of human creative thinking and AI as an efficient technical integration of past human thought.&lt;SEP&gt;Zhao Li states that philosophical thinking in the AI era must be "based on humans, centered on humans, and for humans." He argues that philosophy should "legislate" for the use of science and technology, providing guidance and control.&lt;SEP&gt;A participant who discusses how AI technology shapes the era and necessitates philosophical responses, including rethinking the human-technology relationship and new social problems.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010973</data>
      <data key="d6" />
    </node>
    <node id="哲学思考">
      <data key="d0">哲学思考</data>
      <data key="d1">concept</data>
      <data key="d2">Philosophical thinking is described as a solitary journey into uncharted territory, whose core involves proposing new questions, redefining old ones, and challenging presuppositions, abilities unique to the human mind.&lt;SEP&gt;Philosophical thinking is described as having the purpose of "knowing thyself" through reflective self-examination, which cannot be replaced by examining others or being examined by others. It can also provide possible conditions for transforming the world through speculative power.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010974</data>
      <data key="d6" />
    </node>
    <node id="技术逻辑">
      <data key="d0">技术逻辑</data>
      <data key="d1">concept</data>
      <data key="d2">技术逻辑与哲学逻辑存在争锋，已嵌入人类社会发展的各个阶段，需要在人工智能时代与哲学逻辑实现动态平衡。&lt;SEP&gt;Technological logic refers to the operational framework of AI, which philosophical human thought must transcend to confirm the unique value of human thinking.&lt;SEP&gt;The logic of technology, which historically interacts with philosophical logic.&lt;SEP&gt;Technological logic is mentioned by Wang Tian as a force that should not dominate technological innovation in the development of AI's "philosophy."</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010976</data>
      <data key="d6" />
    </node>
    <node id="哲学是世界观和方法论的统一">
      <data key="d0">哲学是世界观和方法论的统一</data>
      <data key="d1">concept</data>
      <data key="d2">"Philosophy is the unity of worldview and methodology" is a quoted definition of philosophy presented in the article.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010980</data>
      <data key="d6" />
    </node>
    <node id="原创焦虑">
      <data key="d0">原创焦虑</data>
      <data key="d1">concept</data>
      <data key="d2">"Originality Anxiety" is a potential state where philosophical researchers, faced with AI's efficient output, may over-trust or rely on it, losing their own autonomy and originality.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010981</data>
      <data key="d6" />
    </node>
    <node id="深度求索">
      <data key="d0">深度求索</data>
      <data key="d1">concept</data>
      <data key="d2">"Deep Inquiry" is a capacity that philosophical researchers risk losing when overly reliant on AI's ready-made answers and its pre-set problem frameworks.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010982</data>
      <data key="d6" />
    </node>
    <node id="无人之境">
      <data key="d0">无人之境</data>
      <data key="d1">concept</data>
      <data key="d2">"Uncharted Territory" describes the typical landscape of philosophical thinking as a solitary journey requiring the ability for independent exploration within one's own intellectual world.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010983</data>
      <data key="d6" />
    </node>
    <node id="黄昏起飞的密涅瓦猫头鹰">
      <data key="d0">黄昏起飞的密涅瓦猫头鹰</data>
      <data key="d1">concept</data>
      <data key="d2">"Minerva's owl taking flight at dusk" is a metaphor used to describe the difficulty of philosophical reflection in the rapidly evolving AI era, where it is hard to calmly look back or penetrate phenomena to reach essence.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010984</data>
      <data key="d6" />
    </node>
    <node id="实证科学的思维方式">
      <data key="d0">实证科学的思维方式</data>
      <data key="d1">concept</data>
      <data key="d2">"The思维方式of empirical science" refers to a mindset that has become deeply ingrained due to breakthroughs in modern technology and is contrasted with philosophical thinking.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010986</data>
      <data key="d6" />
    </node>
    <node id="主动性和被动性的悖论">
      <data key="d0">主动性和被动性的悖论</data>
      <data key="d1">concept</data>
      <data key="d2">"The paradox of initiative and passivity" is a challenge to the traditional philosophical concept of the rational subject, where humans appear active in initiating human-machine dialogue but are passive in needing to use specific prompts for efficient information retrieval.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010986</data>
      <data key="d6" />
    </node>
    <node id="三位青年学者">
      <data key="d0">三位青年学者</data>
      <data key="d1">person</data>
      <data key="d2">"Three young scholars" are the participants organized by the journal to discuss philosophical research in the age of artificial intelligence.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010989</data>
      <data key="d6" />
    </node>
    <node id="专家">
      <data key="d0">专家</data>
      <data key="d1">person</data>
      <data key="d2">"Experts" are individuals invited by the journal to provide commentary on the discussion by the young scholars.</data>
      <data key="d3">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010991</data>
      <data key="d6" />
    </node>
    <node id="逻辑">
      <data key="d0">逻辑</data>
      <data key="d1">concept</data>
      <data key="d2">Logic is mentioned as part of the doctrine of the laws of the thinking process itself, alongside dialectics.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010991</data>
      <data key="d6" />
    </node>
    <node id="辩证法">
      <data key="d0">辩证法</data>
      <data key="d1">concept</data>
      <data key="d2">Dialectics is mentioned as part of the doctrine of the laws of the thinking process itself, alongside logic. It is a thinking method that is the methodological premise of scientific thinking and can absorb and elevate modern scientific thinking methods.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010992</data>
      <data key="d6" />
    </node>
    <node id="科学思维方法">
      <data key="d0">科学思维方法</data>
      <data key="d1">method</data>
      <data key="d2">Scientific thinking methods are methods that can be absorbed, referenced, and elevated by dialectical thinking.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011001</data>
      <data key="d6" />
    </node>
    <node id="数理逻辑">
      <data key="d0">数理逻辑</data>
      <data key="d1">concept</data>
      <data key="d2">Mathematical logic is the type of logic that AI follows, emphasizing computation, causality, and recursion.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010995</data>
      <data key="d6" />
    </node>
    <node id="古希腊哲人">
      <data key="d0">古希腊哲人</data>
      <data key="d1">person</data>
      <data key="d2">Ancient Greek philosophers discussed the origin of the world, which gave rise to early science and mathematics.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010995</data>
      <data key="d6" />
    </node>
    <node id="早期科学与数学">
      <data key="d0">早期科学与数学</data>
      <data key="d1">concept</data>
      <data key="d2">Early science and mathematics were born from the discussions of ancient Greek philosophers on the origin of the world.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769010999</data>
      <data key="d6" />
    </node>
    <node id="近代启蒙思想家">
      <data key="d0">近代启蒙思想家</data>
      <data key="d1">person</data>
      <data key="d2">Modern Enlightenment thinkers inspired people's pursuit of freedom, equality, and democratic ideals.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011001</data>
      <data key="d6" />
    </node>
    <node id="自由、平等与民主理念">
      <data key="d0">自由、平等与民主理念</data>
      <data key="d1">concept</data>
      <data key="d2">Ideals of freedom, equality, and democracy were pursued by people inspired by modern Enlightenment thinkers.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011001</data>
      <data key="d6" />
    </node>
    <node id="马克思主义">
      <data key="d0">马克思主义</data>
      <data key="d1">concept</data>
      <data key="d2">Marxism revealed the laws of development and future direction of human society, providing a scientific guide for "where humanity is headed."</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011011</data>
      <data key="d6" />
    </node>
    <node id="人类社会">
      <data key="d0">人类社会</data>
      <data key="d1">concept</data>
      <data key="d2">Human society, whose development laws and future direction were revealed by Marxism.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011011</data>
      <data key="d6" />
    </node>
    <node id="魏犇群">
      <data key="d0">魏犇群</data>
      <data key="d1">person</data>
      <data key="d2">魏犇群阐述了哲学思考不可替代性的三个方面：提出深刻问题、关注意义与价值、保持对复杂性和不可通约性的敏感。&lt;SEP&gt;魏犇群提出生成式人工智能的发展是一个“哲学事件”，它改变了传统哲学观念，迫使哲学重新理解一系列基础概念并重组内部研究版图。&lt;SEP&gt;Wei Benqun explains that "AI's philosophy" has two meanings: philosophy about AI and philosophy created by AI itself. Under the first meaning, its core task is to re-understand human uniqueness in the era where AI imitates or even surpasses human intelligence.&lt;SEP&gt;A participant who discusses algorithmic value and philosophical value, explaining that current algorithmic value is a product of human mental labor but differs from philosophical value in manifestation.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011004</data>
      <data key="d6" />
    </node>
    <node id="人工智能的哲学">
      <data key="d0">人工智能的哲学</data>
      <data key="d1">concept</data>
      <data key="d2">AI's philosophy has two meanings according to Wei Benqun: philosophy about AI and philosophy created by AI itself. Under the first meaning, it belongs to human philosophy and aims to guide technological development with humanistic reflection.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011004</data>
      <data key="d6" />
    </node>
    <node id="人的哲学">
      <data key="d0">人的哲学</data>
      <data key="d1">concept</data>
      <data key="d2">Human philosophy, to which AI's philosophy (in the sense of philosophy about AI) belongs, according to Wei Benqun.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011005</data>
      <data key="d6" />
    </node>
    <node id="霍克海默">
      <data key="d0">霍克海默</data>
      <data key="d1">person</data>
      <data key="d2">Horkheimer, a German philosopher cited by Wang Tian, pointed out that understanding the crisis of science depends on a correct theory of the current social situation.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011009</data>
      <data key="d6" />
    </node>
    <node id="社会">
      <data key="d0">社会</data>
      <data key="d1">concept</data>
      <data key="d2">Society, whose conditions and contradictions are reflected by science and are crucial for discussing AI's effects, according to Wang Tian.&lt;SEP&gt;One of the many fields where new problems arise in the AI era.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011011</data>
      <data key="d6" />
    </node>
    <node id="科学技术">
      <data key="d0">科学技术</data>
      <data key="d1">concept</data>
      <data key="d2">Science and technology, as products of human wisdom whose expanding capabilities require philosophical thinking to "legislate," provide guidance, and control their direction and limits, according to Zhao Li.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011012</data>
      <data key="d6" />
    </node>
    <node id="全国哲学社会科学工作办公室">
      <data key="d0">全国哲学社会科学工作办公室</data>
      <data key="d1">organization</data>
      <data key="d2">National Office for Philosophy and Social Sciences, the organizer and sponsor of the content.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011013</data>
      <data key="d6" />
    </node>
    <node id="人民网">
      <data key="d0">人民网</data>
      <data key="d1">organization</data>
      <data key="d2">People's Daily Online, the undertaker of the content.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011014</data>
      <data key="d6" />
    </node>
    <node id="人机协同">
      <data key="d0">人机协同</data>
      <data key="d1">concept</data>
      <data key="d2">Human-machine collaboration is mentioned by the host as an area where the development and progress of philosophy can promote its sustainable development.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011014</data>
      <data key="d6" />
    </node>
    <node id="意识">
      <data key="d0">意识</data>
      <data key="d1">concept</data>
      <data key="d2">Consciousness is mentioned by Wei Benqun as an aspect of human uniqueness that needs to be re-understood in the era of AI.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011015</data>
      <data key="d6" />
    </node>
    <node id="理性">
      <data key="d0">理性</data>
      <data key="d1">concept</data>
      <data key="d2">Reason is mentioned by Wei Benqun as an aspect of human uniqueness that needs to be re-understood in the era of AI.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011019</data>
      <data key="d6" />
    </node>
    <node id="道德">
      <data key="d0">道德</data>
      <data key="d1">concept</data>
      <data key="d2">Morality is mentioned by Wei Benqun as an aspect of human uniqueness that needs to be re-understood in the era of AI.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011020</data>
      <data key="d6" />
    </node>
    <node id="资本逻辑">
      <data key="d0">资本逻辑</data>
      <data key="d1">concept</data>
      <data key="d2">Capital logic is mentioned by Wang Tian as a force that should not dominate technological innovation in the development of AI's "philosophy."</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011022</data>
      <data key="d6" />
    </node>
    <node id="人类尺度">
      <data key="d0">人类尺度</data>
      <data key="d1">concept</data>
      <data key="d2">Human scale is emphasized by Wang Tian as something that must not be abandoned when repositioning the relationship between humans and AI, to ensure AI serves humanity.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011023</data>
      <data key="d6" />
    </node>
    <node id="伦理">
      <data key="d0">伦理</data>
      <data key="d1">concept</data>
      <data key="d2">Ethics is mentioned by Wang Tian as one of the multiple values (like culture, politics, economy) that AI carries.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011024</data>
      <data key="d6" />
    </node>
    <node id="文化">
      <data key="d0">文化</data>
      <data key="d1">concept</data>
      <data key="d2">Culture is mentioned by Wang Tian as one of the multiple values (like ethics, politics, economy) that AI carries.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011025</data>
      <data key="d6" />
    </node>
    <node id="政治">
      <data key="d0">政治</data>
      <data key="d1">concept</data>
      <data key="d2">One of the many fields where new problems arise in the AI era.&lt;SEP&gt;Politics is mentioned by Wang Tian as one of the multiple values (like ethics, culture, economy) that AI carries.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011025</data>
      <data key="d6" />
    </node>
    <node id="经济">
      <data key="d0">经济</data>
      <data key="d1">concept</data>
      <data key="d2">One of the many fields where new problems arise in the AI era.&lt;SEP&gt;Economy is mentioned by Wang Tian as one of the multiple values (like ethics, culture, politics) that AI carries.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011027</data>
      <data key="d6" />
    </node>
    <node id="人权">
      <data key="d0">人权</data>
      <data key="d1">concept</data>
      <data key="d2">Human rights are mentioned by Wang Tian as a value that AI technology development should respect.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011029</data>
      <data key="d6" />
    </node>
    <node id="公平正义">
      <data key="d0">公平正义</data>
      <data key="d1">concept</data>
      <data key="d2">Fairness and justice are mentioned by Wang Tian as values that AI technology development should promote.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011029</data>
      <data key="d6" />
    </node>
    <node id="国家利益">
      <data key="d0">国家利益</data>
      <data key="d1">concept</data>
      <data key="d2">National interest is mentioned by Wang Tian as something AI technology should serve.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011031</data>
      <data key="d6" />
    </node>
    <node id="人民福祉">
      <data key="d0">人民福祉</data>
      <data key="d1">concept</data>
      <data key="d2">People's well-being is mentioned by Wang Tian as something AI technology should serve.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011032</data>
      <data key="d6" />
    </node>
    <node id="文化差异">
      <data key="d0">文化差异</data>
      <data key="d1">concept</data>
      <data key="d2">Cultural differences are mentioned by Wang Tian as something that should be respected in AI technology development.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011034</data>
      <data key="d6" />
    </node>
    <node id="多样性文化">
      <data key="d0">多样性文化</data>
      <data key="d1">concept</data>
      <data key="d2">Diverse cultures are mentioned by Wang Tian as something that should be included and respected in AI technology development.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011034</data>
      <data key="d6" />
    </node>
    <node id="世界和平稳定">
      <data key="d0">世界和平稳定</data>
      <data key="d1">concept</data>
      <data key="d2">World peace and stability are mentioned by Wang Tian as something that should be maintained by AI technology development.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011035</data>
      <data key="d6" />
    </node>
    <node id="全球可持续发展">
      <data key="d0">全球可持续发展</data>
      <data key="d1">concept</data>
      <data key="d2">Global sustainable development is mentioned by Wang Tian as something that should be maintained by AI technology development.</data>
      <data key="d3">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011037</data>
      <data key="d6" />
    </node>
    <node id="技术决定论">
      <data key="d0">技术决定论</data>
      <data key="d1">concept</data>
      <data key="d2">技术决定论是一种可能的发展倾向，即“唯算法”的一端，需要被哲学的价值所平衡。&lt;SEP&gt;Technological determinism, a potential pitfall if philosophical value is not重视d.</data>
      <data key="d3">chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011038</data>
      <data key="d6" />
    </node>
    <node id="哲学逻辑">
      <data key="d0">哲学逻辑</data>
      <data key="d1">concept</data>
      <data key="d2">哲学逻辑与技术逻辑存在争锋，需要在人工智能时代与技术逻辑重启深层次对话，实现动态平衡。&lt;SEP&gt;The logic of philosophy, which historically interacts with technological logic.</data>
      <data key="d3">chunk-1583b867ca44e12600f0775616185d52&lt;SEP&gt;chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011038</data>
      <data key="d6" />
    </node>
    <node id="批判性反思">
      <data key="d0">批判性反思</data>
      <data key="d1">concept</data>
      <data key="d2">批判性反思是哲学思考最本质和核心的特征，用于全面观照人工智能技术的历史、当下与未来，校准其发展方向。</data>
      <data key="d3">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011042</data>
      <data key="d6" />
    </node>
    <node id="辩证思维方法">
      <data key="d0">辩证思维方法</data>
      <data key="d1">concept</data>
      <data key="d2">辩证思维方法是哲学思考的核心，是科学思维方法的方法论前提，并能吸收、借鉴和概括提升现代科学思维方法，不断开拓辩证法。</data>
      <data key="d3">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011042</data>
      <data key="d6" />
    </node>
    <node id="创造性势能">
      <data key="d0">创造性势能</data>
      <data key="d1">concept</data>
      <data key="d2">创造性势能是算法价值与哲学价值之间的张力在人工智能时代可以转化成的推动发展的能量。</data>
      <data key="d3">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011043</data>
      <data key="d6" />
    </node>
    <node id="恩格斯">
      <data key="d0">恩格斯</data>
      <data key="d1">person</data>
      <data key="d2">恩格斯是哲学家，其观点被王田引用，认为哲学留下的领域是关于思维过程本身规律的学说，即逻辑和辩证法。</data>
      <data key="d3">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011045</data>
      <data key="d6" />
    </node>
    <node id="形而上学">
      <data key="d0">形而上学</data>
      <data key="d1">concept</data>
      <data key="d2">形而上学是传统哲学领域之一，在人工智能时代，技术哲学可能与之并驾齐驱。&lt;SEP&gt;A traditional field of philosophy.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011047</data>
      <data key="d6" />
    </node>
    <node id="知识论">
      <data key="d0">知识论</data>
      <data key="d1">concept</data>
      <data key="d2">知识论是传统哲学领域之一，在人工智能时代，技术哲学可能与之并驾齐驱。&lt;SEP&gt;A traditional field of philosophy.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011048</data>
      <data key="d6" />
    </node>
    <node id="伦理学">
      <data key="d0">伦理学</data>
      <data key="d1">concept</data>
      <data key="d2">伦理学是传统哲学领域之一，在人工智能时代，技术哲学可能与之并驾齐驱。&lt;SEP&gt;A traditional field of philosophy.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011050</data>
      <data key="d6" />
    </node>
    <node id="人">
      <data key="d0">人</data>
      <data key="d1">concept</data>
      <data key="d2">The subject of an ancient philosophical question about the basis of being human, whose uniqueness and irreplaceability need redefinition under the impact of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011051</data>
      <data key="d6" />
    </node>
    <node id="人文主义">
      <data key="d0">人文主义</data>
      <data key="d1">concept</data>
      <data key="d2">An old vision or framework concerning humanity.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011051</data>
      <data key="d6" />
    </node>
    <node id="哲学母题">
      <data key="d0">哲学母题</data>
      <data key="d1">concept</data>
      <data key="d2">The central philosophical theme in the age of AI, focusing on redefining what it means to be human.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011052</data>
      <data key="d6" />
    </node>
    <node id="人与技术的关系">
      <data key="d0">人与技术的关系</data>
      <data key="d1">concept</data>
      <data key="d2">A key issue for rethinking in interdisciplinary dialogue, prompted by AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011055</data>
      <data key="d6" />
    </node>
    <node id="人的社会存在">
      <data key="d0">人的社会存在</data>
      <data key="d1">concept</data>
      <data key="d2">An aspect of human existence that requires deep thinking in response to the AI era.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011057</data>
      <data key="d6" />
    </node>
    <node id="人工智能技术">
      <data key="d0">人工智能技术</data>
      <data key="d1">concept</data>
      <data key="d2">Technology that mass-produces information difficult to distinguish as true or false and shapes inequality gaps through algorithms.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011057</data>
      <data key="d6" />
    </node>
    <node id="马克思劳动价值论">
      <data key="d0">马克思劳动价值论</data>
      <data key="d1">concept</data>
      <data key="d2">A theory stating that the value of data elements still condenses in human labor.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011066</data>
      <data key="d6" />
    </node>
    <node id="数据要素">
      <data key="d0">数据要素</data>
      <data key="d1">concept</data>
      <data key="d2">Elements whose value, according to Marx's labor theory of value, condenses in human labor.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011059</data>
      <data key="d6" />
    </node>
    <node id="人类劳动">
      <data key="d0">人类劳动</data>
      <data key="d1">concept</data>
      <data key="d2">The source in which value condenses, according to Marx's theory.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011060</data>
      <data key="d6" />
    </node>
    <node id="人类的思维劳动生产活动">
      <data key="d0">人类的思维劳动生产活动</data>
      <data key="d1">concept</data>
      <data key="d2">The productive activity of human mental labor that philosophical research entails.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011061</data>
      <data key="d6" />
    </node>
    <node id="算法价值">
      <data key="d0">算法价值</data>
      <data key="d1">concept</data>
      <data key="d2">The value created by AI and its algorithms as a new type of production factor, currently still a product of human mental labor.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011063</data>
      <data key="d6" />
    </node>
    <node id="哲学价值">
      <data key="d0">哲学价值</data>
      <data key="d1">concept</data>
      <data key="d2">The value manifested in critical insight and meaning creation, which cannot be replaced or commensurated by algorithmic value.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011063</data>
      <data key="d6" />
    </node>
    <node id="人工智能系统">
      <data key="d0">人工智能系统</data>
      <data key="d1">concept</data>
      <data key="d2">A system that is not yet considered a laboring subject but whose algorithm model design, training, debugging, and optimization condense human labor.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011074</data>
      <data key="d6" />
    </node>
    <node id="算法模型">
      <data key="d0">算法模型</data>
      <data key="d1">concept</data>
      <data key="d2">The model whose design, training, debugging, and optimization condense human labor.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011074</data>
      <data key="d6" />
    </node>
    <node id="信息处理">
      <data key="d0">信息处理</data>
      <data key="d1">concept</data>
      <data key="d2">The main area where algorithmic value is currently manifested.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011075</data>
      <data key="d6" />
    </node>
    <node id="批判性洞察">
      <data key="d0">批判性洞察</data>
      <data key="d1">concept</data>
      <data key="d2">One aspect where philosophical value is manifested.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011076</data>
      <data key="d6" />
    </node>
    <node id="意义创造">
      <data key="d0">意义创造</data>
      <data key="d1">concept</data>
      <data key="d2">One aspect where philosophical value is manifested.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011079</data>
      <data key="d6" />
    </node>
    <node id="效率">
      <data key="d0">效率</data>
      <data key="d1">concept</data>
      <data key="d2">An aspect often embodied by algorithmic value.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011079</data>
      <data key="d6" />
    </node>
    <node id="规模">
      <data key="d0">规模</data>
      <data key="d1">concept</data>
      <data key="d2">An aspect often embodied by algorithmic value.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011081</data>
      <data key="d6" />
    </node>
    <node id="预测能力">
      <data key="d0">预测能力</data>
      <data key="d1">concept</data>
      <data key="d2">An aspect often embodied by algorithmic value.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011081</data>
      <data key="d6" />
    </node>
    <node id="提供现成方案">
      <data key="d0">提供现成方案</data>
      <data key="d1">concept</data>
      <data key="d2">An aspect often embodied by algorithmic value.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011083</data>
      <data key="d6" />
    </node>
    <node id="问题背后的前提">
      <data key="d0">问题背后的前提</data>
      <data key="d1">concept</data>
      <data key="d2">An object of reflection where philosophical value is embodied.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011084</data>
      <data key="d6" />
    </node>
    <node id="框架的设定">
      <data key="d0">框架的设定</data>
      <data key="d1">concept</data>
      <data key="d2">An object of reflection where philosophical value is embodied.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011086</data>
      <data key="d6" />
    </node>
    <node id="基本概念的内涵及限度">
      <data key="d0">基本概念的内涵及限度</data>
      <data key="d1">concept</data>
      <data key="d2">An object of reflection where philosophical value is embodied.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011086</data>
      <data key="d6" />
    </node>
    <node id="劳作">
      <data key="d0">劳作</data>
      <data key="d1">concept</data>
      <data key="d2">Human work that algorithmic value aims to potentially replace.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011079</data>
      <data key="d6" />
    </node>
    <node id="类本质">
      <data key="d0">类本质</data>
      <data key="d1">concept</data>
      <data key="d2">The species-essence of humans, which philosophical value helps humans grasp in consciousness.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011079</data>
      <data key="d6" />
    </node>
    <node id="劳动价值论">
      <data key="d0">劳动价值论</data>
      <data key="d1">concept</data>
      <data key="d2">The theory whose re-examination is the theoretical essence of the tension between algorithmic and philosophical values in the AI era.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011081</data>
      <data key="d6" />
    </node>
    <node id="活劳动">
      <data key="d0">活劳动</data>
      <data key="d1">concept</data>
      <data key="d2">Living labor, part of which is replaced by AI as a breakthrough technology.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011081</data>
      <data key="d6" />
    </node>
    <node id="数字劳动">
      <data key="d0">数字劳动</data>
      <data key="d1">concept</data>
      <data key="d2">A new form of labor created by AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011083</data>
      <data key="d6" />
    </node>
    <node id="劳动的时空条件">
      <data key="d0">劳动的时空条件</data>
      <data key="d1">concept</data>
      <data key="d2">Conditions of labor that are changed by AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011083</data>
      <data key="d6" />
    </node>
    <node id="资本有机构成">
      <data key="d0">资本有机构成</data>
      <data key="d1">concept</data>
      <data key="d2">The organic composition of capital, which is further increased by the significant substitution effect of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011086</data>
      <data key="d6" />
    </node>
    <node id="单位商品价值量">
      <data key="d0">单位商品价值量</data>
      <data key="d1">concept</data>
      <data key="d2">The value per unit commodity, which is lowered by the significant substitution effect of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011086</data>
      <data key="d6" />
    </node>
    <node id="价值实现方式">
      <data key="d0">价值实现方式</data>
      <data key="d1">concept</data>
      <data key="d2">The mode of value realization, which undergoes a huge transformation due to AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011096</data>
      <data key="d6" />
    </node>
    <node id="价值源泉唯一性">
      <data key="d0">价值源泉唯一性</data>
      <data key="d1">concept</data>
      <data key="d2">The uniqueness of the source of value, an important judgment in Marx's labor theory of value not negated by AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011096</data>
      <data key="d6" />
    </node>
    <node id="劳动者主体地位">
      <data key="d0">劳动者主体地位</data>
      <data key="d1">concept</data>
      <data key="d2">The subjective status of laborers, an important judgment in Marx's labor theory of value not negated by AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011090</data>
      <data key="d6" />
    </node>
    <node id="资本属性">
      <data key="d0">资本属性</data>
      <data key="d1">concept</data>
      <data key="d2">The nature of capital, an important judgment in Marx's labor theory of value not negated by AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011090</data>
      <data key="d6" />
    </node>
    <node id="整体生产过程">
      <data key="d0">整体生产过程</data>
      <data key="d1">concept</data>
      <data key="d2">The overall production process, based on which Marx探寻s the source of value.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011093</data>
      <data key="d6" />
    </node>
    <node id="无人化生产">
      <data key="d0">无人化生产</data>
      <data key="d1">concept</data>
      <data key="d2">Unmanned production, whose possibility should not lead to ignoring the need for laborer participation in all links of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011093</data>
      <data key="d6" />
    </node>
    <node id="人工智能研发">
      <data key="d0">人工智能研发</data>
      <data key="d1">concept</data>
      <data key="d2">The research and development link of AI, which requires laborer participation.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011095</data>
      <data key="d6" />
    </node>
    <node id="分配">
      <data key="d0">分配</data>
      <data key="d1">concept</data>
      <data key="d2">The distribution link, which requires laborer participation in the context of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011095</data>
      <data key="d6" />
    </node>
    <node id="交换">
      <data key="d0">交换</data>
      <data key="d1">concept</data>
      <data key="d2">The exchange link, which requires laborer participation in the context of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011097</data>
      <data key="d6" />
    </node>
    <node id="消费">
      <data key="d0">消费</data>
      <data key="d1">concept</data>
      <data key="d2">The consumption link, which requires laborer participation in the context of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011097</data>
      <data key="d6" />
    </node>
    <node id="劳动者">
      <data key="d0">劳动者</data>
      <data key="d1">concept</data>
      <data key="d2">Laborers who play an irreplaceable subjective role and whose participation is needed in all links of AI.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011107</data>
      <data key="d6" />
    </node>
    <node id="资本的剥削性质">
      <data key="d0">资本的剥削性质</data>
      <data key="d1">concept</data>
      <data key="d2">The exploitative nature of capital, which AI not only fails to eliminate but makes more隐蔽.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011107</data>
      <data key="d6" />
    </node>
    <node id="劳动解放论">
      <data key="d0">劳动解放论</data>
      <data key="d1">concept</data>
      <data key="d2">The theory of labor liberation, which must be立足d to achieve the dialectical unity of algorithmic and philosophical values.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011110</data>
      <data key="d6" />
    </node>
    <node id="人的自由全面发展">
      <data key="d0">人的自由全面发展</data>
      <data key="d1">concept</data>
      <data key="d2">The free and comprehensive development of humans, which must be立足d to achieve the dialectical unity of algorithmic and philosophical values.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011110</data>
      <data key="d6" />
    </node>
    <node id="可计算认知模型">
      <data key="d0">可计算认知模型</data>
      <data key="d1">concept</data>
      <data key="d2">Computable cognitive models that shape the contemporary world, with AI technology as a key example.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011112</data>
      <data key="d6" />
    </node>
    <node id="高度数学形式化的算法">
      <data key="d0">高度数学形式化的算法</data>
      <data key="d1">concept</data>
      <data key="d2">Highly mathematically formalized algorithms, the key tool of AI technology.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011112</data>
      <data key="d6" />
    </node>
    <node id="认识世界">
      <data key="d0">认识世界</data>
      <data key="d1">concept</data>
      <data key="d2">Knowing the world, for which algorithm has become a core way.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011115</data>
      <data key="d6" />
    </node>
    <node id="改造世界">
      <data key="d0">改造世界</data>
      <data key="d1">concept</data>
      <data key="d2">Transforming the world, for which algorithm has become a core way.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011115</data>
      <data key="d6" />
    </node>
    <node id="人类智慧">
      <data key="d0">人类智慧</data>
      <data key="d1">concept</data>
      <data key="d2">Human wisdom, whose collective embodiment is算法.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011117</data>
      <data key="d6" />
    </node>
    <node id="精确化">
      <data key="d0">精确化</data>
      <data key="d1">concept</data>
      <data key="d2">Precision, one way in which algorithm achieves the overall construction of contemporary society.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011117</data>
      <data key="d6" />
    </node>
    <node id="数字化">
      <data key="d0">数字化</data>
      <data key="d1">concept</data>
      <data key="d2">Digitization, one way in which algorithm achieves the overall construction of contemporary society.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011120</data>
      <data key="d6" />
    </node>
    <node id="组织化">
      <data key="d0">组织化</data>
      <data key="d1">concept</data>
      <data key="d2">Organization, one way in which algorithm achieves the overall construction of contemporary society.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011120</data>
      <data key="d6" />
    </node>
    <node id="当代社会">
      <data key="d0">当代社会</data>
      <data key="d1">concept</data>
      <data key="d2">Contemporary society, which is整体建构ed by algorithm.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011113</data>
      <data key="d6" />
    </node>
    <node id="人类文明发展">
      <data key="d0">人类文明发展</data>
      <data key="d1">concept</data>
      <data key="d2">The development of human civilization, whose possible space is极大拓展ed by algorithm.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011113</data>
      <data key="d6" />
    </node>
    <node id="唯算法">
      <data key="d0">唯算法</data>
      <data key="d1">concept</data>
      <data key="d2">Algorithm-only thinking, a form of technological determinism that should be avoided by valuing philosophy.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011115</data>
      <data key="d6" />
    </node>
    <node id="哲学逻">
      <data key="d0">哲学逻</data>
      <data key="d1">concept</data>
      <data key="d2">The logic of philosophy, which historically interacts with technological logic, as mentioned in the final incomplete sentence of the input text.</data>
      <data key="d3">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011115</data>
      <data key="d6" />
    </node>
    <node id="主体概念">
      <data key="d0">主体概念</data>
      <data key="d1">concept</data>
      <data key="d2">主体概念是传统哲学中作为理性核心的概念，在人工智能时代面临主动性被动性悖论、知识获取悖论和身份悖论等挑战。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011118</data>
      <data key="d6" />
    </node>
    <node id="主动性被动性悖论">
      <data key="d0">主动性被动性悖论</data>
      <data key="d1">concept</data>
      <data key="d2">该悖论描述了人类在使用人工智能时，表面上占据主动，实则语言需要适应机器，导致主动性变为被动性，可能引发人类思维被异化。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011118</data>
      <data key="d6" />
    </node>
    <node id="知识获取加速化知识增量受限悖论">
      <data key="d0">知识获取加速化知识增量受限悖论</data>
      <data key="d1">concept</data>
      <data key="d2">该悖论指出人工智能加速知识整理与重组，但可能限制人类创造新知识的能力，挤压哲学所需的长期积累空间。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011120</data>
      <data key="d6" />
    </node>
    <node id="人与机器身份悖论">
      <data key="d0">人与机器身份悖论</data>
      <data key="d1">concept</data>
      <data key="d2">该悖论探讨了人工智能作为工具延伸弱化人类自主性，甚至当AI获得法律身份时，迫使哲学重新反思“人是什么”的本质问题。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011120</data>
      <data key="d6" />
    </node>
    <node id="Prompt(提示词)">
      <data key="d0">Prompt(提示词)</data>
      <data key="d1">concept</data>
      <data key="d2">提示词是人类向人工智能表达需求的指令，其语言越贴近机器语言，得到的结果越精准，体现了人机交互中的语言适应现象。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011122</data>
      <data key="d6" />
    </node>
    <node id="数据安全性">
      <data key="d0">数据安全性</data>
      <data key="d1">concept</data>
      <data key="d2">数据安全性涉及大数据技术对个人隐私信息的全息记录与潜在泄露风险，是人工智能带来的社会困境之一，需要哲学反思和监管。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011122</data>
      <data key="d6" />
    </node>
    <node id="信息可靠性">
      <data key="d0">信息可靠性</data>
      <data key="d1">concept</data>
      <data key="d2">信息可靠性问题指人工智能模型可能生成逻辑正确但包含错误、虚假或无中生有内容的文本，从而扰乱公共秩序。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011124</data>
      <data key="d6" />
    </node>
    <node id="数字偏见">
      <data key="d0">数字偏见</data>
      <data key="d1">concept</data>
      <data key="d2">数字偏见源于接触、使用和融合人工智能的机会与能力不均等，导致了“数字鸿沟”，构成了哲学研究公平性问题的新视域。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011124</data>
      <data key="d6" />
    </node>
    <node id="哲学事件">
      <data key="d0">哲学事件</data>
      <data key="d1">concept</data>
      <data key="d2">“哲学事件”指人工智能的出现和发展本身深刻改变甚至颠覆了传统的哲学观念和视野，迫使哲学进行基础概念的重新探究。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011127</data>
      <data key="d6" />
    </node>
    <node id="理解">
      <data key="d0">理解</data>
      <data key="d1">concept</data>
      <data key="d2">“理解”是一个基础哲学概念，人工智能的出现挑战了传统观点，促使人们思考AI是否构建了世界表示系统以及“理解”的真正含义。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011130</data>
      <data key="d6" />
    </node>
    <node id="哲学史">
      <data key="d0">哲学史</data>
      <data key="d1">concept</data>
      <data key="d2">哲学史是哲学研究依赖的长期积累过程，涉及哲学家与时代、思想发展史的“历时态”和“共时态”对话。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011130</data>
      <data key="d6" />
    </node>
    <node id="索菲娅">
      <data key="d0">索菲娅</data>
      <data key="d1">artifact</data>
      <data key="d2">索菲娅是一个获得法律上公民身份的AI机器人，其存在迫使哲学对“人是什么”以及人的本质进行深刻反思。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011132</data>
      <data key="d6" />
    </node>
    <node id="大数据技术">
      <data key="d0">大数据技术</data>
      <data key="d1">method</data>
      <data key="d2">大数据技术凭借数据采集、海量存储及智能分析，可以对个体隐私信息进行全息记录，引发数据安全性问题。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011132</data>
      <data key="d6" />
    </node>
    <node id="数字鸿沟">
      <data key="d0">数字鸿沟</data>
      <data key="d1">concept</data>
      <data key="d2">数字鸿沟是由于接触、使用和融合人工智能的机会与能力不均等而产生的事实，构成了数字偏见公平性研究的一部分。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011134</data>
      <data key="d6" />
    </node>
    <node id="道德地位问题">
      <data key="d0">道德地位问题</data>
      <data key="d1">concept</data>
      <data key="d2">道德地位问题是生成式人工智能激发出的新哲学问题之一。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011134</data>
      <data key="d6" />
    </node>
    <node id="智能驾驶事故归责问题">
      <data key="d0">智能驾驶事故归责问题</data>
      <data key="d1">concept</data>
      <data key="d2">智能驾驶事故归责问题是生成式人工智能激发出的新哲学问题之一。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011137</data>
      <data key="d6" />
    </node>
    <node id="隐私保护问题">
      <data key="d0">隐私保护问题</data>
      <data key="d1">concept</data>
      <data key="d2">隐私保护问题是生成式人工智能激发出的新哲学问题之一。</data>
      <data key="d3">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d4">unknown_source</data>
      <data key="d5">1769011137</data>
      <data key="d6" />
    </node>
    <edge source="深度学习模型" target="神经网络">
      <data key="d7">1.0</data>
      <data key="d8">神经网络是构成深度学习模型的底层技术基础。</data>
      <data key="d9">底层技术,构成</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001794</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="图片">
      <data key="d7">1.0</data>
      <data key="d8">深度学习模型可以识别图片这种复杂的数据模式。</data>
      <data key="d9">处理,识别</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001794</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="文本">
      <data key="d7">1.0</data>
      <data key="d8">深度学习模型可以识别文本这种复杂的数据模式。</data>
      <data key="d9">处理,识别</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001795</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="声音">
      <data key="d7">1.0</data>
      <data key="d8">深度学习模型可以识别声音这种复杂的数据模式。</data>
      <data key="d9">处理,识别</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001795</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="反向传播">
      <data key="d7">1.0</data>
      <data key="d8">反向传播是训练各种深度学习模型(从多层感知器到复杂生成式AI网络)的基础学习机制。</data>
      <data key="d9">learning mechanism,training foundation</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002454</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="自然语言">
      <data key="d7">1.0</data>
      <data key="d8">深度学习模型被用来处理自然语言。</data>
      <data key="d9">处理,应用</data>
      <data key="d10">chunk-fd544a0511ae2b1911f2ec7bdc2235ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006394</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="NNLM模型">
      <data key="d7">1.0</data>
      <data key="d8">NNLM模型是深度学习模型在语言建模中的一个经典范例。</data>
      <data key="d9">继承,范例</data>
      <data key="d10">chunk-fd544a0511ae2b1911f2ec7bdc2235ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006394</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="NLP预处理">
      <data key="d7">1.0</data>
      <data key="d8">NLP预处理将文本转换成深度学习模型更容易分析的特定格式。</data>
      <data key="d9">分析优化,格式转换</data>
      <data key="d10">chunk-38b1076024c94a070f64f72dcaea1102</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006690</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习模型" target="自然语言处理">
      <data key="d7">1.0</data>
      <data key="d8">Natural language processing applies deep learning models as a methodology for processing language.</data>
      <data key="d9">application,methodology</data>
      <data key="d10">chunk-b572e7e95c9e5e07043de0b3cb587187</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006727</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="节点">
      <data key="d7">2.0</data>
      <data key="d8">神经网络由互连的节点或神经元组成。&lt;SEP&gt;神经网络由节点作为基本单元构成。</data>
      <data key="d9">basic unit,component,包含,组成</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002947</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="神经元">
      <data key="d7">1.0</data>
      <data key="d8">神经网络由互连的节点或神经元组成。</data>
      <data key="d9">包含,组成</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001795</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="深度学习">
      <data key="d7">4.0</data>
      <data key="d8">神经网络是深度学习算法的基础，深度学习算法由多层神经网络节点构成。&lt;SEP&gt;Deep learning is a subfield of machine learning that is fundamentally based on the architecture of neural networks.&lt;SEP&gt;深度学习依托于神经网络，特别是深层神经网络，来进行数据处理。&lt;SEP&gt;神经网络是深度学习的基本概念。</data>
      <data key="d9">computational model,subfield,依托于,基础,基础概念,技术基础,算法构成,组成部分</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-03a5749c6bb89c89b202fa903dbb847f&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008536</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="Google">
      <data key="d7">1.0</data>
      <data key="d8">Google的搜索算法是神经网络技术的一个著名应用实例。</data>
      <data key="d9">技术应用,算法示例</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002059</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="反向传播">
      <data key="d7">2.0</data>
      <data key="d8">Back propagation is the core training algorithm and foundational method for learning in neural networks.&lt;SEP&gt;神经网络通过反向传播算法进行训练，以修正权重并减少误差。</data>
      <data key="d9">foundation,training algorithm,参数更新,训练过程</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002657</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="非线性动力学系统">
      <data key="d7">1.0</data>
      <data key="d8">Neural networks are described as an instance of a higher-dimensional nonlinear dynamical system.</data>
      <data key="d9">higher-dimensional system,instance</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002337</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="激活函数">
      <data key="d7">2.0</data>
      <data key="d8">The activation function is a core component within neural network neurons that enables nonlinear transformations.&lt;SEP&gt;神经网络中的神经元使用激活函数(如tanh或softmax)对输入进行非线性变换，以决定其输出。</data>
      <data key="d9">component,node activation,nonlinear transformation</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002456</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="误差损失函数">
      <data key="d7">1.0</data>
      <data key="d8">During training, a neural network's performance is evaluated and optimized using an error loss function.</data>
      <data key="d9">evaluation,optimization target</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002338</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="隐藏层">
      <data key="d7">1.0</data>
      <data key="d8">神经网络通过一个或多个隐藏层逐步提取和转换输入数据的关键特征。</data>
      <data key="d9">data transformation,feature extraction</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002457</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="输出层">
      <data key="d7">1.0</data>
      <data key="d8">神经网络的输出层接收来自隐藏层的处理结果，并生成模型的最终预测(如分类概率)。</data>
      <data key="d9">prediction output,result generation</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002465</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="权重">
      <data key="d7">1.0</data>
      <data key="d8">神经网络通过学习调整连接神经元之间的权重来存储知识和做出预测。</data>
      <data key="d9">parameterization,signal modulation</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002466</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="偏置项">
      <data key="d7">1.0</data>
      <data key="d8">神经网络中的神经元包含偏置项，这是一个可调整的参数，用于与加权输入相加以影响激活。</data>
      <data key="d9">activation threshold,parameter adjustment</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002468</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="前向传播">
      <data key="d7">1.0</data>
      <data key="d8">在神经网络中，前向传播是输入数据通过网络层产生输出的过程。</data>
      <data key="d9">数据流动,计算过程</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002655</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="连接">
      <data key="d7">1.0</data>
      <data key="d8">神经网络中的节点通过连接相互关联。</data>
      <data key="d9">component,pathway</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002949</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="自编码器">
      <data key="d7">1.0</data>
      <data key="d8">自编码器是一类特定的神经网络结构。</data>
      <data key="d9">类别归属,结构基础</data>
      <data key="d10">chunk-e101b215c048456f8049a66e9ebd2c54</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003381</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="自动编码器">
      <data key="d7">1.0</data>
      <data key="d8">自动编码器是神经网络的一种类型。</data>
      <data key="d9">属于,类型</data>
      <data key="d10">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003447</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="Excel">
      <data key="d7">1.0</data>
      <data key="d8">Excel software is used as a tool to replicate and demonstrate the calculation processes involved in a neural network.</data>
      <data key="d9">calculation tool,model replication</data>
      <data key="d10">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003930</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="深度学习工程师">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning engineers can combine multiple neural networks.</data>
      <data key="d9">combination,design</data>
      <data key="d10">chunk-1eb9c8a9254475c3a6672347d5ac549f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006411</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="端到端设计">
      <data key="d7">1.0</data>
      <data key="d8">Neural networks are the components used to implement an end-to-end design.</data>
      <data key="d9">implementation,methodology</data>
      <data key="d10">chunk-1eb9c8a9254475c3a6672347d5ac549f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006412</data>
      <data key="d13" />
    </edge>
    <edge source="神经网络" target="向量">
      <data key="d7">1.0</data>
      <data key="d8">Neural networks use vectors as their internal language for communication between layers and networks.</data>
      <data key="d9">communication,representation</data>
      <data key="d10">chunk-1eb9c8a9254475c3a6672347d5ac549f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006412</data>
      <data key="d13" />
    </edge>
    <edge source="节点" target="分层结构">
      <data key="d7">1.0</data>
      <data key="d8">节点位于神经网络的分层结构中。</data>
      <data key="d9">位于,组织</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001794</data>
      <data key="d13" />
    </edge>
    <edge source="节点" target="反向传播">
      <data key="d7">1.0</data>
      <data key="d8">反向传播的计算顺序在节点间进行，每个节点将计算后的结果传递给下一个节点。</data>
      <data key="d9">梯度传递,计算流程</data>
      <data key="d10">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002359</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="分层结构">
      <data key="d7">1.0</data>
      <data key="d8">神经元位于神经网络的分层结构中。</data>
      <data key="d9">位于,组织</data>
      <data key="d10">chunk-cb5e07f0bad1ec285e66b4df8be69531</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001795</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="反向传播">
      <data key="d7">1.0</data>
      <data key="d8">在反向传播过程中，误差被分配给每个神经元，然后根据其梯度更新与之相连的权重。</data>
      <data key="d9">权重调整,误差分配</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002330</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="输入值">
      <data key="d7">1.0</data>
      <data key="d8">神经元接收输入值，并将其与权重系数结合进行处理。</data>
      <data key="d9">信号处理,数据接收</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002655</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="权重系数">
      <data key="d7">1.0</data>
      <data key="d8">神经元的输出受其输入值与权重系数乘积的影响，权重在训练中被修正。</data>
      <data key="d9">参数调整,连接强度</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002656</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="激活函数">
      <data key="d7">1.0</data>
      <data key="d8">神经元通过激活函数f(e)对加权和进行非线性变换，产生输出y。</data>
      <data key="d9">输出生成,非线性变换</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002657</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="感知器">
      <data key="d7">1.0</data>
      <data key="d8">感知器模仿生物神经元的功能，接收输入并产生输出。</data>
      <data key="d9">analogy,biological inspiration</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002943</data>
      <data key="d13" />
    </edge>
    <edge source="神经元" target="多层感知机">
      <data key="d7">1.0</data>
      <data key="d8">A multilayer perceptron is composed of multiple layers of neurons.</data>
      <data key="d9">composition,structure</data>
      <data key="d10">chunk-2bd963b40a794cdd2a7befd072b521f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003576</data>
      <data key="d13" />
    </edge>
    <edge source="Michael Nielsen" target="Neural Networks And Deep Learning">
      <data key="d7">1.0</data>
      <data key="d8">Michael Nielsen is the author of the open-source textbook "Neural Networks and Deep Learning".</data>
      <data key="d9">authorship,educational resource</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001899</data>
      <data key="d13" />
    </edge>
    <edge source="Michael Nielsen" target="神经网络与深度学习">
      <data key="d7">1.0</data>
      <data key="d8">Michael Nielsen是《神经网络与深度学习》这本在线教科书的作者，该书内容涉及神经网络和反向传播。</data>
      <data key="d9">authorship,educational content</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002457</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Neuron" target="Perceptron">
      <data key="d7">1.0</data>
      <data key="d8">The perceptron is an early and enduring model of an artificial neuron.</data>
      <data key="d9">historical development,model implementation</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001899</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Neuron" target="Artificial Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Artificial neurons are the components used to build artificial neural networks, which simulate thinking.</data>
      <data key="d9">component,simulation</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001906</data>
      <data key="d13" />
    </edge>
    <edge source="Perceptron" target="Weight">
      <data key="d7">1.0</data>
      <data key="d8">Weights are key parameters within the perceptron model used to calculate the weighted sum of inputs.</data>
      <data key="d9">calculation,model parameter</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001900</data>
      <data key="d13" />
    </edge>
    <edge source="Perceptron" target="Threshold">
      <data key="d7">1.0</data>
      <data key="d8">The threshold is used in the perceptron to determine whether the neuron activates (outputs 1) or not (outputs 0).</data>
      <data key="d9">activation,decision criteria</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001902</data>
      <data key="d13" />
    </edge>
    <edge source="Perceptron" target="Sigmoid Function">
      <data key="d7">1.0</data>
      <data key="d8">The sigmoid function is applied to the perceptron's output to create a continuous activation function.</data>
      <data key="d9">function application,output transformation</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001902</data>
      <data key="d13" />
    </edge>
    <edge source="Perceptron" target="Dot Product">
      <data key="d7">1.0</data>
      <data key="d8">The dot product of the weight vector and input vector is a fundamental calculation within the perceptron model.</data>
      <data key="d9">calculation step,model operation</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001903</data>
      <data key="d13" />
    </edge>
    <edge source="Weight" target="Training">
      <data key="d7">1.0</data>
      <data key="d8">Training involves the iterative adjustment of weights to optimize model performance.</data>
      <data key="d9">iterative process,parameter optimization</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001899</data>
      <data key="d13" />
    </edge>
    <edge source="Weight" target="Narrator">
      <data key="d7">1.0</data>
      <data key="d8">The narrator relearned the meaning of the concept of weight clearly and profoundly.</data>
      <data key="d9">learning,understanding</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001914</data>
      <data key="d13" />
    </edge>
    <edge source="Weight" target="Filter">
      <data key="d7">1.0</data>
      <data key="d8">A filter (convolution kernel) is composed of a set of fixed weights.</data>
      <data key="d9">composition,element</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002958</data>
      <data key="d13" />
    </edge>
    <edge source="Threshold" target="Bias">
      <data key="d7">1.0</data>
      <data key="d8">Bias (`b`) is mathematically defined as the negative of the threshold value.</data>
      <data key="d9">mathematical relation,parameter definition</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001899</data>
      <data key="d13" />
    </edge>
    <edge source="Threshold" target="Image Comparison Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">A threshold (like 85% confidence) is used with an image comparison algorithm to validate its probabilistic output.</data>
      <data key="d9">confidence level,result validation</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001902</data>
      <data key="d13" />
    </edge>
    <edge source="Threshold" target="Narrator">
      <data key="d7">1.0</data>
      <data key="d8">The narrator relearned the meaning of the concept of threshold clearly and profoundly.</data>
      <data key="d9">learning,understanding</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001908</data>
      <data key="d13" />
    </edge>
    <edge source="Bias" target="Training">
      <data key="d7">1.0</data>
      <data key="d8">Training involves the iterative adjustment of bias to optimize model performance.</data>
      <data key="d9">iterative process,parameter optimization</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001902</data>
      <data key="d13" />
    </edge>
    <edge source="Bias" target="Neuron Layer">
      <data key="d7">1.0</data>
      <data key="d8">A neuron layer has a shared bias term that is added to the weighted sum of inputs for each neuron.</data>
      <data key="d9">activation shift,network parameter</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002717</data>
      <data key="d13" />
    </edge>
    <edge source="Training" target="Dataset">
      <data key="d7">1.0</data>
      <data key="d8">A dataset with known answers is used during the training process to teach the model.</data>
      <data key="d9">data utilization,model development</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001900</data>
      <data key="d13" />
    </edge>
    <edge source="Training" target="Trial And Error">
      <data key="d7">1.0</data>
      <data key="d8">Trial and error is the methodological basis for the training process of adjusting weights and bias.</data>
      <data key="d9">methodology,process description</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001902</data>
      <data key="d13" />
    </edge>
    <edge source="Training" target="Model">
      <data key="d7">1.0</data>
      <data key="d8">A model undergoes training to optimize its parameters (weights and bias) for accurate performance.</data>
      <data key="d9">optimization,system development</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001904</data>
      <data key="d13" />
    </edge>
    <edge source="Training" target="Partial Derivative">
      <data key="d7">1.0</data>
      <data key="d8">Partial derivatives are used during training to precisely calculate how changes in parameters affect the output.</data>
      <data key="d9">mathematical tool,optimization</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001905</data>
      <data key="d13" />
    </edge>
    <edge source="Dataset" target="Training Set">
      <data key="d7">1.0</data>
      <data key="d8">The Dataset is randomly split, with 80% allocated as the Training Set.</data>
      <data key="d9">data partitioning,subset</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005612</data>
      <data key="d13" />
    </edge>
    <edge source="Dataset" target="Test Set">
      <data key="d7">1.0</data>
      <data key="d8">The Dataset is randomly split, with 20% allocated as the Test Set.</data>
      <data key="d9">data partitioning,subset</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005623</data>
      <data key="d13" />
    </edge>
    <edge source="Dataset" target="Empirical Results">
      <data key="d7">1.0</data>
      <data key="d8">The Empirical Results section describes the composition and partitioning of the Dataset.</data>
      <data key="d9">data description,study section</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005627</data>
      <data key="d13" />
    </edge>
    <edge source="Sigmoid Function" target="Continuous Function">
      <data key="d7">1.0</data>
      <data key="d8">The sigmoid function is a specific implementation used to create a continuous output function from the perceptron's result.</data>
      <data key="d9">function type,implementation</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001903</data>
      <data key="d13" />
    </edge>
    <edge source="Sigmoid Function" target="Activation Function">
      <data key="d7">1.0</data>
      <data key="d8">The sigmoid function is a specific type of activation function used in neural networks.</data>
      <data key="d9">non-linearity,specific implementation</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002719</data>
      <data key="d13" />
    </edge>
    <edge source="License Plate Photo" target="Image Comparison Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">An image comparison algorithm processes input like a license plate photo to perform recognition.</data>
      <data key="d9">analysis method,data processing</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001900</data>
      <data key="d13" />
    </edge>
    <edge source="Nano Degree Course" target="Code Review">
      <data key="d7">1.0</data>
      <data key="d8">The nano degree course includes a code review feature where mentors review student submissions.</data>
      <data key="d9">course feature,quality assurance</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001903</data>
      <data key="d13" />
    </edge>
    <edge source="Nano Degree Course" target="One-On-One Tutoring">
      <data key="d7">1.0</data>
      <data key="d8">The nano degree course offers weekly one-on-one tutoring sessions as a benefit to students.</data>
      <data key="d9">course feature,personalized learning</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001905</data>
      <data key="d13" />
    </edge>
    <edge source="Nano Degree Course" target="Enrollment Quota">
      <data key="d7">1.0</data>
      <data key="d8">The nano degree course has a limited enrollment quota of 200 spots for the current session.</data>
      <data key="d9">administrative limit,capacity</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001906</data>
      <data key="d13" />
    </edge>
    <edge source="Prolog" target="Logic Problem">
      <data key="d7">1.0</data>
      <data key="d8">Prolog is a programming language specifically designed for solving logic problems.</data>
      <data key="d9">application domain,problem-solving</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001904</data>
      <data key="d13" />
    </edge>
    <edge source="Yin Wang" target="AI Research">
      <data key="d7">1.0</data>
      <data key="d8">Yin Wang's blog post provides a critique or commentary on the state of AI research in relation to brain science.</data>
      <data key="d9">commentary,critique</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001905</data>
      <data key="d13" />
    </edge>
    <edge source="Input Vector" target="Weight Vector">
      <data key="d7">1.0</data>
      <data key="d8">The input vector and weight vector are used together in the dot product operation to calculate the perceptron's input sum.</data>
      <data key="d9">mathematical operation,model input</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001901</data>
      <data key="d13" />
    </edge>
    <edge source="Output" target="Continuous Function">
      <data key="d7">1.0</data>
      <data key="d8">The output of a model needs to be a continuous function to ensure sensitivity and correctness during training.</data>
      <data key="d9">requirement,transformation</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001902</data>
      <data key="d13" />
    </edge>
    <edge source="Partial Derivative" target="Error">
      <data key="d7">1.0</data>
      <data key="d8">The partial derivative of the error with respect to a weight is calculated to determine how to adjust that weight.</data>
      <data key="d9">backpropagation,gradient calculation</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002718</data>
      <data key="d13" />
    </edge>
    <edge source="AI Research" target="Brain Science">
      <data key="d7">1.0</data>
      <data key="d8">The text contrasts AI research practices with the foundational knowledge derived from brain science.</data>
      <data key="d9">field comparison,foundational knowledge</data>
      <data key="d10">chunk-c8c18ca634546204b03cd44a9bdee917</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001906</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Neural Network" target="Learning">
      <data key="d7">1.0</data>
      <data key="d8">In artificial intelligence, the modification of connection strengths in artificial neural networks enables learning.</data>
      <data key="d9">capability,mechanism</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003892</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Neural Network" target="AlphaFold">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold utilizes artificial neural networks as its core computational methodology.</data>
      <data key="d9">implementation,methodology</data>
      <data key="d10">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004423</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Neural Network" target="Flood Forecasting">
      <data key="d7">1.0</data>
      <data key="d8">Artificial Neural Networks are used as models for the application of Flood Forecasting.</data>
      <data key="d9">application,modeling</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010129</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Neural Network" target="Copula Entropy Method">
      <data key="d7">1.0</data>
      <data key="d8">The Copula Entropy Method is used to determine input variables for Artificial Neural Networks in flood forecasting contexts.</data>
      <data key="d9">input determination,preprocessing</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010135</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Neural Network" target="Rainfall-Runoff Process">
      <data key="d7">1.0</data>
      <data key="d8">Artificial Neural Networks are used for modeling the Rainfall-Runoff Process.</data>
      <data key="d9">modeling,simulation</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010140</data>
      <data key="d13" />
    </edge>
    <edge source="Wang Yin" target="AI Researcher">
      <data key="d7">1.0</data>
      <data key="d8">Wang Yin's essay questions and critiques the practices and background knowledge of AI researchers regarding brain science.</data>
      <data key="d9">critique,questioning</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001906</data>
      <data key="d13" />
    </edge>
    <edge source="Douglas Hofstadter" target="AI Expert">
      <data key="d7">1.0</data>
      <data key="d8">Douglas Hofstadter criticizes AI experts for their lack of interest and deep research into how the brain and mind work.</data>
      <data key="d9">criticism,disinterest</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001906</data>
      <data key="d13" />
    </edge>
    <edge source="AI Researcher" target="Brain">
      <data key="d7">1.0</data>
      <data key="d8">The text states that AI researchers have not truly studied the human brain, dissected it, or experimented with it.</data>
      <data key="d9">lack of study,neglect</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001907</data>
      <data key="d13" />
    </edge>
    <edge source="AI Researcher" target="Neuroscience">
      <data key="d7">1.0</data>
      <data key="d8">The text claims that AI researchers have not read the research outcomes of neuroscience.</data>
      <data key="d9">ignorance,lack of engagement</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001908</data>
      <data key="d13" />
    </edge>
    <edge source="AI Researcher" target="Cognitive Science">
      <data key="d7">1.0</data>
      <data key="d8">The text states that AI researchers have not conducted genuine research in cognitive science.</data>
      <data key="d9">disconnection,lack of research</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001909</data>
      <data key="d13" />
    </edge>
    <edge source="Mind" target="AI Expert">
      <data key="d7">1.0</data>
      <data key="d8">AI experts are accused of having no real interest in how the mind works, despite claiming to pursue AGI.</data>
      <data key="d9">disinterest,superficial claim</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001907</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial General Intelligence (AGI)" target="AI">
      <data key="d7">1.0</data>
      <data key="d8">AGI is a goal within the field of AI, described as remaining an unrealized or vain dream.</data>
      <data key="d9">field goal,unrealized dream</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001907</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial General Intelligence (AGI)" target="AI Expert">
      <data key="d7">1.0</data>
      <data key="d8">AI experts aspire to achieve Artificial General Intelligence (AGI), but this goal is criticized as vain because they ignore brain and mind research.</data>
      <data key="d9">aspiration,criticism</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001908</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="Google Cloud">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides products and solutions based on AI technology.</data>
      <data key="d9">service domain,technology provider</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002149</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="CPU">
      <data key="d7">1.0</data>
      <data key="d8">AI can typically run on standard CPUs, though complex models require greater computational power.</data>
      <data key="d9">computational baseline,hardware requirement</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002152</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="关键工作流程">
      <data key="d7">1.0</data>
      <data key="d8">AI can be used to reshape key workflows.</data>
      <data key="d9">process transformation,technology application</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003198</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="运营">
      <data key="d7">1.0</data>
      <data key="d8">AI can be used to reshape operations.</data>
      <data key="d9">process optimization,technology application</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003199</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="体验">
      <data key="d7">1.0</data>
      <data key="d8">AI can maximize experience.</data>
      <data key="d9">outcome enhancement,technology impact</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003199</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="实时决策">
      <data key="d7">1.0</data>
      <data key="d8">AI can maximize real-time decision making.</data>
      <data key="d9">capability enhancement,technology impact</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003199</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="商业价值">
      <data key="d7">1.0</data>
      <data key="d8">AI can maximize business value.</data>
      <data key="d9">outcome enhancement,technology impact</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003200</data>
      <data key="d13" />
    </edge>
    <edge source="AI" target="数理逻辑">
      <data key="d7">1.0</data>
      <data key="d8">AI follows mathematical logic, which emphasizes computation, causality, and recursion.</data>
      <data key="d9">computational basis,follows</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011167</data>
      <data key="d13" />
    </edge>
    <edge source="Narrator" target="Neural Networks and Deep Learning">
      <data key="d7">1.0</data>
      <data key="d8">The narrator encountered the resource Neural Networks and Deep Learning at a different time during their educational path.</data>
      <data key="d9">encounter,learning journey</data>
      <data key="d10">chunk-90d06b6fbc58cfba3d096615baf2b706</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001909</data>
      <data key="d13" />
    </edge>
    <edge source="Azure机器学习" target="Foundry模型">
      <data key="d7">1.0</data>
      <data key="d8">Azure机器学习平台提供了Foundry模型，这些是预先训练的深度学习模型，可供用户微调使用。</data>
      <data key="d9">提供,预训练模型</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001982</data>
      <data key="d13" />
    </edge>
    <edge source="Azure机器学习" target="深度学习">
      <data key="d7">1.0</data>
      <data key="d8">Azure机器学习支持构建深度学习解决方案，应用于欺诈检测、语音识别、面部识别、情绪分析和时序预测等领域。</data>
      <data key="d9">应用场景,支持构建</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001985</data>
      <data key="d13" />
    </edge>
    <edge source="Azure机器学习" target="Microsoft Azure Global Edition">
      <data key="d7">1.0</data>
      <data key="d8">Azure Machine Learning is a service within the Microsoft Azure Global Edition cloud platform, and its technical documentation is hosted there.</data>
      <data key="d9">documentation source,hosted on</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001987</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="机器学习">
      <data key="d7">8.0</data>
      <data key="d8">{"实体列表": ["机器学习", "深度学习", "人工神经网络", "深度神经网络", "神经网络", "模式识别"]}</data>
      <data key="d9">advancement,evolution,subset,包含关系,子集,子集关系,子领域,强大引擎,技术基础,技术递进,特殊形式</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008521</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="人工神经网络">
      <data key="d7">3.0</data>
      <data key="d8">深度学习的技术基础是人工神经网络，其多层结构使得深度学习能够进行复杂的数据处理和学习。&lt;SEP&gt;Deep learning represents a revival and significant advancement of artificial neural networks, overcoming previous limitations like local minima.&lt;SEP&gt;Deep Learning models are built upon and implemented using architectures based on Artificial Neural Networks.</data>
      <data key="d9">advancement,architecture,implementation,revival,基于,核心结构</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008581</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="GPU">
      <data key="d7">2.0</data>
      <data key="d8">深度学习依赖于高端硬件如GPU，因为GPU能有效优化深度学习所需执行的大量矩阵乘法运算。&lt;SEP&gt;深度学习算法训练速度的大幅提升依赖于GPU等并行计算硬件的加速。</data>
      <data key="d9">加速依赖,硬件依赖,硬件基础,计算优化</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007034</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="迁移学习">
      <data key="d7">2.0</data>
      <data key="d8">迁移学习是一种用于优化深度学习模型训练过程的技术，能显著减少对数据、时间和计算资源的需求。&lt;SEP&gt;迁移学习是深度学习领域关注的前沿技术之一。</data>
      <data key="d9">前沿技术,技术应用,技术领域,训练优化</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007009</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="生成对抗网络">
      <data key="d7">1.0</data>
      <data key="d8">生成对抗网络是深度学习领域中的一种生成模型，专门用于创建逼真的合成内容。</data>
      <data key="d9">属于,生成模型</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001987</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="转换器">
      <data key="d7">1.0</data>
      <data key="d8">转换器是深度学习中的一种模型架构，专门设计用于处理文本或时序数据等序列问题。</data>
      <data key="d9">属于,序列模型</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001987</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="卷积神经网络">
      <data key="d7">8.0</data>
      <data key="d8">卷积神经网络（Convolutional Neural Network，简称CNN或卷积神经网络）是深度学习领域中的一种特定且经典的网络架构，属于深度学习算法的一个子集和应用。深度学习作为一个更广泛的领域，为构建和理解卷积神经网络模型提供了知识基础。卷积神经网络是深度学习的代表性范例和突出架构之一。在实践应用中，深度学习经常使用卷积神经网络作为对序列进行编码的重要方法，并利用此类模型在诸如医学影像识别等多个领域实现具体应用。</data>
      <data key="d9">application,architecture,example,knowledge base,methodology,model construction,representation,subset,utilization,属于,技术实现,机器学习,架构,模型应用</data>
      <data key="d10">chunk-d22adf07bd762e4e32d9bceea2fa6218&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-c79b805e7da972f5a80b0f9eb1144d75&lt;SEP&gt;chunk-225c135f952fba89e32fc67dcf80d0f5&lt;SEP&gt;chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008578</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="卷积平摊">
      <data key="d7">1.0</data>
      <data key="d8">The field of deep learning includes the concept of convolution flattening as part of its theoretical explanations.</data>
      <data key="d9">concept,includes</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002933</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="人工智能">
      <data key="d7">3.0</data>
      <data key="d8">Deep learning is a core subfield and a driving force within the broader domain of artificial intelligence.&lt;SEP&gt;深度学习是人工智能的一个子领域。&lt;SEP&gt;深度学习是人工智能领域的核心技术之一。</data>
      <data key="d9">core component,subfield,包含关系,子领域,核心技术,领域归属</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010738</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="循环神经网络">
      <data key="d7">2.0</data>
      <data key="d8">深度学习经常使用循环神经网络作为对序列进行编码的方法之一。&lt;SEP&gt;深度学习使用循环神经网络等模型在语音助手等领域进行应用。</data>
      <data key="d9">methodology,utilization,技术实现,模型应用</data>
      <data key="d10">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008580</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="研究">
      <data key="d7">1.0</data>
      <data key="d8">这项研究深入探讨了深度学习中通过优化实现有效学习的机制。</data>
      <data key="d9">探讨,机制分析</data>
      <data key="d10">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003716</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="计算认知">
      <data key="d7">1.0</data>
      <data key="d8">掌握深度学习的基本知识是加深对计算认知理解的基础。</data>
      <data key="d9">基础知识,学习路径</data>
      <data key="d10">chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003754</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="计算神经科学">
      <data key="d7">1.0</data>
      <data key="d8">掌握深度学习的基本知识是加深对计算神经科学理解的基础。</data>
      <data key="d9">基础知识,学习路径</data>
      <data key="d10">chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003754</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="Geoffrey Hinton">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton is a foundational figure who made outstanding contributions to deep learning, including inventing key training methods in 2006.</data>
      <data key="d9">contribution,foundation,invention</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="AlphaGo">
      <data key="d7">1.0</data>
      <data key="d8">AlphaGo's success in Go is considered a prime annotation of the deep learning revolution, demonstrating its capabilities.</data>
      <data key="d9">application,demonstration</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003890</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="蛋白质结构预测">
      <data key="d7">1.0</data>
      <data key="d8">深度学习被应用于蛋白质结构预测领域。</data>
      <data key="d9">应用,计算方法</data>
      <data key="d10">chunk-c5eafae240ac5d07dadf7c4eb744e8eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004058</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="ESMFold">
      <data key="d7">1.0</data>
      <data key="d8">ESMFold是基于深度学习的方法。</data>
      <data key="d9">基于,方法</data>
      <data key="d10">chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004070</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="MIT 6.874">
      <data key="d7">1.0</data>
      <data key="d8">MIT 6.874课程介绍了深度学习的前沿挑战。</data>
      <data key="d9">前沿挑战,课程内容</data>
      <data key="d10">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004342</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="量化交易">
      <data key="d7">2.0</data>
      <data key="d8">Deep learning is applied within quantitative trading, bringing new perspectives and tools to the field.&lt;SEP&gt;文中提及深度学习在量化交易中的应用，特别是在高频场景下的优势。</data>
      <data key="d9">application,transformation,应用,效能评估</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411&lt;SEP&gt;chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005167</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="高维数据">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models possess the capability to effectively process the high-dimensional data involved in quantitative trading.</data>
      <data key="d9">capability,data processing</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004956</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="维度灾难">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models help to avoid the "curse of dimensionality" problem common in traditional statistical methods.</data>
      <data key="d9">problem mitigation</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004957</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="经典因子模型">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models can be seamlessly integrated with classical factor models to form composite or hybrid trading strategies.</data>
      <data key="d9">hybrid strategy,integration</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004958</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="统计套利策略">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models can be seamlessly combined with statistical arbitrage strategies as part of a composite trading approach.</data>
      <data key="d9">composite strategy,integration</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004959</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="资金分配模型">
      <data key="d7">1.0</data>
      <data key="d8">In a hybrid approach, deep learning models generate trading signals while traditional capital allocation models optimize the portfolio.</data>
      <data key="d9">division of labor,hybrid strategy</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004961</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="市场环境">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models can adapt to changing market environments through continuous data training and model updates.</data>
      <data key="d9">adaptation,continuous learning</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004962</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="技术指标">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning's automatic feature extraction capability simplifies the traditional, manual process of designing technical indicators.</data>
      <data key="d9">automation,replacement</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004963</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="高频量化">
      <data key="d7">1.0</data>
      <data key="d8">在高频量化中，深度学习比传统机器学习展现出更多的优势。</data>
      <data key="d9">优势,应用场景</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005169</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="推荐系统">
      <data key="d7">1.0</data>
      <data key="d8">以互联网行业的推荐系统为例，说明深度学习能应用好的前提是人本身也能把这件事做得不错。</data>
      <data key="d9">前提条件,应用领域</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005171</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="反欺诈">
      <data key="d7">1.0</data>
      <data key="d8">深度学习在互联网行业被用于反欺诈等任务。</data>
      <data key="d9">应用领域</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005172</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="因子">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models in quantitative trading can also use factors as input features, and there is mention of using them to mine for new factors.</data>
      <data key="d9">data source,feature utilization</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005174</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="quant-computer">
      <data key="d7">1.0</data>
      <data key="d8">The user 'quant-computer' ultimately switched to working in deep learning (image processing).</data>
      <data key="d9">专业领域,职业转变</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005175</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="Panel_Trader">
      <data key="d7">1.0</data>
      <data key="d8">The user 'Panel_Trader' recommended deep learning as suitable for large-sample, high-frequency data.</data>
      <data key="d9">方法推荐,适用场景</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005177</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="风控建模方法">
      <data key="d7">1.0</data>
      <data key="d8">该风控建模方法基于深度学习技术构建。</data>
      <data key="d9">技术基础,核心方法</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005217</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="欺诈应用检测方法">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning is the foundational methodology used for the fraud application detection method.</data>
      <data key="d9">application,methodology</data>
      <data key="d10">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005742</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="AI Agent风控模型">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型是基于深度学习技术实现的。</data>
      <data key="d9">技术基础,算法实现</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005787</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="大数据">
      <data key="d7">1.0</data>
      <data key="d8">Big data provides the context for the rapid development of deep learning.</data>
      <data key="d9">context,technological development</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006187</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="自然语言处理">
      <data key="d7">2.0</data>
      <data key="d8">深度学习在自然语言处理领域扮演着至关重要的角色，是推动其发展的秘密武器。&lt;SEP&gt;自然语言处理结合深度学习技术来识别、理解和生成文本和语音。</data>
      <data key="d9">技术应用,方法,核心方法,结合</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007484</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="词向量">
      <data key="d7">1.0</data>
      <data key="d8">深度学习机制需要让计算机学会每个独立词汇所代表的词向量，这是其理解语义的基础。</data>
      <data key="d9">技术实现,核心概念</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006620</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="语料库">
      <data key="d7">1.0</data>
      <data key="d8">深度学习的语言学习过程需要通过分析大量文本(语料库)来进行。</data>
      <data key="d9">学习基础,数据依赖</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006622</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="Clear Plaster">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning enables AI to correctly interpret the search query "clear plaster" as a first-aid item, demonstrating its practical application in NLP.</data>
      <data key="d9">practical application,query interpretation</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006626</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="Seed Data">
      <data key="d7">1.0</data>
      <data key="d8">In deep learning applications like keyword marketing, the process starts by inputting some seed data into the AI system.</data>
      <data key="d9">input mechanism,process initiation</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006630</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="孙民">
      <data key="d7">1.0</data>
      <data key="d8">孙民阐述了深度学习如何解决传统方法的问题，使NLP更贴近人类学习模式。</data>
      <data key="d9">专家评论,方法倡导</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006635</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="LSTM">
      <data key="d7">2.0</data>
      <data key="d8">深度学习需要处理长时间依赖的特征时，可以使用LSTM。&lt;SEP&gt;LSTM是深度学习的一种具体实现方式，用于学习上下文特征。</data>
      <data key="d9">包含,实现方式,应用,特征提取</data>
      <data key="d10">chunk-432af570193bd3df6d564434ee8bfbbb&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006995</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="对抗网络">
      <data key="d7">1.0</data>
      <data key="d8">对抗网络是深度学习领域关注的前沿技术之一。</data>
      <data key="d9">前沿技术,技术领域</data>
      <data key="d10">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006998</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="强化学习">
      <data key="d7">2.0</data>
      <data key="d8">根据David Silver的观点，深度学习与强化学习相结合可以构成人工智能。&lt;SEP&gt;强化学习是深度学习领域关注的前沿技术之一。</data>
      <data key="d9">前沿技术,技术领域,构成要素,结合</data>
      <data key="d10">chunk-432af570193bd3df6d564434ee8bfbbb&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006999</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="上下文特征">
      <data key="d7">1.0</data>
      <data key="d8">深度学习(特别是LSTM)能够学习上下文特征，以解决长距离语义理解问题。</data>
      <data key="d9">学习,解决</data>
      <data key="d10">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007011</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="David Silver">
      <data key="d7">1.0</data>
      <data key="d8">David Silver提出了“深度学习+强化学习=人工智能”的观点，将深度学习与人工智能关联起来。</data>
      <data key="d9">关联,观点阐述</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007018</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="特征工程">
      <data key="d7">2.0</data>
      <data key="d8">深度学习颠覆了传统机器学习的过程，不需要手动做特征工程。&lt;SEP&gt;深度学习颠覆了传统机器学习流程，它不需要进行复杂的手动特征工程。</data>
      <data key="d9">替代,自动化,颠覆</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007033</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="CNN">
      <data key="d7">2.0</data>
      <data key="d8">深度学习需要提取局部文本特征时，现在可以使用CNN。&lt;SEP&gt;CNN是深度学习领域中一种典型的神经网络模型。</data>
      <data key="d9">典型模型,属于,应用,特征提取</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007036</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="RNN">
      <data key="d7">2.0</data>
      <data key="d8">深度学习需要处理长时间依赖的特征时，可以使用RNN。&lt;SEP&gt;RNN是深度学习领域中用于处理序列数据的典型模型。</data>
      <data key="d9">典型模型,属于,应用,特征提取</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007038</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="互联网时代">
      <data key="d7">1.0</data>
      <data key="d8">互联网时代带来的海量电子化数据是深度学习得以发展和应用的重要基础。</data>
      <data key="d9">发展条件,数据基础</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007049</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="并行计算">
      <data key="d7">1.0</data>
      <data key="d8">深度学习的算法训练速度极大地依赖于GPU等并行计算技术的加速。</data>
      <data key="d9">加速技术,硬件依赖</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007054</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="N元语法模型">
      <data key="d7">1.0</data>
      <data key="d8">深度学习需要提取局部特征时，传统上可以使用N元语法模型。</data>
      <data key="d9">应用,特征提取</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007051</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="传统机器学习">
      <data key="d7">1.0</data>
      <data key="d8">传统机器学习与深度学习各有优劣，前者依赖特征工程，后者可实现端到端学习，两者是相融相生的关系。</data>
      <data key="d9">方法对比,相融相生</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007107</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="浙江大学人工智能教育教学研究中心">
      <data key="d7">1.0</data>
      <data key="d8">该研究中心的研究展示了深度学习在模拟人类语言理解中的应用。</data>
      <data key="d9">应用,研究</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008539</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="大语言模型">
      <data key="d7">2.0</data>
      <data key="d8">大语言模型是基于Transformer架构的深度学习模型，是处理人类语言的杰出成果。&lt;SEP&gt;深度学习包含大语言模型，大语言模型是深度学习技术的杰出应用之一。</data>
      <data key="d9">包含关系,技术基础,技术应用,架构实现</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008548</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="AI黑话揭秘">
      <data key="d7">1.0</data>
      <data key="d8">文章《AI黑话揭秘》旨在解释深度学习及其相关概念。</data>
      <data key="d9">概念澄清,解释</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008555</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="医学影像识别">
      <data key="d7">1.0</data>
      <data key="d8">深度学习应用于医学影像识别领域，例如使用卷积神经网络。</data>
      <data key="d9">应用领域,技术实现</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008560</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="语音助手">
      <data key="d7">1.0</data>
      <data key="d8">深度学习应用于语音助手领域，例如使用循环神经网络。</data>
      <data key="d9">应用领域,技术实现</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008565</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="大模型">
      <data key="d7">1.0</data>
      <data key="d8">Large Models, especially in NLP, are trained using Deep Learning techniques.</data>
      <data key="d9">training,utilization</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008584</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="深度学习框架">
      <data key="d7">1.0</data>
      <data key="d8">Deep Learning Frameworks are essential software tools that have standardized and accelerated the development of Deep Learning models.</data>
      <data key="d9">standardization,tool</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008594</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="训练数据">
      <data key="d7">1.0</data>
      <data key="d8">Training data is the input for deep learning models; biases in this data can lead to flawed outputs in AI systems.</data>
      <data key="d9">bias source,input</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009047</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="LLM">
      <data key="d7">1.0</data>
      <data key="d8">LLMs, including their Transformer architecture and parameters, are components of the broader deep learning structure used for training.</data>
      <data key="d9">broader framework,training methodology</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009055</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="无监督学习">
      <data key="d7">1.0</data>
      <data key="d8">Unsupervised learning is a method within the broader deep learning framework used to train models like LLMs.</data>
      <data key="d9">AI technique,learning method</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009060</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="遥感图像目标检测">
      <data key="d7">1.0</data>
      <data key="d8">遥感图像目标检测方法是基于深度学习技术实现的。</data>
      <data key="d9">技术实现,方法基础</data>
      <data key="d10">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009590</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="天气现象预报方法">
      <data key="d7">1.0</data>
      <data key="d8">该预报方法基于深度学习技术。</data>
      <data key="d9">技术应用,方法结合</data>
      <data key="d10">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010177</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="杨媛">
      <data key="d7">1.0</data>
      <data key="d8">杨媛撰写了论文，从哲学角度审视深度学习的技术路径。</data>
      <data key="d9">哲学审视,学术研究</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010740</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="技术哲学">
      <data key="d7">1.0</data>
      <data key="d8">本文从技术哲学的角度对深度学习进行审视和反思。</data>
      <data key="d9">哲学审视,学科交叉</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010741</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="学习范式">
      <data key="d7">1.0</data>
      <data key="d8">学习范式是深度学习的一个关键方面，本文对其进行了哲学讨论。</data>
      <data key="d9">分析维度,组成部分</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010743</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="技术演进">
      <data key="d7">1.0</data>
      <data key="d8">技术演进描述了深度学习的发展历程，是本文梳理的内容之一。</data>
      <data key="d9">历史维度,发展脉络</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010747</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="DOI: 10.12677/acpp.2025.145279">
      <data key="d7">1.0</data>
      <data key="d8">该DOI唯一标识了这篇关于深度学习的论文。</data>
      <data key="d9">学术引用,标识符</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010748</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="关键词">
      <data key="d7">1.0</data>
      <data key="d8">“深度学习”是论文关键词列表中的一个核心术语。</data>
      <data key="d9">主题概括,内容索引</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010750</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="Abstract">
      <data key="d7">1.0</data>
      <data key="d8">论文的英文摘要部分对深度学习进行了概述。</data>
      <data key="d9">内容概述,摘要描述</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010752</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习" target="Technical Path and Philosophical Review of Deep Learning">
      <data key="d7">1.0</data>
      <data key="d8">论文的英文标题直接表明其主题是关于深度学习的。</data>
      <data key="d9">内容指向,标题主题</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010755</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="人工智能">
      <data key="d7">8.0</data>
      <data key="d8">人工智能与机器学习之间的关系是子集与核心路径的关系。机器学习是人工智能（AI）领域的一个子集、子领域或重要分支。其核心目标是通过从数据中学习，让系统具备执行智能任务的能力。因此，机器学习是实现人工智能目标的一种核心路径和主要方法，专注于利用包括深度学习在内的各种技术进行优化与预测。</data>
      <data key="d9">foundational relationship,subset,包含关系,子集,子集关系,子领域,实现路径,技术递进,核心分支,组成部分</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4&lt;SEP&gt;chunk-1e18404a1598e3f3a1e3304e3abfc2c0&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008518</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="特征提取">
      <data key="d7">1.0</data>
      <data key="d8">在机器学习中，特征提取是一种关键技术，用于从数据中获取信息以指导算法进行准确预测。</data>
      <data key="d9">使用方法,信息处理</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001983</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="Amazon">
      <data key="d7">1.0</data>
      <data key="d8">Amazon使用机器学习技术，根据客户数据向其推荐产品。</data>
      <data key="d9">商业用例,技术应用</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002061</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="watsonx.ai">
      <data key="d7">1.0</data>
      <data key="d8">watsonx.ai is a platform for training, validating, tuning, and deploying machine learning capabilities.</data>
      <data key="d9">model training,platform capability</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003192</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="脑科学数据">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning can introduce new methods specifically for handling and processing brain science data.</data>
      <data key="d9">data processing,methodological contribution</data>
      <data key="d10">chunk-92f537cdcce6583c2c63c400d634feaf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003736</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="脑功能">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning can introduce new ideas and approaches for simulating brain functions.</data>
      <data key="d9">conceptual contribution,simulation</data>
      <data key="d10">chunk-92f537cdcce6583c2c63c400d634feaf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003737</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="蛋白质结构预测">
      <data key="d7">1.0</data>
      <data key="d8">机器学习被应用于蛋白质结构预测领域。</data>
      <data key="d9">应用,计算方法</data>
      <data key="d10">chunk-c5eafae240ac5d07dadf7c4eb744e8eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004051</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="MIT 6.874">
      <data key="d7">1.0</data>
      <data key="d8">MIT 6.874课程介绍了机器学习的基础知识。</data>
      <data key="d9">方法教学,课程内容</data>
      <data key="d10">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004342</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="量化交易">
      <data key="d7">1.0</data>
      <data key="d8">文中探讨了机器学习在量化交易中的应用，并评估了其在不同频率交易中的效能。</data>
      <data key="d9">应用,效能评估</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005166</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="中低频量化">
      <data key="d7">1.0</data>
      <data key="d8">作者尝试将机器学习应用于中低频量化，但最终所有机器学习模型的表现都不如传统的线性模型。</data>
      <data key="d9">失败,应用尝试</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005167</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="高频量化">
      <data key="d7">1.0</data>
      <data key="d8">作者转到高频量化(日内T0)后，发现机器学习在此场景下展现了比较大的优势。</data>
      <data key="d9">优势展现,应用场景</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005168</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="线性模型">
      <data key="d7">1.0</data>
      <data key="d8">文中将机器学习模型与线性模型在不同量化场景下的效能进行了对比。</data>
      <data key="d9">效能对比</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005168</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="人工智障">
      <data key="d7">1.0</data>
      <data key="d8">文中用“人工智障”戏谑地形容如果机器学习模型学不到人眼能发现的明显机会，则其能力低下。</data>
      <data key="d9">戏谑说法,表现评价</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005169</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="推荐系统">
      <data key="d7">2.0</data>
      <data key="d8">以互联网行业的推荐系统为例，说明机器学习能应用好的前提是人本身也能把这件事(如个性化推荐)做得不错。&lt;SEP&gt;机器学习应用于推荐系统领域，例如使用协同过滤算法。</data>
      <data key="d9">前提条件,应用领域,技术实现</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008565</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="反欺诈">
      <data key="d7">1.0</data>
      <data key="d8">机器学习在互联网行业被用于反欺诈等任务。</data>
      <data key="d9">应用领域</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005171</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="因子">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning models in quantitative trading use factors as their input features or data.</data>
      <data key="d9">data source,feature utilization</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005172</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="quant-computer">
      <data key="d7">1.0</data>
      <data key="d8">The user 'quant-computer' considered transitioning to machine learning after leaving quantitative finance.</data>
      <data key="d9">职业规划,领域兴趣</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005174</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="敬畏常识">
      <data key="d7">1.0</data>
      <data key="d8">The user '敬畏常识' stated that machine learning is merely a modifier of knowledge and does not generate knowledge itself.</data>
      <data key="d9">知识修饰,角色定义</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005176</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="模型风险管理">
      <data key="d7">1.0</data>
      <data key="d8">AI and machine learning can be applied to model risk management processes like validation and monitoring to help manage risk.</data>
      <data key="d9">application,risk mitigation</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005520</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="模型验证">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning is applied during model validation, such as for stress testing market models.</data>
      <data key="d9">application,process enhancement</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005525</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="模型监控">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning is applied during real-time model monitoring.</data>
      <data key="d9">application,process enhancement</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005533</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="自然语言处理">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理使用机器学习方法来使计算机理解人类语言。</data>
      <data key="d9">使用,方法</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007480</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="监督学习">
      <data key="d7">2.0</data>
      <data key="d8">监督学习是机器学习的一种主要学习范式和方法类别。&lt;SEP&gt;Supervised Learning is one of the primary types and methodologies within Machine Learning.</data>
      <data key="d9">methodology,type,学习范式,方法类别</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008520</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="无监督学习">
      <data key="d7">2.0</data>
      <data key="d8">无监督学习是机器学习的一种主要学习范式和方法类别。&lt;SEP&gt;Unsupervised Learning is one of the primary types and methodologies within Machine Learning.</data>
      <data key="d9">methodology,type,学习范式,方法类别</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008522</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="AI黑话揭秘">
      <data key="d7">1.0</data>
      <data key="d8">文章《AI黑话揭秘》旨在解释机器学习及其相关概念。</data>
      <data key="d9">概念澄清,解释</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008551</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="金融风控">
      <data key="d7">1.0</data>
      <data key="d8">机器学习应用于金融风控领域，例如使用逻辑回归算法。</data>
      <data key="d9">应用领域,技术实现</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008559</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="逻辑回归">
      <data key="d7">1.0</data>
      <data key="d8">机器学习使用逻辑回归等算法在金融风控等领域进行应用。</data>
      <data key="d9">技术实现,算法应用</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008570</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="协同过滤">
      <data key="d7">1.0</data>
      <data key="d8">机器学习使用协同过滤等算法在推荐系统等领域进行应用。</data>
      <data key="d9">技术实现,算法应用</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008572</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="大模型">
      <data key="d7">1.0</data>
      <data key="d8">Large Models are a product and a significant advancement within the field of Machine Learning, showcasing its potential.</data>
      <data key="d9">advancement,product</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008573</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="强化学习">
      <data key="d7">1.0</data>
      <data key="d8">Reinforcement Learning is one of the primary types and methodologies within Machine Learning.</data>
      <data key="d9">methodology,type</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008574</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="抖音推荐算法">
      <data key="d7">1.0</data>
      <data key="d8">Douyin's recommendation algorithm is a practical application and implementation of Machine Learning techniques.</data>
      <data key="d9">application,implementation</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008587</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="支付宝信用评分">
      <data key="d7">1.0</data>
      <data key="d8">Alipay's Credit Score system is a practical application and implementation of Machine Learning for financial assessment.</data>
      <data key="d9">application,implementation</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008591</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="RL">
      <data key="d7">1.0</data>
      <data key="d8">RL (Reinforcement Learning) is a method within the broader field of machine learning.</data>
      <data key="d9">method,subset</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008602</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="深度学习地球系统模型">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning is the foundational methodology upon which the Deep Learning Earth System Model (DLESyM) is built.</data>
      <data key="d9">foundation,methodology</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010013</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习" target="传统模型">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning models are noted for being faster and more energy-efficient than traditional weather prediction models.</data>
      <data key="d9">comparison,efficiency</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010015</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="生成式AI">
      <data key="d7">1.0</data>
      <data key="d8">生成式AI是人工智能的一个子集，专门使用深度学习等技术来生成新的内容。</data>
      <data key="d9">子集关系,生成技术</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001983</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="卷积神经网络">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are a key technology within the broader field of Artificial Intelligence.</data>
      <data key="d9">subfield,technology</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002937</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="自然语言处理">
      <data key="d7">7.0</data>
      <data key="d8">Natural language processing utilizes predictive artificial intelligence as a key component.&lt;SEP&gt;自然语言处理是人工智能的一个重要分支，致力于让机器理解人类语言。&lt;SEP&gt;自然语言处理是人工智能的一个子领域。&lt;SEP&gt;自然语言处理是人工智能涵盖的多个方面之一。&lt;SEP&gt;自然语言处理是人工智能领域的一个重要子领域和核心技术。&lt;SEP&gt;人工智能包含自然语言处理，自然语言处理是人工智能的一个子领域。&lt;SEP&gt;Natural Language Processing is a major subfield and application domain within Artificial Intelligence.</data>
      <data key="d9">application domain,component,subfield,utilization,分支,包含关系,子领域,应用,应用领域,核心技术</data>
      <data key="d10">chunk-b572e7e95c9e5e07043de0b3cb587187&lt;SEP&gt;chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792&lt;SEP&gt;chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008531</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="听觉">
      <data key="d7">1.0</data>
      <data key="d8">人工智能涉及对人类感官的模拟，听觉对应语音识别技术。</data>
      <data key="d9">感官模拟,技术对应</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007034</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="视觉">
      <data key="d7">1.0</data>
      <data key="d8">人工智能涉及对人类感官的模拟，视觉对应计算机视觉技术。</data>
      <data key="d9">感官模拟,技术对应</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007037</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="语言">
      <data key="d7">1.0</data>
      <data key="d8">人工智能涉及对人类感官的模拟，语言对应自然语言处理技术。</data>
      <data key="d9">感官模拟,技术对应</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007030</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="Knowledge Base">
      <data key="d7">1.0</data>
      <data key="d8">知识数据库是人工智能的一种实现形式，尽管其智能程度可能有限。</data>
      <data key="d9">包含,实现形式</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007034</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="大语言模型">
      <data key="d7">2.0</data>
      <data key="d8">大语言模型是人工智能领域的一个重要领域和分支。&lt;SEP&gt;大语言模型是人工智能技术发展中的关键组成部分和核心支柱，推动AI向通用AI迈进。</data>
      <data key="d9">包含关系,子领域,技术实现,核心支柱</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008507</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="AIGC">
      <data key="d7">1.0</data>
      <data key="d8">人工智能基于深度学习的大模型技术正向AIGC(人工智能生成内容)应用体系演进。</data>
      <data key="d9">应用构建,技术演进</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008520</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="狭义AI">
      <data key="d7">1.0</data>
      <data key="d8">人工智能的发展范式包括执行特定任务的“狭义AI”阶段。</data>
      <data key="d9">历史阶段,发展范式</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008527</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="通用AI">
      <data key="d7">1.0</data>
      <data key="d8">人工智能的发展范式正向具备更广泛认知与执行能力的“通用AI”迈进。</data>
      <data key="d9">发展范式,演进目标</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008537</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="算法">
      <data key="d7">1.0</data>
      <data key="d8">人工智能的核心在于算法和模型，这些算法和模型能够处理、分析和解释数据。</data>
      <data key="d9">决策基础,核心组成</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008534</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="数据">
      <data key="d7">1.0</data>
      <data key="d8">人工智能系统通过算法和模型从大量数据中学习，并能够做出智能决策。</data>
      <data key="d9">处理对象,学习基础</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008539</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="模型">
      <data key="d7">1.0</data>
      <data key="d8">模型是人工智能系统的核心，用来简化和理解真实世界的过程或对象。</data>
      <data key="d9">核心组成,简化表示</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008540</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="大模型">
      <data key="d7">1.0</data>
      <data key="d8">大模型是人工智能领域用于模拟人类智能的应用概念。</data>
      <data key="d9">应用,组成部分</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008544</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="LLM">
      <data key="d7">2.0</data>
      <data key="d8">LLM is the abbreviation for Large Language Model, which is a subset and important branch of the AI field.&lt;SEP&gt;LLM(大语言模型)是人工智能领域的一个应用概念。</data>
      <data key="d9">abbreviation,subset,应用,组成部分</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008545</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="Agent">
      <data key="d7">1.0</data>
      <data key="d8">Agent是人工智能领域的一个应用概念。</data>
      <data key="d9">应用,组成部分</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008547</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="浙江大学人工智能教育教学研究中心">
      <data key="d7">1.0</data>
      <data key="d8">该研究中心通过其研究成果展示了人工智能的应用。</data>
      <data key="d9">成果展示,研究</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008548</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="AI黑话揭秘">
      <data key="d7">1.0</data>
      <data key="d8">文章《AI黑话揭秘》旨在解释人工智能及其相关概念。</data>
      <data key="d9">概念澄清,解释</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008550</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="计算机视觉">
      <data key="d7">3.0</data>
      <data key="d8">计算机视觉是人工智能涵盖的多个方面之一。&lt;SEP&gt;人工智能包含计算机视觉，计算机视觉是人工智能的一个子领域。&lt;SEP&gt;Computer Vision is a major subfield and application domain within Artificial Intelligence.</data>
      <data key="d9">application domain,subfield,包含关系,子领域,应用领域</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-c0eefe5184862c24ce2da501217562b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008551</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="机器人技术">
      <data key="d7">1.0</data>
      <data key="d8">人工智能包含机器人技术，机器人技术是人工智能的一个子领域。</data>
      <data key="d9">包含关系,子领域</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008555</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="模型部署">
      <data key="d7">1.0</data>
      <data key="d8">Model Deployment is a crucial final stage for implementing AI and machine learning solutions in real-world applications.</data>
      <data key="d9">implementation stage,practical application</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008581</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="扫地机器人">
      <data key="d7">1.0</data>
      <data key="d8">Robotic vacuum cleaners are a practical application and embodiment of Artificial Intelligence in consumer electronics.</data>
      <data key="d9">application,embodiment</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008590</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="人脸识别">
      <data key="d7">1.0</data>
      <data key="d8">Facial Recognition is a key application technology within the field of Artificial Intelligence.</data>
      <data key="d9">application,technology</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008594</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="Siri">
      <data key="d7">1.0</data>
      <data key="d8">Siri is a well-known application and embodiment of Artificial Intelligence as a virtual assistant.</data>
      <data key="d9">application,embodiment</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008602</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="垂直模型">
      <data key="d7">1.0</data>
      <data key="d8">在ChatGPT爆火之前，提到AI模型一般指的是垂直模型，这是传统AI的一种形式。</data>
      <data key="d9">历史发展,类型对比</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008606</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="大数据">
      <data key="d7">1.0</data>
      <data key="d8">Artificial intelligence, particularly AI models, relies on big data for development and performance improvement.</data>
      <data key="d9">data dependency,foundational support</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008611</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="谭铁牛">
      <data key="d7">1.0</data>
      <data key="d8">Academician Tan Tieniu provided a definition for artificial intelligence in a published article.</data>
      <data key="d9">academic contribution,definition</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008613</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="研究人员">
      <data key="d7">1.0</data>
      <data key="d8">Researchers are attempting to combine artificial intelligence with climatology.</data>
      <data key="d9">application,integration</data>
      <data key="d10">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009902</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="气候数据">
      <data key="d7">1.0</data>
      <data key="d8">Artificial intelligence is used to analyze massive climate data to discover new models.</data>
      <data key="d9">data analysis,pattern discovery</data>
      <data key="d10">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009906</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="气候学">
      <data key="d7">1.0</data>
      <data key="d8">Artificial intelligence is being combined with the field of climatology.</data>
      <data key="d9">interdisciplinary integration,methodology</data>
      <data key="d10">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009908</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="关键词">
      <data key="d7">1.0</data>
      <data key="d8">“人工智能”是论文关键词列表中的一个核心术语。</data>
      <data key="d9">主题概括,内容索引</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010752</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="主持人">
      <data key="d7">1.0</data>
      <data key="d8">The host raises questions about the challenges that the development of Artificial Intelligence poses to philosophical research.</data>
      <data key="d9">challenge identification,inquiry</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011139</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="哲学研究">
      <data key="d7">1.0</data>
      <data key="d8">The development of Artificial Intelligence brings numerous challenges to the field of philosophical research.</data>
      <data key="d9">challenge,impact</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011151</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="大型语言模型">
      <data key="d7">1.0</data>
      <data key="d8">Large Language Models are a specific and widely applied part of Artificial Intelligence technology.</data>
      <data key="d9">inclusion,technological component</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011146</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="深度学习算法">
      <data key="d7">1.0</data>
      <data key="d8">Deep Learning Algorithms are a specific and widely applied part of Artificial Intelligence technology.</data>
      <data key="d9">inclusion,technological component</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011151</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="哲学学者">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical scholars face practical challenges in their research from the capabilities of Artificial Intelligence.</data>
      <data key="d9">confrontation,professional challenge</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011161</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="赵立">
      <data key="d7">1.0</data>
      <data key="d8">赵立analyzes Artificial Intelligence as an efficient technical integration of past thought that presents a significant challenge to contemporary philosophical thinking.</data>
      <data key="d9">analysis,conceptual challenge</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011167</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="哲学思考">
      <data key="d7">1.0</data>
      <data key="d8">The core of philosophical thinking, involving questioning and conceptual innovation, is contrasted with the informational efficiency of AI, highlighting a uniquely human capacity.</data>
      <data key="d9">contrast,unique human capacity</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011179</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="王田">
      <data key="d7">1.0</data>
      <data key="d8">Wang Tian discusses that developing AI's "philosophy" requires considering social conditions and ensuring AI serves humanity.</data>
      <data key="d9">development principles,discusses,social conditions</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011187</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="伦理">
      <data key="d7">1.0</data>
      <data key="d8">According to Wang Tian, AI carries ethical value, requiring its development to conform to human values.</data>
      <data key="d9">development requirement,value load</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011193</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="文化">
      <data key="d7">1.0</data>
      <data key="d8">According to Wang Tian, AI carries cultural value, requiring its development to conform to human values.</data>
      <data key="d9">development requirement,value load</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011196</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="政治">
      <data key="d7">1.0</data>
      <data key="d8">According to Wang Tian, AI carries political value, requiring its development to conform to human values.</data>
      <data key="d9">development requirement,value load</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011201</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="经济">
      <data key="d7">1.0</data>
      <data key="d8">According to Wang Tian, AI carries economic value, requiring its development to conform to human values.</data>
      <data key="d9">development requirement,value load</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011208</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="技术哲学">
      <data key="d7">2.0</data>
      <data key="d8">人工智能的普遍应用促使关于技术的深层思考成为哲学主要领域，可能推动技术哲学的兴起。&lt;SEP&gt;The widespread application of AI prompts the formation and elevation of the philosophy of technology as a major field.</data>
      <data key="d9">促进,时代影响,领域兴起,领域形成</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8&lt;SEP&gt;chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011212</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="人">
      <data key="d7">1.0</data>
      <data key="d8">AI technology impacts the understanding of humans, forcing a redefinition of human uniqueness and irreplaceability.</data>
      <data key="d9">冲击,重新定义</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011214</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="活劳动">
      <data key="d7">1.0</data>
      <data key="d8">AI as a breakthrough technology replaces part of living labor.</data>
      <data key="d9">技术影响,替代效应</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011233</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="数字劳动">
      <data key="d7">1.0</data>
      <data key="d8">AI creates a new form of labor called digital labor.</data>
      <data key="d9">创造形态,技术影响</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011238</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="劳动者">
      <data key="d7">1.0</data>
      <data key="d8">Laborers play an irreplaceable subjective role, and AI itself is a product of labor.</data>
      <data key="d9">不可替代,主体作用</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011241</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="主体概念">
      <data key="d7">1.0</data>
      <data key="d8">人工智能的迅猛发展使得传统哲学中作为理性核心的主体概念面临多重挑战和悖论。</data>
      <data key="d9">哲学反思,技术挑战</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011247</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="数据安全性">
      <data key="d7">1.0</data>
      <data key="d8">人工智能的发展带来了数据安全性等社会困境，迫使哲学进行反思。</data>
      <data key="d9">引发,社会困境</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011254</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="信息可靠性">
      <data key="d7">1.0</data>
      <data key="d8">人工智能模型可能生成不可靠信息，这构成了需要哲学反思的社会困境。</data>
      <data key="d9">引发,社会困境</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011257</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="数字偏见">
      <data key="d7">1.0</data>
      <data key="d8">人工智能的应用导致了数字偏见和“数字鸿沟”，这是公平性方面的新哲学视域。</data>
      <data key="d9">引发,社会困境</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011262</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能" target="哲学史">
      <data key="d7">1.0</data>
      <data key="d8">当人类把认知“外包”给AI并习惯“加速”获取知识后，必然会挤压哲学积累的空间，使阅读、实践和反思等能力退化。</data>
      <data key="d9">挤压空间,能力退化</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011268</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="体式AI">
      <data key="d7">1.0</data>
      <data key="d8">体式AI is presented as a concept that promotes growth, which is closely associated with the capabilities of generative AI.</data>
      <data key="d9">growth,technology promotion</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002061</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="投资回报率">
      <data key="d7">2.0</data>
      <data key="d8">Generative AI is described as a means to improve the return on investment (ROI).&lt;SEP&gt;Generative AI is leveraged to improve the return on investment.</data>
      <data key="d9">business value,financial metric,performance improvement,technology impact</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002452</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="AI投资">
      <data key="d7">1.0</data>
      <data key="d8">Generative AI is a key technology area within broader AI investments aimed at obtaining better returns.</data>
      <data key="d9">financial commitment,technology application</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002070</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="IBM watsonx.ai">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai is a platform specifically built to train, validate, tune, and deploy generative AI.&lt;SEP&gt;IBM watsonx.ai is a platform used to train, validate, tune, and deploy generative AI.</data>
      <data key="d9">platform capability,technology deployment</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002454</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="指南">
      <data key="d7">1.0</data>
      <data key="d8">The guide provides instructions on how to leverage generative AI to its full potential.</data>
      <data key="d9">guidance,optimization</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002064</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="AI构建器">
      <data key="d7">1.0</data>
      <data key="d8">AI builders are the personnel who utilize generative AI to construct and deliver innovative solutions.</data>
      <data key="d9">personnel utilization,technology building</data>
      <data key="d10">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002460</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="工作流程">
      <data key="d7">1.0</data>
      <data key="d8">Increasing the use of generative AI helps to reshape key workflows.</data>
      <data key="d9">efficiency,process transformation</data>
      <data key="d10">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002455</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="运营">
      <data key="d7">1.0</data>
      <data key="d8">Increasing the use of generative AI helps to reshape operations to maximize commercial value.</data>
      <data key="d9">operational transformation,value creation</data>
      <data key="d10">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002456</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="IBM Granite">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite AI模型系列经过优化，可用于帮助企业扩展包括生成式AI在内的AI应用程序。</data>
      <data key="d9">enterprise solution,model application</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002458</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="反向传播">
      <data key="d7">1.0</data>
      <data key="d8">反向传播是训练用于生成式AI的复杂深度神经网络架构的关键使能技术。</data>
      <data key="d9">enabling technology,model training</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002468</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="watsonx.ai">
      <data key="d7">1.0</data>
      <data key="d8">watsonx.ai is a platform for training, validating, tuning, and deploying generative AI.</data>
      <data key="d9">model training,platform capability</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003190</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="指南面向CEO的生成式AI指南">
      <data key="d7">1.0</data>
      <data key="d8">The guide helps CEOs understand generative AI.</data>
      <data key="d9">educational resource,guidance provision</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003195</data>
      <data key="d13" />
    </edge>
    <edge source="生成式AI" target="代理式AI">
      <data key="d7">1.0</data>
      <data key="d8">代理式AI和生成式AI是两种不同类型的人工智能，常被放在一起进行对比。</data>
      <data key="d9">AI类型对比,功能差异</data>
      <data key="d10">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009033</data>
      <data key="d13" />
    </edge>
    <edge source="人工神经网络" target="反向传播算法">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法是训练人工神经网络最常用且最有效的算法。</data>
      <data key="d9">核心算法,训练</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002662</data>
      <data key="d13" />
    </edge>
    <edge source="人工神经网络" target="卷积神经网络">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络也被称为人工神经网络，两者是同一概念的不同表述。</data>
      <data key="d9">abbreviation,synonym</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002943</data>
      <data key="d13" />
    </edge>
    <edge source="人工神经网络" target="Geoffrey Hinton">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton has long been dedicated to optimizing the learning process of artificial neural networks.</data>
      <data key="d9">dedication,optimization</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003895</data>
      <data key="d13" />
    </edge>
    <edge source="人工神经网络" target="监督学习">
      <data key="d7">1.0</data>
      <data key="d8">Supervised learning is a training paradigm for artificial neural networks that requires known final answers in advance.</data>
      <data key="d9">requirement,training paradigm</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003889</data>
      <data key="d13" />
    </edge>
    <edge source="特征提取" target="自然语言处理">
      <data key="d7">1.0</data>
      <data key="d8">特征提取是自然语言处理中将文本转换为数字表示的过程。</data>
      <data key="d9">包括,过程</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007503</data>
      <data key="d13" />
    </edge>
    <edge source="特征提取" target="Bag of Words">
      <data key="d7">1.0</data>
      <data key="d8">Bag of Words是特征提取过程中使用的一种技术。</data>
      <data key="d9">使用,技术</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007507</data>
      <data key="d13" />
    </edge>
    <edge source="特征提取" target="TF-IDF">
      <data key="d7">1.0</data>
      <data key="d8">TF-IDF是特征提取过程中使用的一种技术。</data>
      <data key="d9">使用,技术</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007512</data>
      <data key="d13" />
    </edge>
    <edge source="特征提取" target="数字表示">
      <data key="d7">1.0</data>
      <data key="d8">特征提取将原始文本转换为数字表示。</data>
      <data key="d9">生成,输出</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007554</data>
      <data key="d13" />
    </edge>
    <edge source="GPU" target="Machine Learning">
      <data key="d7">1.0</data>
      <data key="d8">Complex machine learning models often depend on high-performance GPUs for efficient training through parallel computation.</data>
      <data key="d9">computational dependency,performance requirement</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002151</data>
      <data key="d13" />
    </edge>
    <edge source="GPU" target="卷积神经网络">
      <data key="d7">1.0</data>
      <data key="d8">卷积操作很容易用GPU进行并行计算，这使得卷积神经网络能够高效地计算。</data>
      <data key="d9">并行计算,高效计算</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002786</data>
      <data key="d13" />
    </edge>
    <edge source="GPU" target="Deep Learning Model">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models depend on GPUs for training and inference, contributing to high technical and cost thresholds.</data>
      <data key="d9">computational cost,resource dependency</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004968</data>
      <data key="d13" />
    </edge>
    <edge source="迁移学习" target="PyTorch">
      <data key="d7">1.0</data>
      <data key="d8">Transfer learning can be implemented using the PyTorch framework for training deep learning models, as referenced in the Azure Machine Learning documentation.</data>
      <data key="d9">implementation framework,training method</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001985</data>
      <data key="d13" />
    </edge>
    <edge source="转换器" target="编码器">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer model architecture contains encoder layers that process input sequences.</data>
      <data key="d9">architectural component,contains</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001984</data>
      <data key="d13" />
    </edge>
    <edge source="转换器" target="解码器">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer model architecture contains decoder layers that generate output sequences.</data>
      <data key="d9">architectural component,contains</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001986</data>
      <data key="d13" />
    </edge>
    <edge source="Microsoft Azure Global Edition" target="Microsoft Azure China">
      <data key="d7">1.0</data>
      <data key="d8">Microsoft Azure Global Edition and Microsoft Azure China are regional counterparts of the same cloud service, operated separately with different documentation sites.</data>
      <data key="d9">regional counterpart,separate operation</data>
      <data key="d10">chunk-0a7f0ecd8f00998a373494f4a3fd9ab4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001984</data>
      <data key="d13" />
    </edge>
    <edge source="PyTorch" target="Conv2d">
      <data key="d7">1.0</data>
      <data key="d8">Conv2d是PyTorch框架中用于构建卷积层的函数。</data>
      <data key="d9">函数定义,框架组件</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003352</data>
      <data key="d13" />
    </edge>
    <edge source="PyTorch" target="MaxPool2d">
      <data key="d7">1.0</data>
      <data key="d8">MaxPool2d是PyTorch框架中用于构建最大池化层的函数。</data>
      <data key="d9">函数定义,框架组件</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003354</data>
      <data key="d13" />
    </edge>
    <edge source="PyTorch" target="Linear">
      <data key="d7">1.0</data>
      <data key="d8">Linear是PyTorch框架中用于构建全连接层的函数。</data>
      <data key="d9">函数定义,框架组件</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003362</data>
      <data key="d13" />
    </edge>
    <edge source="PyTorch" target="Deep Learning">
      <data key="d7">1.0</data>
      <data key="d8">PyTorch is a framework used to implement deep learning models for remote sensing tasks.</data>
      <data key="d9">framework,implementation</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009848</data>
      <data key="d13" />
    </edge>
    <edge source="编码器" target="自动编码器">
      <data key="d7">1.0</data>
      <data key="d8">自动编码器包含编码器作为其组成部分，两者串联合作。</data>
      <data key="d9">串联合作,组成部分</data>
      <data key="d10">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003440</data>
      <data key="d13" />
    </edge>
    <edge source="解码器" target="自动编码器">
      <data key="d7">1.0</data>
      <data key="d8">自动编码器包含解码器作为其组成部分，两者串联合作。</data>
      <data key="d9">串联合作,组成部分</data>
      <data key="d10">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003440</data>
      <data key="d13" />
    </edge>
    <edge source="Synthetic Content" target="Discriminator">
      <data key="d7">1.0</data>
      <data key="d8">The discriminator's goal is to classify input, distinguishing synthetic content from real content.</data>
      <data key="d9">adversarial process,classification</data>
      <data key="d10">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001986</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Encoder">
      <data key="d7">1.0</data>
      <data key="d8">The transformer architecture contains encoder layers for processing input sequences.</data>
      <data key="d9">architecture component,sequence processing</data>
      <data key="d10">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001986</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Decoder">
      <data key="d7">1.0</data>
      <data key="d8">The transformer architecture contains decoder layers for generating output sequences.</data>
      <data key="d9">architecture component,output generation</data>
      <data key="d10">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001987</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Attention Sublayer">
      <data key="d7">1.0</data>
      <data key="d8">The attention sublayer is a key component that distinguishes transformers from other encoder-decoder architectures.</data>
      <data key="d9">architectural distinction,defining feature</data>
      <data key="d10">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001987</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="金融時間序列預測">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer model is applied to financial time series prediction, leveraging its attention mechanism to handle long sequence dependencies and multivariate data.</data>
      <data key="d9">attention mechanism,sequence processing</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004952</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="价格预测">
      <data key="d7">1.0</data>
      <data key="d8">Transformer models are used for the application of price prediction in quantitative trading.</data>
      <data key="d9">model application,prediction task</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004958</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Encoder Block">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer model architecture is composed of stacked Encoder blocks to process input sequences.</data>
      <data key="d9">architecture,composition</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007685</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Decoder Block">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer model architecture is composed of stacked Decoder blocks to generate output sequences.</data>
      <data key="d9">architecture,composition</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007695</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Embedding">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer model uses an Embedding layer to convert input tokens into vector representations.</data>
      <data key="d9">input processing,uses</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007690</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Position Encoding">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer model uses Position Encoding to incorporate sequence order information into the input embeddings.</data>
      <data key="d9">positional information,uses</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007694</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Deep Learning">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer is a prominent model architecture within the field of Deep Learning.</data>
      <data key="d9">model,subfield</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007699</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Attention Mechanism">
      <data key="d7">1.0</data>
      <data key="d8">Transformer utilizes the attention mechanism to improve its training speed.</data>
      <data key="d9">improvement,utilization</data>
      <data key="d10">chunk-778f83860f7db1907e0da6e0cb412723</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007739</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Self-Attention Mechanism">
      <data key="d7">1.0</data>
      <data key="d8">Transformer is completely based on the self-attention mechanism.</data>
      <data key="d9">composition,foundation</data>
      <data key="d10">chunk-778f83860f7db1907e0da6e0cb412723</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007740</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer" target="Hung-yi Lee">
      <data key="d7">1.0</data>
      <data key="d8">Hung-yi Lee created and presented a lecture explaining the Transformer model architecture.</data>
      <data key="d9">explanation,lecture</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008289</data>
      <data key="d13" />
    </edge>
    <edge source="Encoder" target="Decoder">
      <data key="d7">1.0</data>
      <data key="d8">The decoder uses the contextual information generated by the encoder to produce its output.</data>
      <data key="d9">information flow,sequence processing</data>
      <data key="d10">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001987</data>
      <data key="d13" />
    </edge>
    <edge source="Encoder" target="Encoder-Decoder Architecture">
      <data key="d7">1.0</data>
      <data key="d8">The Encoder is a core component that forms part of the Encoder-Decoder Architecture.</data>
      <data key="d9">component,structure</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003531</data>
      <data key="d13" />
    </edge>
    <edge source="Encoder" target="Encoder Block">
      <data key="d7">1.0</data>
      <data key="d8">The Encoder is composed of multiple stacked Encoder blocks.</data>
      <data key="d9">composed of,stacking</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007708</data>
      <data key="d13" />
    </edge>
    <edge source="Decoder" target="Encoder-Decoder Architecture">
      <data key="d7">1.0</data>
      <data key="d8">The Decoder is a core component that forms part of the Encoder-Decoder Architecture.</data>
      <data key="d9">component,structure</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003532</data>
      <data key="d13" />
    </edge>
    <edge source="Decoder" target="Decoder Block">
      <data key="d7">1.0</data>
      <data key="d8">The Decoder is composed of multiple stacked Decoder blocks.</data>
      <data key="d9">composed of,stacking</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007708</data>
      <data key="d13" />
    </edge>
    <edge source="Attention Sublayer" target="Attention">
      <data key="d7">1.0</data>
      <data key="d8">The attention sublayer implements the attention mechanism, which weights input parts based on context.</data>
      <data key="d9">contextual weighting,implements</data>
      <data key="d10">chunk-eb903a35c2a682651dd2704f765bb4c6</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769001988</data>
      <data key="d13" />
    </edge>
    <edge source="Attention" target="Alphafold2">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 uses the Attention mechanism to integrate 1D and 2D information.</data>
      <data key="d9">information integration,model component</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004674</data>
      <data key="d13" />
    </edge>
    <edge source="Attention" target="1D与2D信息">
      <data key="d7">1.0</data>
      <data key="d8">The Attention mechanism is used to fuse 1D and 2D information within the model.</data>
      <data key="d9">information fusion,mechanism purpose</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004678</data>
      <data key="d13" />
    </edge>
    <edge source="Attention" target="Deep Pyramid CNN">
      <data key="d7">1.0</data>
      <data key="d8">Deep Pyramid CNN incorporates Attention mechanisms at different levels (word and sentence) to filter important information, making the model partially interpretable by highlighting important words and sentences.</data>
      <data key="d9">interpretability,model component</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007065</data>
      <data key="d13" />
    </edge>
    <edge source="Attention" target="Generative Summarization">
      <data key="d7">1.0</data>
      <data key="d8">Generative summarization models incorporate an attention mechanism to focus on useful information during decoding, enabling the generation of sequences like news headlines.</data>
      <data key="d9">employs,mechanism</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007071</data>
      <data key="d13" />
    </edge>
    <edge source="Attention" target="Word Level">
      <data key="d7">1.0</data>
      <data key="d8">An Attention mechanism is applied at the word level to determine the importance of individual words before moving to the sentence level.</data>
      <data key="d9">applied at,processing stage</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007079</data>
      <data key="d13" />
    </edge>
    <edge source="Attention" target="Sentence Level">
      <data key="d7">1.0</data>
      <data key="d8">An Attention mechanism is applied at the sentence level before the final output to determine the importance of entire sentences.</data>
      <data key="d9">applied at,processing stage</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007085</data>
      <data key="d13" />
    </edge>
    <edge source="监督学习" target="无监督学习">
      <data key="d7">1.0</data>
      <data key="d8">监督学习和无监督学习是两种不同的机器学习方法，主要区别在于是否使用标记数据集。</data>
      <data key="d9">学习方法,对比</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002059</data>
      <data key="d13" />
    </edge>
    <edge source="监督学习" target="反向传播">
      <data key="d7">1.0</data>
      <data key="d8">反向传播是在监督学习范式下训练神经网络的核心技术，旨在通过调整权重使模型做出更优质的预测。</data>
      <data key="d9">prediction improvement,training paradigm</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002455</data>
      <data key="d13" />
    </edge>
    <edge source="无监督学习" target="自编码器">
      <data key="d7">1.0</data>
      <data key="d8">自编码器是执行无监督学习任务的一类神经网络结构。</data>
      <data key="d9">任务执行,结构类型</data>
      <data key="d10">chunk-e101b215c048456f8049a66e9ebd2c54</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003380</data>
      <data key="d13" />
    </edge>
    <edge source="无监督学习" target="Transformer架构">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer architecture and its parameters guide the unsupervised learning process of LLMs.</data>
      <data key="d9">model guidance,training paradigm</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009057</data>
      <data key="d13" />
    </edge>
    <edge source="Amazon" target="Amazon Alexa">
      <data key="d7">1.0</data>
      <data key="d8">Amazon公司开发了Amazon Alexa语音助手。</data>
      <data key="d9">产品,开发</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007503</data>
      <data key="d13" />
    </edge>
    <edge source="Google" target="卷积神经网络">
      <data key="d7">1.0</data>
      <data key="d8">Google等公司投入巨资研究卷积神经网络，推动了各种变体模型的发展。</data>
      <data key="d9">产业投入,技术研发</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003348</data>
      <data key="d13" />
    </edge>
    <edge source="Google" target="深脑">
      <data key="d7">1.0</data>
      <data key="d8">Google acquired the company DeepMind (深脑).</data>
      <data key="d9">acquisition</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003896</data>
      <data key="d13" />
    </edge>
    <edge source="Google" target="Geoffrey Hinton">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton worked part-time for Google.</data>
      <data key="d9">affiliation,employment</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003889</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="数据管理">
      <data key="d7">1.0</data>
      <data key="d8">IBM提供数据管理等方面的解决方案，帮助企业构建AI系统。</data>
      <data key="d9">业务支持,解决方案提供</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002058</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="生成式人工智能">
      <data key="d7">1.0</data>
      <data key="d8">IBM提供关于如何利用生成式人工智能提高投资回报率的指南。</data>
      <data key="d9">技术推广,投资回报</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002059</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="智能体式人工智能">
      <data key="d7">1.0</data>
      <data key="d8">IBM通过网络研讨会展示如何通过智能体式人工智能实现投资回报率。</data>
      <data key="d9">业务增长,技术推广</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002061</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="2024年AI实际应用报告">
      <data key="d7">1.0</data>
      <data key="d8">IBM发布了一份名为“2024年AI实际应用”的报告，调查了2000家组织的AI计划。</data>
      <data key="d9">内容发布,市场研究</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002062</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="从推行AI项目到实现盈利报告">
      <data key="d7">1.0</data>
      <data key="d8">IBM发布了一份报告，探讨组织如何从AI项目试点转向实现盈利和业务转型。</data>
      <data key="d9">业务转型研究,内容发布</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002063</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="让AI充分发挥作用指南">
      <data key="d7">1.0</data>
      <data key="d8">IBM提供了一份名为“让AI充分发挥作用”的指南，指导如何利用生成式AI提高投资回报率。</data>
      <data key="d9">内容发布,投资回报指导</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002063</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="解锁生成式AI + ML的强大功能电子书">
      <data key="d7">1.0</data>
      <data key="d8">IBM发布了一本名为“解锁生成式AI + ML的强大功能”的电子书。</data>
      <data key="d9">内容发布,技术资源</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002063</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="树立信任，从容自信指南">
      <data key="d7">1.0</data>
      <data key="d8">IBM提供了一份名为“树立信任，从容自信”的指南。</data>
      <data key="d9">信任建立指导,内容发布</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002064</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="IBM watsonx.ai">
      <data key="d7">3.0</data>
      <data key="d8">IBM is the organization that developed and offers the IBM watsonx.ai platform.&lt;SEP&gt;IBM developed and provides the IBM watsonx.ai enterprise AI development platform.&lt;SEP&gt;IBM watsonx.ai is an AI development platform created and offered by IBM.</data>
      <data key="d9">AI tools,corporate offering,development,platform development,product,product development</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003535</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="IBM Consulting AI服务">
      <data key="d7">1.0</data>
      <data key="d8">IBM provides AI consulting services through its IBM Consulting AI Services division.</data>
      <data key="d9">corporate division,service provision</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002066</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="IBM业界领先的AI专业知识和解决方案组合">
      <data key="d7">1.0</data>
      <data key="d8">IBM possesses industry-leading AI expertise and a portfolio of solutions.</data>
      <data key="d9">capability,possession</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002067</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="Think Newsletter">
      <data key="d7">2.0</data>
      <data key="d8">IBM publishes the weekly Think Newsletter, which provides curated insights on AI news.&lt;SEP&gt;The Think Newsletter is provided by IBM to share industry trends.</data>
      <data key="d9">content distribution,information source,publication</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005518</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="IBM Granite">
      <data key="d7">4.0</data>
      <data key="d8">IBM developed and offers the IBM Granite series of AI models.&lt;SEP&gt;IBM Granite is IBM's series of AI models.&lt;SEP&gt;IBM Granite is a series of AI models developed and offered by IBM.&lt;SEP&gt;IBM Granite is a series of AI models developed and created by the company IBM.</data>
      <data key="d9">creation,development,model series,product,product development</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42&lt;SEP&gt;chunk-261214465e9e66011cd2c39022b3dc6b&lt;SEP&gt;chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008231</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="Watson Studio">
      <data key="d7">2.0</data>
      <data key="d8">IBM provides the Watson Studio platform.&lt;SEP&gt;Watson Studio is an IBM platform that provides tools for CNN model development and deployment.</data>
      <data key="d9">platform,platform development,product development,tool provision</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003182</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="watsonx.ai">
      <data key="d7">2.0</data>
      <data key="d8">IBM provides the watsonx.ai platform.&lt;SEP&gt;watsonx.ai is an IBM platform that provides tools for CNN model development and deployment.</data>
      <data key="d9">platform,platform development,product development,tool provision</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0&lt;SEP&gt;chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003183</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="Convolutional Neural Network (CNN)">
      <data key="d7">1.0</data>
      <data key="d8">IBM provides convolutional neural network (CNN) architecture support within its Watson Studio and watsonx.ai platforms.</data>
      <data key="d9">platform support,tool provision</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003192</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="IBM Privacy Statement">
      <data key="d7">1.0</data>
      <data key="d8">IBM provides a privacy statement that governs the subscription and data management for its services like the Think Newsletter.</data>
      <data key="d9">data governance,policy</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005520</data>
      <data key="d13" />
    </edge>
    <edge source="IBM" target="IBM Cloud Pak For Business Automation">
      <data key="d7">1.0</data>
      <data key="d8">IBM offers IBM Cloud Pak for Business Automation as a software solution for business automation.</data>
      <data key="d9">automation solution,product offering</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005525</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Granite" target="语言">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite models have capabilities in language.</data>
      <data key="d9">enterprise solution,model capability</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003190</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Granite" target="代码">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite models have capabilities in code.</data>
      <data key="d9">enterprise solution,model capability</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003191</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Granite" target="时间序列">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite models have capabilities in time series.</data>
      <data key="d9">enterprise solution,model capability</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003192</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Granite" target="护栏选项">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite models offer guardrail options.</data>
      <data key="d9">model feature,safety control</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003192</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Granite" target="AI应用程序">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite AI models help scale AI applications.</data>
      <data key="d9">application scaling,model utility</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003202</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Granite" target="Large Language Model (LLM)">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite is an example of an open-source, enterprise-focused series of AI models.</data>
      <data key="d9">example,instance</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008223</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="金融预测">
      <data key="d7">1.0</data>
      <data key="d8">Generative AI may not be suitable for financial forecasting as other mature models can perform the task with less effort and lower cost.</data>
      <data key="d9">cost-effectiveness,suitability</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005512</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="自然语言处理">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理的研究有助于推动生成式人工智能时代的发展。</data>
      <data key="d9">推动,研究领域</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007485</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="大型语言模型">
      <data key="d7">1.0</data>
      <data key="d8">生成式人工智能涉及大型语言模型的交流技巧。</data>
      <data key="d9">涉及,组成部分</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007486</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="图像生成模型">
      <data key="d7">1.0</data>
      <data key="d8">生成式人工智能涉及图像生成模型理解请求的能力。</data>
      <data key="d9">涉及,组成部分</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007489</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="魏犇群">
      <data key="d7">1.0</data>
      <data key="d8">魏犇群提出并分析了生成式人工智能给哲学研究视域带来的深刻变化。</data>
      <data key="d9">分析,提出</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011255</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="哲学事件">
      <data key="d7">1.0</data>
      <data key="d8">魏犇群认为生成式人工智能的迅猛发展本身就是一个“哲学事件”，它改变甚至颠覆了传统的哲学观念。</data>
      <data key="d9">概念颠覆,被视为</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011266</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="理解">
      <data key="d7">1.0</data>
      <data key="d8">生成式人工智能的表现挑战了传统的“理解”概念，迫使哲学重新探究其含义。</data>
      <data key="d9">挑战,概念重构</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011263</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="道德地位问题">
      <data key="d7">1.0</data>
      <data key="d8">生成式人工智能的应用会激发出新的哲学问题，如人工智能的道德地位问题。</data>
      <data key="d9">新问题,激发</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011269</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="智能驾驶事故归责问题">
      <data key="d7">1.0</data>
      <data key="d8">生成式人工智能的应用会激发出新的哲学问题，如智能驾驶的事故归责问题。</data>
      <data key="d9">新问题,激发</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011273</data>
      <data key="d13" />
    </edge>
    <edge source="生成式人工智能" target="隐私保护问题">
      <data key="d7">1.0</data>
      <data key="d8">生成式人工智能的应用会激发出新的哲学问题，如数据偏见与隐私保护问题。</data>
      <data key="d9">新问题,激发</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011275</data>
      <data key="d13" />
    </edge>
    <edge source="数据管理" target="混合AI就绪型架构">
      <data key="d7">1.0</data>
      <data key="d8">成功的数据管理需要创建一个混合AI就绪型架构来整合各处数据。</data>
      <data key="d9">实现前提,系统构建</data>
      <data key="d10">chunk-1e18404a1598e3f3a1e3304e3abfc2c0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002059</data>
      <data key="d13" />
    </edge>
    <edge source="AI投资" target="回报">
      <data key="d7">1.0</data>
      <data key="d8">The text discusses obtaining better returns from AI investments.</data>
      <data key="d9">financial action,outcome</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003196</data>
      <data key="d13" />
    </edge>
    <edge source="电子书" target="生成式AI + ML">
      <data key="d7">1.0</data>
      <data key="d8">The ebook is a resource designed to help unlock the powerful capabilities of combining generative AI and machine learning.</data>
      <data key="d9">capability unlocking,resource provision</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002062</data>
      <data key="d13" />
    </edge>
    <edge source="AI新时代" target="指南">
      <data key="d7">1.0</data>
      <data key="d8">A guide is offered to help build trust and thrive confidently in the new AI era.</data>
      <data key="d9">adaptation,guidance</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002065</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="基础模型">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai supports the deployment of foundation models.</data>
      <data key="d9">model deployment,platform capability</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002064</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="机器学习功能">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai enables the development and deployment of machine learning capabilities.</data>
      <data key="d9">functionality development,platform capability</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002065</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="AI应用程序">
      <data key="d7">2.0</data>
      <data key="d8">IBM watsonx.ai is used to build AI applications quickly and with minimal data.&lt;SEP&gt;AI applications can be built on the IBM watsonx.ai platform using a small amount of data.</data>
      <data key="d9">application creation,development tool</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19&lt;SEP&gt;chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002455</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="AI构建器">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai is a development platform built for use by AI builders.</data>
      <data key="d9">tool for,user group</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002065</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="AI开发生命周期">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai provides one-stop access to functionalities spanning the entire AI development lifecycle.</data>
      <data key="d9">lifecycle management,platform integration</data>
      <data key="d10">chunk-0e8d4ef62e491849bee6335c81b740ee</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002456</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="Generative AI">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai is a platform designed for deploying and managing Generative AI applications.</data>
      <data key="d9">deployment,platform</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003531</data>
      <data key="d13" />
    </edge>
    <edge source="IBM watsonx.ai" target="Foundation Models">
      <data key="d7">1.0</data>
      <data key="d8">IBM watsonx.ai is a platform designed for deploying and managing Foundation Models.</data>
      <data key="d9">deployment,platform</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003532</data>
      <data key="d13" />
    </edge>
    <edge source="基础模型" target="watsonx.ai">
      <data key="d7">1.0</data>
      <data key="d8">watsonx.ai is a platform for training, validating, tuning, and deploying foundation models.</data>
      <data key="d9">model training,platform capability</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003191</data>
      <data key="d13" />
    </edge>
    <edge source="AI应用程序" target="IBM业界领先的AI专业知识和解决方案组合">
      <data key="d7">1.0</data>
      <data key="d8">IBM's AI expertise and solutions enable the effective functioning and development of AI applications in business.</data>
      <data key="d9">development,enables</data>
      <data key="d10">chunk-d7b8dfbe2e2307428f725f64c9ea6c19</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002065</data>
      <data key="d13" />
    </edge>
    <edge source="AI应用程序" target="watsonx.ai">
      <data key="d7">1.0</data>
      <data key="d8">watsonx.ai enables the building of AI applications quickly with a small amount of data.</data>
      <data key="d9">application development,platform function</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003196</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Vertex AI">
      <data key="d7">2.0</data>
      <data key="d8">Google Cloud offers Vertex AI as one of its managed machine learning platform products.&lt;SEP&gt;Google Cloud provides Vertex AI as a service for accessing AI models like Gemini and building generative AI applications.</data>
      <data key="d9">AI platform,platform service,product offering,service provision</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea&lt;SEP&gt;chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009424</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Machine Learning">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides products and solutions based on Machine Learning technology.</data>
      <data key="d9">service domain,technology provider</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002149</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Gemini For Google Cloud">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud offers Gemini as an AI-powered assistant for use within its platform and IDEs.</data>
      <data key="d9">AI assistant,product offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002149</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Oracle Workload Migration">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides a service for migrating Oracle workloads to its platform.</data>
      <data key="d9">migration solution,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002150</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="SQL Server On Google Cloud">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides solutions for running SQL Server virtual machines on its platform.</data>
      <data key="d9">database solution,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002150</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Red Hat On Google Cloud">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud, in partnership with Red Hat, offers an enterprise platform for applications.</data>
      <data key="d9">partnership platform,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002150</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Google Distributed Cloud Air-Gapped">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud offers an air-gapped deployment solution for isolated environments.</data>
      <data key="d9">deployment solution,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002150</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Relational Database Service">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud offers a managed relational database service for MySQL, PostgreSQL, and SQL Server.</data>
      <data key="d9">database management,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002151</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="GKE">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud offers GKE as a managed Kubernetes service for deploying and running containers.</data>
      <data key="d9">container orchestration,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002151</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Cloud Run">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud offers Cloud Run as a managed platform for running containerized applications.</data>
      <data key="d9">serverless compute,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002151</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Fitbit Data">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud enables the association and analysis of Fitbit data for comprehensive patient insights.</data>
      <data key="d9">data integration,healthcare analytics</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002152</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="API Deployment And Development Management Service">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides a service for managing API deployment and development.</data>
      <data key="d9">API management,service offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002153</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Kubernetes Plugins">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides Kubernetes plugins for managing its resources within Kubernetes.</data>
      <data key="d9">resource management,tool offering</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002160</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="VMware Workload Migration">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides a service for migrating VMware workloads to run natively on its platform.</data>
      <data key="d9">service offering,workload migration</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002153</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Audit Logs">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides capabilities for managing audit logs, platform logs, and application logs.</data>
      <data key="d9">log management,service feature</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002153</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Pay-As-You-Go Pricing">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud employs a Pay-As-You-Go pricing model that offers automatic savings based on usage.</data>
      <data key="d9">cost management,pricing model</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002153</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="$300 Credit">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud offers a $300 promotional credit to new customers for trying its products.</data>
      <data key="d9">customer incentive,promotional offer</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002154</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Always Free Tier">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud provides an Always Free Tier with usage limits for over 20 products.</data>
      <data key="d9">free usage,pricing model</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002154</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Continuous Delivery">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud offers a fully managed continuous delivery service to GKE and Cloud Run.</data>
      <data key="d9">DevOps,service feature</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002154</data>
      <data key="d13" />
    </edge>
    <edge source="Google Cloud" target="Google DeepMind">
      <data key="d7">1.0</data>
      <data key="d8">Google Cloud integrates innovative technologies developed and tested by Google DeepMind into its enterprise AI platform.</data>
      <data key="d9">platform enhancement,technology integration</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009415</data>
      <data key="d13" />
    </edge>
    <edge source="Vertex AI" target="Generative AI on Vertex AI">
      <data key="d7">1.0</data>
      <data key="d8">Vertex AI includes the Generative AI on Vertex AI service for accessing and deploying Google's large generative AI models.</data>
      <data key="d9">AI model access,service inclusion</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009415</data>
      <data key="d13" />
    </edge>
    <edge source="Vertex AI" target="Vertex AI Agent Builder">
      <data key="d7">1.0</data>
      <data key="d8">Vertex AI offers the Vertex AI Agent Builder service for developers to build and control intelligent agents.</data>
      <data key="d9">agent development,service inclusion</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009420</data>
      <data key="d13" />
    </edge>
    <edge source="Vertex AI" target="Generative AI">
      <data key="d7">1.0</data>
      <data key="d8">Generative AI is a category of AI models hosted and provided through the Vertex AI platform on Google Cloud.</data>
      <data key="d9">platform hosting,service category</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009427</data>
      <data key="d13" />
    </edge>
    <edge source="Vertex AI" target="Gemini">
      <data key="d7">1.0</data>
      <data key="d8">Vertex AI provides access to the Gemini model, allowing users to test and build applications using its multimodal capabilities.</data>
      <data key="d9">application development,model access</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009428</data>
      <data key="d13" />
    </edge>
    <edge source="Vertex AI" target="Prompt">
      <data key="d7">1.0</data>
      <data key="d8">Vertex AI provides the functionality for users to input prompts to interact with and test models like Gemini.</data>
      <data key="d9">interface feature,model interaction</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009428</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="TPU">
      <data key="d7">1.0</data>
      <data key="d8">Complex machine learning models often depend on high-performance TPUs for efficient training through parallel computation.</data>
      <data key="d9">computational dependency,performance requirement</data>
      <data key="d10">chunk-cb25bd59eb20459d90d689a472568aea</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002152</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="Fraud Detection">
      <data key="d7">1.0</data>
      <data key="d8">Machine learning is a method applied to the task of fraud detection.</data>
      <data key="d9">application,methodology</data>
      <data key="d10">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005839</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="Traditional Fraud Detection Systems">
      <data key="d7">1.0</data>
      <data key="d8">Many traditional fraud detection systems are built using Machine Learning techniques.</data>
      <data key="d9">method,technology reliance</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006180</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="Supervised Learning">
      <data key="d7">1.0</data>
      <data key="d8">Supervised Learning is a core paradigm within the broader field of Machine Learning.</data>
      <data key="d9">paradigm,subfield</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007974</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="Unsupervised Learning">
      <data key="d7">1.0</data>
      <data key="d8">Unsupervised Learning is a core paradigm within the broader field of Machine Learning.</data>
      <data key="d9">paradigm,subfield</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007977</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="Reinforcement Learning">
      <data key="d7">1.0</data>
      <data key="d8">Reinforcement Learning is a core paradigm within the broader field of Machine Learning.</data>
      <data key="d9">paradigm,subfield</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007979</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="IBM Watsonx.Ai">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai enables the development and deployment of machine learning functionalities.</data>
      <data key="d9">development,platform capability</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008235</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning" target="Weather Forecasting">
      <data key="d7">1.0</data>
      <data key="d8">Weather forecasting utilizes machine learning algorithms to predict future conditions.</data>
      <data key="d9">methodology,prediction</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010287</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="动态规划">
      <data key="d7">1.0</data>
      <data key="d8">反向传播利用动态规划的思想来高效地计算梯度。</data>
      <data key="d9">思想基础,技术实现</data>
      <data key="d10">chunk-9fcf6610f361d14578f6d58fe5b5ea26</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002175</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="梯度">
      <data key="d7">2.0</data>
      <data key="d8">反向传播的核心功能是计算梯度。&lt;SEP&gt;反向传播的主要目的是计算神经网络参数的梯度，以便使用优化算法进行更新。</data>
      <data key="d9">参数更新,核心功能,计算目标,计算目的</data>
      <data key="d10">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002554</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="输出层">
      <data key="d7">1.0</data>
      <data key="d8">反向传播从输出层开始计算误差。</data>
      <data key="d9">流程方向,计算起点</data>
      <data key="d10">chunk-9fcf6610f361d14578f6d58fe5b5ea26</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002175</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="输入层">
      <data key="d7">1.0</data>
      <data key="d8">反向传播的计算过程最终到达输入层。</data>
      <data key="d9">流程方向,计算终点</data>
      <data key="d10">chunk-9fcf6610f361d14578f6d58fe5b5ea26</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002176</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="误差">
      <data key="d7">2.0</data>
      <data key="d8">反向传播的核心过程是逐层计算误差。&lt;SEP&gt;反向传播利用误差信号从输出层向输入层回传，以计算网络中每个参数的梯度。</data>
      <data key="d9">核心过程,梯度计算,计算对象,误差回传</data>
      <data key="d10">chunk-9fcf6610f361d14578f6d58fe5b5ea26&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002655</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="正向传播">
      <data key="d7">1.0</data>
      <data key="d8">反向传播的梯度计算依赖于正向传播计算并存储的变量当前值。</data>
      <data key="d9">算法依赖,计算顺序</data>
      <data key="d10">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002265</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="链式法则">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法利用链式法则将输出层的误差反向传播至网络各层，以计算损失函数对每个权重的梯度。</data>
      <data key="d9">梯度计算,误差传播</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002330</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="激活函数">
      <data key="d7">1.0</data>
      <data key="d8">反向传播需要计算激活函数的导数，因为激活函数引入了非线性，使得损失函数成为复合函数。</data>
      <data key="d9">复合函数,非线性求导</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002331</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="非线性动力学">
      <data key="d7">1.0</data>
      <data key="d8">文中将神经网络求导的非线性动力学特性与反向传播过程进行类比。</data>
      <data key="d9">类比,非线性特性</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002332</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="局部导数">
      <data key="d7">1.0</data>
      <data key="d8">反向传播的计算过程依赖于节点的局部导数，通过将信号E乘以该导数来传递梯度。</data>
      <data key="d9">梯度计算,计算依赖</data>
      <data key="d10">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002359</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="信号E">
      <data key="d7">1.0</data>
      <data key="d8">在反向传播中，信号E被乘以局部导数，计算结果被传递到下一个节点。</data>
      <data key="d9">信号传递,计算操作</data>
      <data key="d10">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002359</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="梯度下降算法">
      <data key="d7">1.0</data>
      <data key="d8">反向传播使用梯度下降算法来计算梯度并更新神经网络的权重，以最小化误差。</data>
      <data key="d9">optimization,weight update</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002452</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="损失函数">
      <data key="d7">2.0</data>
      <data key="d8">反向传播通过损失函数计算模型的预测误差，并将该误差反向传播以了解网络各部分对误差的贡献。&lt;SEP&gt;反向传播的目标是最小化损失函数，该函数的值是计算误差和梯度的起点。</data>
      <data key="d9">error propagation,gradient calculation,目标优化,误差来源</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002660</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="神经网络与深度学习">
      <data key="d7">1.0</data>
      <data key="d8">在《神经网络与深度学习》教科书中，Michael Nielsen解释了反向传播算法，并将其与计算梯度的直观方法进行了效率比较。</data>
      <data key="d9">algorithm explanation,efficiency comparison</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002465</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="多层感知器">
      <data key="d7">1.0</data>
      <data key="d8">反向传播是训练基本的多层感知器神经网络模型的基础方法。</data>
      <data key="d9">foundational architecture,training method</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002467</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="计算图">
      <data key="d7">2.0</data>
      <data key="d8">计算图用于可视化反向传播过程中操作符和变量的依赖关系。&lt;SEP&gt;反向传播通常在计算图这一数据结构上执行，以高效地组织前向和反向计算。</data>
      <data key="d9">依赖关系,可视化,数据结构,计算框架</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd&lt;SEP&gt;chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002656</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="链式规则">
      <data key="d7">1.0</data>
      <data key="d8">反向传播方法根据微积分中的链式规则来计算梯度。</data>
      <data key="d9">数学原理,计算基础</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002548</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="前向传播">
      <data key="d7">1.0</data>
      <data key="d8">前向传播按从输入到输出的顺序计算，而反向传播按相反顺序计算梯度。</data>
      <data key="d9">神经网络训练,计算顺序</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002550</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="自动微分">
      <data key="d7">1.0</data>
      <data key="d8">自动微分技术通过自动计算梯度简化了反向传播的实现。</data>
      <data key="d9">实现简化,梯度计算</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="参数">
      <data key="d7">1.0</data>
      <data key="d8">反向传播遍历网络以计算关于模型参数(如权重矩阵)的梯度。</data>
      <data key="d9">优化对象,计算目标</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002554</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="BP算法">
      <data key="d7">1.0</data>
      <data key="d8">BP算法是反向传播思想的一种具体实现，用于训练神经网络。</data>
      <data key="d9">核心思想,算法实现</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002666</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="梯度下降法">
      <data key="d7">1.0</data>
      <data key="d8">反向传播计算得到的梯度被梯度下降法或其变种用于更新神经网络的参数。</data>
      <data key="d9">参数优化,算法应用</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002661</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播" target="权重">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法根据误差信号回传来修正神经网络每层的权重系数。</data>
      <data key="d9">参数修正,误差反馈</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002662</data>
      <data key="d13" />
    </edge>
    <edge source="梯度" target="链式规则">
      <data key="d7">1.0</data>
      <data key="d8">链式规则是反向传播中用于计算复合函数(即神经网络)梯度的核心数学工具。</data>
      <data key="d9">导数计算,数学工具</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002552</data>
      <data key="d13" />
    </edge>
    <edge source="梯度" target="梯度下降法">
      <data key="d7">1.0</data>
      <data key="d8">梯度下降法依据梯度所指示的方向和幅度来调整网络参数。</data>
      <data key="d9">优化依据,方向指引</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002656</data>
      <data key="d13" />
    </edge>
    <edge source="梯度" target="反向传播算法">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法的核心是通过计算损失函数对网络参数的梯度来优化网络。</data>
      <data key="d9">优化,计算</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002663</data>
      <data key="d13" />
    </edge>
    <edge source="输出层" target="卷积神经网络">
      <data key="d7">1.0</data>
      <data key="d8">输出层是卷积神经网络的一个组成部分，负责生成最终的输出结果。</data>
      <data key="d9">component,result generation</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002944</data>
      <data key="d13" />
    </edge>
    <edge source="输出层" target="多层感知机">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机由输出层构成。</data>
      <data key="d9">composition,structure</data>
      <data key="d10">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003565</data>
      <data key="d13" />
    </edge>
    <edge source="输入层" target="卷积神经网络">
      <data key="d7">1.0</data>
      <data key="d8">输入层是卷积神经网络的一个组成部分，负责接收原始图像数据。</data>
      <data key="d9">component,data reception</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002944</data>
      <data key="d13" />
    </edge>
    <edge source="输入层" target="颜色通道">
      <data key="d7">1.0</data>
      <data key="d8">输入层接收由红、绿、蓝三个颜色通道组成的图像数据。</data>
      <data key="d9">data composition,reception</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002944</data>
      <data key="d13" />
    </edge>
    <edge source="输入层" target="二维矩阵">
      <data key="d7">1.0</data>
      <data key="d8">输入层接收的图像数据以二维矩阵的形式表示像素强度值。</data>
      <data key="d9">data structure,representation</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002945</data>
      <data key="d13" />
    </edge>
    <edge source="输入层" target="数字化信号">
      <data key="d7">1.0</data>
      <data key="d8">输入层可以接收文字、语音、图像、视频等各种数字化信号作为输入。</data>
      <data key="d9">数据接收,输入类型</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003357</data>
      <data key="d13" />
    </edge>
    <edge source="输入层" target="多层感知机">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机由输入层构成。</data>
      <data key="d9">composition,structure</data>
      <data key="d10">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003564</data>
      <data key="d13" />
    </edge>
    <edge source="计算机科学" target="MIT 6.874">
      <data key="d7">1.0</data>
      <data key="d8">MIT 6.874课程广泛介绍了计算机科学领域的知识。</data>
      <data key="d9">课程内容,领域覆盖</data>
      <data key="d10">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004342</data>
      <data key="d13" />
    </edge>
    <edge source="计算机科学" target="自然语言处理">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理是计算机科学的一个子领域。</data>
      <data key="d9">子领域,应用</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007465</data>
      <data key="d13" />
    </edge>
    <edge source="Hidden Layer Weight Parameter" target="Hidden Layer Variable">
      <data key="d7">1.0</data>
      <data key="d8">The hidden layer weight parameter W^(1) is used to compute the intermediate variable z, which is then transformed by the activation function to produce the hidden layer variable h.</data>
      <data key="d9">linear algebra,parameter transformation</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002259</data>
      <data key="d13" />
    </edge>
    <edge source="Hidden Layer Variable" target="Output Layer Variable">
      <data key="d7">1.0</data>
      <data key="d8">The hidden layer variable h is multiplied by the output layer weight parameter W^(2) to produce the output layer variable o.</data>
      <data key="d9">layer connection,linear transformation</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002261</data>
      <data key="d13" />
    </edge>
    <edge source="Hidden Layer Variable" target="Activation Function">
      <data key="d7">1.0</data>
      <data key="d8">The activation function φ is applied element-wise to the intermediate variable z to produce the non-linear hidden layer variable h.</data>
      <data key="d9">element-wise operation,non-linear transformation</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002262</data>
      <data key="d13" />
    </edge>
    <edge source="Hidden Layer Variable" target="Intermediate Variable Z">
      <data key="d7">1.0</data>
      <data key="d8">The intermediate variable z is the linear pre-activation value that is passed through the activation function φ to produce the hidden layer variable h.</data>
      <data key="d9">pre-activation,transformation</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002264</data>
      <data key="d13" />
    </edge>
    <edge source="Output Layer Weight Parameter" target="Output Layer Variable">
      <data key="d7">1.0</data>
      <data key="d8">The output layer weight parameter W^(2) is the parameter used in the computation that directly produces the output layer variable o.</data>
      <data key="d9">model output,parameter definition</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002259</data>
      <data key="d13" />
    </edge>
    <edge source="Regularization Term" target="Objective Function">
      <data key="d7">1.0</data>
      <data key="d8">The regularization term s is a component added to the loss term L to form the complete objective function J that is to be minimized.</data>
      <data key="d9">function composition,optimization</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002259</data>
      <data key="d13" />
    </edge>
    <edge source="Regularization Term" target="Gradient Of Objective Function With Respect To Hidden Layer Weight Parameter">
      <data key="d7">1.0</data>
      <data key="d8">The gradient ∂J/∂W^(1) includes a component λW^(1) derived from the derivative of the regularization term s with respect to W^(1).</data>
      <data key="d9">gradient component,weight penalty</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002264</data>
      <data key="d13" />
    </edge>
    <edge source="Regularization Term" target="Gradient Of Objective Function With Respect To Output Layer Weight Parameter">
      <data key="d7">1.0</data>
      <data key="d8">The gradient ∂J/∂W^(2) includes a component λW^(2) derived from the derivative of the regularization term s with respect to W^(2).</data>
      <data key="d9">gradient component,weight penalty</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002257</data>
      <data key="d13" />
    </edge>
    <edge source="Objective Function" target="Backpropagation">
      <data key="d7">1.0</data>
      <data key="d8">The goal of the backpropagation algorithm is to compute the gradients of the objective function J with respect to the model's parameters.</data>
      <data key="d9">gradient computation,optimization target</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002261</data>
      <data key="d13" />
    </edge>
    <edge source="Objective Function" target="Loss Term L">
      <data key="d7">1.0</data>
      <data key="d8">The loss term L is a primary component of the objective function J, which backpropagation aims to minimize.</data>
      <data key="d9">function component,optimization target</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002262</data>
      <data key="d13" />
    </edge>
    <edge source="Chain Rule" target="Backpropagation">
      <data key="d7">1.0</data>
      <data key="d8">The chain rule is the core mathematical principle applied within the backpropagation algorithm to compute gradients sequentially.</data>
      <data key="d9">algorithm step,mathematical foundation</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002262</data>
      <data key="d13" />
    </edge>
    <edge source="Chain Rule" target="Partial J/Partial W^{(2)}">
      <data key="d7">1.0</data>
      <data key="d8">The chain rule is applied to compute the gradient Partial J/Partial W^{(2)} during the backpropagation process.</data>
      <data key="d9">differentiation,gradient calculation</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="Backpropagation" target="Forward Propagation">
      <data key="d7">2.0</data>
      <data key="d8">Backpropagation computes gradients in the reverse order of forward propagation and relies on the variable values computed during forward propagation.&lt;SEP&gt;Backpropagation depends on values (like h) computed during forward propagation, and its calculations proceed in the reverse order.</data>
      <data key="d9">algorithm sequence,computational order,dependency,value dependency</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb&lt;SEP&gt;chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002545</data>
      <data key="d13" />
    </edge>
    <edge source="Backpropagation" target="Hidden Variable h">
      <data key="d7">1.0</data>
      <data key="d8">During backpropagation, the calculation of parameter gradients depends on the current value of the hidden variable h from forward propagation.</data>
      <data key="d9">dependency,gradient calculation</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002546</data>
      <data key="d13" />
    </edge>
    <edge source="Backpropagation" target="Computational Graph">
      <data key="d7">1.0</data>
      <data key="d8">Backpropagation operates on the computational graph, starting from the result and moving backward to compute gradients for parameters.</data>
      <data key="d9">algorithm application,structure</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002547</data>
      <data key="d13" />
    </edge>
    <edge source="Activation Function" target="Neuron">
      <data key="d7">1.0</data>
      <data key="d8">A neuron applies an activation function to its total net input to produce its final output.</data>
      <data key="d9">non-linear transformation,output generation</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002719</data>
      <data key="d13" />
    </edge>
    <edge source="Activation Function" target="Convolution Layer">
      <data key="d7">1.0</data>
      <data key="d8">An activation function, such as ReLU, is applied to the output of a convolution layer.</data>
      <data key="d9">application,processing</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002954</data>
      <data key="d13" />
    </edge>
    <edge source="Activation Function" target="ReLU">
      <data key="d7">2.0</data>
      <data key="d8">ReLU is a common example of an activation function used in neural networks.&lt;SEP&gt;ReLU is a specific type of activation function used in neural networks.</data>
      <data key="d9">categorization,example,neural network component,type</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003608</data>
      <data key="d13" />
    </edge>
    <edge source="Activation Function" target="Sigmoid">
      <data key="d7">1.0</data>
      <data key="d8">Sigmoid is a specific type of activation function used in neural networks.</data>
      <data key="d9">categorization,neural network component</data>
      <data key="d10">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003609</data>
      <data key="d13" />
    </edge>
    <edge source="Activation Function" target="Tanh">
      <data key="d7">1.0</data>
      <data key="d8">Tanh is a specific type of activation function used in neural networks.</data>
      <data key="d9">categorization,neural network component</data>
      <data key="d10">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003610</data>
      <data key="d13" />
    </edge>
    <edge source="Forward Propagation" target="Hidden Variable h">
      <data key="d7">1.0</data>
      <data key="d8">Forward propagation computes the current value of the hidden variable h, which is later used in backpropagation.</data>
      <data key="d9">computation,intermediate value</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="Loss Term L" target="Objective Function J">
      <data key="d7">1.0</data>
      <data key="d8">The objective function J is composed of the loss term L, as J = L + s.</data>
      <data key="d9">composition,summation</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="Input Variable X" target="Gradient Of Objective Function With Respect To Hidden Layer Weight Parameter">
      <data key="d7">1.0</data>
      <data key="d8">The input variable x is used in the formula to compute the gradient ∂J/∂W^(1), specifically in the term (∂J/∂z) x^⊤.</data>
      <data key="d9">computation dependency,gradient formula</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002261</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient Of Objective Function With Respect To Output" target="Gradient Of Objective Function With Respect To Output Layer Weight Parameter">
      <data key="d7">1.0</data>
      <data key="d8">The gradient ∂J/∂o is a direct component in the chain rule calculation for the gradient ∂J/∂W^(2) with respect to the output layer weight parameter.</data>
      <data key="d9">chain rule application,parameter update</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002262</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient Of Objective Function With Respect To Hidden Layer Variable" target="Gradient Of Objective Function With Respect To Intermediate Variable Z">
      <data key="d7">1.0</data>
      <data key="d8">The gradient ∂J/∂h is used, along with the derivative of the activation function, to compute the gradient ∂J/∂z via element-wise multiplication.</data>
      <data key="d9">chain rule step,element-wise operation</data>
      <data key="d10">chunk-75a5bc7ce82bf1f70e397344566d62eb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002263</data>
      <data key="d13" />
    </edge>
    <edge source="梯度计算" target="参数梯度">
      <data key="d7">1.0</data>
      <data key="d8">梯度计算是生成参数梯度的具体过程。</data>
      <data key="d9">算法核心,计算过程</data>
      <data key="d10">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002265</data>
      <data key="d13" />
    </edge>
    <edge source="参数梯度" target="隐藏层变量">
      <data key="d7">1.0</data>
      <data key="d8">计算参数梯度(如 ∂J/∂W^(2))需要依赖隐藏层变量的当前值。</data>
      <data key="d9">数据需求,计算依赖</data>
      <data key="d10">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002257</data>
      <data key="d13" />
    </edge>
    <edge source="参数梯度" target="损失函数">
      <data key="d7">1.0</data>
      <data key="d8">参数梯度是损失函数相对于模型参数的偏导数，是优化模型的基础。</data>
      <data key="d9">优化基础,数学关系</data>
      <data key="d10">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002265</data>
      <data key="d13" />
    </edge>
    <edge source="参数梯度" target="模型参数">
      <data key="d7">1.0</data>
      <data key="d8">参数梯度直接用于更新对应的模型参数。</data>
      <data key="d9">优化目标,更新依据</data>
      <data key="d10">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002258</data>
      <data key="d13" />
    </edge>
    <edge source="参数梯度" target="正则化项">
      <data key="d7">1.0</data>
      <data key="d8">参数梯度的计算公式中包含来自正则化项的贡献(如+ λW)。</data>
      <data key="d9">数学公式,组成部分</data>
      <data key="d10">chunk-29234d7a518b3ee30e3ee9cbc39d7e68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002258</data>
      <data key="d13" />
    </edge>
    <edge source="正向传播" target="局部导数">
      <data key="d7">1.0</data>
      <data key="d8">局部导数的定义来源于正向传播中的函数y=f(x)，是该函数的导数。</data>
      <data key="d9">函数关系,定义来源</data>
      <data key="d10">chunk-7844fb38c827827af06d614fe4afb4df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002359</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="梯度下降法">
      <data key="d7">1.0</data>
      <data key="d8">梯度下降法被用于最小化损失函数，通过迭代调整权重来减少预测误差。</data>
      <data key="d9">优化,最小化</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002330</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="梯度下降算法">
      <data key="d7">1.0</data>
      <data key="d8">梯度下降算法利用损失函数计算出的梯度来调整模型参数，目的是最小化由损失函数衡量的误差。</data>
      <data key="d9">error minimization,optimization</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002454</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="成本函数">
      <data key="d7">1.0</data>
      <data key="d8">在上下文中，“成本函数”一词可以作为“损失函数”的同义词使用，都指用于衡量模型误差的函数。</data>
      <data key="d9">error measurement,synonym</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002467</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="误差函数">
      <data key="d7">1.0</data>
      <data key="d8">在上下文中，“误差函数”一词可以作为“损失函数”的同义词使用，都指用于衡量模型预测错误的函数。</data>
      <data key="d9">error measurement,synonym</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002468</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="目标函数">
      <data key="d7">1.0</data>
      <data key="d8">损失函数是构成目标函数的核心部分，用于衡量模型误差。</data>
      <data key="d9">优化目标,组成部分</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002550</data>
      <data key="d13" />
    </edge>
    <edge source="损失函数" target="样本标签">
      <data key="d7">1.0</data>
      <data key="d8">损失函数使用样本标签作为监督信号来计算模型预测的误差。</data>
      <data key="d9">监督信号,计算依据</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002553</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降法" target="权重参数">
      <data key="d7">1.0</data>
      <data key="d8">梯度下降法通过计算梯度来迭代更新神经网络的权重参数。</data>
      <data key="d9">参数更新,迭代</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002330</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降法" target="学习率">
      <data key="d7">1.0</data>
      <data key="d8">学习率是梯度下降法中的一个关键超参数，它控制着每次权重更新的步长大小。</data>
      <data key="d9">步长控制,超参数</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002331</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降法" target="随机梯度下降法">
      <data key="d7">1.0</data>
      <data key="d8">随机梯度下降法是梯度下降法的一种变体，其特点是每次迭代只使用一个训练样本。</data>
      <data key="d9">变体,在线学习</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002332</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降法" target="批量梯度下降法">
      <data key="d7">1.0</data>
      <data key="d8">批量梯度下降法是梯度下降法的一种变体，其特点是每次迭代使用全部训练样本。</data>
      <data key="d9">变体,批量学习</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002333</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降法" target="小批量梯度下降法">
      <data key="d7">1.0</data>
      <data key="d8">小批量梯度下降法是梯度下降法的一种变体，它折中了随机和批量梯度下降法的特点，每次使用一小批样本。</data>
      <data key="d9">变体,折中方法</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002335</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降法" target="误差损失函数">
      <data key="d7">1.0</data>
      <data key="d8">Gradient descent is the method used to minimize the error loss function during neural network training.</data>
      <data key="d9">minimization,optimization method</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002336</data>
      <data key="d13" />
    </edge>
    <edge source="学习率" target="SGD">
      <data key="d7">1.0</data>
      <data key="d8">优化器SGD的学习率被设置为0.1。</data>
      <data key="d9">优化参数,训练设置</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003354</data>
      <data key="d13" />
    </edge>
    <edge source="链式法则" target="链式求导法则">
      <data key="d7">1.0</data>
      <data key="d8">链式求导法则与链式法则指的是相同的数学原理，用于BP算法的推导。</data>
      <data key="d9">数学原理,术语关联</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002666</data>
      <data key="d13" />
    </edge>
    <edge source="链式法则" target="反向传播算法">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法的本质是微积分中链式法则的应用。</data>
      <data key="d9">应用,数学基础</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002664</data>
      <data key="d13" />
    </edge>
    <edge source="激活函数" target="双曲正切函数">
      <data key="d7">1.0</data>
      <data key="d8">双曲正切(tanh)函数是神经网络中常用的一种激活函数类型，它将输入值映射到-1到1的范围内。</data>
      <data key="d9">activation type,value mapping</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002457</data>
      <data key="d13" />
    </edge>
    <edge source="激活函数" target="Softmax函数">
      <data key="d7">1.0</data>
      <data key="d8">Softmax函数是神经网络输出层常用的一种激活函数，它将原始输出转换为概率分布。</data>
      <data key="d9">output normalization,probability distribution</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002465</data>
      <data key="d13" />
    </edge>
    <edge source="激活函数" target="隐藏单元">
      <data key="d7">1.0</data>
      <data key="d8">神经网络中的隐藏单元通过应用激活函数(如tanh)来计算其输出值，以实现非线性处理。</data>
      <data key="d9">nonlinear processing,output calculation</data>
      <data key="d10">chunk-072c6009a64360fcdc975b14582a2c8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002466</data>
      <data key="d13" />
    </edge>
    <edge source="激活函数" target="反向传播算法">
      <data key="d7">1.0</data>
      <data key="d8">文中分析激活函数(如Sigmoid)的特性会影响反向传播算法中的梯度扩散问题。</data>
      <data key="d9">影响,梯度扩散</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002666</data>
      <data key="d13" />
    </edge>
    <edge source="激活函数" target="ReLU">
      <data key="d7">1.0</data>
      <data key="d8">ReLU是激活函数的一种具体类型。</data>
      <data key="d9">example,type</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002941</data>
      <data key="d13" />
    </edge>
    <edge source="激活函数" target="卷积层">
      <data key="d7">2.0</data>
      <data key="d8">卷积操作后，卷积层应用激活函数如ReLU来引入非线性。&lt;SEP&gt;卷积层在运算后通常会结合激活函数，为模型引入非线性因素。</data>
      <data key="d9">application,nonlinear transformation,结合使用,非线性引入</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003360</data>
      <data key="d13" />
    </edge>
    <edge source="激活函数" target="非线性">
      <data key="d7">1.0</data>
      <data key="d8">激活函数为神经网络引入了非线性特性。</data>
      <data key="d9">introduction,property</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002945</data>
      <data key="d13" />
    </edge>
    <edge source="NONLINEAR DYNAMICS AND CHAOS with Applications to Physics, Biology, Chemistry, and Engineering (second edition)" target="CRC Press">
      <data key="d7">1.0</data>
      <data key="d8">《NONLINEAR DYNAMICS AND CHAOS with Applications to Physics, Biology, Chemistry, and Engineering (second edition)》这本书由CRC Press出版社出版。</data>
      <data key="d9">出版,学术著作</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002330</data>
      <data key="d13" />
    </edge>
    <edge source="盛昭瀚" target="非线性动力系统分析引论">
      <data key="d7">1.0</data>
      <data key="d8">盛昭瀚是《非线性动力系统分析引论》这本书的作者之一。</data>
      <data key="d9">作者,著作</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002331</data>
      <data key="d13" />
    </edge>
    <edge source="马军海" target="非线性动力系统分析引论">
      <data key="d7">1.0</data>
      <data key="d8">马军海是《非线性动力系统分析引论》这本书的作者之一。</data>
      <data key="d9">作者,著作</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002332</data>
      <data key="d13" />
    </edge>
    <edge source="非线性动力系统分析引论" target="科学出版社">
      <data key="d7">1.0</data>
      <data key="d8">《非线性动力系统分析引论》这本书由科学出版社出版。</data>
      <data key="d9">出版,学术著作</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002333</data>
      <data key="d13" />
    </edge>
    <edge source="Doctor of Philosophy" target="科学">
      <data key="d7">1.0</data>
      <data key="d8">博士学位被称为Doctor of Philosophy，体现了科学和艺术领域之间的深层逻辑联系。</data>
      <data key="d9">学术联系,跨领域</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002340</data>
      <data key="d13" />
    </edge>
    <edge source="Doctor of Philosophy" target="艺术">
      <data key="d7">1.0</data>
      <data key="d8">博士学位被称为Doctor of Philosophy，体现了科学和艺术领域之间的深层逻辑联系。</data>
      <data key="d9">学术联系,跨领域</data>
      <data key="d10">chunk-a815fcba7c08869c15a406f42f940fb2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002335</data>
      <data key="d13" />
    </edge>
    <edge source="蝴蝶效应" target="混沌理论">
      <data key="d7">1.0</data>
      <data key="d8">The butterfly effect is a famous phenomenon and conceptual example within the broader study of chaos theory.</data>
      <data key="d9">conceptual example,phenomenon</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002333</data>
      <data key="d13" />
    </edge>
    <edge source="蝴蝶效应" target="埃文">
      <data key="d7">1.0</data>
      <data key="d8">The protagonist Evan's time-travel actions in the film serve as a narrative device and conceptual analogy for the butterfly effect.</data>
      <data key="d9">conceptual analogy,narrative device</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002336</data>
      <data key="d13" />
    </edge>
    <edge source="混沌理论" target="非线性动力学系统">
      <data key="d7">1.0</data>
      <data key="d8">Chaos theory is a subfield that studies a specific type of behavior within nonlinear dynamical systems.</data>
      <data key="d9">subfield,system type</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002337</data>
      <data key="d13" />
    </edge>
    <edge source="非线性动力学系统" target="Strogatz">
      <data key="d7">1.0</data>
      <data key="d8">Strogatz, as a nonlinear dynamicist, provides classifications and perspectives on systems like nonlinear dynamical systems.</data>
      <data key="d9">classification,expertise</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002334</data>
      <data key="d13" />
    </edge>
    <edge source="非线性动力学系统" target="三体问题">
      <data key="d7">1.0</data>
      <data key="d8">The three-body problem is cited as an example of a three-dimensional nonlinear dynamical system.</data>
      <data key="d9">example,system dynamics</data>
      <data key="d10">chunk-ecf37963c494ecfacb6a6432c237dd3b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002336</data>
      <data key="d13" />
    </edge>
    <edge source="科学" target="霍克海默">
      <data key="d7">1.0</data>
      <data key="d8">Horkheimer theorized that understanding the crisis of science depends on a correct theory of the current social situation.</data>
      <data key="d9">crisis understanding,social dependency,theorized</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011180</data>
      <data key="d13" />
    </edge>
    <edge source="隐藏层" target="多层感知机">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机由隐藏层构成。</data>
      <data key="d9">composition,structure</data>
      <data key="d10">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003564</data>
      <data key="d13" />
    </edge>
    <edge source="Think Newsletter" target="AI News">
      <data key="d7">1.0</data>
      <data key="d8">The Think Newsletter provides curated insights and analysis on AI news.</data>
      <data key="d9">analysis,dissemination</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003532</data>
      <data key="d13" />
    </edge>
    <edge source="权重" target="反向传播算法">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法通过公式3计算权重的梯度，用于后续的参数更新。</data>
      <data key="d9">参数更新,梯度计算</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002665</data>
      <data key="d13" />
    </edge>
    <edge source="Objective Function J" target="Regularization Term s">
      <data key="d7">1.0</data>
      <data key="d8">The objective function J is composed of the regularization term s, as J = L + s.</data>
      <data key="d9">composition,summation</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002546</data>
      <data key="d13" />
    </edge>
    <edge source="Objective Function J" target="Partial J/Partial L">
      <data key="d7">1.0</data>
      <data key="d8">The partial derivative Partial J/Partial L describes how the objective function J changes with respect to its loss component L.</data>
      <data key="d9">differentiation,gradient component</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002547</data>
      <data key="d13" />
    </edge>
    <edge source="Objective Function J" target="Partial J/Partial s">
      <data key="d7">1.0</data>
      <data key="d8">The partial derivative Partial J/Partial s describes how the objective function J changes with respect to its regularization component s.</data>
      <data key="d9">differentiation,gradient component</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002555</data>
      <data key="d13" />
    </edge>
    <edge source="Regularization Term s" target="Parameter W^{(1)}">
      <data key="d7">1.0</data>
      <data key="d8">The regularization term s depends on the current value of parameter W^{(1)}, involving it in its calculation (e.g., λW^{(1)}).</data>
      <data key="d9">dependency,penalty</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="Regularization Term s" target="Parameter W^{(2)}">
      <data key="d7">1.0</data>
      <data key="d8">The regularization term s depends on the current value of parameter W^{(2)}, involving it in its calculation (e.g., λW^{(2)}).</data>
      <data key="d9">dependency,penalty</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002545</data>
      <data key="d13" />
    </edge>
    <edge source="Regularization Term s" target="Partial s/Partial W^{(1)}">
      <data key="d7">1.0</data>
      <data key="d8">The partial derivative Partial s/Partial W^{(1)} describes how the regularization term s changes with respect to the parameter W^{(1)}.</data>
      <data key="d9">differentiation,parameter gradient</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002547</data>
      <data key="d13" />
    </edge>
    <edge source="Regularization Term s" target="Partial s/Partial W^{(2)}">
      <data key="d7">1.0</data>
      <data key="d8">The partial derivative Partial s/Partial W^{(2)} describes how the regularization term s changes with respect to the parameter W^{(2)}.</data>
      <data key="d9">differentiation,parameter gradient</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002555</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient" target="ReLU">
      <data key="d7">1.0</data>
      <data key="d8">The gradient of the ReLU function is calculated and plotted, which is essential for training neural networks.</data>
      <data key="d9">backpropagation,mathematical property</data>
      <data key="d10">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003608</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient" target="Sigmoid">
      <data key="d7">1.0</data>
      <data key="d8">The gradient of the Sigmoid function is calculated and plotted, which is essential for training neural networks.</data>
      <data key="d9">backpropagation,mathematical property</data>
      <data key="d10">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003608</data>
      <data key="d13" />
    </edge>
    <edge source="Gradient" target="Tanh">
      <data key="d7">1.0</data>
      <data key="d8">The gradient of the Tanh function is calculated and plotted, which is essential for training neural networks.</data>
      <data key="d9">backpropagation,mathematical property</data>
      <data key="d10">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003609</data>
      <data key="d13" />
    </edge>
    <edge source="Parameter W^{(1)}" target="Optimization Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">The optimization algorithm updates the parameter W^{(1)} based on gradients provided by recent backpropagation iterations.</data>
      <data key="d9">iteration,update</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002545</data>
      <data key="d13" />
    </edge>
    <edge source="Parameter W^{(2)}" target="Optimization Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">The optimization algorithm updates the parameter W^{(2)} based on gradients provided by recent backpropagation iterations.</data>
      <data key="d9">iteration,update</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002546</data>
      <data key="d13" />
    </edge>
    <edge source="Partial s/Partial W^{(1)}" target="Regularization Parameter λ">
      <data key="d7">1.0</data>
      <data key="d8">The regularization parameter λ scales the weight matrix W^{(1)} in the calculation of the gradient Partial s/Partial W^{(1)}.</data>
      <data key="d9">coefficient,scaling</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002555</data>
      <data key="d13" />
    </edge>
    <edge source="Partial s/Partial W^{(2)}" target="Regularization Parameter λ">
      <data key="d7">1.0</data>
      <data key="d8">The regularization parameter λ scales the weight matrix W^{(2)} in the calculation of the gradient Partial s/Partial W^{(2)}.</data>
      <data key="d9">coefficient,scaling</data>
      <data key="d10">chunk-22b82197e907c906b6de43d41ffe2efe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002550</data>
      <data key="d13" />
    </edge>
    <edge source="前向传播" target="小批量随机梯度下降">
      <data key="d7">1.0</data>
      <data key="d8">使用小批量随机梯度下降训练模型时，涉及前向传播的计算过程。</data>
      <data key="d9">计算过程,训练算法</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="计算图" target="操作符">
      <data key="d7">1.0</data>
      <data key="d8">计算图由代表变量的方形节点和代表数学运算的操作符(圆形节点)组成。</data>
      <data key="d9">可视化,组成元素</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002553</data>
      <data key="d13" />
    </edge>
    <edge source="自动微分" target="张量">
      <data key="d7">1.0</data>
      <data key="d8">自动微分系统能够处理以张量形式表示的输入、输出和中间变量。</data>
      <data key="d9">处理对象,数据表示</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002553</data>
      <data key="d13" />
    </edge>
    <edge source="权重衰减" target="L2正则化">
      <data key="d7">1.0</data>
      <data key="d8">权重衰减是L2正则化的另一种表述，用于防止模型过拟合。</data>
      <data key="d9">同义词,正则化技术</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002550</data>
      <data key="d13" />
    </edge>
    <edge source="单隐藏层多层感知机" target="隐藏变量">
      <data key="d7">1.0</data>
      <data key="d8">在单隐藏层多层感知机中，隐藏层会产生隐藏变量作为中间产物。</data>
      <data key="d9">中间产物,网络架构</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002550</data>
      <data key="d13" />
    </edge>
    <edge source="单隐藏层多层感知机" target="输出层变量">
      <data key="d7">1.0</data>
      <data key="d8">单隐藏层多层感知机的输出层产生输出层变量作为最终结果。</data>
      <data key="d9">最终输出,网络架构</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="L2正则化" target="目标函数">
      <data key="d7">1.0</data>
      <data key="d8">L2正则化项被添加到损失函数中以构成最终需要优化的目标函数。</data>
      <data key="d9">惩罚项,组成部分</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002551</data>
      <data key="d13" />
    </edge>
    <edge source="L2正则化" target="Frobenius范数">
      <data key="d7">1.0</data>
      <data key="d8">在L2正则化中，对权重矩阵的惩罚项使用Frobenius范数进行计算。</data>
      <data key="d9">惩罚项计算,计算方式</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002553</data>
      <data key="d13" />
    </edge>
    <edge source="目标函数" target="正则化损失">
      <data key="d7">1.0</data>
      <data key="d8">目标函数J是模型需要最小化的最终表达式，它等于正则化损失。</data>
      <data key="d9">优化目标,最终形式</data>
      <data key="d10">chunk-3a728b359622810cd77efd2985a7fcfd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002553</data>
      <data key="d13" />
    </edge>
    <edge source="参数" target="Transformer架构">
      <data key="d7">1.0</data>
      <data key="d8">Parameters are the fundamental, numerous components of the Transformer architecture that enable its learning capacity.</data>
      <data key="d9">model components,scalability</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009055</data>
      <data key="d13" />
    </edge>
    <edge source="BP算法" target="链式求导法则">
      <data key="d7">1.0</data>
      <data key="d8">BP算法的推导依赖于链式求导法则来计算误差对网络权重的偏导数。</data>
      <data key="d9">数学基础,算法推导</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002655</data>
      <data key="d13" />
    </edge>
    <edge source="Hadamard乘积" target="公式1">
      <data key="d7">2.0</data>
      <data key="d8">公式1在计算最后一层神经网络的错误时，使用了Hadamard乘积进行点对点乘法运算。&lt;SEP&gt;公式1的计算中使用了Hadamard乘积进行矩阵或向量之间点对点的乘法运算。</data>
      <data key="d9">公式组成,应用,数学运算,计算错误</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a&lt;SEP&gt;chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002660</data>
      <data key="d13" />
    </edge>
    <edge source="博主" target="CC 4.0 BY-SA版权协议">
      <data key="d7">1.0</data>
      <data key="d8">博主声明其原创文章遵循CC 4.0 BY-SA版权协议进行发布和传播。</data>
      <data key="d9">内容许可,版权声明</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002658</data>
      <data key="d13" />
    </edge>
    <edge source="国外某网站" target="第一组图">
      <data key="d7">1.0</data>
      <data key="d8">国外某网站提供了用于讲解神经网络前向传播和反向传播算法的第一组生动形象的图解。</data>
      <data key="d9">内容来源,图解提供</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002659</data>
      <data key="d13" />
    </edge>
    <edge source="公式1" target="公式2">
      <data key="d7">1.0</data>
      <data key="d8">公式2由公式1推导而来，用于计算每一层神经网络产生的错误。</data>
      <data key="d9">公式推导,错误传递</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002661</data>
      <data key="d13" />
    </edge>
    <edge source="out o1" target="误差E">
      <data key="d7">1.0</data>
      <data key="d8">在求误差E对w5的导数过程中，需要先求误差E对out o1的导数。</data>
      <data key="d9">中间计算,链式求导</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002661</data>
      <data key="d13" />
    </edge>
    <edge source="out o1" target="net o1">
      <data key="d7">1.0</data>
      <data key="d8">在求误差E对w5的导数过程中，需要求out o1对net o1的导数。</data>
      <data key="d9">函数关系,求导步骤</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002661</data>
      <data key="d13" />
    </edge>
    <edge source="net o1" target="w5">
      <data key="d7">1.0</data>
      <data key="d8">在求误差E对w5的导数过程中，最后需要求net o1对w5的导数。</data>
      <data key="d9">参数依赖,求导步骤</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002662</data>
      <data key="d13" />
    </edge>
    <edge source="w5" target="误差E">
      <data key="d7">1.0</data>
      <data key="d8">在具体计算举例中，通过链式求导过程计算了误差E对权重w5的导数(偏导)。</data>
      <data key="d9">参数优化,梯度计算</data>
      <data key="d10">chunk-a5ecc39f0afdf3e1ae562d6befd49d9a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002659</data>
      <data key="d13" />
    </edge>
    <edge source="AI大模型学习资源" target="AI大模型全套学习路线图">
      <data key="d7">1.0</data>
      <data key="d8">AI大模型学习资源包含了AI大模型全套学习路线图作为其组成部分。</data>
      <data key="d9">包含,组成部分</data>
      <data key="d10">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002661</data>
      <data key="d13" />
    </edge>
    <edge source="AI大模型学习资源" target="精品AI大模型学习书籍手册">
      <data key="d7">1.0</data>
      <data key="d8">AI大模型学习资源包含了精品AI大模型学习书籍手册作为其组成部分。</data>
      <data key="d9">包含,组成部分</data>
      <data key="d10">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002662</data>
      <data key="d13" />
    </edge>
    <edge source="AI大模型学习资源" target="视频教程">
      <data key="d7">1.0</data>
      <data key="d8">AI大模型学习资源包含了视频教程作为其组成部分。</data>
      <data key="d9">包含,组成部分</data>
      <data key="d10">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002663</data>
      <data key="d13" />
    </edge>
    <edge source="AI大模型学习资源" target="实战学习">
      <data key="d7">1.0</data>
      <data key="d8">AI大模型学习资源包含了实战学习作为其组成部分。</data>
      <data key="d9">包含,组成部分</data>
      <data key="d10">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002664</data>
      <data key="d13" />
    </edge>
    <edge source="AI大模型学习资源" target="面试题">
      <data key="d7">1.0</data>
      <data key="d8">AI大模型学习资源包含了面试题作为其组成部分。</data>
      <data key="d9">包含,组成部分</data>
      <data key="d10">chunk-03ea8b90f698c0a32f89ceeecd701030</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002664</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="前向传播算法">
      <data key="d7">1.0</data>
      <data key="d8">前向传播算法与反向传播算法共同构成了神经网络完整的计算和训练过程。</data>
      <data key="d9">互补过程,神经网络计算</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002664</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="偏置">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法通过公式4计算偏置的梯度，用于后续的参数更新。</data>
      <data key="d9">参数更新,梯度计算</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002665</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="梯度下降">
      <data key="d7">1.0</data>
      <data key="d8">梯度下降优化算法利用反向传播算法计算出的梯度来更新网络权重。</data>
      <data key="d9">优化,利用</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002666</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="卷积神经网络">
      <data key="d7">2.0</data>
      <data key="d8">卷积神经网络的训练也使用反向传播算法，其卷积层的梯度推导是重点。&lt;SEP&gt;Convolutional Neural Networks can be trained using the backpropagation algorithm.</data>
      <data key="d9">method,trained by,梯度推导,训练</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002936</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="陈唯源">
      <data key="d7">1.0</data>
      <data key="d8">陈唯源撰写了关于反向传播算法工作过程和公式推导的文章。</data>
      <data key="d9">推导,阐述</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002667</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="CSDN">
      <data key="d7">1.0</data>
      <data key="d8">CSDN技术社区上分享了关于反向传播算法公式推导的深度学习系列文章。</data>
      <data key="d9">平台分享,技术文章</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002667</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="RNN">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法也应用于训练RNN，文中提到了RNN反向传播公式的推导。</data>
      <data key="d9">公式推导,结构应用</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002667</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="CNN">
      <data key="d7">1.0</data>
      <data key="d8">反向传播算法是训练CNN的核心，文中重点探讨了CNN中卷积层的反向传播梯度推导。</data>
      <data key="d9">梯度推导,结构应用</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002668</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="多层感知机">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机在1980年代通过反向传播算法取得了重大进展。</data>
      <data key="d9">advancement,training</data>
      <data key="d10">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003564</data>
      <data key="d13" />
    </edge>
    <edge source="反向传播算法" target="Geoffrey Hinton">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton, along with peers, promoted the widespread application of the Back-propagation algorithm.</data>
      <data key="d9">application,promotion</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="CNN">
      <data key="d7">3.0</data>
      <data key="d8">CNN是卷积神经网络的常用缩写。&lt;SEP&gt;CNN是卷积神经网络的英文缩写，指代同一概念。&lt;SEP&gt;CNN是卷积神经网络的英文简称，两者指代同一种模型。</data>
      <data key="d9">同义词,术语,简称,缩写</data>
      <data key="d10">chunk-d22adf07bd762e4e32d9bceea2fa6218&lt;SEP&gt;chunk-225c135f952fba89e32fc67dcf80d0f5&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003354</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="ConvNets">
      <data key="d7">1.0</data>
      <data key="d8">ConvNets是卷积神经网络的另一种术语表达。</data>
      <data key="d9">同义词,术语</data>
      <data key="d10">chunk-d22adf07bd762e4e32d9bceea2fa6218</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002735</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="图像数据">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络是一类专门为处理具有空间结构的图像数据而设计的强大神经网络。</data>
      <data key="d9">专门设计,高效处理</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002785</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="计算机视觉">
      <data key="d7">4.0</data>
      <data key="d8">基于卷积神经网络架构的模型在计算机视觉领域占据主导地位，是当前图像识别、目标检测等应用的基础。&lt;SEP&gt;卷积神经网络是计算机视觉领域取得成功的关键技术。&lt;SEP&gt;Convolutional Neural Networks are a core and successful technology widely applied in the field of computer vision for tasks like image and video processing.&lt;SEP&gt;卷积神经网络最初相遇和应用在计算机视觉领域。</data>
      <data key="d9">application,application domain,core technology,enabling technology,主导地位,基础应用,应用领域,技术起源</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003352</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="全连接的多层感知机">
      <data key="d7">1.0</data>
      <data key="d8">与全连接的多层感知机相比，卷积神经网络所需的参数更少，并且能更高效地利用图像的空间结构信息。</data>
      <data key="d9">参数更少,效率更高</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002785</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="循环神经网络">
      <data key="d7">1.0</data>
      <data key="d8">即使在传统上使用循环神经网络处理的一维序列任务(如音频、文本分析)中，卷积神经网络也变得越来越受欢迎。</data>
      <data key="d9">任务扩展,日益流行</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002786</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="卷积层">
      <data key="d7">6.0</data>
      <data key="d8">卷积层是构成所有卷积神经网络主干的基本核心元素之一。&lt;SEP&gt;The convolutional layer is a primary and essential structural component within a Convolutional Neural Network.&lt;SEP&gt;卷积层是卷积神经网络的一个核心组成部分，通过卷积操作提取特征。&lt;SEP&gt;Convolutional Neural Networks use convolutional layers as a core component to perform convolution operations and extract local features from data.&lt;SEP&gt;卷积神经网络包含卷积层作为其核心组件之一，该层负责从输入数据中提取特征。&lt;SEP&gt;卷积层是卷积神经网络的核心组成部分之一，负责通过卷积核进行特征提取。</data>
      <data key="d9">component,contains,feature extraction,fundamental component,信息提取,基本元素,架构组成,核心构成,特征提取,组成部分</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3&lt;SEP&gt;chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-c79065b95e8586e85c1d4a6dfcdb5d37&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003355</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="填充">
      <data key="d7">1.0</data>
      <data key="d8">填充是卷积神经网络中使用的一项基本技术，用于控制卷积层输出特征图的空间尺寸。</data>
      <data key="d9">包含技术,控制输出</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002787</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="步幅">
      <data key="d7">1.0</data>
      <data key="d8">步幅是卷积神经网络中使用的一项基本技术，用于控制卷积核在输入数据上移动的步长。</data>
      <data key="d9">包含技术,控制滑动</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002787</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="汇聚层">
      <data key="d7">1.0</data>
      <data key="d8">汇聚层是卷积神经网络中的一种层，用于在相邻区域汇聚信息，实现下采样。</data>
      <data key="d9">信息汇聚,包含技术</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002787</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="多通道">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络在每一层中使用多通道(例如处理彩色图像)来有效地处理复杂数据。</data>
      <data key="d9">利用特性,处理数据</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002788</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="LeNet模型">
      <data key="d7">1.0</data>
      <data key="d8">LeNet模型是第一个成功应用的卷积神经网络，是卷积神经网络发展史上的一个重要早期实现。</data>
      <data key="d9">成功案例,早期实现</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002788</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="生物学">
      <data key="d7">1.0</data>
      <data key="d8">现代卷积神经网络的设计得益于生物学的启发。</data>
      <data key="d9">灵感来源,设计启发</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002788</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="群论">
      <data key="d7">1.0</data>
      <data key="d8">现代卷积神经网络的设计得益于群论的启发。</data>
      <data key="d9">理论基础,设计启发</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002789</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="图结构数据">
      <data key="d7">1.0</data>
      <data key="d8">通过对卷积神经网络进行巧妙的调整，使其能够在图结构数据任务中发挥作用。</data>
      <data key="d9">应用扩展,结构调整</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002789</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="推荐系统">
      <data key="d7">1.0</data>
      <data key="d8">通过对卷积神经网络进行巧妙的调整，使其能够在推荐系统任务中发挥作用。</data>
      <data key="d9">应用扩展,结构调整</data>
      <data key="d10">chunk-37f0a7ef7d63be3d8878c173058865c3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002796</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="池化层">
      <data key="d7">4.0</data>
      <data key="d8">The pooling layer is a standard component within the architecture of a Convolutional Neural Network.&lt;SEP&gt;池化层是卷积神经网络的一个组成部分，用于对特征图进行下采样。&lt;SEP&gt;Convolutional Neural Networks incorporate pooling layers to reduce the spatial dimensions of the features extracted by convolutional layers.&lt;SEP&gt;池化层是卷积神经网络的核心组成部分之一，负责汇聚特征并减少数据维度。</data>
      <data key="d9">component,contains,dimensionality reduction,downsampling,组成部分,降维</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003357</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="全连接层">
      <data key="d7">4.0</data>
      <data key="d8">全连接层是卷积神经网络的一个组成部分，通常用于最终的处理和输出。&lt;SEP&gt;Convolutional Neural Networks utilize fully connected layers as a final component to perform classification or regression tasks.&lt;SEP&gt;全连接层是卷积神经网络结构中的一种层，通常用于最终的分类任务。&lt;SEP&gt;卷积神经网络最后往往保留全连接层，用于从全局出发做出最终结论，与前面的卷积层形成先局部后整体的学习结构。</data>
      <data key="d9">classification,component,final processing,分类,特征整合,组成部分,网络架构</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003345</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="图像识别">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are a fundamental and successful technology applied in the field of image recognition.</data>
      <data key="d9">application,core technology</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002931</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="基础CNN">
      <data key="d7">1.0</data>
      <data key="d8">A Basic CNN is a simple, introductory variant of the Convolutional Neural Network architecture designed for classification tasks.</data>
      <data key="d9">simplified model,variant</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002932</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="SSD">
      <data key="d7">1.0</data>
      <data key="d8">SSD is a specific variant of Convolutional Neural Network architecture optimized for fast, single-stage object detection.</data>
      <data key="d9">object detection,variant</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002932</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="Faster R-CNN">
      <data key="d7">1.0</data>
      <data key="d8">Faster R-CNN is a specific variant of Convolutional Neural Network architecture designed for high-accuracy, two-stage object detection.</data>
      <data key="d9">object detection,variant</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002932</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="Mask R-CNN">
      <data key="d7">1.0</data>
      <data key="d8">Mask R-CNN is an advanced variant of Convolutional Neural Network architecture capable of both object detection and instance segmentation.</data>
      <data key="d9">segmentation,variant</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002933</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="卷积操作">
      <data key="d7">1.0</data>
      <data key="d8">The convolution operation is the fundamental mathematical process that defines and gives its name to the Convolutional Neural Network.</data>
      <data key="d9">core mechanism,namesake</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002933</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="滤波器">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks utilize filters (convolution kernels) as sets of fixed weights within their convolutional layers to detect features.</data>
      <data key="d9">parameter,utilizes</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002934</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="平移不变性">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks achieve the property of translation invariance through their use of convolution operations, overcoming limitations of traditional neural networks in image processing.</data>
      <data key="d9">achieves,property</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002941</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="层级化特征提取">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks implement a process of hierarchical feature extraction through their layered architecture, moving from basic to advanced semantic understanding.</data>
      <data key="d9">implements,process</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002935</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="图像处理">
      <data key="d7">2.0</data>
      <data key="d8">Convolutional Neural Networks are a key deep learning algorithm applied to the field of image processing, driving its progress.&lt;SEP&gt;卷积神经网络是图像处理领域的关键技术之一。</data>
      <data key="d9">advancement,application,application domain,technology use</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe&lt;SEP&gt;chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002938</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="Hubel">
      <data key="d7">1.0</data>
      <data key="d8">The design of Convolutional Neural Networks was inspired by the scientific work on biological visual systems conducted by Hubel and Wiesel.</data>
      <data key="d9">biological basis,inspiration</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002938</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="Wiesel">
      <data key="d7">1.0</data>
      <data key="d8">The design of Convolutional Neural Networks was inspired by the scientific work on biological visual systems conducted by Hubel and Wiesel.</data>
      <data key="d9">biological basis,inspiration</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002939</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="生物视觉系统">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are designed to simulate the processing mechanisms of the human biological visual system.</data>
      <data key="d9">design inspiration,simulation</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002939</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="激活层">
      <data key="d7">1.0</data>
      <data key="d8">The activation layer is a standard component within the architecture of a Convolutional Neural Network.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002940</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="全链接层">
      <data key="d7">1.0</data>
      <data key="d8">The fully connected layer is a standard component within the architecture of a Convolutional Neural Network.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002941</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="腾讯云">
      <data key="d7">1.0</data>
      <data key="d8">Tencent Cloud published an article that explains the basic structure and principles of Convolutional Neural Networks.</data>
      <data key="d9">explains,publishes content</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002941</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="知网">
      <data key="d7">1.0</data>
      <data key="d8">CNKI provides access to research papers, including master's theses, which discuss the training and theoretical aspects of Convolutional Neural Networks.</data>
      <data key="d9">provides resources,research papers</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002943</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="二维卷积层">
      <data key="d7">1.0</data>
      <data key="d8">二维卷积层是卷积神经网络中最常见的一种卷积层类型。</data>
      <data key="d9">common form,type</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002945</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="多层堆叠">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络可以通过多层堆叠卷积层、激活层和池化层来构造。</data>
      <data key="d9">construction method,layer organization</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002948</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="构建模块">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络是计算机视觉取得巨大成功的关键构建模块。</data>
      <data key="d9">role,technological importance</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002949</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="训练">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络需要通过训练过程来学习。</data>
      <data key="d9">model development,process</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002950</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="深度学习系统">
      <data key="d7">1.0</data>
      <data key="d8">深度学习系统包含卷积神经网络作为其主要类型之一。</data>
      <data key="d9">架构分类,类型包含</data>
      <data key="d10">chunk-c79065b95e8586e85c1d4a6dfcdb5d37</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002981</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="CNN架构">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络由特定的CNN架构定义，该架构描述了其内部层组结构。</data>
      <data key="d9">架构定义,结构描述</data>
      <data key="d10">chunk-c79065b95e8586e85c1d4a6dfcdb5d37</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002981</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="卷积计算">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks incorporate convolutional computation as a core mathematical operation.</data>
      <data key="d9">component,mathematical operation</data>
      <data key="d10">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003013</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="前馈神经网络">
      <data key="d7">2.0</data>
      <data key="d8">Convolutional Neural Networks are a specific class of Feedforward Neural Networks.&lt;SEP&gt;卷积神经网络是前馈神经网络的一种特定类型。</data>
      <data key="d9">architecture,subclass,架构,类型</data>
      <data key="d10">chunk-c79b805e7da972f5a80b0f9eb1144d75&lt;SEP&gt;chunk-df57bc33c49fe522c66616c1a4be5336</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003218</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="ConvNet">
      <data key="d7">1.0</data>
      <data key="d8">ConvNet是卷积神经网络的英文缩写，指代同一概念。</data>
      <data key="d9">同义词,缩写</data>
      <data key="d10">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003044</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="图像">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络特别适合在图像中寻找模式以识别对象、类和类别。</data>
      <data key="d9">应用,模式识别</data>
      <data key="d10">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003045</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="音频">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络能很好地对音频数据进行处理。</data>
      <data key="d9">应用,数据处理</data>
      <data key="d10">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003045</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="时间序列">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络能很好地对时间序列数据进行处理。</data>
      <data key="d9">应用,数据处理</data>
      <data key="d10">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003045</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="信号">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络能很好地对信号数据进行处理。</data>
      <data key="d9">应用,数据处理</data>
      <data key="d10">chunk-225c135f952fba89e32fc67dcf80d0f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003046</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="人工神经元">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络由人工神经元构成，这些神经元是其基本计算组件。</data>
      <data key="d9">组成,计算单元</data>
      <data key="d10">chunk-df57bc33c49fe522c66616c1a4be5336</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003218</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="大型图像处理">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络在处理大型图像任务时表现出色。</data>
      <data key="d9">应用,性能</data>
      <data key="d10">chunk-df57bc33c49fe522c66616c1a4be5336</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003219</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="福岛邦彦">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络的前身“神经认知模型”由日本学者福岛邦彦提出，受生物视觉系统研究启发。</data>
      <data key="d9">历史起源,理论启发</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003347</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="Yann LeCun">
      <data key="d7">2.0</data>
      <data key="d8">法国学者Yann LeCun等人提出了基于梯度学习的卷积神经网络算法LeNet，标志着卷积与神经网络真正意义上的合体。&lt;SEP&gt;Yann LeCun invented the Convolutional Neural Network, inspired by extending the organizational structure of the brain's visual system to artificial neural networks.</data>
      <data key="d9">inspiration,invention,实际应用,算法发展</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="AlexNet">
      <data key="d7">1.0</data>
      <data key="d8">AlexNet在2012年ImageNet竞赛中的成功，让学术界意识到了卷积神经网络改造的巨大潜力。</data>
      <data key="d9">学术影响,性能突破</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003348</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="ZFNet">
      <data key="d7">1.0</data>
      <data key="d8">ZFNet通过可视化展示了卷积神经网络各层的功能和作用。</data>
      <data key="d9">功能可视化,模型解释</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003348</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="VGGNet">
      <data key="d7">1.0</data>
      <data key="d8">VGGNet采用堆积的小卷积核替代大的卷积核，是卷积神经网络的一种重要变体。</data>
      <data key="d9">参数优化,模型改进</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003349</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="GoogleNet">
      <data key="d7">1.0</data>
      <data key="d8">GoogleNet增加了卷积神经网络的宽度并使用1x1卷积降维，是卷积神经网络的一种变体。</data>
      <data key="d9">架构创新,计算效率</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003349</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="ResNet">
      <data key="d7">1.0</data>
      <data key="d8">ResNet解决了网络模型的退化问题，允许构建更深的卷积神经网络。</data>
      <data key="d9">深度扩展,问题解决</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003350</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="MNIST模型">
      <data key="d7">1.0</data>
      <data key="d8">MNIST模型是用于实现卷积神经网络的一个具体示例，常用于图像分类任务。</data>
      <data key="d9">任务应用,示例实现</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003351</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="手写体数字">
      <data key="d7">1.0</data>
      <data key="d8">识别手写体数字是卷积神经网络的一个具体应用任务示例。</data>
      <data key="d9">任务说明,应用示例</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003358</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="车型">
      <data key="d7">1.0</data>
      <data key="d8">识别车型是卷积神经网络的另一个具体应用任务示例。</data>
      <data key="d9">任务说明,应用示例</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003359</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="计算机学者">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络是由计算机学者受生理学家和数学家启发而创造出来的。</data>
      <data key="d9">创造者,灵感来源</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003360</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="序列">
      <data key="d7">1.0</data>
      <data key="d8">卷积神经网络用于对序列数据进行编码处理。</data>
      <data key="d9">encoding,processing</data>
      <data key="d10">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003415</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="特征工程">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks (CNN) automate the feature extraction process, greatly simplifying the traditional feature engineering workflow.</data>
      <data key="d9">automation,simplification</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004956</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="高频交易">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks (CNN) are applied in the field of high-frequency trading to process large volumes of micro-market data.</data>
      <data key="d9">data processing,model application</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004957</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="K线图">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks (CNN) can analyze K-line chart visual patterns to identify potential buy or sell signals.</data>
      <data key="d9">feature extraction,visual analysis</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004959</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="买入信号">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks (CNN) can analyze patterns to identify potential buy signals from K-line charts.</data>
      <data key="d9">pattern recognition,signal identification</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004962</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="卖出信号">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks (CNN) can analyze patterns to identify potential sell signals from K-line charts.</data>
      <data key="d9">pattern recognition,signal identification</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004963</data>
      <data key="d13" />
    </edge>
    <edge source="卷积神经网络" target="短期交易策略">
      <data key="d7">1.0</data>
      <data key="d8">The signals identified by CNN from K-line charts can be used to inform short-term trading strategies.</data>
      <data key="d9">application,strategy enablement</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004963</data>
      <data key="d13" />
    </edge>
    <edge source="梯度下降" target="Adam优化器">
      <data key="d7">1.0</data>
      <data key="d8">Adam优化器是在梯度下降基础上引入动量和自适应学习率等机制的更复杂优化器。</data>
      <data key="d9">增强,改进</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002671</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习算法与自然语言处理公众号" target="陈楠">
      <data key="d7">1.0</data>
      <data key="d8">机器学习算法与自然语言处理公众号转载并整理了知乎作者陈楠关于反向传播算法直观理解的文章。</data>
      <data key="d9">整理,转载</data>
      <data key="d10">chunk-95faa80d73b4394851b10e9cc65232d2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002665</data>
      <data key="d13" />
    </edge>
    <edge source="RNN" target="深度學習模型">
      <data key="d7">1.0</data>
      <data key="d8">RNN is a specific type of deep learning model designed for handling sequential data.</data>
      <data key="d9">model type,sequential data</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004952</data>
      <data key="d13" />
    </edge>
    <edge source="RNN" target="长短期记忆网络">
      <data key="d7">1.0</data>
      <data key="d8">RNN is good at remembering recent information, while LSTM extends this capability to remember both long-term and short-term information.</data>
      <data key="d9">memory capability,neural networks</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007102</data>
      <data key="d13" />
    </edge>
    <edge source="RNN" target="Transformer Model">
      <data key="d7">1.0</data>
      <data key="d8">The transformer model's architecture and performance, particularly with multi-head attention, surpassed previous state-of-the-art RNNs.</data>
      <data key="d9">architecture comparison,performance</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008207</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="计算机视觉模型">
      <data key="d7">1.0</data>
      <data key="d8">CNN is described as one of the mainstream types of computer vision models.</data>
      <data key="d9">application,architecture</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003188</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="LeNet-5">
      <data key="d7">1.0</data>
      <data key="d8">LeNet-5 is listed as a common CNN architecture.</data>
      <data key="d9">architecture example,model type</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003189</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="AlexNet">
      <data key="d7">1.0</data>
      <data key="d8">AlexNet is listed as a common CNN architecture.</data>
      <data key="d9">architecture example,model type</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003189</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="VGGNet">
      <data key="d7">1.0</data>
      <data key="d8">VGGNet is listed as a common CNN architecture.</data>
      <data key="d9">architecture example,model type</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003189</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="GoogLeNet">
      <data key="d7">1.0</data>
      <data key="d8">GoogLeNet is listed as a common CNN architecture.</data>
      <data key="d9">architecture example,model type</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003190</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="ResNet">
      <data key="d7">1.0</data>
      <data key="d8">ResNet is listed as a common CNN architecture.</data>
      <data key="d9">architecture example,model type</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003190</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="Watson Studio">
      <data key="d7">1.0</data>
      <data key="d8">Watson Studio provides tools for the full lifecycle of building, training, tuning, and deploying CNN models.</data>
      <data key="d9">model lifecycle,tool support</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003191</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="watsonx.ai">
      <data key="d7">1.0</data>
      <data key="d8">watsonx.ai provides tools for the full lifecycle of building, training, tuning, and deploying CNN models.</data>
      <data key="d9">model lifecycle,tool support</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003193</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="图像任务">
      <data key="d7">1.0</data>
      <data key="d8">CNN architectures are suitable for image tasks of varying complexity and performance requirements.</data>
      <data key="d9">model application,task suitability</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003194</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="High-Frequency Trading Strategy">
      <data key="d7">1.0</data>
      <data key="d8">CNN serves as the underlying algorithmic model for another version of the high-frequency trading strategy.</data>
      <data key="d9">algorithmic basis,model implementation</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004806</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="深度學習模型">
      <data key="d7">1.0</data>
      <data key="d8">CNN is a specific type of deep learning model used for extracting local features from image-like financial data.</data>
      <data key="d9">feature extraction,model type</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004951</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="K線圖">
      <data key="d7">1.0</data>
      <data key="d8">CNN can process candlestick charts as image-like inputs to automatically extract local features and recognize technical patterns.</data>
      <data key="d9">feature extraction,pattern recognition</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004952</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="技術指標">
      <data key="d7">1.0</data>
      <data key="d8">CNN can process the trend charts of technical indicators as inputs to extract features and capture patterns.</data>
      <data key="d9">feature extraction,pattern recognition</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004960</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="頭肩頂">
      <data key="d7">1.0</data>
      <data key="d8">CNN can be used to identify classic technical chart patterns like the head and shoulders top.</data>
      <data key="d9">pattern recognition,technical analysis</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004954</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="雙底">
      <data key="d7">1.0</data>
      <data key="d8">CNN can be used to identify classic technical chart patterns like the double bottom.</data>
      <data key="d9">pattern recognition,technical analysis</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004955</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="卷积">
      <data key="d7">1.0</data>
      <data key="d8">CNN使用卷积操作，通过过滤器在输入上滑动相乘来提取特征。</data>
      <data key="d9">核心操作,特征提取</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007054</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="图像识别网络">
      <data key="d7">1.0</data>
      <data key="d8">图像识别网络应用CNN，网络越深效果越好。</data>
      <data key="d9">应用,网络结构</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007052</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="Deep Pyramid CNN">
      <data key="d7">1.0</data>
      <data key="d8">Deep Pyramid CNN is described as a deep version of CNN, addressing CNN's inherent limitation of limited width and semantic loss by using a stacked, identical block structure.</data>
      <data key="d9">architectural comparison,evolution</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007060</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="Max-Pooling">
      <data key="d7">1.0</data>
      <data key="d8">The described CNN model uses max-pooling to obtain the largest feature from each feature map for its final output.</data>
      <data key="d9">feature extraction,utilizes</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007073</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="Feature Map">
      <data key="d7">1.0</data>
      <data key="d8">The convolutional layers in the CNN generate feature maps, which are then processed by max-pooling.</data>
      <data key="d9">generates,intermediate data</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007081</data>
      <data key="d13" />
    </edge>
    <edge source="CNN" target="Transformer Model">
      <data key="d7">1.0</data>
      <data key="d8">The transformer model's architecture and performance, particularly with multi-head attention, surpassed previous state-of-the-art CNNs.</data>
      <data key="d9">architecture comparison,performance</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008211</data>
      <data key="d13" />
    </edge>
    <edge source="Hidden Layer" target="Weight Coefficient">
      <data key="d7">1.0</data>
      <data key="d8">The weight coefficients of neurons in the hidden layer are updated during the training process to reduce error.</data>
      <data key="d9">parameter adjustment,training</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002716</data>
      <data key="d13" />
    </edge>
    <edge source="Weight Coefficient" target="Neuron">
      <data key="d7">1.0</data>
      <data key="d8">Each neuron contains weight coefficients that determine the strength of its connections to inputs.</data>
      <data key="d9">computation,connection strength</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002718</data>
      <data key="d13" />
    </edge>
    <edge source="Weight Coefficient" target="Gradient Descent">
      <data key="d7">1.0</data>
      <data key="d8">Gradient descent is the method used to update weight coefficients by calculating the partial derivative of error with respect to each weight.</data>
      <data key="d9">optimization algorithm,parameter update</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002719</data>
      <data key="d13" />
    </edge>
    <edge source="Neuron" target="Total Net Input">
      <data key="d7">1.0</data>
      <data key="d8">A neuron calculates its total net input as the sum of its weighted inputs plus its bias.</data>
      <data key="d9">input aggregation,pre-activation</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002719</data>
      <data key="d13" />
    </edge>
    <edge source="Error" target="Output Layer">
      <data key="d7">1.0</data>
      <data key="d8">The error is calculated at the output layer by comparing the network's prediction to the target output.</data>
      <data key="d9">optimization target,performance measurement</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002716</data>
      <data key="d13" />
    </edge>
    <edge source="Error" target="Squared Error">
      <data key="d7">1.0</data>
      <data key="d8">The error for a neuron is calculated using the squared error formula.</data>
      <data key="d9">error metric,loss function</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002719</data>
      <data key="d13" />
    </edge>
    <edge source="Training Set" target="Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">A neural network uses training sets to learn and adjust its internal parameters.</data>
      <data key="d9">learning data,model optimization</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002716</data>
      <data key="d13" />
    </edge>
    <edge source="Training Set" target="Training Phase">
      <data key="d7">1.0</data>
      <data key="d8">The training phase uses the Training Set to build and initially evaluate the model.</data>
      <data key="d9">data utilization,model development</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005617</data>
      <data key="d13" />
    </edge>
    <edge source="Training Set" target="Deep Auto-Encoders">
      <data key="d7">1.0</data>
      <data key="d8">The Deep Auto-Encoder model was trained on a training set that constituted 75% of the available data.</data>
      <data key="d9">data partitioning,model training</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006177</data>
      <data key="d13" />
    </edge>
    <edge source="Feed Forward" target="Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">The feed forward method is the process by which a neural network processes input data to generate a prediction.</data>
      <data key="d9">information propagation,prediction</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002718</data>
      <data key="d13" />
    </edge>
    <edge source="Feed Forward" target="Encoder Block">
      <data key="d7">1.0</data>
      <data key="d8">An Encoder block contains a Feed Forward neural network layer as a core component.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007693</data>
      <data key="d13" />
    </edge>
    <edge source="Neural Network" target="Random Initialization">
      <data key="d7">1.0</data>
      <data key="d8">A neural network's weights and biases are initialized randomly before the training process begins.</data>
      <data key="d9">parameter start,training setup</data>
      <data key="d10">chunk-b0c9962abc15c97c8cc9a40c8f13e070</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002726</data>
      <data key="d13" />
    </edge>
    <edge source="Neural Network" target="Large Language Model (LLM)">
      <data key="d7">1.0</data>
      <data key="d8">LLMs use neural networks trained on large text datasets to perform tasks, with accuracy improving as data increases.</data>
      <data key="d9">model training,performance foundation</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009416</data>
      <data key="d13" />
    </edge>
    <edge source="Neural Network" target="Meteorological Elements Forecasting Method">
      <data key="d7">1.0</data>
      <data key="d8">Neural Networks serve as a fundamental computational model for implementing the Meteorological Elements Forecasting Method.</data>
      <data key="d9">core component,implementation</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010133</data>
      <data key="d13" />
    </edge>
    <edge source="计算机视觉" target="自动驾驶">
      <data key="d7">1.0</data>
      <data key="d8">计算机视觉技术使自动驾驶成为可能。</data>
      <data key="d9">application,enabling</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002943</data>
      <data key="d13" />
    </edge>
    <edge source="计算机视觉" target="智能医疗保健">
      <data key="d7">1.0</data>
      <data key="d8">计算机视觉技术应用于智能医疗保健领域。</data>
      <data key="d9">application,enabling</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002943</data>
      <data key="d13" />
    </edge>
    <edge source="计算机视觉" target="自助零售">
      <data key="d7">1.0</data>
      <data key="d8">计算机视觉技术应用于自助零售领域。</data>
      <data key="d9">application,enabling</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002944</data>
      <data key="d13" />
    </edge>
    <edge source="计算机视觉" target="面部解锁">
      <data key="d7">1.0</data>
      <data key="d8">面部解锁是计算机视觉在日常生活中的一个具体应用。</data>
      <data key="d9">application,daily use</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002944</data>
      <data key="d13" />
    </edge>
    <edge source="计算机视觉" target="自动修图">
      <data key="d7">1.0</data>
      <data key="d8">自动修图是计算机视觉在日常生活中的一个具体应用。</data>
      <data key="d9">application,daily use</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002945</data>
      <data key="d13" />
    </edge>
    <edge source="循环神经网络" target="深度学习系统">
      <data key="d7">1.0</data>
      <data key="d8">深度学习系统包含循环神经网络作为其主要类型之一。</data>
      <data key="d9">架构分类,类型包含</data>
      <data key="d10">chunk-c79065b95e8586e85c1d4a6dfcdb5d37</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002979</data>
      <data key="d13" />
    </edge>
    <edge source="循环神经网络" target="序列">
      <data key="d7">1.0</data>
      <data key="d8">循环神经网络用于对序列数据进行编码处理。</data>
      <data key="d9">encoding,processing</data>
      <data key="d10">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003415</data>
      <data key="d13" />
    </edge>
    <edge source="循环神经网络" target="时间序列数据">
      <data key="d7">1.0</data>
      <data key="d8">Recurrent Neural Networks (RNN) are applied to capture complex relationships within time series data.</data>
      <data key="d9">data processing,model application</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004955</data>
      <data key="d13" />
    </edge>
    <edge source="循环神经网络" target="高频交易">
      <data key="d7">1.0</data>
      <data key="d8">Recurrent Neural Networks (RNN) are applied in the field of high-frequency trading to process large volumes of micro-market data.</data>
      <data key="d9">data processing,model application</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004958</data>
      <data key="d13" />
    </edge>
    <edge source="卷积层" target="卷积核">
      <data key="d7">2.0</data>
      <data key="d8">卷积层使用卷积核与输入图像进行卷积操作。&lt;SEP&gt;卷积层使用卷积核进行运算，卷积核具有共享权重的特性，能大幅减少参数数量。</data>
      <data key="d9">operation tool,utilization,使用工具,参数共享</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478&lt;SEP&gt;chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003357</data>
      <data key="d13" />
    </edge>
    <edge source="卷积层" target="池化层">
      <data key="d7">1.0</data>
      <data key="d8">池化层通常跟在卷积层后面，用于进一步放大主要特征并降低数据维度。</data>
      <data key="d9">特征提取,网络结构</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003345</data>
      <data key="d13" />
    </edge>
    <edge source="卷积层" target="特征图">
      <data key="d7">1.0</data>
      <data key="d8">卷积层通过卷积运算生成特征图，作为提取到的特征的表示。</data>
      <data key="d9">特征表示,生成结果</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003358</data>
      <data key="d13" />
    </edge>
    <edge source="卷积层" target="深度卷积网络">
      <data key="d7">1.0</data>
      <data key="d8">通过层层堆叠卷积层可以构成深度卷积网络，以增强特征表达能力。</data>
      <data key="d9">堆叠,构成方式</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003359</data>
      <data key="d13" />
    </edge>
    <edge source="卷积层" target="二维图像">
      <data key="d7">1.0</data>
      <data key="d8">卷积层中的卷积运算(如使用3x3卷积核)常以二维图像为例进行特征提取。</data>
      <data key="d9">处理数据,应用对象</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003361</data>
      <data key="d13" />
    </edge>
    <edge source="推荐系统" target="工程师">
      <data key="d7">1.0</data>
      <data key="d8">An engineer, given sufficient user data, can manually provide a good personalized advertisement recommendation, setting a benchmark that machine learning aims to automate and scale.</data>
      <data key="d9">benchmark,manual capability</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005172</data>
      <data key="d13" />
    </edge>
    <edge source="池化层" target="下采样">
      <data key="d7">1.0</data>
      <data key="d8">池化层的作用是对数据进行下采样。</data>
      <data key="d9">data reduction,function</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002951</data>
      <data key="d13" />
    </edge>
    <edge source="池化层" target="过拟合">
      <data key="d7">1.0</data>
      <data key="d8">池化层通过降低数据维度和减少训练参数，有助于避免过拟合问题。</data>
      <data key="d9">模型泛化,正则化</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003347</data>
      <data key="d13" />
    </edge>
    <edge source="池化层" target="局部池化">
      <data key="d7">1.0</data>
      <data key="d8">池化层包含局部池化这种具体操作，通常使用2x2矩阵来减少数据维度。</data>
      <data key="d9">操作类型,维度缩减</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003348</data>
      <data key="d13" />
    </edge>
    <edge source="池化层" target="2x2矩阵">
      <data key="d7">1.0</data>
      <data key="d8">局部池化操作一般选择2x2的矩阵。</data>
      <data key="d9">操作参数,矩阵尺寸</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003349</data>
      <data key="d13" />
    </edge>
    <edge source="全连接层" target="过拟合">
      <data key="d7">1.0</data>
      <data key="d8">全连接层参数众多，层数一多就容易导致模型过拟合。</data>
      <data key="d9">导致问题,模型缺陷</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003356</data>
      <data key="d13" />
    </edge>
    <edge source="SSD" target="Object Detection">
      <data key="d7">1.0</data>
      <data key="d8">SSD is cited as an example of a one-stage model for object detection in remote sensing.</data>
      <data key="d9">model example,one-stage</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009864</data>
      <data key="d13" />
    </edge>
    <edge source="Faster R-CNN" target="Object Detection">
      <data key="d7">1.0</data>
      <data key="d8">Faster R-CNN is cited as an example of a two-stage model for object detection in remote sensing.</data>
      <data key="d9">model example,two-stage</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009848</data>
      <data key="d13" />
    </edge>
    <edge source="卷积操作" target="卷积核">
      <data key="d7">1.0</data>
      <data key="d8">卷积操作是使用卷积核对输入图像执行的运算。</data>
      <data key="d9">execution,tool usage</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002944</data>
      <data key="d13" />
    </edge>
    <edge source="卷积操作" target="输入图像">
      <data key="d7">1.0</data>
      <data key="d8">卷积操作的目标是处理输入图像。</data>
      <data key="d9">data processing,operation target</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002947</data>
      <data key="d13" />
    </edge>
    <edge source="天善智能" target="商业智能BI">
      <data key="d7">2.0</data>
      <data key="d8">The organization Tianshan Intelligence focuses on the field of Business Intelligence (BI).&lt;SEP&gt;Tianshan Intelligence is a vertical community focused on the field of Business Intelligence (BI).</data>
      <data key="d9">community focus,domain expertise,field,focuses on</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002934</data>
      <data key="d13" />
    </edge>
    <edge source="天善智能" target="人工智能AI">
      <data key="d7">1.0</data>
      <data key="d8">The organization Tianshan Intelligence focuses on the field of Artificial Intelligence (AI).</data>
      <data key="d9">field,focuses on</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002935</data>
      <data key="d13" />
    </edge>
    <edge source="天善智能" target="大数据分析">
      <data key="d7">2.0</data>
      <data key="d8">The organization Tianshan Intelligence focuses on the field of Big Data Analysis.&lt;SEP&gt;Tianshan Intelligence is a vertical community focused on the field of big data analysis.</data>
      <data key="d9">community focus,domain expertise,field,focuses on</data>
      <data key="d10">chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc&lt;SEP&gt;chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002935</data>
      <data key="d13" />
    </edge>
    <edge source="天善智能" target="数据挖掘">
      <data key="d7">1.0</data>
      <data key="d8">Tianshan Intelligence is a vertical community focused on the field of data mining.</data>
      <data key="d9">community focus,domain expertise</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002939</data>
      <data key="d13" />
    </edge>
    <edge source="天善智能" target="数据爱好者交流群">
      <data key="d7">1.0</data>
      <data key="d8">Tianshan Intelligence manages and invites people to join the Data Enthusiasts Exchange Group.</data>
      <data key="d9">community group,manages</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002940</data>
      <data key="d13" />
    </edge>
    <edge source="图像处理" target="深度学习技术">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning technology has achieved breakthroughs in the field of image processing.</data>
      <data key="d9">application,technological advancement</data>
      <data key="d10">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009450</data>
      <data key="d13" />
    </edge>
    <edge source="生物视觉系统" target="福岛邦彦">
      <data key="d7">1.0</data>
      <data key="d8">福岛邦彦受前人关于生物视觉系统研究的启发，提出了“神经认知模型”。</data>
      <data key="d9">理论来源,研究启发</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003349</data>
      <data key="d13" />
    </edge>
    <edge source="知网" target="CAJ文档">
      <data key="d7">1.0</data>
      <data key="d8">CNKI provides research papers in the CAJ document file format for download.</data>
      <data key="d9">platform provides,resource format</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002939</data>
      <data key="d13" />
    </edge>
    <edge source="PaddlePaddle" target="手写数字识别">
      <data key="d7">1.0</data>
      <data key="d8">The PaddlePaddle deep learning framework was used in a previous article to perform the task of handwritten digit recognition.</data>
      <data key="d9">framework application,task example</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002938</data>
      <data key="d13" />
    </edge>
    <edge source="手写数字识别" target="LeNet">
      <data key="d7">1.0</data>
      <data key="d8">LeNet被广泛应用于手写数字识别任务。</data>
      <data key="d9">任务类型,核心功能</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003351</data>
      <data key="d13" />
    </edge>
    <edge source="CAJ文档" target="CAJ工具">
      <data key="d7">1.0</data>
      <data key="d8">CAJ document files require the CAJ tool software application to be opened and read.</data>
      <data key="d9">file format,software dependency</data>
      <data key="d10">chunk-cb9ff55215bc8081de2f351af1fd25fe</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002939</data>
      <data key="d13" />
    </edge>
    <edge source="数据挖掘" target="数据分析">
      <data key="d7">1.0</data>
      <data key="d8">Data mining is a process closely related to data analysis, focused on discovering patterns in data.</data>
      <data key="d9">knowledge discovery,related process</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008607</data>
      <data key="d13" />
    </edge>
    <edge source="Python" target="象牙山李宝库">
      <data key="d7">1.0</data>
      <data key="d8">The user distinguished using Python for basic data scraping and analysis from more advanced machine learning tasks.</data>
      <data key="d9">基础任务,工具使用</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005192</data>
      <data key="d13" />
    </edge>
    <edge source="Python" target="Natural Language Toolkit">
      <data key="d7">1.0</data>
      <data key="d8">The Natural Language Toolkit (NLTK) is written in the Python programming language.</data>
      <data key="d9">programming language,software development</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007462</data>
      <data key="d13" />
    </edge>
    <edge source="卷积核" target="二维离散卷积">
      <data key="d7">1.0</data>
      <data key="d8">卷积核通过二维离散卷积操作来实现特征提取。</data>
      <data key="d9">执行操作,数学基础</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003360</data>
      <data key="d13" />
    </edge>
    <edge source="卷积核" target="空间平移不变性">
      <data key="d7">1.0</data>
      <data key="d8">卷积核具备空间平移不变的特性，使其能识别图像中不同位置的目标。</data>
      <data key="d9">具备特性,功能优势</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003360</data>
      <data key="d13" />
    </edge>
    <edge source="感知器" target="神经网络单元">
      <data key="d7">1.0</data>
      <data key="d8">神经网络单元的数学模型被称为感知器。</data>
      <data key="d9">abstraction,model</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002942</data>
      <data key="d13" />
    </edge>
    <edge source="感知器" target="外部刺激">
      <data key="d7">1.0</data>
      <data key="d8">感知器的输入类比于神经末梢感受的外部刺激。</data>
      <data key="d9">analogy,input source</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002948</data>
      <data key="d13" />
    </edge>
    <edge source="感知器" target="电信号">
      <data key="d7">1.0</data>
      <data key="d8">感知器的输出类比于生物神经元产生的电信号。</data>
      <data key="d9">analogy,output form</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002956</data>
      <data key="d13" />
    </edge>
    <edge source="二维卷积层" target="空间维度">
      <data key="d7">1.0</data>
      <data key="d8">二维卷积层具有高和宽两个空间维度。</data>
      <data key="d9">dimensional characteristic,property</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002949</data>
      <data key="d13" />
    </edge>
    <edge source="连接" target="突触">
      <data key="d7">1.0</data>
      <data key="d8">神经网络中的连接模仿了生物神经网络中的突触。</data>
      <data key="d9">analogy,biological model</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002948</data>
      <data key="d13" />
    </edge>
    <edge source="数学方程" target="文章">
      <data key="d7">1.0</data>
      <data key="d8">文章中包含了复杂的数学方程来解释卷积神经网络的原理。</data>
      <data key="d9">content inclusion,explanation tool</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002949</data>
      <data key="d13" />
    </edge>
    <edge source="数学方程" target="线性代数">
      <data key="d7">1.0</data>
      <data key="d8">理解文章中的数学方程需要线性代数知识。</data>
      <data key="d9">knowledge requirement,mathematical basis</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002950</data>
      <data key="d13" />
    </edge>
    <edge source="数学方程" target="微分">
      <data key="d7">1.0</data>
      <data key="d8">理解文章中的数学方程需要微分知识。</data>
      <data key="d9">knowledge requirement,mathematical basis</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002952</data>
      <data key="d13" />
    </edge>
    <edge source="架构设计" target="讲义">
      <data key="d7">1.0</data>
      <data key="d8">讲义内容涵盖了卷积神经网络的架构设计。</data>
      <data key="d9">knowledge coverage,topic</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002950</data>
      <data key="d13" />
    </edge>
    <edge source="应用方法" target="讲义">
      <data key="d7">1.0</data>
      <data key="d8">讲义内容涵盖了卷积神经网络的应用方法。</data>
      <data key="d9">knowledge coverage,topic</data>
      <data key="d10">chunk-61775650edeed94f49f7144412443478</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002951</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Computer Vision">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks have achieved great success in the field of computer vision.</data>
      <data key="d9">application,success</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002951</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Image">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are designed to process image data.</data>
      <data key="d9">input,processing</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002952</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Traditional Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks address limitations of traditional neural networks, such as achieving translation invariance.</data>
      <data key="d9">comparison,improvement</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002953</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Translation Invariance">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are designed to achieve translation invariance, allowing them to recognize objects regardless of position.</data>
      <data key="d9">achievement,property</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002953</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Convolution Operation">
      <data key="d7">1.0</data>
      <data key="d8">The convolution operation is the fundamental and namesake operation of Convolutional Neural Networks.</data>
      <data key="d9">core operation,namesake</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002953</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Input Layer">
      <data key="d7">1.0</data>
      <data key="d8">The input layer is the first component of a Convolutional Neural Network, receiving the raw image data.</data>
      <data key="d9">component,structure</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002954</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Convolution Layer">
      <data key="d7">1.0</data>
      <data key="d8">Convolution layers are core components of a Convolutional Neural Network where convolution operations occur.</data>
      <data key="d9">component,structure</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002961</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Deep Learning">
      <data key="d7">3.0</data>
      <data key="d8">Convolutional Neural Network is a model within the deep learning subfield of artificial intelligence.&lt;SEP&gt;Deep Learning encompasses architectures like Convolutional Neural Network, which are used for feature extraction.&lt;SEP&gt;Convolutional Neural Network is a type of architecture within deep learning used for the task.</data>
      <data key="d9">categorization,feature extraction,foundational technology,model architecture,subfield</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794&lt;SEP&gt;chunk-fe2c7c19ec682c0e709a26a55e0b8005&lt;SEP&gt;chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009680</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Biological Visual System">
      <data key="d7">1.0</data>
      <data key="d8">The design of Convolutional Neural Networks is inspired by biological visual systems.</data>
      <data key="d9">inspiration,origin</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002957</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network" target="Human Visual Processing">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks aim to simulate the way human visual processing works.</data>
      <data key="d9">goal,simulation</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002958</data>
      <data key="d13" />
    </edge>
    <edge source="Computer Vision" target="Object Detection">
      <data key="d7">1.0</data>
      <data key="d8">Object detection is a specific task within the field of computer vision.</data>
      <data key="d9">application,task</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002957</data>
      <data key="d13" />
    </edge>
    <edge source="Computer Vision" target="Image Generation">
      <data key="d7">1.0</data>
      <data key="d8">Image generation is a specific task within the field of computer vision.</data>
      <data key="d9">application,task</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002958</data>
      <data key="d13" />
    </edge>
    <edge source="Computer Vision" target="Convolutional Neural Network (CNN)">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional neural networks are a powerful driving force for performing image recognition and computer vision tasks.</data>
      <data key="d9">application field,enabling technology</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003184</data>
      <data key="d13" />
    </edge>
    <edge source="Computer Vision" target="Nankai Statistics">
      <data key="d7">1.0</data>
      <data key="d8">The research directions of Nankai Statistics cover the application of Computer Vision in biomedicine.</data>
      <data key="d9">application,research direction</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004246</data>
      <data key="d13" />
    </edge>
    <edge source="Image" target="RGB Color Model">
      <data key="d7">1.0</data>
      <data key="d8">Images are commonly represented using the RGB color model, which consists of three channels.</data>
      <data key="d9">composition,representation</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002951</data>
      <data key="d13" />
    </edge>
    <edge source="Image" target="Pixel">
      <data key="d7">1.0</data>
      <data key="d8">An image is composed of a grid of pixels, each with an intensity value.</data>
      <data key="d9">composition,unit</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002955</data>
      <data key="d13" />
    </edge>
    <edge source="Image" target="Tensor">
      <data key="d7">1.0</data>
      <data key="d8">An image with multiple color channels can be understood and represented as a three-dimensional tensor.</data>
      <data key="d9">representation,structure</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002956</data>
      <data key="d13" />
    </edge>
    <edge source="Image" target="Width">
      <data key="d7">1.0</data>
      <data key="d8">The width is one of the dimensions used to describe the size of an image.</data>
      <data key="d9">description,dimension</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002957</data>
      <data key="d13" />
    </edge>
    <edge source="Image" target="Height">
      <data key="d7">1.0</data>
      <data key="d8">The height is one of the dimensions used to describe the size of an image.</data>
      <data key="d9">description,dimension</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002958</data>
      <data key="d13" />
    </edge>
    <edge source="Image" target="Depth">
      <data key="d7">1.0</data>
      <data key="d8">The depth (number of channels) is one of the dimensions used to describe an image's structure.</data>
      <data key="d9">description,dimension</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002966</data>
      <data key="d13" />
    </edge>
    <edge source="RGB Color Model" target="Channel">
      <data key="d7">1.0</data>
      <data key="d8">In the RGB color model, an image is composed of three channels: red, green, and blue.</data>
      <data key="d9">component,composition</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002952</data>
      <data key="d13" />
    </edge>
    <edge source="Convolution Operation" target="Data Window">
      <data key="d7">1.0</data>
      <data key="d8">The convolution operation utilizes a movable data window to scan across the input image.</data>
      <data key="d9">tool,utilization</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002954</data>
      <data key="d13" />
    </edge>
    <edge source="Convolution Operation" target="Filter">
      <data key="d7">1.0</data>
      <data key="d8">The convolution operation uses a filter (convolution kernel) containing fixed weights to extract features.</data>
      <data key="d9">tool,utilization</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002961</data>
      <data key="d13" />
    </edge>
    <edge source="Convolution Operation" target="Zero-Padding">
      <data key="d7">1.0</data>
      <data key="d8">Zero-padding is a technique applied to input images to facilitate the convolution operation, especially with specific stride values.</data>
      <data key="d9">application,technique</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002954</data>
      <data key="d13" />
    </edge>
    <edge source="Convolution Operation" target="Stride">
      <data key="d7">1.0</data>
      <data key="d8">The stride parameter controls the step size of the convolution kernel's movement during the convolution operation.</data>
      <data key="d9">control,parameter</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002956</data>
      <data key="d13" />
    </edge>
    <edge source="Convolution Operation" target="Feature Map">
      <data key="d7">1.0</data>
      <data key="d8">Applying a convolution operation to an input image produces an output called a feature map.</data>
      <data key="d9">output,production</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002957</data>
      <data key="d13" />
    </edge>
    <edge source="Convolution Operation" target="Local Feature">
      <data key="d7">1.0</data>
      <data key="d8">The primary purpose of the convolution operation is to extract local features from an image.</data>
      <data key="d9">extraction,purpose</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002958</data>
      <data key="d13" />
    </edge>
    <edge source="Convolution Operation" target="Output Feature Map">
      <data key="d7">1.0</data>
      <data key="d8">Performing a convolution operation on an input image produces an output feature map.</data>
      <data key="d9">production,result</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002966</data>
      <data key="d13" />
    </edge>
    <edge source="Filter" target="Convolution Kernel">
      <data key="d7">1.0</data>
      <data key="d8">Filter and Convolution Kernel are synonymous terms for the same artifact used in convolution.</data>
      <data key="d9">equivalence,synonym</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002952</data>
      <data key="d13" />
    </edge>
    <edge source="Zero-Padding" target="Padding">
      <data key="d7">1.0</data>
      <data key="d8">Zero-padding is a specific type of padding technique where zeros are added.</data>
      <data key="d9">specific instance,type</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002959</data>
      <data key="d13" />
    </edge>
    <edge source="Feature Map" target="Convolutional Layer">
      <data key="d7">1.0</data>
      <data key="d8">The application of a filter to input data during convolution produces a feature map, which represents the extracted features.</data>
      <data key="d9">feature extraction,output</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003183</data>
      <data key="d13" />
    </edge>
    <edge source="Feature Map" target="单层CNN">
      <data key="d7">1.0</data>
      <data key="d8">The single-layer CNN generates feature maps by applying several types of convolution operations.</data>
      <data key="d9">network operation,output generation</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007110</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Artificial Intelligence">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning is a subfield within the broader domain of artificial intelligence.</data>
      <data key="d9">categorization,subfield</data>
      <data key="d10">chunk-9654c79f59367cfc9f7483a23aec5794</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769002956</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Convolutional Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are a representative example of deep learning.</data>
      <data key="d9">example,representation</data>
      <data key="d10">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003014</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Synapse">
      <data key="d7">1.0</data>
      <data key="d8">The modifiable strength of biological synapses inspired the adjustable connection weights fundamental to deep learning algorithms.</data>
      <data key="d9">biological analogy,inspiration</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003887</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Geoffrey Hinton">
      <data key="d7">2.0</data>
      <data key="d8">Geoffrey Hinton co-authored the introductory review article on deep learning.&lt;SEP&gt;Geoffrey Hinton made prominent contributions that helped drive the deep learning revolution.</data>
      <data key="d9">advancement,authorship,contribution,introduction</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003889</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Deep Learning Revolution">
      <data key="d7">1.0</data>
      <data key="d8">The advancement of deep learning methods has led to a significant revolution in technology.</data>
      <data key="d9">cause,effect</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003891</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Network Search">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning technology is applied in network search systems.</data>
      <data key="d9">application,utilization</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Website Filtering">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning technology is applied in website filtering systems.</data>
      <data key="d9">application,utilization</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Advertising Push">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning technology is applied in advertising push systems.</data>
      <data key="d9">application,utilization</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Image Recognition">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning technology is applied in image recognition systems.</data>
      <data key="d9">application,utilization</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003895</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Language Translation">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning technology is applied in language translation systems.</data>
      <data key="d9">application,utilization</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003896</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Yann LeCun">
      <data key="d7">1.0</data>
      <data key="d8">Yann LeCun co-authored the introductory review article on deep learning.</data>
      <data key="d9">authorship,introduction</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Yoshua Bengio">
      <data key="d7">1.0</data>
      <data key="d8">Yoshua Bengio co-authored the introductory review article on deep learning.</data>
      <data key="d9">authorship,introduction</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Nature">
      <data key="d7">1.0</data>
      <data key="d8">The journal Nature published the 2015 review article titled "Deep learning".</data>
      <data key="d9">dissemination,publication</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="AlphaFold">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold's technical core integrates deep learning as a key method.</data>
      <data key="d9">core component,technology integration</data>
      <data key="d10">chunk-5899806c994fc2f391826abc901a8669</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004449</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Multi-Modal Learning">
      <data key="d7">1.0</data>
      <data key="d8">Multi-modal learning represents a future direction for deep learning in quantitative trading, integrating diverse data types.</data>
      <data key="d9">data integration,future direction</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004969</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Quantitative Trading">
      <data key="d7">1.0</data>
      <data key="d8">Deep Learning is actively reshaping the quantitative trading landscape by providing unprecedented analytical and decision-making tools.</data>
      <data key="d9">analytical tools,technological transformation</data>
      <data key="d10">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004972</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Electronic Health Records">
      <data key="d7">1.0</data>
      <data key="d8">Deep Learning methods are being used to analyze Electronic Health Records for building disease risk models.</data>
      <data key="d9">data analysis,technological application</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005372</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Recurrent Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Deep Learning encompasses architectures like Recurrent Neural Network, which are used for analyzing temporal sequences.</data>
      <data key="d9">model architecture,temporal analysis</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005389</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Interpretability">
      <data key="d7">1.0</data>
      <data key="d8">Deep Learning methods transform features to improve classification but simultaneously reduce the Interpretability of the model.</data>
      <data key="d9">model characteristic,trade-off</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005390</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Fraud Detection">
      <data key="d7">1.0</data>
      <data key="d8">There is a transition from using machine learning to using deep learning for fraud detection, which has a significant business impact.</data>
      <data key="d9">application,methodology,transition</data>
      <data key="d10">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005840</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Deep Learning Models">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models are the specific implementation of the deep learning method.</data>
      <data key="d9">implementation,technology</data>
      <data key="d10">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005838</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="CRF">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models can overcome the drawback of traditional CRF models, which struggle to capture long-range contextual dependencies that are crucial for certain semantic understanding tasks.</data>
      <data key="d9">comparison,contextual modeling</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007072</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Plaintiff Lawyer">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models are highlighted as a solution to overcome traditional models' limitations in capturing long-range context, which is necessary for correctly identifying entities like "Plaintiff Lawyer" based on distant clues.</data>
      <data key="d9">addresses challenge of,long-context understanding</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007098</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Global Features">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning is the method used to extract global features for satellite image tasks.</data>
      <data key="d9">feature extraction,model application</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009664</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Evaluation System">
      <data key="d7">1.0</data>
      <data key="d8">The evaluation system is established to assess the feasibility and performance of deep learning for the specified tasks.</data>
      <data key="d9">feasibility study,performance assessment</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009666</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="DenseNet">
      <data key="d7">2.0</data>
      <data key="d8">DenseNet is a specific deep learning model evaluated within the study.&lt;SEP&gt;DenseNet is part of the discussed evolution of deep learning model structures for optimization.</data>
      <data key="d9">model evolution,model implementation,optimization,performance benchmark</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8&lt;SEP&gt;chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009869</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="ResNet-18">
      <data key="d7">1.0</data>
      <data key="d8">ResNet-18 is a specific deep learning model evaluated within the study.</data>
      <data key="d9">model implementation,performance benchmark</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009672</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="VggNet">
      <data key="d7">1.0</data>
      <data key="d8">VggNet is a specific deep learning model evaluated within the study.</data>
      <data key="d9">model implementation,performance benchmark</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009677</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Lv Xiangyang">
      <data key="d7">1.0</data>
      <data key="d8">Lv Xiangyang authored a blog post discussing the application of deep learning in remote sensing.</data>
      <data key="d9">application discussion,authoring</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009843</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Remote Sensing Image">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning methods are applied to process and analyze remote sensing images for various applications.</data>
      <data key="d9">application,processing</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009853</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Object Detection">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning provides the methodology for performing object detection tasks on remote sensing images.</data>
      <data key="d9">methodology,task</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009848</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Image Segmentation">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning provides the methodology for performing image segmentation tasks on remote sensing images.</data>
      <data key="d9">methodology,task</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009850</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="AlexNet">
      <data key="d7">1.0</data>
      <data key="d8">AlexNet is part of the discussed evolution of deep learning model structures for optimization.</data>
      <data key="d9">model evolution,optimization</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009853</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="VGG">
      <data key="d7">1.0</data>
      <data key="d8">VGG is part of the discussed evolution of deep learning model structures for optimization.</data>
      <data key="d9">model evolution,optimization</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009864</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="GoogleNet">
      <data key="d7">1.0</data>
      <data key="d8">GoogleNet is part of the discussed evolution of deep learning model structures for optimization.</data>
      <data key="d9">model evolution,optimization</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009859</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="ResNet">
      <data key="d7">1.0</data>
      <data key="d8">ResNet is part of the discussed evolution of deep learning model structures for optimization.</data>
      <data key="d9">model evolution,optimization</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009864</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Meteorological Elements Forecasting Method">
      <data key="d7">1.0</data>
      <data key="d8">The Meteorological Elements Forecasting Method is based on the concept and techniques of Deep Learning.</data>
      <data key="d9">application,methodology</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010127</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Weather Forecasting">
      <data key="d7">1.0</data>
      <data key="d8">Weather forecasting utilizes deep learning techniques for enhanced prediction models.</data>
      <data key="d9">methodology,prediction</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010288</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="From Deep Learning to Rational Machines">
      <data key="d7">1.0</data>
      <data key="d8">The book "From Deep Learning to Rational Machines" introduces and discusses the philosophical implications of deep learning.</data>
      <data key="d9">discussion,philosophical analysis</data>
      <data key="d10">chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010781</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning" target="Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning fundamentally involves and is changed by the development of neural networks.</data>
      <data key="d9">core component,technology</data>
      <data key="d10">chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010782</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Intelligence" target="McCulloch-Pitts Network">
      <data key="d7">1.0</data>
      <data key="d8">The abstract model of the McCulloch-Pitts network provided a foundational concept for the field of Artificial Intelligence.</data>
      <data key="d9">foundation,influence</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003888</data>
      <data key="d13" />
    </edge>
    <edge source="Artificial Intelligence" target="Traditional Fraud Detection Systems">
      <data key="d7">1.0</data>
      <data key="d8">Current traditional fraud detection systems rely on Artificial Intelligence as a foundational technology.</data>
      <data key="d9">method,technology reliance</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006170</data>
      <data key="d13" />
    </edge>
    <edge source="Object Detection" target="Convolutional Neural Network (CNN)">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are a class of models specifically designed for the task of object detection.</data>
      <data key="d9">design purpose,primary function</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003189</data>
      <data key="d13" />
    </edge>
    <edge source="Object Detection" target="YOLO">
      <data key="d7">1.0</data>
      <data key="d8">YOLO is cited as an example of a one-stage model series for object detection in remote sensing.</data>
      <data key="d9">model example,one-stage</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009853</data>
      <data key="d13" />
    </edge>
    <edge source="Object Detection" target="mAP">
      <data key="d7">1.0</data>
      <data key="d8">mAP is a key metric used to evaluate the performance of object detection models.</data>
      <data key="d9">evaluation metric</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009850</data>
      <data key="d13" />
    </edge>
    <edge source="Object Detection" target="R-CNN">
      <data key="d7">1.0</data>
      <data key="d8">R-CNN is part of the evolution of two-stage object detection models discussed.</data>
      <data key="d9">model evolution,two-stage</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009864</data>
      <data key="d13" />
    </edge>
    <edge source="Object Detection" target="Fast R-CNN">
      <data key="d7">1.0</data>
      <data key="d8">Fast R-CNN is part of the evolution of two-stage object detection models discussed.</data>
      <data key="d9">model evolution,two-stage</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009859</data>
      <data key="d13" />
    </edge>
    <edge source="文章" target="GPT-4">
      <data key="d7">1.0</data>
      <data key="d8">GPT-4可以根据提示生成文章。</data>
      <data key="d9">内容,生成</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007535</data>
      <data key="d13" />
    </edge>
    <edge source="前馈神经网络" target="自编码器">
      <data key="d7">1.0</data>
      <data key="d8">自编码器是前馈神经网络的一种。</data>
      <data key="d9">技术分类,模型架构</data>
      <data key="d10">chunk-0c8c61555719c99f2248173e3fd5ae4f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003450</data>
      <data key="d13" />
    </edge>
    <edge source="前馈神经网络" target="多层感知机">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机是一种前馈神经网络。</data>
      <data key="d9">classification,type</data>
      <data key="d10">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003564</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Networks" target="Convolutional Computation">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks incorporate convolutional computation as a core mathematical operation.</data>
      <data key="d9">component,mathematical operation</data>
      <data key="d10">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003013</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Networks" target="Feedforward Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are a specific class of Feedforward Neural Networks.</data>
      <data key="d9">architecture,subclass</data>
      <data key="d10">chunk-c79b805e7da972f5a80b0f9eb1144d75</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003013</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Convolutional Layer">
      <data key="d7">1.0</data>
      <data key="d8">The convolutional layer is the core building block of a CNN, responsible for performing most of the computational work through convolution operations.</data>
      <data key="d9">computational block,core component</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003181</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Pooling Layer">
      <data key="d7">1.0</data>
      <data key="d8">Pooling layers are used in CNNs to reduce complexity, improve efficiency, and limit overfitting, despite some information loss.</data>
      <data key="d9">complexity reduction,efficiency</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003181</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Fully Connected Layer">
      <data key="d7">1.0</data>
      <data key="d8">The fully connected layer is the final layer in the architecture of a convolutional neural network.</data>
      <data key="d9">architecture,final layer</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003182</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Feature Hierarchy">
      <data key="d7">1.0</data>
      <data key="d8">CNNs form a feature hierarchy where lower-level patterns (simple features) combine into higher-level patterns (complex objects) as data progresses through the network.</data>
      <data key="d9">hierarchical structure,pattern recognition</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003183</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="LeNet-5">
      <data key="d7">1.0</data>
      <data key="d8">LeNet-5 is a classic and widely recognized architecture of a convolutional neural network.</data>
      <data key="d9">architecture example,classic model</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003184</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Medical Imaging Diagnosis">
      <data key="d7">1.0</data>
      <data key="d8">CNNs are widely applied in medical imaging diagnosis, with deployment support available on platforms like IBM's.</data>
      <data key="d9">application,deployment</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003185</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Autonomous Driving Perception">
      <data key="d7">1.0</data>
      <data key="d8">CNNs are widely applied in autonomous driving perception, with deployment support available on platforms like IBM's.</data>
      <data key="d9">application,deployment</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003185</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Intelligent Security">
      <data key="d7">1.0</data>
      <data key="d8">CNNs are widely applied in intelligent security, with deployment support available on platforms like IBM's.</data>
      <data key="d9">application,deployment</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003185</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Traditional Feedforward Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Compared to traditional feedforward neural networks, CNNs have advantages like parameter sharing and local receptive fields, making them more efficient for structured data.</data>
      <data key="d9">comparison,efficiency advantage</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003186</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Parameter Sharing">
      <data key="d7">1.0</data>
      <data key="d8">CNNs utilize parameter sharing as a key mechanism to increase efficiency and reduce the number of parameters compared to traditional networks.</data>
      <data key="d9">efficiency mechanism,model optimization</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003187</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Local Receptive Field">
      <data key="d7">1.0</data>
      <data key="d8">CNNs possess local receptive field capabilities, allowing them to efficiently process local spatial patterns in structured data like images.</data>
      <data key="d9">feature extraction,spatial processing</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003188</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Image Recognition">
      <data key="d7">1.0</data>
      <data key="d8">Convolutional Neural Networks are a class of models specifically designed for the task of image recognition.</data>
      <data key="d9">design purpose,primary function</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003189</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Neural Network (CNN)" target="Structured Data">
      <data key="d7">1.0</data>
      <data key="d8">CNNs are more efficient than traditional feedforward neural networks when processing structured data such as images and audio.</data>
      <data key="d9">data processing,efficiency</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003190</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Layer" target="Rectified Linear Unit (ReLU)">
      <data key="d7">1.0</data>
      <data key="d8">After each convolution operation, a ReLU transformation is applied to the feature map to introduce non-linearity into the CNN model.</data>
      <data key="d9">non-linearity,transformation</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003181</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Layer" target="Kernel (Filter)">
      <data key="d7">1.0</data>
      <data key="d8">The convolutional layer uses a kernel or filter as a feature detector that moves across the image's receptive fields to perform convolution.</data>
      <data key="d9">convolution,feature detection</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003182</data>
      <data key="d13" />
    </edge>
    <edge source="Convolutional Layer" target="RGB">
      <data key="d7">1.0</data>
      <data key="d8">When processing a color image, the input to a convolutional layer is a three-dimensional matrix where the depth corresponds to the RGB color channels.</data>
      <data key="d9">color channels,input data</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003185</data>
      <data key="d13" />
    </edge>
    <edge source="Pooling Layer" target="Overfitting">
      <data key="d7">1.0</data>
      <data key="d8">Pooling layers in CNNs help limit the risk of overfitting, a common problem in machine learning models.</data>
      <data key="d9">regularization,risk mitigation</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003187</data>
      <data key="d13" />
    </edge>
    <edge source="Rectified Linear Unit (ReLU)" target="Non-Linearity">
      <data key="d7">1.0</data>
      <data key="d8">The ReLU transformation is applied to introduce non-linearity into the CNN model, enabling it to learn complex patterns.</data>
      <data key="d9">activation function,model capability</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003186</data>
      <data key="d13" />
    </edge>
    <edge source="Kernel (Filter)" target="Receptive Field">
      <data key="d7">1.0</data>
      <data key="d8">A kernel or filter in a CNN moves across and examines features within the receptive fields of the input image.</data>
      <data key="d9">feature detection area,spatial scope</data>
      <data key="d10">chunk-2d11b22a41860af6077284a29530e1e0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003186</data>
      <data key="d13" />
    </edge>
    <edge source="AlexNet" target="层叠的卷积层">
      <data key="d7">1.0</data>
      <data key="d8">AlexNet使用了层叠的卷积层来获取特征。</data>
      <data key="d9">特征提取,网络结构</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003351</data>
      <data key="d13" />
    </edge>
    <edge source="AlexNet" target="超高识别率">
      <data key="d7">1.0</data>
      <data key="d8">AlexNet在ImageNet竞赛中取得了超高的识别率。</data>
      <data key="d9">性能表现,竞赛结果</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003351</data>
      <data key="d13" />
    </edge>
    <edge source="VGGNet" target="牛津大学">
      <data key="d7">1.0</data>
      <data key="d8">VGGNet模型是由牛津大学提出的。</data>
      <data key="d9">机构研发,模型提出</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003351</data>
      <data key="d13" />
    </edge>
    <edge source="ResNet" target="网络模型退化问题">
      <data key="d7">1.0</data>
      <data key="d8">ResNet解决了网络模型的退化问题。</data>
      <data key="d9">核心贡献,问题解决</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003352</data>
      <data key="d13" />
    </edge>
    <edge source="Overfitting" target="Cross-Validation">
      <data key="d7">1.0</data>
      <data key="d8">Cross-validation is a crucial method to mitigate the risk of overfitting in deep learning models.</data>
      <data key="d9">mitigation,validation technique</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004964</data>
      <data key="d13" />
    </edge>
    <edge source="Overfitting" target="Out-Of-Sample Testing">
      <data key="d7">1.0</data>
      <data key="d8">Out-of-sample testing is essential for validating model performance and preventing overfitting.</data>
      <data key="d9">mitigation,validation technique</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004965</data>
      <data key="d13" />
    </edge>
    <edge source="Overfitting" target="Deep Learning Model">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models are vulnerable to overfitting, especially in the non-stationary financial market environment.</data>
      <data key="d9">model risk,vulnerability</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004966</data>
      <data key="d13" />
    </edge>
    <edge source="Overfitting" target="Multiple Backtesting">
      <data key="d7">1.0</data>
      <data key="d8">Multiple backtesting is a rigorous process to validate strategy robustness and avoid overfitting.</data>
      <data key="d9">mitigation,validation technique</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004966</data>
      <data key="d13" />
    </edge>
    <edge source="AI模型" target="数据集">
      <data key="d7">1.0</data>
      <data key="d8">Preparing a dataset is a step in selecting and training an AI model.</data>
      <data key="d9">data dependency,model training</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003192</data>
      <data key="d13" />
    </edge>
    <edge source="AI模型" target="性能">
      <data key="d7">1.0</data>
      <data key="d8">Performance is a key factor to consider when choosing an AI model.</data>
      <data key="d9">evaluation criteria,model attribute</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003193</data>
      <data key="d13" />
    </edge>
    <edge source="AI模型" target="成本">
      <data key="d7">1.0</data>
      <data key="d8">Cost is a key factor to consider when choosing an AI model.</data>
      <data key="d9">evaluation criteria,model attribute</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003194</data>
      <data key="d13" />
    </edge>
    <edge source="AI模型" target="风险">
      <data key="d7">1.0</data>
      <data key="d8">Risk is a key factor to consider when choosing an AI model.</data>
      <data key="d9">evaluation criteria,model attribute</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003202</data>
      <data key="d13" />
    </edge>
    <edge source="AI模型" target="部署需求">
      <data key="d7">1.0</data>
      <data key="d8">Deployment requirements are a key factor to consider when choosing an AI model.</data>
      <data key="d9">evaluation criteria,model attribute</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003195</data>
      <data key="d13" />
    </edge>
    <edge source="AI模型" target="利益相关者要求">
      <data key="d7">1.0</data>
      <data key="d8">Stakeholder requirements are a key factor to consider when choosing an AI model.</data>
      <data key="d9">evaluation criteria,model attribute</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003199</data>
      <data key="d13" />
    </edge>
    <edge source="AI模型" target="数据">
      <data key="d7">1.0</data>
      <data key="d8">AI模型的发展离不开数据的支持，通过对大量数据的分析和学习，AI模型能够不断提升性能。</data>
      <data key="d9">依赖关系,性能提升</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008597</data>
      <data key="d13" />
    </edge>
    <edge source="语言" target="大语言模型">
      <data key="d7">1.0</data>
      <data key="d8">语言在大语言模型中是核心，是模型的学习对象和推理过程中生成与理解的基础。</data>
      <data key="d9">学习与生成基础,核心对象</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008600</data>
      <data key="d13" />
    </edge>
    <edge source="报告2024年AI实际应用" target="AI计划">
      <data key="d7">1.0</data>
      <data key="d8">The report is based on a survey investigating organizations' AI plans to discover effective and ineffective approaches.</data>
      <data key="d9">insight provision,research publication</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003194</data>
      <data key="d13" />
    </edge>
    <edge source="指南面向CEO的生成式AI指南" target="投资">
      <data key="d7">1.0</data>
      <data key="d8">The guide addresses the investment required for generative AI.</data>
      <data key="d9">guidance topic,resource allocation</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003196</data>
      <data key="d13" />
    </edge>
    <edge source="指南面向CEO的生成式AI指南" target="风险">
      <data key="d7">1.0</data>
      <data key="d8">The guide addresses the risks associated with generative AI.</data>
      <data key="d9">guidance topic,risk management</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003198</data>
      <data key="d13" />
    </edge>
    <edge source="性能" target="最佳模型">
      <data key="d7">1.0</data>
      <data key="d8">Balancing performance with other factors helps determine the best model.</data>
      <data key="d9">balancing factor,decision criteria</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003194</data>
      <data key="d13" />
    </edge>
    <edge source="成本" target="最佳模型">
      <data key="d7">1.0</data>
      <data key="d8">Balancing cost with other factors helps determine the best model.</data>
      <data key="d9">balancing factor,decision criteria</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003202</data>
      <data key="d13" />
    </edge>
    <edge source="风险" target="最佳模型">
      <data key="d7">1.0</data>
      <data key="d8">Balancing risk with other factors helps determine the best model.</data>
      <data key="d9">balancing factor,decision criteria</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003194</data>
      <data key="d13" />
    </edge>
    <edge source="部署需求" target="最佳模型">
      <data key="d7">1.0</data>
      <data key="d8">Balancing deployment requirements with other factors helps determine the best model.</data>
      <data key="d9">balancing factor,decision criteria</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003196</data>
      <data key="d13" />
    </edge>
    <edge source="利益相关者要求" target="最佳模型">
      <data key="d7">1.0</data>
      <data key="d8">Balancing stakeholder requirements with other factors helps determine the best model.</data>
      <data key="d9">balancing factor,decision criteria</data>
      <data key="d10">chunk-6ea76c6cb7ba7180cc09124704c29e42</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003198</data>
      <data key="d13" />
    </edge>
    <edge source="神经认知模型" target="手写字符识别">
      <data key="d7">1.0</data>
      <data key="d8">福岛邦彦提出的“神经认知模型”用于处理手写字符识别问题。</data>
      <data key="d9">应用任务,问题解决</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003350</data>
      <data key="d13" />
    </edge>
    <edge source="Yann LeCun" target="神经科学">
      <data key="d7">1.0</data>
      <data key="d8">Yann LeCun drew inspiration from the principles of the nervous system, specifically the brain's visual system, to invent CNNs.</data>
      <data key="d9">application,inspiration</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003895</data>
      <data key="d13" />
    </edge>
    <edge source="Yann LeCun" target="Geoffrey Hinton">
      <data key="d7">1.0</data>
      <data key="d8">Both Geoffrey Hinton and Yann LeCun are foundational figures in deep learning, and their perseverance is seen as a testament to the rewards of坚守(perseverance).</data>
      <data key="d9">perseverance,shared foundation</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003896</data>
      <data key="d13" />
    </edge>
    <edge source="LeNet" target="美国邮政系统">
      <data key="d7">1.0</data>
      <data key="d8">LeNet算法被广泛应用于美国邮政系统的手写数字和字符识别。</data>
      <data key="d9">实际部署,算法应用</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003350</data>
      <data key="d13" />
    </edge>
    <edge source="Hinton" target="Talking Nets">
      <data key="d7">1.0</data>
      <data key="d8">An interview with Hinton is featured in the book "Talking Nets".</data>
      <data key="d9">feature,interview</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003895</data>
      <data key="d13" />
    </edge>
    <edge source="Hinton" target="Christian Ideology">
      <data key="d7">1.0</data>
      <data key="d8">Hinton expressed a critical view of Christian ideology, considering it "complete rubbish".</data>
      <data key="d9">belief,criticism</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003895</data>
      <data key="d13" />
    </edge>
    <edge source="GoogleNet" target="1x1卷积">
      <data key="d7">1.0</data>
      <data key="d8">GoogleNet使用1x1卷积进行降维以减少参数量。</data>
      <data key="d9">参数优化,技术手段</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003352</data>
      <data key="d13" />
    </edge>
    <edge source="MNIST模型" target="交叉熵">
      <data key="d7">1.0</data>
      <data key="d8">在MNIST模型训练中，采用交叉熵作为损失函数。</data>
      <data key="d9">损失函数,模型训练</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003352</data>
      <data key="d13" />
    </edge>
    <edge source="MNIST模型" target="SGD">
      <data key="d7">1.0</data>
      <data key="d8">在MNIST模型训练中，采用SGD作为优化器，学习率设为0.1。</data>
      <data key="d9">优化算法,参数更新</data>
      <data key="d10">chunk-0a618e37c4fa120a22ba1b02c9ff4878</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003354</data>
      <data key="d13" />
    </edge>
    <edge source="特征图" target="感受野">
      <data key="d7">1.0</data>
      <data key="d8">特征图上每个点的值由其感受野内的点决定，感受野定义了该点依赖的上一层数据的范围。</data>
      <data key="d9">依赖范围,属性定义</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003362</data>
      <data key="d13" />
    </edge>
    <edge source="深度卷积网络" target="图像分类">
      <data key="d7">1.0</data>
      <data key="d8">深度卷积网络可用于图像分类任务，通过逐层学习更复杂的特征。</data>
      <data key="d9">任务示例,应用领域</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003360</data>
      <data key="d13" />
    </edge>
    <edge source="计算机学者" target="生理学家">
      <data key="d7">1.0</data>
      <data key="d8">计算机学者在创造卷积神经网络时受到了生理学家的启发。</data>
      <data key="d9">学科交叉,灵感来源</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003358</data>
      <data key="d13" />
    </edge>
    <edge source="计算机学者" target="数学家">
      <data key="d7">1.0</data>
      <data key="d8">计算机学者在创造卷积神经网络时受到了数学家的启发。</data>
      <data key="d9">学科交叉,灵感来源</data>
      <data key="d10">chunk-0424a179537a1b36c1d9bf13f9a5a922</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003359</data>
      <data key="d13" />
    </edge>
    <edge source="图像分类" target="卷积">
      <data key="d7">1.0</data>
      <data key="d8">卷积作为特征提取的基础方法，是图像分类等深度学习应用的核心原理之一。</data>
      <data key="d9">基础原理,特征提取</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007098</data>
      <data key="d13" />
    </edge>
    <edge source="图像分类" target="图像描述">
      <data key="d7">1.0</data>
      <data key="d8">图像分类和图像描述都是深度学习在计算机视觉领域的具体应用，分别属于一对一和一对多任务。</data>
      <data key="d9">任务类型,计算机视觉</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007105</data>
      <data key="d13" />
    </edge>
    <edge source="自编码器" target="编码">
      <data key="d7">1.0</data>
      <data key="d8">自编码器的目的是学习数据的编码，即一种重新表达。</data>
      <data key="d9">功能目的,学习目标</data>
      <data key="d10">chunk-e101b215c048456f8049a66e9ebd2c54</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003381</data>
      <data key="d13" />
    </edge>
    <edge source="自编码器" target="深度前馈神经网络">
      <data key="d7">1.0</data>
      <data key="d8">在结构上，自编码器是包含若干隐藏层的深度前馈神经网络。</data>
      <data key="d9">架构类型,结构归属</data>
      <data key="d10">chunk-e101b215c048456f8049a66e9ebd2c54</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003381</data>
      <data key="d13" />
    </edge>
    <edge source="注意力机制" target="注意力池化">
      <data key="d7">1.0</data>
      <data key="d8">注意力机制是注意力池化操作中的核心组件，用于增强信息处理能力。</data>
      <data key="d9">component,enhancement</data>
      <data key="d10">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003413</data>
      <data key="d13" />
    </edge>
    <edge source="词元序列" target="注意力池化">
      <data key="d7">1.0</data>
      <data key="d8">注意力池化接收词元序列作为输入数据并进行处理。</data>
      <data key="d9">input,processing</data>
      <data key="d10">chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003414</data>
      <data key="d13" />
    </edge>
    <edge source="自动编码器" target="数据降维">
      <data key="d7">1.0</data>
      <data key="d8">自动编码器可以实现数据降维的功能。</data>
      <data key="d9">实现,应用</data>
      <data key="d10">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003440</data>
      <data key="d13" />
    </edge>
    <edge source="自动编码器" target="特征学习">
      <data key="d7">1.0</data>
      <data key="d8">自动编码器可以实现特征学习的功能。</data>
      <data key="d9">实现,应用</data>
      <data key="d10">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003440</data>
      <data key="d13" />
    </edge>
    <edge source="自动编码器" target="生成模型">
      <data key="d7">1.0</data>
      <data key="d8">自动编码器现在被广泛用于生成模型。</data>
      <data key="d9">广泛用于,应用</data>
      <data key="d10">chunk-0a82bdcf222bdb547252e178dfe4d622</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003440</data>
      <data key="d13" />
    </edge>
    <edge source="Generative AI" target="Large Language Model (LLM)">
      <data key="d7">1.0</data>
      <data key="d8">The development of large language models catalyzed and enabled the field of generative AI.</data>
      <data key="d9">catalyzation,enabling</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008202</data>
      <data key="d13" />
    </edge>
    <edge source="Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition" target="Martin, J.">
      <data key="d7">1.0</data>
      <data key="d8">Martin, J. is the author of the textbook "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition".</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003533</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing with Transformers" target="OReilly">
      <data key="d7">1.0</data>
      <data key="d8">O’Reilly is the publisher of the book "Natural Language Processing with Transformers".</data>
      <data key="d9">publication,publisher</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003534</data>
      <data key="d13" />
    </edge>
    <edge source="Neural network methods for Natural Language Processing" target="Springer">
      <data key="d7">1.0</data>
      <data key="d8">Springer is the publisher of the book "Neural network methods for Natural Language Processing".</data>
      <data key="d9">publication,publisher</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003534</data>
      <data key="d13" />
    </edge>
    <edge source="Hands-on Large Language Models" target="OReilly">
      <data key="d7">1.0</data>
      <data key="d8">O’Reilly is the publisher of the book "Hands-on Large Language Models".</data>
      <data key="d9">publication,publisher</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003535</data>
      <data key="d13" />
    </edge>
    <edge source="Transformers for Natural Language Processing" target="OReilly">
      <data key="d7">1.0</data>
      <data key="d8">O’Reilly is the publisher of the book "Transformers for Natural Language Processing".</data>
      <data key="d9">publication,publisher</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003536</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Computational Linguistics">
      <data key="d7">1.0</data>
      <data key="d8">Natural Language Processing is closely related to and often overlaps with the field of Computational Linguistics.</data>
      <data key="d9">interdisciplinary,subfield</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003531</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Speech Recognition">
      <data key="d7">1.0</data>
      <data key="d8">Speech Recognition is a key application area within the broader field of Natural Language Processing.</data>
      <data key="d9">application,technology</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003533</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Nankai Statistics">
      <data key="d7">1.0</data>
      <data key="d8">The research directions of Nankai Statistics cover the application of Natural Language Processing in biomedicine.</data>
      <data key="d9">application,research direction</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004254</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Stemming">
      <data key="d7">1.0</data>
      <data key="d8">Stemming is a text preprocessing technique used within Natural Language Processing to prepare text for analysis.</data>
      <data key="d9">language analysis,text preprocessing</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007449</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Text Cleaning">
      <data key="d7">1.0</data>
      <data key="d8">Text cleaning is a preprocessing step in Natural Language Processing that removes unwanted elements from text data.</data>
      <data key="d9">data preparation,noise removal</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007443</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Feature Extraction">
      <data key="d7">1.0</data>
      <data key="d8">Feature extraction is a core process in Natural Language Processing that converts text into a format suitable for machine analysis.</data>
      <data key="d9">data transformation,numerical representation</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007444</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Text Analysis">
      <data key="d7">1.0</data>
      <data key="d8">Text analysis is a key application area of Natural Language Processing, involving various techniques to derive meaning from text.</data>
      <data key="d9">computational techniques,information extraction</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007454</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Natural Language Understanding">
      <data key="d7">1.0</data>
      <data key="d8">Natural Language Understanding is a specialized subset of Natural Language Processing focused on deriving meaning from sentences.</data>
      <data key="d9">meaning analysis,semantic understanding</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007452</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Natural Language Toolkit">
      <data key="d7">1.0</data>
      <data key="d8">The Natural Language Toolkit is a software environment used for implementing various Natural Language Processing tasks.</data>
      <data key="d9">library,software tool</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007456</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Tensorflow">
      <data key="d7">1.0</data>
      <data key="d8">TensorFlow is a software library used for training machine learning models, including those for Natural Language Processing applications.</data>
      <data key="d9">machine learning library,model training</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007462</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Healthcare Industry">
      <data key="d7">1.0</data>
      <data key="d8">Natural Language Processing is applied in the healthcare industry to analyze medical texts and records.</data>
      <data key="d9">data analysis,technology application</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007468</data>
      <data key="d13" />
    </edge>
    <edge source="Natural Language Processing" target="Insurance Industry">
      <data key="d7">1.0</data>
      <data key="d8">Natural Language Processing is applied in the insurance industry to analyze claims and optimize processes.</data>
      <data key="d9">process optimization,technology application</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007471</data>
      <data key="d13" />
    </edge>
    <edge source="Transformers" target="Large Language Models">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer architecture serves as the foundational model for most modern Large Language Models.</data>
      <data key="d9">architecture,foundation</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003533</data>
      <data key="d13" />
    </edge>
    <edge source="Transformers" target="BERT">
      <data key="d7">1.0</data>
      <data key="d8">BERT is a specific, pre-trained implementation of the Transformer architecture for language tasks.</data>
      <data key="d9">implementation,model</data>
      <data key="d10">chunk-261214465e9e66011cd2c39022b3dc6b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003534</data>
      <data key="d13" />
    </edge>
    <edge source="Transformers" target="Hugging Face">
      <data key="d7">1.0</data>
      <data key="d8">Hugging Face developed the Transformers package.</data>
      <data key="d9">creation,development</data>
      <data key="d10">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008025</data>
      <data key="d13" />
    </edge>
    <edge source="Transformers" target="NLP">
      <data key="d7">1.0</data>
      <data key="d8">The Transformers package supports the field of NLP.</data>
      <data key="d9">application,support</data>
      <data key="d10">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008028</data>
      <data key="d13" />
    </edge>
    <edge source="BERT" target="Transformer编码器">
      <data key="d7">1.0</data>
      <data key="d8">BERT is a pre-trained model that utilizes the Transformer encoder architecture.</data>
      <data key="d9">architecture,model basis</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006478</data>
      <data key="d13" />
    </edge>
    <edge source="BERT" target="文本表示">
      <data key="d7">1.0</data>
      <data key="d8">BERT adapts the text representation of a token to be context-dependent, unlike static embeddings.</data>
      <data key="d9">contextualization,model application</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006474</data>
      <data key="d13" />
    </edge>
    <edge source="BERT" target="Transformers Library">
      <data key="d7">1.0</data>
      <data key="d8">The rise of the BERT model contributed to the increased adoption of the Transformers library.</data>
      <data key="d9">adoption,influence</data>
      <data key="d10">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008025</data>
      <data key="d13" />
    </edge>
    <edge source="BERT" target="大模型">
      <data key="d7">1.0</data>
      <data key="d8">BERT is a specific, well-known instance of a pre-trained Large Model in NLP.</data>
      <data key="d9">example,instance</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008600</data>
      <data key="d13" />
    </edge>
    <edge source="多层感知机" target="Frank Rosenblatt">
      <data key="d7">1.0</data>
      <data key="d8">Frank Rosenblatt在1950年代提出了多层感知机。</data>
      <data key="d9">invention,proposal</data>
      <data key="d10">chunk-93860b80c6ea559ea9b38a8562c8df8c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003563</data>
      <data key="d13" />
    </edge>
    <edge source="多层感知机" target="深度网络">
      <data key="d7">1.0</data>
      <data key="d8">A multilayer perceptron is a specific type of deep network.</data>
      <data key="d9">example,type</data>
      <data key="d10">chunk-2bd963b40a794cdd2a7befd072b521f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003576</data>
      <data key="d13" />
    </edge>
    <edge source="多层感知机" target="单层感知机">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机相比单层感知机，其表达能力的提升关键在于非线性激活函数的复合使用。</data>
      <data key="d9">模型比较,表达能力</data>
      <data key="d10">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003695</data>
      <data key="d13" />
    </edge>
    <edge source="多层感知机" target="隐含层">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机包含一个或多个隐含层，这些层是提升其表达能力的关键结构。</data>
      <data key="d9">功能实现,结构组成</data>
      <data key="d10">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003696</data>
      <data key="d13" />
    </edge>
    <edge source="多层感知机" target="非线性激活函数">
      <data key="d7">1.0</data>
      <data key="d8">多层感知机表达能力的提升依赖于非线性激活函数的复合作用。</data>
      <data key="d9">功能依赖,核心组件</data>
      <data key="d10">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003696</data>
      <data key="d13" />
    </edge>
    <edge source="认知神经科学" target="研究">
      <data key="d7">1.0</data>
      <data key="d8">这项研究属于认知神经科学领域。</data>
      <data key="d9">学科背景,领域归属</data>
      <data key="d10">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003716</data>
      <data key="d13" />
    </edge>
    <edge source="认知神经科学" target="教育部重点实验室">
      <data key="d7">1.0</data>
      <data key="d8">The field of cognitive neuroscience is associated with the key laboratory under the Ministry of Education.</data>
      <data key="d9">organizational structure,research domain</data>
      <data key="d10">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004004</data>
      <data key="d13" />
    </edge>
    <edge source="认知神经科学" target="认知神经科学中心">
      <data key="d7">1.0</data>
      <data key="d8">The field of cognitive neuroscience is the focus of the Cognitive Neuroscience Center.</data>
      <data key="d9">organizational structure,research domain</data>
      <data key="d10">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004005</data>
      <data key="d13" />
    </edge>
    <edge source="Sigmoid" target="Tanh">
      <data key="d7">1.0</data>
      <data key="d8">The text presents a mathematical proof showing the identity tanh(x) + 1 = 2 * sigmoid(2x), establishing a formal relationship between the two functions.</data>
      <data key="d9">identity proof,mathematical equivalence</data>
      <data key="d10">chunk-8bed972d3227719ebad6c051fae785c9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003608</data>
      <data key="d13" />
    </edge>
    <edge source="自监督学习" target="文本表示">
      <data key="d7">1.0</data>
      <data key="d8">Self-supervised learning is the method used to pre-train text representations from large amounts of unlabeled text data.</data>
      <data key="d9">representation learning,training method</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006471</data>
      <data key="d13" />
    </edge>
    <edge source="自监督学习" target="大型语料库">
      <data key="d7">1.0</data>
      <data key="d8">Large corpora serve as the data source for self-supervised learning to pre-train text representations.</data>
      <data key="d9">data source,training foundation</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006472</data>
      <data key="d13" />
    </edge>
    <edge source="自监督学习" target="海量文本数据">
      <data key="d7">1.0</data>
      <data key="d8">Massive text data enables supervised learning within self-supervised pre-training without the need for expensive labels.</data>
      <data key="d9">cost efficiency,training data</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006472</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="Q学习">
      <data key="d7">1.0</data>
      <data key="d8">Q-learning is a specific algorithm within the broader field of reinforcement learning.</data>
      <data key="d9">algorithm,subfield</data>
      <data key="d10">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003675</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="SARSA">
      <data key="d7">1.0</data>
      <data key="d8">SARSA is a specific algorithm within the broader field of reinforcement learning.</data>
      <data key="d9">algorithm,subfield</data>
      <data key="d10">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003683</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="时序差分">
      <data key="d7">1.0</data>
      <data key="d8">Temporal-difference learning is a core method used in reinforcement learning.</data>
      <data key="d9">method,subfield</data>
      <data key="d10">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003675</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="多智能体">
      <data key="d7">1.0</data>
      <data key="d8">Multi-agent reinforcement learning is a specialized subfield of reinforcement learning.</data>
      <data key="d9">application,subfield</data>
      <data key="d10">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003676</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="Self-play">
      <data key="d7">1.0</data>
      <data key="d8">Self-play is a training technique used in reinforcement learning, particularly for game-playing agents.</data>
      <data key="d9">application,technique</data>
      <data key="d10">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003676</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="RLHF">
      <data key="d7">1.0</data>
      <data key="d8">Reinforcement Learning from Human Feedback is a technique used to align reinforcement learning models with human values.</data>
      <data key="d9">alignment,technique</data>
      <data key="d10">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003676</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="深脑">
      <data key="d7">1.0</data>
      <data key="d8">DeepMind integrated the concept of reinforcement learning from neuroscience with deep learning.</data>
      <data key="d9">combination,integration</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003897</data>
      <data key="d13" />
    </edge>
    <edge source="强化学习" target="AlphaGo">
      <data key="d7">1.0</data>
      <data key="d8">AlphaGo utilizes a combination of deep learning and reinforcement learning.</data>
      <data key="d9">integration,utilization</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003891</data>
      <data key="d13" />
    </edge>
    <edge source="RLHF" target="Reinforcement Learning">
      <data key="d7">1.0</data>
      <data key="d8">RLHF (Reinforcement Learning from Human Feedback) is a method within reinforcement learning used for AI alignment.</data>
      <data key="d9">alignment,feedback</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009229</data>
      <data key="d13" />
    </edge>
    <edge source="NeurIPS" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">NeurIPS is a major conference included under the category of Conferences and Publications in machine learning.</data>
      <data key="d9">academic event,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007980</data>
      <data key="d13" />
    </edge>
    <edge source="ICML" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">ICML is a major conference included under the category of Conferences and Publications in machine learning.</data>
      <data key="d9">academic event,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007985</data>
      <data key="d13" />
    </edge>
    <edge source="ICLR" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">ICLR is a major conference included under the category of Conferences and Publications in machine learning.</data>
      <data key="d9">academic event,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007988</data>
      <data key="d13" />
    </edge>
    <edge source="AAAI" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">AAAI is a major conference included under the category of Conferences and Publications in machine learning.</data>
      <data key="d9">academic event,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007990</data>
      <data key="d13" />
    </edge>
    <edge source="IJCAI" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">IJCAI is a major conference included under the category of Conferences and Publications in machine learning.</data>
      <data key="d9">academic event,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007992</data>
      <data key="d13" />
    </edge>
    <edge source="CVPR" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">CVPR is a major conference included under the category of Conferences and Publications in machine learning.</data>
      <data key="d9">academic event,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007993</data>
      <data key="d13" />
    </edge>
    <edge source="JMLR" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">JMLR is an academic journal included under the category of Conferences and Publications.</data>
      <data key="d9">academic publication,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007995</data>
      <data key="d13" />
    </edge>
    <edge source="TensorFlow" target="Keras">
      <data key="d7">1.0</data>
      <data key="d8">Keras is a high-level API that is integrated into and can run on top of the TensorFlow framework.</data>
      <data key="d9">API,integration</data>
      <data key="d10">chunk-80c468f42f64d269b4538a150a4f94cd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003675</data>
      <data key="d13" />
    </edge>
    <edge source="非线性激活函数" target="连续函数">
      <data key="d7">1.0</data>
      <data key="d8">理论上可以证明，通过非线性激活函数的复合，多层感知机能够逼近任意连续函数。</data>
      <data key="d9">函数逼近,数学理论</data>
      <data key="d10">chunk-6d725020748a8a4cbf40cdbf97928919</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003695</data>
      <data key="d13" />
    </edge>
    <edge source="随机梯度下降" target="损失函数地形">
      <data key="d7">1.0</data>
      <data key="d8">随机梯度下降算法在损失函数地形上进行导航，以寻找最优的模型参数。</data>
      <data key="d9">优化,导航</data>
      <data key="d10">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003716</data>
      <data key="d13" />
    </edge>
    <edge source="随机梯度下降" target="有效学习">
      <data key="d7">1.0</data>
      <data key="d8">随机梯度下降通过与损失函数地形的相互作用，是实现有效学习的关键机制。</data>
      <data key="d9">优化过程,实现机制</data>
      <data key="d10">chunk-88c27f8b7b31c4aea51cfc3d8f79a013</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003716</data>
      <data key="d13" />
    </edge>
    <edge source="计算神经科学" target="类脑智能技术">
      <data key="d7">1.0</data>
      <data key="d8">World-class computational neuroscience is a prerequisite for achieving world-class innovation in brain-inspired intelligence technology.</data>
      <data key="d9">foundation,innovation dependency</data>
      <data key="d10">chunk-92f537cdcce6583c2c63c400d634feaf</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003736</data>
      <data key="d13" />
    </edge>
    <edge source="计算神经科学" target="Coursera">
      <data key="d7">1.0</data>
      <data key="d8">Coursera平台上有推荐的课程，用于加深对计算神经科学的理解。</data>
      <data key="d9">学习资源,推荐课程</data>
      <data key="d10">chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003755</data>
      <data key="d13" />
    </edge>
    <edge source="计算认知" target="Coursera">
      <data key="d7">1.0</data>
      <data key="d8">Coursera平台上有推荐的课程，用于加深对计算认知的理解。</data>
      <data key="d9">学习资源,推荐课程</data>
      <data key="d10">chunk-9ed0526c7eff8b1a424224e53050b149</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003754</data>
      <data key="d13" />
    </edge>
    <edge source="Walter Pitts" target="Bertrand Russell">
      <data key="d7">1.0</data>
      <data key="d8">Walter Pitts wrote to Bertrand Russell to point out errors in Principia Mathematica, and Russell invited him to study.</data>
      <data key="d9">correspondence,mentorship</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003885</data>
      <data key="d13" />
    </edge>
    <edge source="Walter Pitts" target="Principia Mathematica">
      <data key="d7">1.0</data>
      <data key="d8">Walter Pitts was captivated by and independently studied the Principia Mathematica.</data>
      <data key="d9">critique,study</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003886</data>
      <data key="d13" />
    </edge>
    <edge source="Walter Pitts" target="Carnap">
      <data key="d7">1.0</data>
      <data key="d8">Walter Pitts critiqued Carnap's new book on logic in his office, leading to an extended discussion.</data>
      <data key="d9">academic interaction,critique</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003887</data>
      <data key="d13" />
    </edge>
    <edge source="Walter Pitts" target="Warren McCulloch">
      <data key="d7">3.0</data>
      <data key="d8">Warren McCulloch hosted Walter Pitts and co-authored the seminal paper "A Logical Calculus of the Ideas Immanent in Nervous Activity."&lt;SEP&gt;Walter Pitts lived with Warren McCulloch and collaborated with him on modeling the nervous system as a logical machine.&lt;SEP&gt;Warren McCulloch and Walter Pitts co-developed the McCulloch-Pitts neural network model.</data>
      <data key="d9">co-authorship,collaboration,model development,publication</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003889</data>
      <data key="d13" />
    </edge>
    <edge source="Walter Pitts" target="University Of Chicago">
      <data key="d7">1.0</data>
      <data key="d8">Walter Pitts attended lectures and lived on the campus of the University of Chicago.</data>
      <data key="d9">attendance,study</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003891</data>
      <data key="d13" />
    </edge>
    <edge source="Warren McCulloch" target="University Of Illinois">
      <data key="d7">1.0</data>
      <data key="d8">Warren McCulloch was a professor at the University of Illinois.</data>
      <data key="d9">affiliation,employment</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003885</data>
      <data key="d13" />
    </edge>
    <edge source="Warren McCulloch" target="McCulloch–Pitts神经元">
      <data key="d7">1.0</data>
      <data key="d8">Warren McCulloch co-created the mathematical model of the neuron that bears his name (McCulloch–Pitts neuron).</data>
      <data key="d9">co-creation,namesake</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003898</data>
      <data key="d13" />
    </edge>
    <edge source="McCulloch-Pitts Network" target="Finite Automata">
      <data key="d7">1.0</data>
      <data key="d8">The McCulloch-Pitts network is considered one of the earliest forms of a finite automaton.</data>
      <data key="d9">instantiation,model type</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003886</data>
      <data key="d13" />
    </edge>
    <edge source="McCulloch-Pitts Network" target="A Logical Calculus Of The Ideas Immanent In Nervous Activity">
      <data key="d7">1.0</data>
      <data key="d8">The McCulloch-Pitts network model was formally described in the paper "A Logical Calculus of the Ideas Immanent in Nervous Activity."</data>
      <data key="d9">description,publication</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003887</data>
      <data key="d13" />
    </edge>
    <edge source="McCulloch-Pitts Network" target="Computational Neuroscience">
      <data key="d7">1.0</data>
      <data key="d8">The logical foundation provided by the McCulloch-Pitts work is an early cornerstone of computational neuroscience.</data>
      <data key="d9">contribution,foundation</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003890</data>
      <data key="d13" />
    </edge>
    <edge source="McCulloch-Pitts Network" target="Connection Strength Matrix">
      <data key="d7">1.0</data>
      <data key="d8">The McCulloch-Pitts network model uses a connection strength matrix to define the influence between neurons.</data>
      <data key="d9">component,model specification</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003892</data>
      <data key="d13" />
    </edge>
    <edge source="Synapse" target="Learning">
      <data key="d7">1.0</data>
      <data key="d8">Neuroscience finds that the modifiable strength of synapses is likely the material basis for learning.</data>
      <data key="d9">biological basis,mechanism</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003891</data>
      <data key="d13" />
    </edge>
    <edge source="Geoffrey Hinton" target="Terry Sejnowski">
      <data key="d7">2.0</data>
      <data key="d8">Geoffrey Hinton and Terry Sejnowski collaborated to find effective methods for training artificial neural networks.&lt;SEP&gt;Geoffrey Hinton and Terry Sejnowski collaborated around 1982 to invent the Boltzmann machine.</data>
      <data key="d9">co-invention,collaboration,research</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c&lt;SEP&gt;chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003887</data>
      <data key="d13" />
    </edge>
    <edge source="Geoffrey Hinton" target="玻尔兹曼机">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton co-invented the Boltzmann machine, a method for training artificial neural networks.</data>
      <data key="d9">contribution,invention</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="Geoffrey Hinton" target="神经科学">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton transplanted the layered organizational principle of the cerebral cortex into artificial neural networks, inspiring his 2006 deep learning training method.</data>
      <data key="d9">application,inspiration</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003897</data>
      <data key="d13" />
    </edge>
    <edge source="Geoffrey Hinton" target="Talking Nets">
      <data key="d7">1.0</data>
      <data key="d8">The book "Talking nets" contains an interview with Geoffrey Hinton.</data>
      <data key="d9">documentation,interview</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="Geoffrey Hinton" target="Christian Ideology">
      <data key="d7">1.0</data>
      <data key="d8">Geoffrey Hinton was convinced that Christian ideology was complete rubbish during his childhood and schooling.</data>
      <data key="d9">belief,rejection</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaGo" target="Ke Jie">
      <data key="d7">1.0</data>
      <data key="d8">The AlphaGo AI algorithm defeated top Go player Ke Jie in competition.</data>
      <data key="d9">AI victory,competition</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003889</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaGo" target="深脑">
      <data key="d7">1.0</data>
      <data key="d8">DeepMind, led by its team, created the AlphaGo program.</data>
      <data key="d9">creation,development</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003889</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaGo" target="李世石">
      <data key="d7">1.0</data>
      <data key="d8">AlphaGo defeated top professional Go player Lee Sedol (李世石).</data>
      <data key="d9">competition,victory</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003892</data>
      <data key="d13" />
    </edge>
    <edge source="Alan Turing" target="Universal Computing Engine">
      <data key="d7">1.0</data>
      <data key="d8">Alan Turing published a famous article on the concept of a universal computing engine.</data>
      <data key="d9">conceptualization,publication</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003889</data>
      <data key="d13" />
    </edge>
    <edge source="Gottfried Wilhelm Leibniz" target="Logical Machine">
      <data key="d7">1.0</data>
      <data key="d8">Gottfried Wilhelm Leibniz proved that any well-defined problem could be computed by a logical machine.</data>
      <data key="d9">conceptualization,proof</data>
      <data key="d10">chunk-6de93055a89fdb2a0b2d1eab2a75410c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003890</data>
      <data key="d13" />
    </edge>
    <edge source="Pitts" target="McCulloch–Pitts神经元">
      <data key="d7">1.0</data>
      <data key="d8">Pitts co-created the mathematical model of the neuron that bears his name (McCulloch–Pitts neuron).</data>
      <data key="d9">co-creation,namesake</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003897</data>
      <data key="d13" />
    </edge>
    <edge source="Pitts" target="MIT">
      <data key="d7">1.0</data>
      <data key="d8">Pitts refused offers of a degree and a formal faculty position from MIT.</data>
      <data key="d9">refusal,rejection</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003890</data>
      <data key="d13" />
    </edge>
    <edge source="Pitts" target="芝加哥大学">
      <data key="d7">1.0</data>
      <data key="d8">Pitts audited classes at the University of Chicago without registering as a student.</data>
      <data key="d9">affiliation,attendance</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003898</data>
      <data key="d13" />
    </edge>
    <edge source="Pitts" target="Norbert">
      <data key="d7">1.0</data>
      <data key="d8">Norbert may have arranged for MIT to offer Pitts a degree.</data>
      <data key="d9">arrangement,assistance</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003892</data>
      <data key="d13" />
    </edge>
    <edge source="Jim Anderson" target="Talking Nets">
      <data key="d7">1.0</data>
      <data key="d8">Jim Anderson co-authored the book "Talking nets".</data>
      <data key="d9">authorship,creation</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003898</data>
      <data key="d13" />
    </edge>
    <edge source="Jim Anderson" target="Lettvin">
      <data key="d7">1.0</data>
      <data key="d8">Jim Anderson conducted an interview with Lettvin, which is referenced.</data>
      <data key="d9">collaboration,interview</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="Edward Rosenfeld" target="Talking Nets">
      <data key="d7">2.0</data>
      <data key="d8">Edward Rosenfeld is an author of the book "Talking Nets".&lt;SEP&gt;Edward Rosenfeld co-authored the book "Talking nets".</data>
      <data key="d9">authorship,creation,publication</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c&lt;SEP&gt;chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003892</data>
      <data key="d13" />
    </edge>
    <edge source="Lettvin" target="Talking Nets">
      <data key="d7">1.0</data>
      <data key="d8">The book "Talking nets" contains an interview with Lettvin, providing information about Pitts.</data>
      <data key="d9">documentation,interview</data>
      <data key="d10">chunk-c9ebca01c6cfa5bfc38e623dde85f68c</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003893</data>
      <data key="d13" />
    </edge>
    <edge source="Talking Nets" target="James Anderson">
      <data key="d7">1.0</data>
      <data key="d8">James Anderson is an author of the book "Talking Nets".</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="Talking Nets" target="MIT Press">
      <data key="d7">1.0</data>
      <data key="d8">MIT Press published the book "Talking Nets" in 1998.</data>
      <data key="d9">production,publishing</data>
      <data key="d10">chunk-e7712ad4739a66b6cf3b8376df6a6837</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003894</data>
      <data key="d13" />
    </edge>
    <edge source="Nature" target="AlphaFold2">
      <data key="d7">1.0</data>
      <data key="d8">The paper detailing AlphaFold2 was published online in the journal Nature.</data>
      <data key="d9">dissemination,publication</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004503</data>
      <data key="d13" />
    </edge>
    <edge source="Nature" target="Alphafold2">
      <data key="d7">1.0</data>
      <data key="d8">The journal Nature published papers in 2020 and 2021 that describe the AlphaFold2 model and its architecture.</data>
      <data key="d9">model documentation,scientific publication</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004673</data>
      <data key="d13" />
    </edge>
    <edge source="Nature" target="Jumper, J">
      <data key="d7">1.0</data>
      <data key="d8">Jumper, J is an author of the AlphaFold2 paper published in Nature.</data>
      <data key="d9">authorship,scientific contribution</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004674</data>
      <data key="d13" />
    </edge>
    <edge source="科学实证" target="人生外挂">
      <data key="d7">1.0</data>
      <data key="d8">The concept of "人生外挂" (life-enhancing tools) is presented as being validated and supported by scientific evidence.</data>
      <data key="d9">concept application,validation method</data>
      <data key="d10">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003929</data>
      <data key="d13" />
    </edge>
    <edge source="科学实证" target="运气">
      <data key="d7">1.0</data>
      <data key="d8">The concept of "运气" (luck) is analyzed and claimed to be validated through scientific evidence.</data>
      <data key="d9">concept analysis,validation method</data>
      <data key="d10">chunk-03a5749c6bb89c89b202fa903dbb847f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769003930</data>
      <data key="d13" />
    </edge>
    <edge source="生物医学影像中心" target="张江国际脑影像中心">
      <data key="d7">1.0</data>
      <data key="d8">The Biomedical Imaging Center is also known as the Zhangjiang International Brain Imaging Center.</data>
      <data key="d9">alternative name,location</data>
      <data key="d10">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004004</data>
      <data key="d13" />
    </edge>
    <edge source="生物医学大数据中心" target="张江国际脑库">
      <data key="d7">1.0</data>
      <data key="d8">The Biomedical Big Data Center is also known as the Zhangjiang International Brain Bank.</data>
      <data key="d9">alternative name,location</data>
      <data key="d10">chunk-a0a9ca6f9242eabc77977a8fe45c5022</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004004</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质结构预测" target="氨基酸序列">
      <data key="d7">1.0</data>
      <data key="d8">蛋白质结构预测以氨基酸序列作为输入信息进行结构推断。</data>
      <data key="d9">输入,预测基础</data>
      <data key="d10">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004025</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质结构预测" target="三维空间结构">
      <data key="d7">1.0</data>
      <data key="d8">蛋白质结构预测的目标是推断出蛋白质的三维空间结构。</data>
      <data key="d9">输出,预测目标</data>
      <data key="d10">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004026</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质结构预测" target="计算机计算模拟方法">
      <data key="d7">1.0</data>
      <data key="d8">蛋白质结构预测依赖于计算机计算模拟方法来实现。</data>
      <data key="d9">依赖,技术手段</data>
      <data key="d10">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004033</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质结构预测" target="物理学">
      <data key="d7">1.0</data>
      <data key="d8">蛋白质结构预测可以基于物理学的原理进行计算模拟。</data>
      <data key="d9">原理应用,基于</data>
      <data key="d10">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004026</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质结构预测" target="自然-方法学">
      <data key="d7">1.0</data>
      <data key="d8">Protein structure prediction was named the Method of the Year by the journal Nature Methods in 2021.</data>
      <data key="d9">award,recognition</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004147</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质结构预测" target="AlphaFold2">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 solved the long-standing major problem of protein structure prediction in life sciences.</data>
      <data key="d9">advancement,solution</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004150</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质结构预测" target="Alphafold2">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 is a method designed to solve the problem of protein structure prediction.</data>
      <data key="d9">model application,task solution</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004677</data>
      <data key="d13" />
    </edge>
    <edge source="氨基酸序列" target="ESMFold">
      <data key="d7">1.0</data>
      <data key="d8">ESMFold根据氨基酸序列进行预测。</data>
      <data key="d9">处理,输入</data>
      <data key="d10">chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004070</data>
      <data key="d13" />
    </edge>
    <edge source="三维空间结构" target="生理功能">
      <data key="d7">1.0</data>
      <data key="d8">蛋白质的三维空间结构决定了其生理功能。</data>
      <data key="d9">决定,结构功能关系</data>
      <data key="d10">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004033</data>
      <data key="d13" />
    </edge>
    <edge source="王天尧" target="生物信息学">
      <data key="d7">1.0</data>
      <data key="d8">王天尧是生物信息学领域的文献作者。</data>
      <data key="d9">作者领域,研究归属</data>
      <data key="d10">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004025</data>
      <data key="d13" />
    </edge>
    <edge source="王天尧" target="2024">
      <data key="d7">1.0</data>
      <data key="d8">王天尧在2024年发表了相关文献。</data>
      <data key="d9">发表时间,文献年份</data>
      <data key="d10">chunk-99be6d80a8d1a4129da56c2930cc8b6d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004026</data>
      <data key="d13" />
    </edge>
    <edge source="生物信息学" target="Deep Learning In Life Sciences">
      <data key="d7">1.0</data>
      <data key="d8">The lecture series Deep Learning in Life Sciences is situated within the domain of bioinformatics.</data>
      <data key="d9">domain application,field of study</data>
      <data key="d10">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004384</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="模型">
      <data key="d7">1.0</data>
      <data key="d8">算法是构成人工智能模型、使其能够从数据中学习并做出决策的要素。</data>
      <data key="d9">实现手段,构成要素</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008522</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="人工智能时代">
      <data key="d7">1.0</data>
      <data key="d8">算法在人工智能时代狂飙突进，实现了对社会的整体建构，但也引发了诸多争议。</data>
      <data key="d9">技术建构,社会影响</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011198</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="哲学">
      <data key="d7">1.0</data>
      <data key="d8">算法价值与哲学价值之间存在张力，这种张力可以转化为人工智能时代发展的创造性势能。</data>
      <data key="d9">价值张力,势能转化</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011218</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="人工智能技术">
      <data key="d7">1.0</data>
      <data key="d8">AI technology uses algorithms as a key tool, which shapes problems like inequality gaps.</data>
      <data key="d9">塑造问题,工具</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011222</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="认识世界">
      <data key="d7">1.0</data>
      <data key="d8">Algorithm has become a core way of knowing the world.</data>
      <data key="d9">功能角色,核心方式</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011240</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="改造世界">
      <data key="d7">1.0</data>
      <data key="d8">Algorithm has become a core way of transforming the world.</data>
      <data key="d9">功能角色,核心方式</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011245</data>
      <data key="d13" />
    </edge>
    <edge source="算法" target="人类智慧">
      <data key="d7">1.0</data>
      <data key="d8">Algorithm is the collective embodiment of human wisdom.</data>
      <data key="d9">关系属性,集体体现</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011253</data>
      <data key="d13" />
    </edge>
    <edge source="FAIR" target="ESMFold">
      <data key="d7">1.0</data>
      <data key="d8">ESMFold是由FAIR开发的。</data>
      <data key="d9">开发,所属</data>
      <data key="d10">chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004070</data>
      <data key="d13" />
    </edge>
    <edge source="ESMFold" target="蛋白质结构">
      <data key="d7">1.0</data>
      <data key="d8">ESMFold用于预测蛋白质结构。</data>
      <data key="d9">应用,预测</data>
      <data key="d10">chunk-62c73611ffdf6388dc832abdf23ad216</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004070</data>
      <data key="d13" />
    </edge>
    <edge source="DeepMind" target="AlphaFold">
      <data key="d7">2.0</data>
      <data key="d8">DeepMind is the company that developed the AlphaFold system for protein structure prediction.&lt;SEP&gt;DeepMind decided to improve the AlphaFold system, which initially did not meet expectations, leading to a re-evaluation.</data>
      <data key="d9">development,improvement,ownership</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004502</data>
      <data key="d13" />
    </edge>
    <edge source="DeepMind" target="AlphaFold2 Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">DeepMind made the AlphaFold2 algorithm freely available for global researchers.</data>
      <data key="d9">open access,release</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004150</data>
      <data key="d13" />
    </edge>
    <edge source="DeepMind" target="AlphaFold 2">
      <data key="d7">1.0</data>
      <data key="d8">DeepMind issued press releases that propelled media attention for AlphaFold 2's success.</data>
      <data key="d9">announcement,development</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004301</data>
      <data key="d13" />
    </edge>
    <edge source="DeepMind" target="Deep Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Researchers from DeepMind are involved with the neural networks that predict protein properties.</data>
      <data key="d9">development,research</data>
      <data key="d10">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004397</data>
      <data key="d13" />
    </edge>
    <edge source="DeepMind" target="Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">DeepMind made the AlphaFold2 algorithm freely available for global researchers to use.</data>
      <data key="d9">dissemination,open access</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004503</data>
      <data key="d13" />
    </edge>
    <edge source="DeepMind" target="CASP14">
      <data key="d7">1.0</data>
      <data key="d8">DeepMind presented information about AlphaFold2 at the CASP14 competition.</data>
      <data key="d9">competition participation,presentation</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004673</data>
      <data key="d13" />
    </edge>
    <edge source="DeepMind" target="Alphafold2">
      <data key="d7">1.0</data>
      <data key="d8">DeepMind is the organization that developed the AlphaFold2 model.</data>
      <data key="d9">model creation,research and development</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004675</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="江珀">
      <data key="d7">1.0</data>
      <data key="d8">Jiang Po led a team to re-examine and improve the initial version of AlphaFold.</data>
      <data key="d9">improvement,leadership</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004148</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="AlphaFold2">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 is the significantly improved and breakthrough successor to the initial AlphaFold system.</data>
      <data key="d9">evolution,improvement</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004151</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Deep Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold builds models that rely on deep neural networks.</data>
      <data key="d9">dependency,model construction</data>
      <data key="d10">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004396</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Protein Property">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold models predict protein properties.</data>
      <data key="d9">model output,prediction</data>
      <data key="d10">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004397</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Sequence">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold takes sequence data as a primary input for its structural predictions.</data>
      <data key="d9">analysis,input</data>
      <data key="d10">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004424</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Structure">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold produces predicted molecular structures as its output.</data>
      <data key="d9">output,prediction</data>
      <data key="d10">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004424</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Bioinformatics">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold's technical core integrates bioinformatics as a key concept.</data>
      <data key="d9">core component,technology integration</data>
      <data key="d10">chunk-5899806c994fc2f391826abc901a8669</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004442</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Protein Sequences">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold analyzes protein sequences to learn relationships.</data>
      <data key="d9">data analysis,learning</data>
      <data key="d10">chunk-5899806c994fc2f391826abc901a8669</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004442</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Protein Structures">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold analyzes protein structures to learn relationships.</data>
      <data key="d9">data analysis,learning</data>
      <data key="d10">chunk-5899806c994fc2f391826abc901a8669</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004442</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold" target="Jiang Po">
      <data key="d7">1.0</data>
      <data key="d8">Jiang Po led a team to re-examine and comprehensively adjust the initial version of AlphaFold.</data>
      <data key="d9">leadership,technical revision</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004503</data>
      <data key="d13" />
    </edge>
    <edge source="江珀" target="空间立体结构">
      <data key="d7">1.0</data>
      <data key="d8">Jiang Po's team introduced the concept of spatial three-dimensional structure into the AlphaFold improvement process.</data>
      <data key="d9">integration,introduction</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004149</data>
      <data key="d13" />
    </edge>
    <edge source="江珀" target="进化理念">
      <data key="d7">1.0</data>
      <data key="d8">Jiang Po's team integrated the evolutionary concept into the AlphaFold improvement process.</data>
      <data key="d9">integration,introduction</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004150</data>
      <data key="d13" />
    </edge>
    <edge source="江珀" target="机器有效学习策略">
      <data key="d7">1.0</data>
      <data key="d8">Jiang Po's team refined effective machine learning strategies to improve AlphaFold's data extraction capabilities.</data>
      <data key="d9">application,refinement</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004151</data>
      <data key="d13" />
    </edge>
    <edge source="江珀" target="传统算法">
      <data key="d7">1.0</data>
      <data key="d8">Jiang Po's team abandoned the constraints of traditional algorithms during the development of AlphaFold2.</data>
      <data key="d9">abandonment,innovation</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004151</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="CASP 14">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 demonstrated exceptional performance and achieved high scores at the CASP14 competition.</data>
      <data key="d9">achievement,competition</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004147</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="《自然》周刊">
      <data key="d7">1.0</data>
      <data key="d8">The detailed paper describing AlphaFold2 was published online in the journal Nature.</data>
      <data key="d9">dissemination,publication</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004148</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="《科学》周刊">
      <data key="d7">1.0</data>
      <data key="d8">The achievement of AlphaFold2 was selected by the journal Science as the top scientific breakthrough of 2021.</data>
      <data key="d9">award,recognition</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004149</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="生命科学研究">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 provided an incredible breakthrough for life science research by drastically reducing the time and cost to obtain protein structures.</data>
      <data key="d9">acceleration,impact</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004151</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="Protein Sequence">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 processes a protein sequence to generate a predicted protein structure.</data>
      <data key="d9">input,processing</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004152</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="AlphaFold2 Paper">
      <data key="d7">1.0</data>
      <data key="d8">The AlphaFold2 paper documents the system's methodology and results, published in Nature.</data>
      <data key="d9">documentation,publication</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004152</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="D-I-TASSER">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER算法在结构预测精度上显著优于AlphaFold2，在困难单结构域蛋白预测中84%的案例生成质量更高。</data>
      <data key="d9">性能比较,算法改进</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004239</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="CASP Competition">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 performed exceptionally well at the 14th CASP competition, achieving high GDT scores far above competitors.</data>
      <data key="d9">performance,validation</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004502</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="Science">
      <data key="d7">1.0</data>
      <data key="d8">The achievement of AlphaFold2 was selected by the journal Science as the top scientific breakthrough of 2021.</data>
      <data key="d9">breakthrough,recognition</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004505</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="Protein Structure Prediction">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 solved the protein structure prediction problem, providing a breakthrough for life sciences research.</data>
      <data key="d9">impact,solution</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004505</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="GDT Score">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2's performance was measured by its high GDT scores in protein structure prediction.</data>
      <data key="d9">evaluation,metric</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004505</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="Paper">
      <data key="d7">1.0</data>
      <data key="d8">The paper detailing AlphaFold2 was published and has garnered nearly ten thousand citations.</data>
      <data key="d9">citation impact,documentation</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004506</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold2" target="Life Sciences Research">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 provided a breakthrough for life sciences research by enabling researchers to obtain protein structures in days/hours instead of months/years and at a fraction of the cost.</data>
      <data key="d9">efficiency,transformation</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004506</data>
      <data key="d13" />
    </edge>
    <edge source="Demis Hassabis" target="Albert Lasker Basic Medical Research Award">
      <data key="d7">2.0</data>
      <data key="d8">Demis Hassabis received the 2023 Albert Lasker Basic Medical Research Award for his work on AlphaFold.&lt;SEP&gt;Demis Hassabis shared the 2023 Albert Lasker Basic Medical Research Award for his work on AlphaFold.</data>
      <data key="d9">award,receipt,recognition</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004503</data>
      <data key="d13" />
    </edge>
    <edge source="John Jumper" target="Albert Lasker Basic Medical Research Award">
      <data key="d7">2.0</data>
      <data key="d8">John Jumper received the 2023 Albert Lasker Basic Medical Research Award for his work on AlphaFold.&lt;SEP&gt;John Jumper shared the 2023 Albert Lasker Basic Medical Research Award for his work on AlphaFold.</data>
      <data key="d9">award,receipt,recognition</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f&lt;SEP&gt;chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004504</data>
      <data key="d13" />
    </edge>
    <edge source="大数据" target="AI工具">
      <data key="d7">1.0</data>
      <data key="d8">Big data is an important characteristic of modern science, and AI tools are a key direction for leveraging this data to solve problems.</data>
      <data key="d9">characteristic,enabler</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004150</data>
      <data key="d13" />
    </edge>
    <edge source="大数据" target="Genome Sequencing Results">
      <data key="d7">1.0</data>
      <data key="d8">Genome sequencing results are provided as a specific example of big data in science.</data>
      <data key="d9">characteristic,example</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004151</data>
      <data key="d13" />
    </edge>
    <edge source="大数据" target="Massive Papers">
      <data key="d7">1.0</data>
      <data key="d8">Massive papers are provided as a specific example of big data in science.</data>
      <data key="d9">characteristic,example</data>
      <data key="d10">chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004151</data>
      <data key="d13" />
    </edge>
    <edge source="大数据" target="数据分析">
      <data key="d7">1.0</data>
      <data key="d8">Data analysis is a key process applied to big data to extract insights.</data>
      <data key="d9">analysis technique,process</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008603</data>
      <data key="d13" />
    </edge>
    <edge source="南开大学" target="郑伟">
      <data key="d7">1.0</data>
      <data key="d8">郑伟教授是南开大学统计与数据科学学院的教授，代表南开大学进行此项研究。</data>
      <data key="d9">研究,隶属</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004240</data>
      <data key="d13" />
    </edge>
    <edge source="郑伟" target="D-I-TASSER">
      <data key="d7">1.0</data>
      <data key="d8">郑伟教授作为第一作者，开发了D-I-TASSER蛋白质结构预测算法。</data>
      <data key="d9">开发,研究</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004239</data>
      <data key="d13" />
    </edge>
    <edge source="郑伟" target="Nature Biotechnology">
      <data key="d7">1.0</data>
      <data key="d8">郑伟教授作为第一作者在Nature Biotechnology期刊上发表了关于D-I-TASSER的研究论文。</data>
      <data key="d9">发表论文,学术成果</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004239</data>
      <data key="d13" />
    </edge>
    <edge source="郑伟" target="DMFold">
      <data key="d7">1.0</data>
      <data key="d8">郑伟教授开发了DMFold等一系列结构预测算法。</data>
      <data key="d9">开发,研究</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004240</data>
      <data key="d13" />
    </edge>
    <edge source="郑伟" target="Nature Methods">
      <data key="d7">1.0</data>
      <data key="d8">郑伟教授在Nature Methods期刊上发表过文章。</data>
      <data key="d9">发表论文,学术成果</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004249</data>
      <data key="d13" />
    </edge>
    <edge source="郑伟" target="Nature Communications">
      <data key="d7">1.0</data>
      <data key="d8">郑伟教授在Nature Communications期刊上发表过文章。</data>
      <data key="d9">发表论文,学术成果</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004242</data>
      <data key="d13" />
    </edge>
    <edge source="郑伟" target="PNAS">
      <data key="d7">1.0</data>
      <data key="d8">郑伟教授在PNAS期刊上发表过文章。</data>
      <data key="d9">发表论文,学术成果</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004242</data>
      <data key="d13" />
    </edge>
    <edge source="张阳" target="D-I-TASSER">
      <data key="d7">1.0</data>
      <data key="d8">张阳教授是论文的通讯作者之一，对D-I-TASSER的研究进行了指导。</data>
      <data key="d9">指导研究,通讯作者</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004249</data>
      <data key="d13" />
    </edge>
    <edge source="Lydia Freddolino" target="D-I-TASSER">
      <data key="d7">1.0</data>
      <data key="d8">Lydia Freddolino副教授是论文的通讯作者之一，对D-I-TASSER的研究进行了指导。</data>
      <data key="d9">指导研究,通讯作者</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004242</data>
      <data key="d13" />
    </edge>
    <edge source="Nature Biotechnology" target="Nankai Statistics">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published dozens of papers in authoritative biomedical journals including Nature Biotechnology.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004246</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="AlphaFold3">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER算法实现了超越AlphaFold3算法的高精度蛋白质结构预测。</data>
      <data key="d9">性能比较,算法改进</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004240</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="CASP">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER参加了第15届CASP比赛，在单结构域蛋白和多结构域蛋白两个单项比赛中均排名世界第一。</data>
      <data key="d9">竞赛参与,获奖</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004240</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="孤儿蛋白">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER算法旨在解决AlphaFold系列对孤儿蛋白预测效果不理想的问题。</data>
      <data key="d9">解决难题,预测</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004241</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="多结构域蛋白">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER算法旨在解决AlphaFold系列难以处理多结构域蛋白的问题。</data>
      <data key="d9">解决难题,预测</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004241</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="人类基因组">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER对人类基因组的蛋白质进行了结构和功能预测。</data>
      <data key="d9">应用,预测</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004242</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="抗体筛选与优化">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER在抗体筛选与优化任务中取得了初步进展。</data>
      <data key="d9">应用,进展</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004243</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="罕见病致病基因识别">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER在罕见病致病基因识别任务中取得了初步进展。</data>
      <data key="d9">应用,进展</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004244</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="病毒感染性预测">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER在病毒感染性预测任务中取得了初步进展。</data>
      <data key="d9">应用,进展</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004244</data>
      <data key="d13" />
    </edge>
    <edge source="D-I-TASSER" target="辅助冷冻电镜结构解析">
      <data key="d7">1.0</data>
      <data key="d8">D-I-TASSER在辅助冷冻电镜结构解析任务中取得了初步进展。</data>
      <data key="d9">应用,进展</data>
      <data key="d10">chunk-a4bf6e4cf6f9e616e1d6f994a99479a8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004245</data>
      <data key="d13" />
    </edge>
    <edge source="CASP" target="AlphaFold 2">
      <data key="d7">1.0</data>
      <data key="d8">CASP issued press releases that propelled media attention for AlphaFold 2's success.</data>
      <data key="d9">announcement,scientific achievement</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004301</data>
      <data key="d13" />
    </edge>
    <edge source="统计与数据科学学院" target="河北金融学院">
      <data key="d7">1.0</data>
      <data key="d8">统计与数据科学学院是河北金融学院的学院之一。</data>
      <data key="d9">contains,parent organization</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006378</data>
      <data key="d13" />
    </edge>
    <edge source="Nature Methods" target="Nankai Statistics">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published over 50 articles in high-level SCI journals including Nature Methods.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004242</data>
      <data key="d13" />
    </edge>
    <edge source="Nature Communications" target="Nankai Statistics">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published over 50 articles in high-level SCI journals including Nature Communications.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004243</data>
      <data key="d13" />
    </edge>
    <edge source="PNAS" target="Nankai Statistics">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published over 50 articles in high-level SCI journals including PNAS.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004244</data>
      <data key="d13" />
    </edge>
    <edge source="Structural Prediction Algorithm" target="Nankai Statistics">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics developed the structural prediction algorithm that serves nearly 100,000 users globally.</data>
      <data key="d9">development,service</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004244</data>
      <data key="d13" />
    </edge>
    <edge source="Structural Prediction Algorithm" target="Nearly 100,000 Users">
      <data key="d7">1.0</data>
      <data key="d8">The structural prediction algorithm has served nearly 100,000 users.</data>
      <data key="d9">service,user base</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004248</data>
      <data key="d13" />
    </edge>
    <edge source="Structural Prediction Algorithm" target="Over 100 Countries">
      <data key="d7">1.0</data>
      <data key="d8">The structural prediction algorithm serves users from over 100 countries.</data>
      <data key="d9">global reach,service scope</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004248</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Biomedical Interdisciplinary Field">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics continues to exert effort in the biomedical interdisciplinary field.</data>
      <data key="d9">involvement,research focus</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004245</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Biostatistics">
      <data key="d7">1.0</data>
      <data key="d8">The research directions of Nankai Statistics cover Biostatistics.</data>
      <data key="d9">coverage,research direction</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004246</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Bioinformatics">
      <data key="d7">1.0</data>
      <data key="d8">The research directions of Nankai Statistics cover Bioinformatics.</data>
      <data key="d9">coverage,research direction</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004246</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Mathematical Epidemiology">
      <data key="d7">1.0</data>
      <data key="d8">The research directions of Nankai Statistics cover Mathematical Epidemiology.</data>
      <data key="d9">coverage,research direction</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004246</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Nature Cancer">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published dozens of papers in authoritative biomedical journals including Nature Cancer.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004247</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Circulation">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published dozens of papers in authoritative biomedical journals including Circulation.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004247</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Gut">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published dozens of papers in authoritative biomedical journals including Gut.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004248</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Epidemic Situation Analysis Reports">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics produced multiple epidemic situation analysis reports that received instructions from national leaders.</data>
      <data key="d9">production,recognition</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004248</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="International Protein Structure And Function Prediction Competitions">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has won the championship multiple times in International Protein Structure and Function Prediction Competitions.</data>
      <data key="d9">achievement,participation</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004249</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Nankai University">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics is an academic unit affiliated with Nankai University.</data>
      <data key="d9">affiliation,part of</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004249</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Nature Communication">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published dozens of papers in authoritative biomedical journals including Nature Communication.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004250</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Over 50 Articles">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published over 50 articles in high-level SCI journals.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004250</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Cumulative Citations Of 3500+">
      <data key="d7">1.0</data>
      <data key="d8">The articles published by Nankai Statistics have been cited over 3500 times.</data>
      <data key="d9">citation,research impact</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004250</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Dozens Of Papers">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has published dozens of papers in authoritative biomedical journals.</data>
      <data key="d9">publication,research output</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004250</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai Statistics" target="Multiple Championships">
      <data key="d7">1.0</data>
      <data key="d8">Nankai Statistics has won multiple championships in international competitions.</data>
      <data key="d9">achievement,competition success</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004251</data>
      <data key="d13" />
    </edge>
    <edge source="Bioinformatics" target="Protein Design">
      <data key="d7">1.0</data>
      <data key="d8">Protein design is a research area within the broader domain of bioinformatics.</data>
      <data key="d9">domain,subfield</data>
      <data key="d10">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004544</data>
      <data key="d13" />
    </edge>
    <edge source="Nankai University" target="Nankai University News Center">
      <data key="d7">1.0</data>
      <data key="d8">Nankai University's News Center is responsible for designing and maintaining the website.</data>
      <data key="d9">management,oversight</data>
      <data key="d10">chunk-95ce0b0b365782f95d313a054721a437</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004246</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold 2" target="Protein Structure Prediction">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold 2 is an AI algorithm that provides the ability to predict protein structures accurately.</data>
      <data key="d9">capability,solution</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004309</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold 2" target="Fifty-Year Old Grand Challenge Of Biology">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold 2 solved the fifty-year old grand challenge of biology by predicting protein structures.</data>
      <data key="d9">breakthrough,solution</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004302</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold 2" target="MIT Technology Review">
      <data key="d7">1.0</data>
      <data key="d8">MIT Technology Review covered the story of AlphaFold 2's success and noted its significance in solving a grand challenge.</data>
      <data key="d9">coverage,scientific commentary</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004302</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaFold 2" target="Amino Acid Sequence">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold 2 predicts protein structures based on the constituent amino acid sequence.</data>
      <data key="d9">input data,prediction basis</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004303</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="Life Sciences">
      <data key="d7">1.0</data>
      <data key="d8">Accurate protein structure prediction is expected to have wide benefits in the life sciences space.</data>
      <data key="d9">application,benefit</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004301</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="Patent Data">
      <data key="d7">1.0</data>
      <data key="d8">The paper uses patent data as the basis for analyzing the global research status of protein structure prediction.</data>
      <data key="d9">data source,research analysis</data>
      <data key="d10">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004713</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="Application Trends">
      <data key="d7">1.0</data>
      <data key="d8">The paper analyzes application trends to understand the development trajectory of the protein structure prediction field.</data>
      <data key="d9">field monitoring,trend analysis</data>
      <data key="d10">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004713</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="Regional Distribution">
      <data key="d7">1.0</data>
      <data key="d8">The paper examines the regional distribution of research and patent activity in protein structure prediction.</data>
      <data key="d9">geographical analysis,global research</data>
      <data key="d10">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004714</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="Major Applicants">
      <data key="d7">1.0</data>
      <data key="d8">The paper identifies major applicants to understand who is leading innovation in protein structure prediction.</data>
      <data key="d9">innovation landscape,key players</data>
      <data key="d10">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004714</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="Technological Evolution">
      <data key="d7">1.0</data>
      <data key="d8">The paper studies the technological evolution to map how prediction methods have advanced over time.</data>
      <data key="d9">methodological change,progress tracking</data>
      <data key="d10">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004714</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="Opportunities And Challenges">
      <data key="d7">1.0</data>
      <data key="d8">The paper assesses the opportunities and challenges facing the future development of the protein structure prediction industry.</data>
      <data key="d9">future outlook,industry assessment</data>
      <data key="d10">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004715</data>
      <data key="d13" />
    </edge>
    <edge source="Protein Structure Prediction" target="High-Quality Development">
      <data key="d7">1.0</data>
      <data key="d8">The analysis aims to scientifically promote the high-quality development of the protein structure prediction industry.</data>
      <data key="d9">industry promotion,strategic goal</data>
      <data key="d10">chunk-cfa0a8834ed9c35960b3f0264cbc2d1d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004715</data>
      <data key="d13" />
    </edge>
    <edge source="Life Sciences" target="Drug Discovery">
      <data key="d7">1.0</data>
      <data key="d8">Accurate protein structure prediction is expected to accelerate advanced drug discovery within life sciences.</data>
      <data key="d9">acceleration,application</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004301</data>
      <data key="d13" />
    </edge>
    <edge source="Life Sciences" target="Disease Understanding">
      <data key="d7">1.0</data>
      <data key="d8">Accurate protein structure prediction is expected to enable better understanding of diseases within life sciences.</data>
      <data key="d9">application,improvement</data>
      <data key="d10">chunk-d23247c8edaf8929e7855d9186007c46</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004309</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习技术" target="基因组数据分析">
      <data key="d7">1.0</data>
      <data key="d8">深度学习技术被应用于基因组数据分析，旨在增强其准确性和处理能力。</data>
      <data key="d9">性能增强,技术应用</data>
      <data key="d10">chunk-8ac6b800c024bfc59d45d5769abdcb86</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004324</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习技术" target="交易员">
      <data key="d7">1.0</data>
      <data key="d8">Traders employ deep learning technology for data analysis and model-related activities.</data>
      <data key="d9">analytical capability,method application</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005004</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习技术" target="遥感图像">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning technology is implied to be a potential method for processing remote sensing images, which have inherent challenges.</data>
      <data key="d9">data processing,potential application</data>
      <data key="d10">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009452</data>
      <data key="d13" />
    </edge>
    <edge source="概念性框架" target="畜禽基因组学研究">
      <data key="d7">1.0</data>
      <data key="d8">构建的概念性框架旨在指导畜禽基因组学研究策略的发展。</data>
      <data key="d9">理论指导,策略发展</data>
      <data key="d10">chunk-8ac6b800c024bfc59d45d5769abdcb86</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004324</data>
      <data key="d13" />
    </edge>
    <edge source="MIT 6.874" target="麻省理工学院">
      <data key="d7">1.0</data>
      <data key="d8">麻省理工学院是MIT 6.874课程的开设机构。</data>
      <data key="d9">教育提供,课程开设</data>
      <data key="d10">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004342</data>
      <data key="d13" />
    </edge>
    <edge source="MIT 6.874" target="生命科学">
      <data key="d7">1.0</data>
      <data key="d8">MIT 6.874课程广泛介绍了生命科学领域的知识。</data>
      <data key="d9">课程内容,领域覆盖</data>
      <data key="d10">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004349</data>
      <data key="d13" />
    </edge>
    <edge source="MIT 6.874" target="基因组学">
      <data key="d7">1.0</data>
      <data key="d8">MIT 6.874课程介绍了基因组学领域的知识。</data>
      <data key="d9">专题介绍,课程内容</data>
      <data key="d10">chunk-dcad4a5abb7347f0e6403bab97eb576b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004342</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning In Life Sciences" target="Regulatory Genomics">
      <data key="d7">1.0</data>
      <data key="d8">Deep Learning in Life Sciences includes a lecture specifically focused on the topic of Regulatory Genomics.</data>
      <data key="d9">course content,lecture topic</data>
      <data key="d10">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004375</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning In Life Sciences" target="Spring 2021">
      <data key="d7">1.0</data>
      <data key="d8">The lecture series Deep Learning in Life Sciences was scheduled and offered during the Spring 2021 semester.</data>
      <data key="d9">academic schedule,course offering</data>
      <data key="d10">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004376</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning In Life Sciences" target="20.390">
      <data key="d7">1.0</data>
      <data key="d8">The lecture series Deep Learning in Life Sciences is identified by the course number 20.390.</data>
      <data key="d9">academic catalog,course identification</data>
      <data key="d10">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004376</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning In Life Sciences" target="20.490">
      <data key="d7">1.0</data>
      <data key="d8">The lecture series Deep Learning in Life Sciences is identified by the course number 20.490.</data>
      <data key="d9">academic catalog,course identification</data>
      <data key="d10">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004376</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning In Life Sciences" target="HST.506">
      <data key="d7">1.0</data>
      <data key="d8">The lecture series Deep Learning in Life Sciences is identified by the course number HST.506.</data>
      <data key="d9">academic catalog,course identification</data>
      <data key="d10">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004376</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning In Life Sciences" target="Prof.">
      <data key="d7">1.0</data>
      <data key="d8">Prof. is the instructor teaching the lecture series Deep Learning in Life Sciences.</data>
      <data key="d9">academic leadership,instruction</data>
      <data key="d10">chunk-41671c7e5bea6a9ae05e6b008b3a38f2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004377</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network" target="Protein">
      <data key="d7">1.0</data>
      <data key="d8">Deep neural networks are trained to predict the properties of proteins.</data>
      <data key="d9">prediction,property analysis</data>
      <data key="d10">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004397</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network" target="Gene Sequence">
      <data key="d7">1.0</data>
      <data key="d8">Deep neural networks use gene sequences as input data for making predictions.</data>
      <data key="d9">data processing,input</data>
      <data key="d10">chunk-7d901977dd7e6d929821ca079c401c7e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004397</data>
      <data key="d13" />
    </edge>
    <edge source="Multiple Sequence Alignment (MSA)" target="Traditional Tools">
      <data key="d7">1.0</data>
      <data key="d8">Some traditional tools utilize the Multiple Sequence Alignment (MSA) method.</data>
      <data key="d9">methodology,utilization</data>
      <data key="d10">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004424</data>
      <data key="d13" />
    </edge>
    <edge source="Traditional Tools" target="Physical Model">
      <data key="d7">1.0</data>
      <data key="d8">Traditional bioinformatics tools often depend on physical models for their analysis.</data>
      <data key="d9">methodology,reliance</data>
      <data key="d10">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004423</data>
      <data key="d13" />
    </edge>
    <edge source="Traditional Tools" target="Simple Machine Learning">
      <data key="d7">1.0</data>
      <data key="d8">Some traditional bioinformatics tools rely on simple machine learning techniques.</data>
      <data key="d9">methodology,reliance</data>
      <data key="d10">chunk-13f6a612ad21f33701d7916a1d76aa3e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004424</data>
      <data key="d13" />
    </edge>
    <edge source="Big Data" target="AI Tools">
      <data key="d7">1.0</data>
      <data key="d8">Big data enables the use of AI tools to solve scientific problems, representing a key direction in modern science.</data>
      <data key="d9">enabler,scientific method</data>
      <data key="d10">chunk-3692370e0fbe26ddf6ddebef5657ecc2</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004505</data>
      <data key="d13" />
    </edge>
    <edge source="Google DeepMind" target="AlphaDev">
      <data key="d7">1.0</data>
      <data key="d8">Google DeepMind trained the reinforcement learning agent AlphaDev.</data>
      <data key="d9">development,training</data>
      <data key="d10">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004525</data>
      <data key="d13" />
    </edge>
    <edge source="Google DeepMind" target="Gemini">
      <data key="d7">1.0</data>
      <data key="d8">Google DeepMind developed the Gemini model, a multimodal AI with advanced reasoning and generation capabilities.</data>
      <data key="d9">innovation,model development</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009420</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaDev" target="Sorting Program">
      <data key="d7">1.0</data>
      <data key="d8">AlphaDev was used to find better sorting programs.</data>
      <data key="d9">discovery,optimization</data>
      <data key="d10">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004525</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaDev" target="Small Sorting Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">AlphaDev discovered small sorting algorithms from scratch.</data>
      <data key="d9">creation,discovery</data>
      <data key="d10">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004525</data>
      <data key="d13" />
    </edge>
    <edge source="Small Sorting Algorithm" target="Human Benchmark">
      <data key="d7">1.0</data>
      <data key="d8">The small sorting algorithms discovered by AlphaDev outperformed previous human benchmarks.</data>
      <data key="d9">performance,superiority</data>
      <data key="d10">chunk-82b403277dd4d1f793acce70ac7e2f82</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004525</data>
      <data key="d13" />
    </edge>
    <edge source="David Baker" target="University Of Washington">
      <data key="d7">1.0</data>
      <data key="d8">David Baker is a professor at the University of Washington.</data>
      <data key="d9">affiliation,employment</data>
      <data key="d10">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004544</data>
      <data key="d13" />
    </edge>
    <edge source="David Baker" target="Protein Design">
      <data key="d7">1.0</data>
      <data key="d8">David Baker is a leading expert and conducts extensive research in the field of protein design.</data>
      <data key="d9">expertise,research focus</data>
      <data key="d10">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004545</data>
      <data key="d13" />
    </edge>
    <edge source="David Baker" target="Research Papers">
      <data key="d7">1.0</data>
      <data key="d8">David Baker is the author of over 700 research papers in the field of proteins.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004545</data>
      <data key="d13" />
    </edge>
    <edge source="David Baker" target="Citations">
      <data key="d7">1.0</data>
      <data key="d8">David Baker's research has accumulated a significant number of citations, indicating its impact.</data>
      <data key="d9">academic impact,research influence</data>
      <data key="d10">chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004545</data>
      <data key="d13" />
    </edge>
    <edge source="多序列比对" target="预测距离分布">
      <data key="d7">1.0</data>
      <data key="d8">Multiple sequence alignment is used to generate predicted distance distributions.</data>
      <data key="d9">data processing,feature generation</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004676</data>
      <data key="d13" />
    </edge>
    <edge source="多序列比对" target="二面角分布">
      <data key="d7">1.0</data>
      <data key="d8">Multiple sequence alignment is used to generate predicted dihedral angle distributions.</data>
      <data key="d9">data processing,feature generation</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004677</data>
      <data key="d13" />
    </edge>
    <edge source="预测距离分布" target="结构优化">
      <data key="d7">1.0</data>
      <data key="d8">Predicted distance distributions are used as constraints during structure optimization.</data>
      <data key="d9">constraint application,model refinement</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004677</data>
      <data key="d13" />
    </edge>
    <edge source="二面角分布" target="结构优化">
      <data key="d7">1.0</data>
      <data key="d8">Predicted dihedral angle distributions are used as constraints during structure optimization.</data>
      <data key="d9">constraint application,model refinement</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004678</data>
      <data key="d13" />
    </edge>
    <edge source="Alphafold2" target="End-to-end架构">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 is built using an end-to-end architecture.</data>
      <data key="d9">architectural feature,model design</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004674</data>
      <data key="d13" />
    </edge>
    <edge source="Alphafold2" target="3D Equivariant Structure Module">
      <data key="d7">1.0</data>
      <data key="d8">The 3D Equivariant Structure Module is a key component of AlphaFold2 responsible for generating the 3D structure.</data>
      <data key="d9">core component,structure prediction</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004674</data>
      <data key="d13" />
    </edge>
    <edge source="Alphafold2" target="Evoformer">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 contains an Evoformer module for processing multiple sequence alignments and template information.</data>
      <data key="d9">feature extraction,processing module</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004675</data>
      <data key="d13" />
    </edge>
    <edge source="Alphafold2" target="Recycling多轮迭代">
      <data key="d7">1.0</data>
      <data key="d8">AlphaFold2 employs a recycling process of multiple iterations to refine its structure predictions.</data>
      <data key="d9">iterative optimization,refinement process</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004676</data>
      <data key="d13" />
    </edge>
    <edge source="Alphafold2" target="主要特点">
      <data key="d7">1.0</data>
      <data key="d8">The key features listed describe the architectural characteristics of AlphaFold2.</data>
      <data key="d9">feature listing,model description</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004678</data>
      <data key="d13" />
    </edge>
    <edge source="Alphafold2" target="Chapter1">
      <data key="d7">1.0</data>
      <data key="d8">Chapter1 of the document introduces the overall architecture of AlphaFold2.</data>
      <data key="d9">document structure,topic introduction</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004680</data>
      <data key="d13" />
    </edge>
    <edge source="3D Equivariant Structure Module" target="IPA (Invariant Point Attention)">
      <data key="d7">1.0</data>
      <data key="d8">The IPA (Invariant Point Attention) is a crucial part of the 3D Equivariant Structure Module that ensures equivariance.</data>
      <data key="d9">architectural implementation,sub-component</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004675</data>
      <data key="d13" />
    </edge>
    <edge source="3D Equivariant Structure Module" target="Residue Gas">
      <data key="d7">1.0</data>
      <data key="d8">The Structure Module uses the Residue Gas representation to model the protein backbone.</data>
      <data key="d9">input format,structural representation</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004675</data>
      <data key="d13" />
    </edge>
    <edge source="3D Equivariant Structure Module" target="序列信息">
      <data key="d7">1.0</data>
      <data key="d8">The Structure Module takes sequence information of the target protein as one of its inputs.</data>
      <data key="d9">data input,model processing</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004676</data>
      <data key="d13" />
    </edge>
    <edge source="3D Equivariant Structure Module" target="Distance Map信息">
      <data key="d7">1.0</data>
      <data key="d8">The Structure Module uses predicted distance map information as an input.</data>
      <data key="d9">constraint utilization,data input</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004677</data>
      <data key="d13" />
    </edge>
    <edge source="3D Equivariant Structure Module" target="蛋白质骨架初始Residue Gas">
      <data key="d7">1.0</data>
      <data key="d8">The Structure Module is initialized with a starting Residue Gas representation of the protein backbone.</data>
      <data key="d9">initial state,structural input</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004678</data>
      <data key="d13" />
    </edge>
    <edge source="3D Equivariant Structure Module" target="全原子的位置坐标">
      <data key="d7">1.0</data>
      <data key="d8">The primary output of the Structure Module is the full set of atomic position coordinates for the protein.</data>
      <data key="d9">model output,prediction result</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004680</data>
      <data key="d13" />
    </edge>
    <edge source="3D Equivariant Structure Module" target="lDDT-Cα">
      <data key="d7">1.0</data>
      <data key="d8">The Structure Module outputs an lDDT-Cα score to assess the accuracy of its predicted structure.</data>
      <data key="d9">accuracy assessment,output metric</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004681</data>
      <data key="d13" />
    </edge>
    <edge source="CASP14" target="DeepMind slides">
      <data key="d7">1.0</data>
      <data key="d8">The slides containing the picture were presented by DeepMind at the CASP14 event.</data>
      <data key="d9">event context,presentation material</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004679</data>
      <data key="d13" />
    </edge>
    <edge source="Jumper, J" target="Alphafold模型架构">
      <data key="d7">1.0</data>
      <data key="d8">Jumper, J is an author who documented the AlphaFold model architecture in the Nature paper.</data>
      <data key="d9">authorship,model documentation</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004682</data>
      <data key="d13" />
    </edge>
    <edge source="IPA (Invariant Point Attention)" target="重要架构">
      <data key="d7">1.0</data>
      <data key="d8">IPA is listed as an important architectural component.</data>
      <data key="d9">architectural element,component listing</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004680</data>
      <data key="d13" />
    </edge>
    <edge source="Residue Gas" target="Protein backbone = gas of 3-D rigid bodies">
      <data key="d7">1.0</data>
      <data key="d8">The equation defines the Residue Gas as representing the protein backbone as a gas of 3D rigid bodies.</data>
      <data key="d9">conceptual definition,representation explanation</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004680</data>
      <data key="d13" />
    </edge>
    <edge source="Residue Gas" target="重要架构">
      <data key="d7">1.0</data>
      <data key="d8">Residue Gas is listed as an important architectural component.</data>
      <data key="d9">architectural element,component listing</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004682</data>
      <data key="d13" />
    </edge>
    <edge source="序列信息" target="输入">
      <data key="d7">1.0</data>
      <data key="d8">Sequence information is specified as one of the inputs to the Structure Module.</data>
      <data key="d9">data specification,module requirement</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004681</data>
      <data key="d13" />
    </edge>
    <edge source="Distance Map信息" target="输入">
      <data key="d7">1.0</data>
      <data key="d8">Distance map information is specified as one of the inputs to the Structure Module.</data>
      <data key="d9">data specification,module requirement</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004682</data>
      <data key="d13" />
    </edge>
    <edge source="蛋白质骨架初始Residue Gas" target="输入">
      <data key="d7">1.0</data>
      <data key="d8">The initial Residue Gas for the protein backbone is specified as an input to the Structure Module.</data>
      <data key="d9">data specification,module requirement</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004683</data>
      <data key="d13" />
    </edge>
    <edge source="全原子的位置坐标" target="输出">
      <data key="d7">1.0</data>
      <data key="d8">Full atomic position coordinates are specified as an output of the Structure Module.</data>
      <data key="d9">module product,result specification</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004682</data>
      <data key="d13" />
    </edge>
    <edge source="lDDT-Cα" target="输出">
      <data key="d7">1.0</data>
      <data key="d8">The lDDT-Cα score is specified as an output of the Structure Module.</data>
      <data key="d9">module product,result specification</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004683</data>
      <data key="d13" />
    </edge>
    <edge source="Evoformer" target="更强大的MSA &amp; Templates">
      <data key="d7">1.0</data>
      <data key="d8">More powerful MSA and template data are processed by the Evoformer module.</data>
      <data key="d9">data processing,module input</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004682</data>
      <data key="d13" />
    </edge>
    <edge source="Evoformer" target="用于结构预测的Attention架构">
      <data key="d7">1.0</data>
      <data key="d8">The description "Attention architecture for structure prediction" refers to the Evoformer module.</data>
      <data key="d9">architectural description,module identification</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004683</data>
      <data key="d13" />
    </edge>
    <edge source="Recycling多轮迭代" target="多输出">
      <data key="d7">1.0</data>
      <data key="d8">The recycling iteration process refines the model to produce multiple outputs.</data>
      <data key="d9">process refinement,result generation</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004683</data>
      <data key="d13" />
    </edge>
    <edge source="Chapter2" target="Alphafold模型架构">
      <data key="d7">1.0</data>
      <data key="d8">Chapter2 of the document provides a detailed explanation of the AlphaFold model architecture.</data>
      <data key="d9">detailed explanation,document structure</data>
      <data key="d10">chunk-224a7273b9442fd233a7ec61f799fa44</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004680</data>
      <data key="d13" />
    </edge>
    <edge source="Deep-Algotrading" target="Regression Analysis">
      <data key="d7">1.0</data>
      <data key="d8">The Deep-Algotrading resource repository covers regression analysis as a simple, foundational topic for learners.</data>
      <data key="d9">educational coverage,foundational topic</data>
      <data key="d10">chunk-201fcd200de194e722ae83a479174b8b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004750</data>
      <data key="d13" />
    </edge>
    <edge source="Deep-Algotrading" target="Time Series Forecasting">
      <data key="d7">1.0</data>
      <data key="d8">The Deep-Algotrading resource repository covers time series forecasting as a complex topic for learners.</data>
      <data key="d9">advanced topic,educational coverage</data>
      <data key="d10">chunk-201fcd200de194e722ae83a479174b8b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004751</data>
      <data key="d13" />
    </edge>
    <edge source="Time Series Forecasting" target="LSTM">
      <data key="d7">1.0</data>
      <data key="d8">LSTM is presented as a specific, complex technique used within the broader domain of time series forecasting.</data>
      <data key="d9">model architecture,technique implementation</data>
      <data key="d10">chunk-201fcd200de194e722ae83a479174b8b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004750</data>
      <data key="d13" />
    </edge>
    <edge source="LSTM" target="上下文特征">
      <data key="d7">1.0</data>
      <data key="d8">LSTM模型能够捕捉和学习上下文特征。</data>
      <data key="d9">学习,捕捉</data>
      <data key="d10">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007014</data>
      <data key="d13" />
    </edge>
    <edge source="LSTM" target="GRU">
      <data key="d7">1.0</data>
      <data key="d8">GRU比LSTM算法稍微简单，在层次深或复杂时运算效率更高，但实际精度可能稍差。</data>
      <data key="d9">效率与精度,比较</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007044</data>
      <data key="d13" />
    </edge>
    <edge source="LSTM" target="Bi-LSTM">
      <data key="d7">1.0</data>
      <data key="d8">Bi-LSTM是一种双向的LSTM，可以学到前后上下文的特征和语义。</data>
      <data key="d9">双向学习,扩展</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007050</data>
      <data key="d13" />
    </edge>
    <edge source="LSTM" target="Context">
      <data key="d7">1.0</data>
      <data key="d8">LSTM networks are capable of learning long-range contextual information, which is beneficial for recognition tasks.</data>
      <data key="d9">learns,long-range dependency</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007084</data>
      <data key="d13" />
    </edge>
    <edge source="Reinforcement Learning" target="Financial Data">
      <data key="d7">1.0</data>
      <data key="d8">Reinforcement learning methods are described as utilizing financial data for their application in algorithmic trading.</data>
      <data key="d9">data utilization,method application</data>
      <data key="d10">chunk-201fcd200de194e722ae83a479174b8b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004750</data>
      <data key="d13" />
    </edge>
    <edge source="Market Participants" target="Algorithmic Trading">
      <data key="d7">1.0</data>
      <data key="d8">Market participants have a widespread demand for algorithmic trading.</data>
      <data key="d9">application,demand</data>
      <data key="d10">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004771</data>
      <data key="d13" />
    </edge>
    <edge source="Algorithmic Trading" target="Deep Reinforcement Learning (DRL)">
      <data key="d7">1.0</data>
      <data key="d8">Deep Reinforcement Learning is used as a perspective to analyze and implement algorithmic trading.</data>
      <data key="d9">analysis,implementation</data>
      <data key="d10">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004772</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Reinforcement Learning (DRL)" target="Strategy Inputs And Outputs">
      <data key="d7">1.0</data>
      <data key="d8">Strategy inputs and outputs are part of the analysis of algorithmic trading from a Deep Reinforcement Learning perspective.</data>
      <data key="d9">framework component,modeling</data>
      <data key="d10">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004771</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Reinforcement Learning (DRL)" target="Incentive Function">
      <data key="d7">1.0</data>
      <data key="d8">The incentive function is a key component within the Deep Reinforcement Learning framework for optimizing algorithmic trading strategies.</data>
      <data key="d9">framework component,optimization</data>
      <data key="d10">chunk-001d35968d5312a9b345486c646a5cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004771</data>
      <data key="d13" />
    </edge>
    <edge source="Back-Testing Results" target="High-Frequency Trading Strategy">
      <data key="d7">1.0</data>
      <data key="d8">The high-frequency trading strategy is evaluated through back-testing results to measure its effectiveness.</data>
      <data key="d9">performance evaluation,strategy validation</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004805</data>
      <data key="d13" />
    </edge>
    <edge source="Back-Testing Results" target="交易次数">
      <data key="d7">1.0</data>
      <data key="d8">Back-testing results include the metric for number of trades.</data>
      <data key="d9">data component,performance metric</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004806</data>
      <data key="d13" />
    </edge>
    <edge source="Back-Testing Results" target="胜率">
      <data key="d7">1.0</data>
      <data key="d8">Back-testing results include the metric for win rate.</data>
      <data key="d9">data component,performance metric</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004806</data>
      <data key="d13" />
    </edge>
    <edge source="Back-Testing Results" target="平均盈利">
      <data key="d7">1.0</data>
      <data key="d8">Back-testing results include the metric for average profit.</data>
      <data key="d9">data component,performance metric</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004807</data>
      <data key="d13" />
    </edge>
    <edge source="Back-Testing Results" target="平均亏损">
      <data key="d7">1.0</data>
      <data key="d8">Back-testing results include the metric for average loss.</data>
      <data key="d9">data component,performance metric</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004807</data>
      <data key="d13" />
    </edge>
    <edge source="Back-Testing Results" target="盈亏比">
      <data key="d7">1.0</data>
      <data key="d8">Back-testing results include the metric for profit-to-loss ratio.</data>
      <data key="d9">data component,performance metric</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004815</data>
      <data key="d13" />
    </edge>
    <edge source="Back-Testing Results" target="期望收益">
      <data key="d7">1.0</data>
      <data key="d8">Back-testing results include the metric for expected return.</data>
      <data key="d9">data component,performance metric</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004807</data>
      <data key="d13" />
    </edge>
    <edge source="High-Frequency Trading Strategy" target="ANN">
      <data key="d7">1.0</data>
      <data key="d8">ANN serves as the underlying algorithmic model for one version of the high-frequency trading strategy.</data>
      <data key="d9">algorithmic basis,model implementation</data>
      <data key="d10">chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004806</data>
      <data key="d13" />
    </edge>
    <edge source="High-Frequency Trading Strategy" target="Deep Learning Model">
      <data key="d7">1.0</data>
      <data key="d8">The high-speed demands of high-frequency trading strategies create significant barriers to applying deep learning models.</data>
      <data key="d9">application barrier,technical requirement</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004968</data>
      <data key="d13" />
    </edge>
    <edge source="高頻交易" target="深度學習模型">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models are applied in high-frequency trading to process massive micro-market data and classify signals for predicting short-term price movements.</data>
      <data key="d9">data processing,signal classification</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004950</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習模型" target="微觀市場結構數據">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models process vast amounts of micro-market structure data, such as order book changes and bid-ask spreads, in real-time.</data>
      <data key="d9">data processing,real-time analysis</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004960</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習模型" target="多因子模型">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models are used within multi-factor models to predict the future effectiveness of specific factors, aiding in dynamic strategy adjustment.</data>
      <data key="d9">factor prediction,strategy adaptation</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004954</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習模型" target="投資組合">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models are used for portfolio optimization by predicting correlations, volatility, and expected returns among different assets.</data>
      <data key="d9">asset allocation,portfolio optimization</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004955</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習模型" target="套利機會">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models classify high-frequency signals to predict short-term price movements, which is crucial for capturing fleeting arbitrage opportunities.</data>
      <data key="d9">opportunity capture,signal prediction</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004956</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習模型" target="資料品質">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models typically require large, high-quality datasets for effective training, posing a challenge in financial applications.</data>
      <data key="d9">data dependency,training requirement</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004957</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習模型" target="樣本數限制">
      <data key="d7">1.0</data>
      <data key="d8">A significant limitation for applying deep learning in finance is the sample size restriction, as these models need vast amounts of data.</data>
      <data key="d9">data scarcity,training challenge</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004958</data>
      <data key="d13" />
    </edge>
    <edge source="自動編碼器" target="風險管理">
      <data key="d7">1.0</data>
      <data key="d8">Autoencoder models are applied in risk management to learn normal market data patterns and detect significant deviations for risk warnings.</data>
      <data key="d9">anomaly detection,risk warning</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004950</data>
      <data key="d13" />
    </edge>
    <edge source="另類數據" target="自然語言處理">
      <data key="d7">1.0</data>
      <data key="d8">Natural Language Processing (NLP), a branch of deep learning, analyzes alternative data like news and social media text to extract market sentiment and trends.</data>
      <data key="d9">information extraction,text analysis</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004951</data>
      <data key="d13" />
    </edge>
    <edge source="自然語言處理" target="深度學習">
      <data key="d7">1.0</data>
      <data key="d8">自然語言處理機制建立在深度學習之上，使其能夠進行更精準的上下文理解和情感分析。</data>
      <data key="d9">技術基礎,機制建立</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006630</data>
      <data key="d13" />
    </edge>
    <edge source="自然語言處理" target="情感分析">
      <data key="d7">1.0</data>
      <data key="d8">建立在深度學習上的自然語言處理機制可以更精準地進行情感分析，判斷使用者的搜尋意圖和感受。</data>
      <data key="d9">功能實現,精準度提升</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006645</data>
      <data key="d13" />
    </edge>
    <edge source="自然語言處理" target="孫民">
      <data key="d7">1.0</data>
      <data key="d8">孫民表示自然語言處理能提高情感分析精確度，但也指出其在文本生成方面的不穩定性和對訓練資料質量的依賴。</data>
      <data key="d9">優勢與挑戰,專家評價</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006652</data>
      <data key="d13" />
    </edge>
    <edge source="自然語言處理" target="詞向量">
      <data key="d7">1.0</data>
      <data key="d8">詞向量作為自然語言處理的應用，可以幫助企業避免錯失與搜尋特定關鍵字(如「宿霧」和「潛水」)的消費者互動的機會。</data>
      <data key="d9">技術應用,避免遺漏</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006650</data>
      <data key="d13" />
    </edge>
    <edge source="長短期記憶網路" target="時間序列數據">
      <data key="d7">1.0</data>
      <data key="d8">LSTM networks are particularly skilled at processing and predicting time series data, effectively capturing long-term dependencies in financial sequences.</data>
      <data key="d9">dependency capture,time series prediction</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004951</data>
      <data key="d13" />
    </edge>
    <edge source="長短期記憶網路" target="梯度消失/爆炸問題">
      <data key="d7">1.0</data>
      <data key="d8">LSTM's internal gating mechanism effectively addresses the vanishing/exploding gradient problem common in traditional RNNs.</data>
      <data key="d9">model improvement,problem mitigation</data>
      <data key="d10">chunk-82bdb1406dfe17a400fa95a5a4727859</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004953</data>
      <data key="d13" />
    </edge>
    <edge source="量化交易" target="基本面分析">
      <data key="d7">1.0</data>
      <data key="d8">Fundamental analysis is a traditional method relied upon in quantitative trading strategies.</data>
      <data key="d9">strategy component,traditional method</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004959</data>
      <data key="d13" />
    </edge>
    <edge source="量化交易" target="统计模型">
      <data key="d7">1.0</data>
      <data key="d8">Statistical models are traditional methods relied upon in quantitative trading strategies.</data>
      <data key="d9">strategy component,traditional method</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004961</data>
      <data key="d13" />
    </edge>
    <edge source="量化交易" target="象牙山李宝库">
      <data key="d7">1.0</data>
      <data key="d8">The user '象牙山李宝库' discussed the field of quantitative trading.</data>
      <data key="d9">讨论主题,金融实践</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005177</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="大语言模型">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型是由深度神经网络构建的。</data>
      <data key="d9">实现,构建</data>
      <data key="d10">chunk-3678971988880bb3960a90e15878444d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008637</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="遥感图像分类">
      <data key="d7">1.0</data>
      <data key="d8">深度神经网络被应用于执行遥感图像分类任务。</data>
      <data key="d9">任务执行,方法应用</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009491</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="目标检测">
      <data key="d7">1.0</data>
      <data key="d8">深度神经网络被应用于执行目标检测任务。</data>
      <data key="d9">任务执行,方法应用</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009492</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="语义分割">
      <data key="d7">1.0</data>
      <data key="d8">深度神经网络被应用于执行语义分割任务。</data>
      <data key="d9">任务执行,方法应用</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009495</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="变化检测">
      <data key="d7">1.0</data>
      <data key="d8">深度神经网络被应用于执行变化检测任务。</data>
      <data key="d9">任务执行,方法应用</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009495</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="多模态数据">
      <data key="d7">1.0</data>
      <data key="d8">多模态数据可以与深度神经网络结合，以提升遥感分析的性能。</data>
      <data key="d9">数据融合,方法增强</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009497</data>
      <data key="d13" />
    </edge>
    <edge source="深度神经网络" target="本研究">
      <data key="d7">1.0</data>
      <data key="d8">本研究对深度神经网络在遥感领域的应用进行了系统的综述和分析。</data>
      <data key="d9">研究主题,综述分析</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009498</data>
      <data key="d13" />
    </edge>
    <edge source="长短期记忆网络" target="时间序列数据">
      <data key="d7">1.0</data>
      <data key="d8">Long Short-Term Memory networks (LSTM) are applied to capture complex relationships and long-term dependencies within time series data.</data>
      <data key="d9">data processing,model application</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004956</data>
      <data key="d13" />
    </edge>
    <edge source="长短期记忆网络" target="价格预测">
      <data key="d7">1.0</data>
      <data key="d8">Long Short-Term Memory networks (LSTM) are used for the application of price prediction in quantitative trading.</data>
      <data key="d9">model application,prediction task</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004957</data>
      <data key="d13" />
    </edge>
    <edge source="长短期记忆网络" target="细胞状态">
      <data key="d7">1.0</data>
      <data key="d8">长短期记忆网络通过细胞状态来存储长期信息，这是其区别于传统循环神经网络的关键。</data>
      <data key="d9">信息存储,核心组件</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007101</data>
      <data key="d13" />
    </edge>
    <edge source="长短期记忆网络" target="文本分类">
      <data key="d7">1.0</data>
      <data key="d8">长短期记忆网络能够记忆长短期语义信息，对文本分类等序列建模任务中的特征选择有很大帮助。</data>
      <data key="d9">序列建模,特征选择</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007107</data>
      <data key="d13" />
    </edge>
    <edge source="金融领域" target="本文的方法">
      <data key="d7">1.0</data>
      <data key="d8">The method presented in the text shows broad future prospects for application in the financial sector.</data>
      <data key="d9">application,future prospects</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006191</data>
      <data key="d13" />
    </edge>
    <edge source="金融领域" target="系统">
      <data key="d7">1.0</data>
      <data key="d8">The system enhances fraud detection capabilities, indicating its application in the financial sector.</data>
      <data key="d9">application,fraud detection</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006196</data>
      <data key="d13" />
    </edge>
    <edge source="特征工程" target="TF-IDF">
      <data key="d7">2.0</data>
      <data key="d8">特征工程中会根据TF-IDF等方式去算特征值或对特征进行过滤排序。&lt;SEP&gt;在传统机器学习的特征工程中，会使用TF-IDF等方法来计算特征值。</data>
      <data key="d9">使用工具,特征计算,特征过滤,计算方法</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007021</data>
      <data key="d13" />
    </edge>
    <edge source="特征工程" target="互信息">
      <data key="d7">2.0</data>
      <data key="d8">特征工程中会根据互信息等方式去算特征值或对特征进行过滤排序。&lt;SEP&gt;互信息是特征工程中用于特征过滤和选择的一种方法。</data>
      <data key="d9">使用工具,特征过滤,特征选择,计算方法</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007026</data>
      <data key="d13" />
    </edge>
    <edge source="特征工程" target="信息增益">
      <data key="d7">2.0</data>
      <data key="d8">特征工程中会根据信息增益等方式去算特征值或对特征进行过滤排序。&lt;SEP&gt;信息增益是特征工程中用于评估特征重要性的指标之一。</data>
      <data key="d9">使用工具,特征过滤,特征选择,计算方法</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007029</data>
      <data key="d13" />
    </edge>
    <edge source="特征工程" target="传统机器学习">
      <data key="d7">1.0</data>
      <data key="d8">传统机器学习90%的时间会花在特征工程上。</data>
      <data key="d9">时间消耗,核心过程</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007037</data>
      <data key="d13" />
    </edge>
    <edge source="特征工程" target="经典机器学习">
      <data key="d7">1.0</data>
      <data key="d8">经典机器学习90%的时间会花在特征工程上。</data>
      <data key="d9">时间消耗,核心过程</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007042</data>
      <data key="d13" />
    </edge>
    <edge source="价格预测" target="开盘价">
      <data key="d7">1.0</data>
      <data key="d8">Opening price data is used as part of the historical time series input for price prediction models.</data>
      <data key="d9">data utilization,prediction input</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004960</data>
      <data key="d13" />
    </edge>
    <edge source="价格预测" target="收盘价">
      <data key="d7">1.0</data>
      <data key="d8">Closing price data is used as both input and a prediction target in price forecasting models.</data>
      <data key="d9">data utilization,prediction input and target</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004961</data>
      <data key="d13" />
    </edge>
    <edge source="价格预测" target="最高价">
      <data key="d7">1.0</data>
      <data key="d8">Highest price data is used as part of the historical time series input for price prediction models.</data>
      <data key="d9">data utilization,prediction input</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004962</data>
      <data key="d13" />
    </edge>
    <edge source="价格预测" target="最低价">
      <data key="d7">1.0</data>
      <data key="d8">Lowest price data is used as part of the historical time series input for price prediction models.</data>
      <data key="d9">data utilization,prediction input</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004970</data>
      <data key="d13" />
    </edge>
    <edge source="价格预测" target="成交量">
      <data key="d7">1.0</data>
      <data key="d8">Trading volume data is used as part of the historical time series input for price prediction models.</data>
      <data key="d9">data utilization,prediction input</data>
      <data key="d10">chunk-279be5ddf8d39d85d83b28cea5971411</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004964</data>
      <data key="d13" />
    </edge>
    <edge source="高频交易" target="象牙山李宝库">
      <data key="d7">1.0</data>
      <data key="d8">The user mentioned high-frequency trading as a specific type within quantitative trading, requiring a large team and high mathematical modeling skills.</data>
      <data key="d9">具体类型,团队要求</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005180</data>
      <data key="d13" />
    </edge>
    <edge source="Autoencoder" target="Risk Management Module">
      <data key="d7">1.0</data>
      <data key="d8">Autoencoder is applied within the risk management module to detect data anomalies.</data>
      <data key="d9">anomaly detection,application</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004963</data>
      <data key="d13" />
    </edge>
    <edge source="Autoencoder" target="Market Risk">
      <data key="d7">1.0</data>
      <data key="d8">Autoencoder helps identify market risk by detecting anomalies in financial data.</data>
      <data key="d9">identification,risk detection</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004963</data>
      <data key="d13" />
    </edge>
    <edge source="Autoencoder" target="Fraudulent Behavior">
      <data key="d7">1.0</data>
      <data key="d8">Autoencoder assists in detecting fraudulent behavior by identifying anomalous patterns in data.</data>
      <data key="d9">detection,security</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004965</data>
      <data key="d13" />
    </edge>
    <edge source="Autoencoder" target="Reconstruction Error">
      <data key="d7">1.0</data>
      <data key="d8">Autoencoder uses reconstruction error as a metric to judge whether data is anomalous.</data>
      <data key="d9">anomaly detection,measurement</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004970</data>
      <data key="d13" />
    </edge>
    <edge source="Autoencoder" target="Variational Autoencoder">
      <data key="d7">1.0</data>
      <data key="d8">The variational autoencoder is a specific variant of the autoencoder, designed as a generative model.</data>
      <data key="d9">generative model,variant</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009225</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Financial Market Data">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models require large amounts of financial market data for training, but this data often has quality issues.</data>
      <data key="d9">data requirement,training dependency</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004963</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Black Box Problem">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models suffer from the black box problem, making their decisions difficult to interpret.</data>
      <data key="d9">characteristic,interpretability challenge</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004966</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Real-Time Trading">
      <data key="d7">1.0</data>
      <data key="d8">Deploying deep learning models in real-time trading environments poses high computational and latency challenges.</data>
      <data key="d9">deployment challenge,performance requirement</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004967</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Market Non-Stationarity">
      <data key="d7">1.0</data>
      <data key="d8">The non-stationary nature of financial markets challenges deep learning models, requiring continuous adaptation.</data>
      <data key="d9">adaptation challenge,environmental factor</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004970</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Hybrid Strategy">
      <data key="d7">1.0</data>
      <data key="d8">A hybrid strategy integrates deep learning models as auxiliary tools with traditional methods to enhance robustness.</data>
      <data key="d9">integration,robustness enhancement</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004971</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Backtesting">
      <data key="d7">1.0</data>
      <data key="d8">Backtesting is a strict validation process used to assess the historical performance of strategies involving deep learning models.</data>
      <data key="d9">performance assessment,validation</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004972</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Forward Testing">
      <data key="d7">1.0</data>
      <data key="d8">Forward testing validates deep learning models in a simulated real-time environment before full deployment.</data>
      <data key="d9">real-time simulation,validation</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004980</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Model" target="Model Monitoring Mechanism">
      <data key="d7">1.0</data>
      <data key="d8">A model monitoring mechanism is implemented to oversee and ensure the stability of deployed deep learning models.</data>
      <data key="d9">oversight,stability assurance</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004973</data>
      <data key="d13" />
    </edge>
    <edge source="Black Box Problem" target="Explainable AI (XAI)">
      <data key="d7">1.0</data>
      <data key="d8">Explainable AI (XAI) is a developing field aimed at solving the black box problem of deep learning models.</data>
      <data key="d9">interpretability enhancement,solution</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004975</data>
      <data key="d13" />
    </edge>
    <edge source="Modular Strategy Architecture" target="Signal Generation Module">
      <data key="d7">1.0</data>
      <data key="d8">Modular strategy architecture includes a signal generation module, which can be powered by deep learning.</data>
      <data key="d9">design component,functional decomposition</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004966</data>
      <data key="d13" />
    </edge>
    <edge source="Modular Strategy Architecture" target="Capital Allocation Module">
      <data key="d7">1.0</data>
      <data key="d8">Modular strategy architecture includes a capital allocation module, which can use traditional optimization methods.</data>
      <data key="d9">design component,functional decomposition</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004967</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-Modal Learning" target="Quantitative Trading">
      <data key="d7">1.0</data>
      <data key="d8">Multi-Modal Learning is identified as an important development direction for building a more comprehensive market view in quantitative trading.</data>
      <data key="d9">data integration,market analysis</data>
      <data key="d10">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004971</data>
      <data key="d13" />
    </edge>
    <edge source="Federated Learning" target="Financial Institution">
      <data key="d7">1.0</data>
      <data key="d8">Federated learning is a technique that may enable collaboration between financial institutions while protecting data privacy.</data>
      <data key="d9">collaboration enabler,privacy protection</data>
      <data key="d10">chunk-2dc1c848682669d15114cbb84e3cd6b4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004969</data>
      <data key="d13" />
    </edge>
    <edge source="Federated Learning" target="Quantitative Trading">
      <data key="d7">1.0</data>
      <data key="d8">Federated Learning is a technology that can play a significant role in collaborations between financial institutions within the quantitative trading landscape.</data>
      <data key="d9">data privacy,financial collaboration</data>
      <data key="d10">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004971</data>
      <data key="d13" />
    </edge>
    <edge source="Arthur" target="Documentation">
      <data key="d7">1.0</data>
      <data key="d8">Arthur is the author who created the documentation content discussing advanced learning methods in finance.</data>
      <data key="d9">authorship,content creation</data>
      <data key="d10">chunk-d9ecda3ea425b03f3129938c0ba44219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769004971</data>
      <data key="d13" />
    </edge>
    <edge source="Gpu" target="交易员">
      <data key="d7">1.0</data>
      <data key="d8">Traders use advanced GPU technology to execute complex financial data tasks.</data>
      <data key="d9">performance enhancement,technology utilization</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005003</data>
      <data key="d13" />
    </edge>
    <edge source="交易员" target="高强度计算平台">
      <data key="d7">1.0</data>
      <data key="d8">Traders operate on a high-intensity computing platform to perform data exploration, model development, and model consumption.</data>
      <data key="d9">platform operation,task execution</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005005</data>
      <data key="d13" />
    </edge>
    <edge source="Kinetica数据库" target="高强度计算平台">
      <data key="d7">1.0</data>
      <data key="d8">The high-intensity computing platform is equipped with the Kinetica database for handling financial data.</data>
      <data key="d9">data management,system integration</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005003</data>
      <data key="d13" />
    </edge>
    <edge source="Nvidia Gpu" target="高强度计算平台">
      <data key="d7">1.0</data>
      <data key="d8">The high-intensity computing platform incorporates NVIDIA GPUs to provide the necessary computational power.</data>
      <data key="d9">computational power,hardware integration</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005004</data>
      <data key="d13" />
    </edge>
    <edge source="高强度计算平台" target="数据探索">
      <data key="d7">1.0</data>
      <data key="d8">Data exploration is one of the heavy tasks executed on the high-intensity computing platform.</data>
      <data key="d9">platform capability,process execution</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005005</data>
      <data key="d13" />
    </edge>
    <edge source="高强度计算平台" target="模型开发/评分">
      <data key="d7">1.0</data>
      <data key="d8">Model development and scoring are performed on the high-intensity computing platform.</data>
      <data key="d9">platform capability,process execution</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005005</data>
      <data key="d13" />
    </edge>
    <edge source="高强度计算平台" target="模型消耗">
      <data key="d7">1.0</data>
      <data key="d8">Model consumption is executed on the high-intensity computing platform.</data>
      <data key="d9">platform capability,process execution</data>
      <data key="d10">chunk-858e73004375c211a45ff338fb81b219</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005005</data>
      <data key="d13" />
    </edge>
    <edge source="金融学" target="风控建模方法">
      <data key="d7">1.0</data>
      <data key="d8">该风控建模方法属于金融学领域。</data>
      <data key="d9">学科归属,应用领域</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005218</data>
      <data key="d13" />
    </edge>
    <edge source="量化投资" target="基股传声">
      <data key="d7">1.0</data>
      <data key="d8">“基股传声”作为作者，在雪球平台上分享其在量化投资领域的个人研发经验和观点。</data>
      <data key="d9">经验分享,职业领域</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005169</data>
      <data key="d13" />
    </edge>
    <edge source="中低频量化" target="线性模型">
      <data key="d7">1.0</data>
      <data key="d8">在中低频量化中，传统的线性模型被作为基准，其表现优于作者尝试的各种机器学习模型。</data>
      <data key="d9">优势,基准比较</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005168</data>
      <data key="d13" />
    </edge>
    <edge source="中低频量化" target="信噪比">
      <data key="d7">1.0</data>
      <data key="d8">作者认为中低频量化信噪比太低，是导致机器学习模型效果不佳的原因之一。</data>
      <data key="d9">原因分析,限制因素</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005168</data>
      <data key="d13" />
    </edge>
    <edge source="中低频量化" target="数据量">
      <data key="d7">1.0</data>
      <data key="d8">作者认为中低频量化可用的数据量太少，是导致机器学习模型效果不佳的另一个原因。</data>
      <data key="d9">原因分析,限制因素</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005169</data>
      <data key="d13" />
    </edge>
    <edge source="中低频量化" target="主观的研究员">
      <data key="d7">1.0</data>
      <data key="d8">The inability of subjective researchers to achieve high performance in medium-to-low frequency investing illustrates the inherent difficulty and low signal-to-noise ratio in this domain.</data>
      <data key="d9">difficulty indication,performance benchmark</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005171</data>
      <data key="d13" />
    </edge>
    <edge source="中低频量化" target="基金经理">
      <data key="d7">1.0</data>
      <data key="d8">The inability of fund managers to achieve high performance in medium-to-low frequency investing illustrates the inherent difficulty and low signal-to-noise ratio in this domain.</data>
      <data key="d9">difficulty indication,performance benchmark</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005173</data>
      <data key="d13" />
    </edge>
    <edge source="高频量化" target="信噪比">
      <data key="d7">1.0</data>
      <data key="d8">作者认为高频量化信噪比较高，是机器学习能在此场景表现更好的原因之一。</data>
      <data key="d9">原因分析,有利条件</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005167</data>
      <data key="d13" />
    </edge>
    <edge source="高频量化" target="数据量">
      <data key="d7">1.0</data>
      <data key="d8">作者指出高频量化(如使用Tick数据)数据量巨大，是机器学习能有效学习的前提。</data>
      <data key="d9">原因分析,有利条件</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005168</data>
      <data key="d13" />
    </edge>
    <edge source="线性模型" target="Panel_Trader">
      <data key="d7">1.0</data>
      <data key="d8">The user 'Panel_Trader' recommended linear models as suitable for small-sample, low-frequency data.</data>
      <data key="d9">方法推荐,适用场景</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005175</data>
      <data key="d13" />
    </edge>
    <edge source="基股传声" target="雪球">
      <data key="d7">1.0</data>
      <data key="d8">作者“基股传声”在雪球平台上发布了这篇文章。</data>
      <data key="d9">内容发布,平台</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005170</data>
      <data key="d13" />
    </edge>
    <edge source="Barra" target="风险控制">
      <data key="d7">1.0</data>
      <data key="d8">The Barra framework is primarily considered from a risk control perspective.</data>
      <data key="d9">framework application,primary purpose</data>
      <data key="d10">chunk-0ff265f7709913907a277247870f20cc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005171</data>
      <data key="d13" />
    </edge>
    <edge source="quant-computer" target="量化">
      <data key="d7">1.0</data>
      <data key="d8">The user 'quant-computer' worked in the field of quantitative finance after graduation.</data>
      <data key="d9">职业经历,领域转换</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005173</data>
      <data key="d13" />
    </edge>
    <edge source="站内推荐" target="仅在正文下讨论">
      <data key="d7">1.0</data>
      <data key="d8">The "站内推荐" feature includes the "仅在正文下讨论" function, which controls the visibility of discussion content.</data>
      <data key="d9">功能,可见性控制</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005172</data>
      <data key="d13" />
    </edge>
    <edge source="仅在正文下讨论" target="讨论区">
      <data key="d7">1.0</data>
      <data key="d8">The "仅在正文下讨论" function restricts the visibility of discussion content to the discussion area under the current post.</data>
      <data key="d9">内容可见性,功能限制</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005180</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="噪音">
      <data key="d7">1.0</data>
      <data key="d8">The user '厚积薄发磨一剑' identified excessive noise (invalid data) as a major challenge in quantitative finance.</data>
      <data key="d9">挑战分析,数据问题</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005174</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="数据清洗预处理">
      <data key="d7">1.0</data>
      <data key="d8">The user '厚积薄发磨一剑' mentioned that data cleaning and preprocessing are required to handle noise, demanding professional experience.</data>
      <data key="d9">专业要求,解决方案</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005175</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="股票">
      <data key="d7">1.0</data>
      <data key="d8">The user's comment is in the context of stock market analysis, where various factors create noise.</data>
      <data key="d9">市场因素,应用领域</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005177</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="懂股票又懂机器学习的人">
      <data key="d7">1.0</data>
      <data key="d8">The user '厚积薄发磨一剑' pointed out that individuals who understand both stocks and machine learning are very scarce.</data>
      <data key="d9">人才需求,稀缺性分析</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005180</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="美股">
      <data key="d7">1.0</data>
      <data key="d8">The user mentioned the US stock market as an example of a source of market volatility (大涨大跌) that creates noise.</data>
      <data key="d9">市场举例,波动来源</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005181</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="周末假期效应">
      <data key="d7">1.0</data>
      <data key="d8">The user listed the weekend/holiday effect as one of the factors that introduces noise into the market.</data>
      <data key="d9">因素列举,市场异常</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005182</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="个股利好利空">
      <data key="d7">1.0</data>
      <data key="d8">The user listed positive/negative news on individual stocks as a factor that introduces noise.</data>
      <data key="d9">个股影响,因素列举</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005191</data>
      <data key="d13" />
    </edge>
    <edge source="厚积薄发磨一剑" target="大盘板块大涨大跌">
      <data key="d7">1.0</data>
      <data key="d8">The user listed significant movements in major indices or sectors as a factor that introduces noise affecting individual stocks.</data>
      <data key="d9">因素列举,系统性影响</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005192</data>
      <data key="d13" />
    </edge>
    <edge source="噪音" target="无效数据">
      <data key="d7">1.0</data>
      <data key="d8">"噪音" is synonymous with "无效数据", both referring to irrelevant data that hinders analysis.</data>
      <data key="d9">同义词,概念等同</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005180</data>
      <data key="d13" />
    </edge>
    <edge source="敬畏常识" target="模型">
      <data key="d7">1.0</data>
      <data key="d8">The user '敬畏常识' argued that unquantifiable stock information leads to distorted inputs for models.</data>
      <data key="d9">局限性分析,输入失真</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005174</data>
      <data key="d13" />
    </edge>
    <edge source="敬畏常识" target="知识的修饰器">
      <data key="d7">1.0</data>
      <data key="d8">The user '敬畏常识' defined machine learning as a "modifier of knowledge" to clarify its role.</data>
      <data key="d9">概念定义,角色阐述</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005181</data>
      <data key="d13" />
    </edge>
    <edge source="Panel_Trader" target="达人认证">
      <data key="d7">1.0</data>
      <data key="d8">The user 'Panel_Trader' holds an expert certification (达人认证).</data>
      <data key="d9">用户属性,身份标识</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005181</data>
      <data key="d13" />
    </edge>
    <edge source="Panel_Trader" target="其它机器学习方法">
      <data key="d7">1.0</data>
      <data key="d8">The user 'Panel_Trader' recommended other machine learning methods as suitable for medium-frequency data.</data>
      <data key="d9">方法推荐,适用场景</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005183</data>
      <data key="d13" />
    </edge>
    <edge source="象牙山李宝库" target="高盛">
      <data key="d7">1.0</data>
      <data key="d8">The user '象牙山李宝库' shared information about a friend who works on quantitative trading at Goldman Sachs.</data>
      <data key="d9">信息分享,职业关联</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005176</data>
      <data key="d13" />
    </edge>
    <edge source="象牙山李宝库" target="基本面量化投资">
      <data key="d7">1.0</data>
      <data key="d8">The user discussed fundamental quantitative investing as a popular strategy with high excess returns.</data>
      <data key="d9">市场现状,投资策略</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005181</data>
      <data key="d13" />
    </edge>
    <edge source="象牙山李宝库" target="财务分析">
      <data key="d7">1.0</data>
      <data key="d8">The user gave financial analysis as an example where quantitative data analysis significantly speeds up the process compared to traditional methods.</data>
      <data key="d9">应用案例,效率提升</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005182</data>
      <data key="d13" />
    </edge>
    <edge source="象牙山李宝库" target="几十人团队">
      <data key="d7">1.0</data>
      <data key="d8">The user mentioned that the quantitative trading team at Goldman Sachs consists of dozens of people.</data>
      <data key="d9">团队规模,资源需求</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005191</data>
      <data key="d13" />
    </edge>
    <edge source="象牙山李宝库" target="基础分析">
      <data key="d7">1.0</data>
      <data key="d8">The user described writing Python programs for basic data analysis as a task distinct from machine learning.</data>
      <data key="d9">任务描述,技术层次</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005193</data>
      <data key="d13" />
    </edge>
    <edge source="财务分析" target="量化数据分析">
      <data key="d7">1.0</data>
      <data key="d8">Quantitative data analysis is applied to financial analysis, producing results much faster than manual analysis by researchers.</data>
      <data key="d9">效率对比,方法应用</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005178</data>
      <data key="d13" />
    </edge>
    <edge source="财务分析" target="几分钟">
      <data key="d7">1.0</data>
      <data key="d8">Quantitative data analysis for financial analysis can produce results in just a few minutes.</data>
      <data key="d9">效率指标,时间对比</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005191</data>
      <data key="d13" />
    </edge>
    <edge source="研究员" target="上市公司">
      <data key="d7">1.0</data>
      <data key="d8">Research analysts traditionally analyze listed companies.</data>
      <data key="d9">分析目标,工作对象</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005178</data>
      <data key="d13" />
    </edge>
    <edge source="研究员" target="几个小时">
      <data key="d7">1.0</data>
      <data key="d8">Traditionally, a research analyst spent several hours analyzing a single listed company.</data>
      <data key="d9">传统耗时,效率指标</data>
      <data key="d10">chunk-6bc1d4e50f0179dd98e01918a3be7977</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005191</data>
      <data key="d13" />
    </edge>
    <edge source="Image 64" target="企业微信">
      <data key="d7">1.0</data>
      <data key="d8">Image 64 is a screenshot that depicts the interface or content of the software企业微信.</data>
      <data key="d9">content,depiction</data>
      <data key="d10">chunk-7b1e8c21b7d64e83d4ee433e43a86a4b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005191</data>
      <data key="d13" />
    </edge>
    <edge source="Image 65" target="二维码">
      <data key="d7">1.0</data>
      <data key="d8">Image 65 is a screenshot that depicts a QR code.</data>
      <data key="d9">content,depiction</data>
      <data key="d10">chunk-7b1e8c21b7d64e83d4ee433e43a86a4b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005192</data>
      <data key="d13" />
    </edge>
    <edge source="风控建模方法" target="云端数据库">
      <data key="d7">1.0</data>
      <data key="d8">该风控建模方法通过云端数据库获取所需的用户数据。</data>
      <data key="d9">数据来源,数据获取</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005218</data>
      <data key="d13" />
    </edge>
    <edge source="风控建模方法" target="用户数据">
      <data key="d7">1.0</data>
      <data key="d8">该风控建模方法以用户数据作为主要处理对象。</data>
      <data key="d9">处理对象,数据输入</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005218</data>
      <data key="d13" />
    </edge>
    <edge source="风控建模方法" target="初步筛选">
      <data key="d7">1.0</data>
      <data key="d8">该风控建模方法包含对用户数据进行初步筛选的步骤。</data>
      <data key="d9">处理步骤,数据预处理</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005225</data>
      <data key="d13" />
    </edge>
    <edge source="风控建模方法" target="S1">
      <data key="d7">1.0</data>
      <data key="d8">该风控建模方法包含步骤S1。</data>
      <data key="d9">包含步骤,执行流程</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005219</data>
      <data key="d13" />
    </edge>
    <edge source="风控建模方法" target="S2">
      <data key="d7">1.0</data>
      <data key="d8">该风控建模方法包含步骤S2。</data>
      <data key="d9">包含步骤,执行流程</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005219</data>
      <data key="d13" />
    </edge>
    <edge source="用户数据" target="结构化数据">
      <data key="d7">1.0</data>
      <data key="d8">用户数据被区分为结构化数据这一类型。</data>
      <data key="d9">数据分类,组成部分</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005225</data>
      <data key="d13" />
    </edge>
    <edge source="用户数据" target="非结构化数据">
      <data key="d7">1.0</data>
      <data key="d8">用户数据被区分为非结构化数据这一类型。</data>
      <data key="d9">数据分类,组成部分</data>
      <data key="d10">chunk-ead8239d6c7d35f7d27952face0dd715</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005218</data>
      <data key="d13" />
    </edge>
    <edge source="Fuwei Jiang" target="Deep Learning and Corporate Bond Credit Risk">
      <data key="d7">1.0</data>
      <data key="d8">Fuwei Jiang is an author of the research paper titled "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005253</data>
      <data key="d13" />
    </edge>
    <edge source="Bailin Chai" target="Deep Learning and Corporate Bond Credit Risk">
      <data key="d7">1.0</data>
      <data key="d8">Bailin Chai is an author of the research paper titled "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005254</data>
      <data key="d13" />
    </edge>
    <edge source="Yihao Lin" target="Deep Learning and Corporate Bond Credit Risk">
      <data key="d7">1.0</data>
      <data key="d8">Yihao Lin is an author of the research paper titled "Deep Learning and Corporate Bond Credit Risk".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005254</data>
      <data key="d13" />
    </edge>
    <edge source="China Journal of Econometrics" target="Deep Learning and Corporate Bond Credit Risk">
      <data key="d7">1.0</data>
      <data key="d8">The research paper "Deep Learning and Corporate Bond Credit Risk" is published in the China Journal of Econometrics.</data>
      <data key="d9">publication,venue</data>
      <data key="d10">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005254</data>
      <data key="d13" />
    </edge>
    <edge source="DOI 10.12012/CJoE2024-0092" target="Deep Learning and Corporate Bond Credit Risk">
      <data key="d7">1.0</data>
      <data key="d8">The research paper "Deep Learning and Corporate Bond Credit Risk" is identified by the DOI 10.12012/CJoE2024-0092.</data>
      <data key="d9">identification,reference</data>
      <data key="d10">chunk-6d22dc080f5fd339b89bf3f7732fc258</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005255</data>
      <data key="d13" />
    </edge>
    <edge source="Logistic Regression Model" target="Recurrent Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">The final hidden state from the RNN was fed into a Logistic Regression Model to calculate the final heart failure risk probability.</data>
      <data key="d9">model combination,risk calculation</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005390</data>
      <data key="d13" />
    </edge>
    <edge source="Wang et al." target="Stroke Prediction Model">
      <data key="d7">1.0</data>
      <data key="d8">Wang et al. evaluated the Stroke Prediction Model, assessing its calibration and discrimination.</data>
      <data key="d9">model evaluation,research</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005371</data>
      <data key="d13" />
    </edge>
    <edge source="Stroke Prediction Model" target="Calibration">
      <data key="d7">1.0</data>
      <data key="d8">The Stroke Prediction Model is evaluated using the Calibration metric, measured by the Hosmer-Lemeshow statistic.</data>
      <data key="d9">evaluation metric,statistical assessment</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005374</data>
      <data key="d13" />
    </edge>
    <edge source="Stroke Prediction Model" target="Discrimination">
      <data key="d7">1.0</data>
      <data key="d8">The Stroke Prediction Model is evaluated using the Discrimination metric, measured by the c-statistic (AUC).</data>
      <data key="d9">evaluation metric,performance measure</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005381</data>
      <data key="d13" />
    </edge>
    <edge source="Discrimination" target="C-Statistic">
      <data key="d7">1.0</data>
      <data key="d8">Discrimination is evaluated using the C-Statistic, which is equivalent to the Area Under The Curve of the ROC curve.</data>
      <data key="d9">metric equivalence,performance evaluation</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005384</data>
      <data key="d13" />
    </edge>
    <edge source="Khosla et al." target="Support Vector Machine">
      <data key="d7">1.0</data>
      <data key="d8">Khosla et al. experimented with using Support Vector Machine for prediction tasks.</data>
      <data key="d9">algorithm application,predictive modeling</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005371</data>
      <data key="d13" />
    </edge>
    <edge source="Khosla et al." target="Margin-Based Censored Regression">
      <data key="d7">1.0</data>
      <data key="d8">Khosla et al. explored the use of Margin-Based Censored Regression as a modeling method.</data>
      <data key="d9">method exploration,survival analysis</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005374</data>
      <data key="d13" />
    </edge>
    <edge source="Khosla et al." target="KDD">
      <data key="d7">1.0</data>
      <data key="d8">Khosla et al. published their research paper at the KDD conference in 2010.</data>
      <data key="d9">academic conference,publication venue</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005384</data>
      <data key="d13" />
    </edge>
    <edge source="Support Vector Machine" target="L1 Regularized Logistic Regression">
      <data key="d7">1.0</data>
      <data key="d8">L1 Regularized Logistic Regression was used for feature selection before prediction was performed using Support Vector Machine.</data>
      <data key="d9">feature selection,model pipeline</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005374</data>
      <data key="d13" />
    </edge>
    <edge source="Electronic Health Records" target="Chio et al.">
      <data key="d7">1.0</data>
      <data key="d8">Chio et al. used Electronic Health Records data to train their prediction model.</data>
      <data key="d9">data source,model training</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005382</data>
      <data key="d13" />
    </edge>
    <edge source="Recurrent Neural Network" target="Chio et al.">
      <data key="d7">1.0</data>
      <data key="d8">Chio et al. pioneered the application of Recurrent Neural Network methods for predicting Heart Failure.</data>
      <data key="d9">heart failure prediction,method application</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005377</data>
      <data key="d13" />
    </edge>
    <edge source="Recurrent Neural Network" target="One-Hot Vector">
      <data key="d7">1.0</data>
      <data key="d8">In the RNN model by Chio et al., clinical events were represented as One-Hot Vectors for input.</data>
      <data key="d9">data representation,input encoding</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005382</data>
      <data key="d13" />
    </edge>
    <edge source="Recurrent Neural Network" target="Gated Recurrent Unit">
      <data key="d7">1.0</data>
      <data key="d8">The RNN model utilized Gated Recurrent Unit cells to compute hidden states from input event vectors.</data>
      <data key="d9">network unit,state computation</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005387</data>
      <data key="d13" />
    </edge>
    <edge source="Recurrent Neural Network" target="K-Nearest Neighbors">
      <data key="d7">1.0</data>
      <data key="d8">The performance of the RNN-based method was compared against classical methods like K-Nearest Neighbors.</data>
      <data key="d9">algorithm comparison,performance benchmark</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005393</data>
      <data key="d13" />
    </edge>
    <edge source="Recurrent Neural Network" target="Temporal Relation">
      <data key="d7">1.0</data>
      <data key="d8">Recurrent Neural Network methods are used to analyze the Temporal Relation between clinical events in EHR data.</data>
      <data key="d9">model application,sequence analysis</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005394</data>
      <data key="d13" />
    </edge>
    <edge source="Framingham Heart Study" target="Wang TJ">
      <data key="d7">1.0</data>
      <data key="d8">Wang TJ is an author associated with the Framingham Heart Study, which produced a risk score for stroke or death.</data>
      <data key="d9">research affiliation,study authorship</data>
      <data key="d10">chunk-fe2c7c19ec682c0e709a26a55e0b8005</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005387</data>
      <data key="d13" />
    </edge>
    <edge source="模型风险管理" target="金融机构">
      <data key="d7">1.0</data>
      <data key="d8">Financial institutions rely on models for various services, making model risk management a critical consideration for them.</data>
      <data key="d9">reliance,risk management</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005508</data>
      <data key="d13" />
    </edge>
    <edge source="模型风险管理" target="模型风险管理监管指南">
      <data key="d7">1.0</data>
      <data key="d8">Model risk management must follow regulatory guidelines, such as the Model Risk Management Supervisory Guide issued by the Federal Reserve and OCC, which serves as a benchmark.</data>
      <data key="d9">framework benchmark,regulation</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005518</data>
      <data key="d13" />
    </edge>
    <edge source="模型风险管理" target="模型风险管理软件">
      <data key="d7">1.0</data>
      <data key="d8">Model risk management software is a tool that helps organizations manage model risk more effectively.</data>
      <data key="d9">efficiency improvement,tool</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005525</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能模型" target="训练数据集">
      <data key="d7">1.0</data>
      <data key="d8">AI models are trained on datasets; if these datasets contain bias, the models can reflect and perpetuate that bias.</data>
      <data key="d9">bias propagation,training</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005508</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能模型" target="求职者筛选系统">
      <data key="d7">1.0</data>
      <data key="d8">The job applicant screening system is an example of an AI model that can manifest bias, such as favoring certain demographics.</data>
      <data key="d9">bias manifestation,example</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005514</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能模型" target="医疗保健预测软件">
      <data key="d7">1.0</data>
      <data key="d8">Healthcare prediction software is an example of an AI model that can manifest bias, such as racial bias in patient prioritization.</data>
      <data key="d9">bias manifestation,example</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005517</data>
      <data key="d13" />
    </edge>
    <edge source="美联储" target="模型风险管理监管指南">
      <data key="d7">1.0</data>
      <data key="d8">The Federal Reserve issued the Model Risk Management Supervisory Guidance as part of its regulatory role.</data>
      <data key="d9">issuance,regulatory authority</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005512</data>
      <data key="d13" />
    </edge>
    <edge source="货币监理署" target="模型风险管理监管指南">
      <data key="d7">1.0</data>
      <data key="d8">The Office of the Comptroller of the Currency (OCC) issued the Model Risk Management Supervisory Guidance as part of its regulatory role.</data>
      <data key="d9">issuance,regulatory authority</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005516</data>
      <data key="d13" />
    </edge>
    <edge source="训练数据集" target="数值天气预报产品">
      <data key="d7">1.0</data>
      <data key="d8">训练数据集是根据数值天气预报产品构建的。</data>
      <data key="d9">数据构成,来源</data>
      <data key="d10">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010177</data>
      <data key="d13" />
    </edge>
    <edge source="训练数据集" target="天气现象观测数据">
      <data key="d7">1.0</data>
      <data key="d8">训练数据集是根据天气现象观测数据构建的。</data>
      <data key="d9">数据构成,来源</data>
      <data key="d10">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010179</data>
      <data key="d13" />
    </edge>
    <edge source="训练数据集" target="深度学习网络模型">
      <data key="d7">1.0</data>
      <data key="d8">深度学习网络模型使用训练数据集进行训练。</data>
      <data key="d9">数据处理,模型训练</data>
      <data key="d10">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010189</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Openpages" target="IBM CIO Organization">
      <data key="d7">1.0</data>
      <data key="d8">The IBM CIO organization implemented IBM OpenPages to manage governance, risk, and compliance.</data>
      <data key="d9">governance tool,implementation</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005520</data>
      <data key="d13" />
    </edge>
    <edge source="Generative AI For Business" target="Virtual Agent">
      <data key="d7">1.0</data>
      <data key="d8">Generative AI is enabling the development of more capable and accurate virtual agents for business.</data>
      <data key="d9">capability enhancement,enabling technology</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005522</data>
      <data key="d13" />
    </edge>
    <edge source="Generative AI For Business" target="CEO">
      <data key="d7">1.0</data>
      <data key="d8">CEOs are utilizing generative AI as a tool to drive innovation and maintain competitiveness.</data>
      <data key="d9">strategic tool,utilization</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005530</data>
      <data key="d13" />
    </edge>
    <edge source="SR 11-7" target="Federal Reserve">
      <data key="d7">1.0</data>
      <data key="d8">The Federal Reserve published the SR 11-7 guidance document on model risk management.</data>
      <data key="d9">publication,regulatory guidance</data>
      <data key="d10">chunk-2103a1c2471cc6226897b2080204b309</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005530</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning Algorithm" target="Training Phase">
      <data key="d7">1.0</data>
      <data key="d8">During the training phase, the machine learning algorithm builds and refines its model through an iterative process.</data>
      <data key="d9">learning method,process</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005610</data>
      <data key="d13" />
    </edge>
    <edge source="Supervisory Machine Learning Algorithm" target="Deep Neural Network (DNN)">
      <data key="d7">1.0</data>
      <data key="d8">DNN is one type of supervisory machine learning algorithm selected for this research.</data>
      <data key="d9">categorization,type</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005615</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network (DNN)" target="Binary Classification Problem">
      <data key="d7">1.0</data>
      <data key="d8">The DNN is used to handle the binary classification problem of identifying loans that may be downgraded.</data>
      <data key="d9">model application,task</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005610</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network (DNN)" target="Data Processing Procedure">
      <data key="d7">1.0</data>
      <data key="d8">Training a DNN model requires the significant computational power provided by the Data Processing Procedure.</data>
      <data key="d9">computational requirement,model training</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005621</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network (DNN)" target="Area Under the Curve of Receiver Operating Characteristic (AUC)">
      <data key="d7">1.0</data>
      <data key="d8">The performance of the trained DNN model is evaluated using the AUC metric.</data>
      <data key="d9">evaluation metric,performance measurement</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005625</data>
      <data key="d13" />
    </edge>
    <edge source="Data Processing Procedure" target="Internal Data Science Laboratory">
      <data key="d7">1.0</data>
      <data key="d8">The data processing procedure is completed rapidly by leveraging the computational power of the Internal Data Science Laboratory.</data>
      <data key="d9">computational support,infrastructure</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005610</data>
      <data key="d13" />
    </edge>
    <edge source="Training Phase" target="Model Parameters">
      <data key="d7">1.0</data>
      <data key="d8">The training phase involves the iterative fine-tuning of model parameters to improve performance.</data>
      <data key="d9">fine-tuning,optimization</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005623</data>
      <data key="d13" />
    </edge>
    <edge source="Area Under the Curve of Receiver Operating Characteristic (AUC)" target="Test Set">
      <data key="d7">1.0</data>
      <data key="d8">The performance of the fully trained model is evaluated using the Test Set data, measured by the AUC metric.</data>
      <data key="d9">metric,performance evaluation</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005617</data>
      <data key="d13" />
    </edge>
    <edge source="Hong Kong Monetary Authority (HKMA)" target="Internal Data Science Laboratory">
      <data key="d7">1.0</data>
      <data key="d8">The Internal Data Science Laboratory was developed under the HKMA's 'Digitalisation Programme'.</data>
      <data key="d9">development,organizational initiative</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005615</data>
      <data key="d13" />
    </edge>
    <edge source="Test Set" target="Deep Auto-Encoders">
      <data key="d7">1.0</data>
      <data key="d8">The performance of the Deep Auto-Encoder model was evaluated on a test set that constituted 25% of the available data.</data>
      <data key="d9">data partitioning,model evaluation</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006182</data>
      <data key="d13" />
    </edge>
    <edge source="Benchmark Model" target="Figure 2">
      <data key="d7">1.0</data>
      <data key="d8">Figure 2 visually presents a comparison of performance between the trained DNN model and the Benchmark Model.</data>
      <data key="d9">performance comparison,visualization</data>
      <data key="d10">chunk-dd790e22e66ff566c3fcba5e9ed475b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005618</data>
      <data key="d13" />
    </edge>
    <edge source="金融行业" target="交易欺诈风险">
      <data key="d7">1.0</data>
      <data key="d8">The financial industry focuses on detecting transaction fraud risks.</data>
      <data key="d9">detection,risk management</data>
      <data key="d10">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005655</data>
      <data key="d13" />
    </edge>
    <edge source="金融行业" target="基于机器学习算法">
      <data key="d7">1.0</data>
      <data key="d8">The financial industry employs the machine learning algorithm-based method for detecting transaction fraud risks.</data>
      <data key="d9">application,methodology</data>
      <data key="d10">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005658</data>
      <data key="d13" />
    </edge>
    <edge source="金融行业" target="基于规则的方法">
      <data key="d7">1.0</data>
      <data key="d8">The financial industry employs the rule-based method for detecting transaction fraud risks.</data>
      <data key="d9">application,methodology</data>
      <data key="d10">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005660</data>
      <data key="d13" />
    </edge>
    <edge source="基于规则的方法" target="规则库">
      <data key="d7">1.0</data>
      <data key="d8">The rule-based method relies on the continuous establishment and updating of a rule library.</data>
      <data key="d9">dependency,implementation</data>
      <data key="d10">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005655</data>
      <data key="d13" />
    </edge>
    <edge source="规则库" target="交易行为特征">
      <data key="d7">1.0</data>
      <data key="d8">The rule library is built and updated based on transaction behavior characteristics.</data>
      <data key="d9">construction,foundation</data>
      <data key="d10">chunk-d5073dc88c604f20a0eefda8a24a1214</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005658</data>
      <data key="d13" />
    </edge>
    <edge source="欺诈应用检测方法" target="移动广告数据">
      <data key="d7">1.0</data>
      <data key="d8">The fraud application detection method uses mobile advertising data as its primary input for processing.</data>
      <data key="d9">data input,processing</data>
      <data key="d10">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005738</data>
      <data key="d13" />
    </edge>
    <edge source="欺诈应用检测方法" target="结构数据">
      <data key="d7">1.0</data>
      <data key="d8">The fraud application detection method involves extracting structural data from the input.</data>
      <data key="d9">data processing,feature extraction</data>
      <data key="d10">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005740</data>
      <data key="d13" />
    </edge>
    <edge source="欺诈应用检测方法" target="样本数据">
      <data key="d7">1.0</data>
      <data key="d8">The fraud application detection method involves extracting sample data from the input.</data>
      <data key="d9">data processing,feature extraction</data>
      <data key="d10">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005741</data>
      <data key="d13" />
    </edge>
    <edge source="移动广告数据" target="预处理">
      <data key="d7">1.0</data>
      <data key="d8">Mobile advertising data undergoes preprocessing as an initial step in the method.</data>
      <data key="d9">cleaning,data preparation</data>
      <data key="d10">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005742</data>
      <data key="d13" />
    </edge>
    <edge source="结构数据" target="图">
      <data key="d7">1.0</data>
      <data key="d8">Structural data is used to construct a graph for analysis.</data>
      <data key="d9">graph construction,representation</data>
      <data key="d10">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005735</data>
      <data key="d13" />
    </edge>
    <edge source="图" target="图嵌入特征">
      <data key="d7">1.0</data>
      <data key="d8">Graph embedding features are derived from the constructed graph.</data>
      <data key="d9">embedding,feature extraction</data>
      <data key="d10">chunk-a6a52780a97b8eca9204ad8ed2f86840</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005738</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="实时欺诈检测算法">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型实现了实时欺诈检测算法。</data>
      <data key="d9">功能实现,核心算法</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005788</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="用户行为">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型通过分析用户行为来识别欺诈。</data>
      <data key="d9">数据分析,行为识别</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005789</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="交易模式">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型通过分析交易模式来识别欺诈。</data>
      <data key="d9">数据分析,模式识别</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005790</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="历史数据">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型通过分析历史数据来识别欺诈。</data>
      <data key="d9">历史分析,数据分析</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005791</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="潜在欺诈行为">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型的主要目标是识别潜在的欺诈行为。</data>
      <data key="d9">目标,风险识别</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005792</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="企业">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型旨在帮助企业保护其资产和信誉。</data>
      <data key="d9">价值提供,服务对象</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005794</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="资产">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型旨在保护企业的资产。</data>
      <data key="d9">保护目标,风险管理</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005795</data>
      <data key="d13" />
    </edge>
    <edge source="AI Agent风控模型" target="信誉">
      <data key="d7">1.0</data>
      <data key="d8">AI Agent风控模型旨在保护企业的信誉。</data>
      <data key="d9">保护目标,风险管理</data>
      <data key="d10">chunk-c00652dd3948d32546676fffc8064300</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005796</data>
      <data key="d13" />
    </edge>
    <edge source="Fraud Detection" target="Deep Learning Models">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models improve the accuracy of fraud detection, enable real-time detection, and reduce false positives.</data>
      <data key="d9">capability,improvement</data>
      <data key="d10">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005842</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Models" target="Real-Time Detection">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models enable real-time detection of fraudulent activities.</data>
      <data key="d9">capability,feature</data>
      <data key="d10">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005842</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Models" target="False Positives">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models reduce the number of false positives in fraud detection.</data>
      <data key="d9">outcome,reduction</data>
      <data key="d10">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005835</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Learning Models" target="Scalability">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning models are described as being highly scalable.</data>
      <data key="d9">attribute,property</data>
      <data key="d10">chunk-ac1ed9e88e425ab885199259d92315e5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005837</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习图神经网络" target="端到端近乎实时反欺诈系统">
      <data key="d7">1.0</data>
      <data key="d8">深度学习图神经网络是实现该端到端、近乎实时反欺诈系统的核心技术方法。</data>
      <data key="d9">技术实现,系统构建</data>
      <data key="d10">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005878</data>
      <data key="d13" />
    </edge>
    <edge source="蓝图架构" target="深度图库">
      <data key="d7">1.0</data>
      <data key="d8">蓝图架构使用深度图库(DGL)作为工具来根据表格数据构造异构图。</data>
      <data key="d9">工具使用,数据处理</data>
      <data key="d10">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005878</data>
      <data key="d13" />
    </edge>
    <edge source="蓝图架构" target="图神经网络模型">
      <data key="d7">1.0</data>
      <data key="d8">蓝图架构的核心是训练图神经网络(GNN)模型，用于在构造的异构图上进行欺诈检测。</data>
      <data key="d9">模型训练,系统核心</data>
      <data key="d10">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005881</data>
      <data key="d13" />
    </edge>
    <edge source="深度图库" target="异构图">
      <data key="d7">1.0</data>
      <data key="d8">深度图库(DGL)负责将表格数据转换为异构图结构。</data>
      <data key="d9">图构建,数据转换</data>
      <data key="d10">chunk-7ae4a8c47961536abb443d07e622440b</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005881</data>
      <data key="d13" />
    </edge>
    <edge source="Amazon Web Services" target="Real-Time Anti-Fraud Solution">
      <data key="d7">1.0</data>
      <data key="d8">The Real-Time Anti-Fraud Solution is deployed on the Amazon Web Services cloud platform.</data>
      <data key="d9">cloud platform,deployment</data>
      <data key="d10">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005931</data>
      <data key="d13" />
    </edge>
    <edge source="Real-Time Anti-Fraud Solution" target="Deep Learning Graph Neural Networks">
      <data key="d7">1.0</data>
      <data key="d8">The Real-Time Anti-Fraud Solution utilizes Deep Learning Graph Neural Networks as its core analytical method for detecting fraud.</data>
      <data key="d9">core technology,utilization</data>
      <data key="d10">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005928</data>
      <data key="d13" />
    </edge>
    <edge source="Real-Time Anti-Fraud Solution" target="Graph Database">
      <data key="d7">1.0</data>
      <data key="d8">The Real-Time Anti-Fraud Solution depends on a Graph Database to store and process the data needed for its fraud detection analysis.</data>
      <data key="d9">data infrastructure,dependency</data>
      <data key="d10">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005929</data>
      <data key="d13" />
    </edge>
    <edge source="Real-Time Anti-Fraud Solution" target="Implementation Guide">
      <data key="d7">1.0</data>
      <data key="d8">The Implementation Guide provides documentation and instructions for deploying the Real-Time Anti-Fraud Solution.</data>
      <data key="d9">deployment instructions,documentation</data>
      <data key="d10">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005932</data>
      <data key="d13" />
    </edge>
    <edge source="Implementation Guide" target="Architectural Considerations">
      <data key="d7">1.0</data>
      <data key="d8">The Implementation Guide documents the Architectural Considerations for the solution's deployment.</data>
      <data key="d9">design factors,documentation</data>
      <data key="d10">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005934</data>
      <data key="d13" />
    </edge>
    <edge source="Implementation Guide" target="Configuration Steps">
      <data key="d7">1.0</data>
      <data key="d8">The Implementation Guide provides the Configuration Steps for deploying the solution.</data>
      <data key="d9">documentation,setup procedures</data>
      <data key="d10">chunk-b3378e1cd34422d214370ca24a5f17ef</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005935</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="伪卡欺诈侦测">
      <data key="d7">1.0</data>
      <data key="d8">该深度学习模型被设计用于处理伪卡欺诈侦测这一具体应用场景。</data>
      <data key="d9">应用场景,目标</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005982</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="骗保检测">
      <data key="d7">1.0</data>
      <data key="d8">该深度学习模型被设计用于处理骗保检测这一具体应用场景。</data>
      <data key="d9">应用场景,目标</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005983</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="银行">
      <data key="d7">1.0</data>
      <data key="d8">该模型被应用于银行业务中，以侦测相关欺诈行为。</data>
      <data key="d9">应用领域,服务对象</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005992</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="保险业务">
      <data key="d7">1.0</data>
      <data key="d8">该模型被应用于保险业务中，以侦测相关欺诈行为。</data>
      <data key="d9">应用领域,服务对象</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005986</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="真实数据">
      <data key="d7">1.0</data>
      <data key="d8">该模型使用真实业务数据进行仿真验证。</data>
      <data key="d9">数据源,训练验证</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005987</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="仿真验证">
      <data key="d7">1.0</data>
      <data key="d8">该模型通过仿真验证方法来评估其性能和有效性。</data>
      <data key="d9">性能测试,评估方法</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005989</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="GBDT→GRU→RF三明治结构">
      <data key="d7">1.0</data>
      <data key="d8">该深度学习模型采用了GBDT→GRU→RF三明治结构作为其核心架构。</data>
      <data key="d9">核心技术,模型架构</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005989</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习欺诈侦测模型" target="三方工程师">
      <data key="d7">1.0</data>
      <data key="d8">The three-party engineers conducted simulation verification for the new deep learning fraud detection model.</data>
      <data key="d9">development,verification</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005991</data>
      <data key="d13" />
    </edge>
    <edge source="真实数据" target="三方工程师">
      <data key="d7">1.0</data>
      <data key="d8">The three-party engineers used real data for their simulation verification.</data>
      <data key="d9">testing,utilization</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005994</data>
      <data key="d13" />
    </edge>
    <edge source="仿真验证" target="三方工程师">
      <data key="d7">1.0</data>
      <data key="d8">The three-party engineers performed multiple simulation verifications.</data>
      <data key="d9">execution,methodology</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005996</data>
      <data key="d13" />
    </edge>
    <edge source="GBDT→GRU→RF三明治结构" target="GBDT">
      <data key="d7">1.0</data>
      <data key="d8">The GBDT→GRU→RF sandwich structure includes GBDT as one of its components.</data>
      <data key="d9">architecture,component</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005991</data>
      <data key="d13" />
    </edge>
    <edge source="GBDT→GRU→RF三明治结构" target="GRU">
      <data key="d7">1.0</data>
      <data key="d8">The GBDT→GRU→RF sandwich structure includes GRU as one of its components.</data>
      <data key="d9">architecture,component</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005994</data>
      <data key="d13" />
    </edge>
    <edge source="GBDT→GRU→RF三明治结构" target="RF">
      <data key="d7">1.0</data>
      <data key="d8">The GBDT→GRU→RF sandwich structure includes RF as one of its components.</data>
      <data key="d9">architecture,component</data>
      <data key="d10">chunk-98217948cb9ad0bfdb25f3db0b7cd900</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769005996</data>
      <data key="d13" />
    </edge>
    <edge source="Moonlight" target="Credit Card Fraud Detection: A Deep Learning Approach">
      <data key="d7">1.0</data>
      <data key="d8">Moonlight, as an AI research assistant, provides a summary and analytical tools for understanding the paper "Credit Card Fraud Detection: A Deep Learning Approach".</data>
      <data key="d9">content analysis,tool functionality</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006177</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Multi-layer Feed-forward Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">The paper proposes using a Multi-layer Feed-forward Neural Network as its first deep learning model for detecting credit card fraud.</data>
      <data key="d9">methodology,model application</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006154</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Deep Auto-Encoders">
      <data key="d7">1.0</data>
      <data key="d8">The paper introduces Deep Auto-Encoders as an unsupervised learning method to identify anomalous transaction patterns in imbalanced data.</data>
      <data key="d9">methodology,unsupervised learning</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006158</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Bat Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">The paper employs the Bat Algorithm to optimize the performance of its deep learning models by selecting better features and reducing training costs.</data>
      <data key="d9">feature selection,optimization</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006162</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Kaggle Credit Card Fraud Detection Dataset">
      <data key="d7">1.0</data>
      <data key="d8">The paper's experiments are conducted using the Kaggle Credit Card Fraud Detection Dataset to train and evaluate the proposed models.</data>
      <data key="d9">data source,experimentation</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006164</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Scikit-learn">
      <data key="d7">1.0</data>
      <data key="d8">The paper compares the performance of its proposed deep learning methods against various algorithms from the Scikit-learn library.</data>
      <data key="d9">benchmarking,performance comparison</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006167</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Class Imbalance">
      <data key="d7">1.0</data>
      <data key="d8">A core focus of the paper is to address the challenge of class imbalance in credit card fraud detection data using its proposed methods.</data>
      <data key="d9">data challenge,problem addressed</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006170</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Concept Drift">
      <data key="d7">1.0</data>
      <data key="d8">The paper aims to overcome the challenge of concept drift, which affects traditional fraud detection systems.</data>
      <data key="d9">problem addressed,system challenge</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006172</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Financial Transactions">
      <data key="d7">1.0</data>
      <data key="d8">The paper focuses on detecting fraud within financial transactions to address the high costs caused by fraudulent behavior.</data>
      <data key="d9">cost reduction,problem domain</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006180</data>
      <data key="d13" />
    </edge>
    <edge source="Credit Card Fraud Detection: A Deep Learning Approach" target="Financial Field">
      <data key="d7">1.0</data>
      <data key="d8">The paper concludes that its proposed method shows broad future application prospects within the financial field.</data>
      <data key="d9">application domain,future prospects</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006187</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-layer Feed-forward Neural Network" target="Tanh Function">
      <data key="d7">1.0</data>
      <data key="d8">In experiments, the Tanh activation function was found to perform better than the Logistic Sigmoid function for the feed-forward neural network.</data>
      <data key="d9">activation,parameter tuning</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006157</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-layer Feed-forward Neural Network" target="Z-score Standardization">
      <data key="d7">1.0</data>
      <data key="d8">The neural network's performance was optimized when the Tanh activation function was combined with Z-score data standardization.</data>
      <data key="d9">data preprocessing,performance</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006160</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-layer Feed-forward Neural Network" target="Validation Set">
      <data key="d7">1.0</data>
      <data key="d8">A validation set was used to fine-tune the Multi-layer Feed-forward Neural Network by determining the best standardization and activation function.</data>
      <data key="d9">evaluation,model tuning</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006174</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Auto-Encoders" target="Mean Squared Error (MSE)">
      <data key="d7">1.0</data>
      <data key="d8">The Deep Auto-Encoder model was trained using Mean Squared Error as its loss function to reconstruct data and detect anomalies.</data>
      <data key="d9">loss function,training</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006155</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Auto-Encoders" target="Reconstruction Method">
      <data key="d7">1.0</data>
      <data key="d8">The Deep Auto-Encoder uses a reconstruction method to identify anomalous data points by comparing original and reconstructed outputs.</data>
      <data key="d9">anomaly detection,technique</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006189</data>
      <data key="d13" />
    </edge>
    <edge source="Bat Algorithm" target="AUC Score">
      <data key="d7">1.0</data>
      <data key="d8">Using the Bat Algorithm for optimization helped the model achieve a high AUC score, surpassing traditional methods.</data>
      <data key="d9">evaluation,performance optimization</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006164</data>
      <data key="d13" />
    </edge>
    <edge source="Bat Algorithm" target="Global Best Position">
      <data key="d7">1.0</data>
      <data key="d8">The Bat Algorithm operates by updating bat positions to find the global best position, which corresponds to the optimal feature set.</data>
      <data key="d9">goal,optimization process</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006182</data>
      <data key="d13" />
    </edge>
    <edge source="Scikit-learn" target="Confusion Matrix">
      <data key="d7">1.0</data>
      <data key="d8">Algorithms from Scikit-learn were evaluated using confusion matrices to compare their fraud classification performance.</data>
      <data key="d9">algorithm comparison,evaluation</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006158</data>
      <data key="d13" />
    </edge>
    <edge source="Concept Drift" target="Traditional Fraud Detection Systems">
      <data key="d7">1.0</data>
      <data key="d8">Traditional fraud detection systems face the challenge of concept drift, where data patterns change over time.</data>
      <data key="d9">challenge,system limitation</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006187</data>
      <data key="d13" />
    </edge>
    <edge source="Class Imbalance" target="Traditional Fraud Detection Systems">
      <data key="d7">1.0</data>
      <data key="d8">Traditional fraud detection systems struggle with the challenge of class imbalance in fraud data.</data>
      <data key="d9">challenge,system limitation</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006177</data>
      <data key="d13" />
    </edge>
    <edge source="Verification Latency" target="Traditional Fraud Detection Systems">
      <data key="d7">1.0</data>
      <data key="d8">Traditional fraud detection systems are challenged by verification latency, the delay in confirming transaction labels.</data>
      <data key="d9">challenge,system limitation</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006167</data>
      <data key="d13" />
    </edge>
    <edge source="Traditional Fraud Detection Systems" target="Fuzzy Logic">
      <data key="d7">1.0</data>
      <data key="d8">Some traditional fraud detection systems incorporate Fuzzy Logic as part of their methodology.</data>
      <data key="d9">method,technology reliance</data>
      <data key="d10">chunk-9f34e4a3e164d008eba0c74c96804047</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006172</data>
      <data key="d13" />
    </edge>
    <edge source="检测方法" target="系统">
      <data key="d7">1.0</data>
      <data key="d8">The detection method enables the system to achieve higher automation and performance.</data>
      <data key="d9">automation,performance enhancement</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006183</data>
      <data key="d13" />
    </edge>
    <edge source="CEO Younghyun Chung" target="Corca, Inc.">
      <data key="d7">1.0</data>
      <data key="d8">Younghyun Chung is the CEO leading Corca, Inc.</data>
      <data key="d9">leadership,management</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006192</data>
      <data key="d13" />
    </edge>
    <edge source="Corca, Inc." target="6F, 11-8 Teheran-ro 77-gil, Gangnam-gu, Seoul, Republic of Korea, 06159">
      <data key="d7">1.0</data>
      <data key="d8">Corca, Inc. is headquartered at the specified address in Seoul.</data>
      <data key="d9">headquarters,location</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006196</data>
      <data key="d13" />
    </edge>
    <edge source="Corca, Inc." target="Contact 02-6925-6978">
      <data key="d7">1.0</data>
      <data key="d8">The phone number is the contact information for Corca, Inc.</data>
      <data key="d9">communication,contact information</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006199</data>
      <data key="d13" />
    </edge>
    <edge source="Corca, Inc." target="E-mail: moonlight@corca.ai">
      <data key="d7">1.0</data>
      <data key="d8">The email address is the contact information for Corca, Inc.</data>
      <data key="d9">communication,contact information</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006207</data>
      <data key="d13" />
    </edge>
    <edge source="Corca, Inc." target="Business Registration Number 271-86-02206">
      <data key="d7">1.0</data>
      <data key="d8">The business registration number is the official legal identifier for Corca, Inc.</data>
      <data key="d9">legal identification,registration</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006201</data>
      <data key="d13" />
    </edge>
    <edge source="Corca, Inc." target="© 2026 Corca, Inc. All rights reserved.">
      <data key="d7">1.0</data>
      <data key="d8">The copyright notice asserts Corca, Inc.'s intellectual property rights over its materials.</data>
      <data key="d9">copyright,intellectual property</data>
      <data key="d10">chunk-5e9c7c6b034fa0090c148c9fb494cca9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006202</data>
      <data key="d13" />
    </edge>
    <edge source="李峰" target="河北金融学院">
      <data key="d7">1.0</data>
      <data key="d8">李峰是河北金融学院的研究人员，隶属于该机构。</data>
      <data key="d9">affiliation,research</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006357</data>
      <data key="d13" />
    </edge>
    <edge source="李峰" target="基于动态时序图神经网络的信用卡欺诈检测方法研究">
      <data key="d7">1.0</data>
      <data key="d8">李峰是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的作者之一。</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006373</data>
      <data key="d13" />
    </edge>
    <edge source="李惠先" target="河北金融学院">
      <data key="d7">1.0</data>
      <data key="d8">李惠先是河北金融学院的研究人员，隶属于该机构。</data>
      <data key="d9">affiliation,research</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006358</data>
      <data key="d13" />
    </edge>
    <edge source="李惠先" target="基于动态时序图神经网络的信用卡欺诈检测方法研究">
      <data key="d7">1.0</data>
      <data key="d8">李惠先是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的作者之一。</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006374</data>
      <data key="d13" />
    </edge>
    <edge source="陈雪" target="河北金融学院">
      <data key="d7">1.0</data>
      <data key="d8">陈雪是河北金融学院的研究人员，隶属于该机构。</data>
      <data key="d9">affiliation,research</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006360</data>
      <data key="d13" />
    </edge>
    <edge source="陈雪" target="基于动态时序图神经网络的信用卡欺诈检测方法研究">
      <data key="d7">1.0</data>
      <data key="d8">陈雪是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的作者之一。</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006374</data>
      <data key="d13" />
    </edge>
    <edge source="韩祝华" target="河北金融学院">
      <data key="d7">1.0</data>
      <data key="d8">韩祝华是河北金融学院的研究人员，隶属于该机构。</data>
      <data key="d9">affiliation,research</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006363</data>
      <data key="d13" />
    </edge>
    <edge source="韩祝华" target="基于动态时序图神经网络的信用卡欺诈检测方法研究">
      <data key="d7">1.0</data>
      <data key="d8">韩祝华是论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》的作者之一。</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006382</data>
      <data key="d13" />
    </edge>
    <edge source="河北金融学院" target="河北省金融科技应用重点实验室">
      <data key="d7">1.0</data>
      <data key="d8">河北省金融科技应用重点实验室是隶属于河北金融学院的研究机构。</data>
      <data key="d9">contains,parent organization</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006366</data>
      <data key="d13" />
    </edge>
    <edge source="河北金融学院" target="金融科技学院">
      <data key="d7">1.0</data>
      <data key="d8">金融科技学院是河北金融学院的学院之一。</data>
      <data key="d9">contains,parent organization</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006370</data>
      <data key="d13" />
    </edge>
    <edge source="河北金融学院" target="保定">
      <data key="d7">1.0</data>
      <data key="d8">河北金融学院位于河北省保定市。</data>
      <data key="d9">based in,location</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006371</data>
      <data key="d13" />
    </edge>
    <edge source="信用卡欺诈" target="动态时序图神经网络模型">
      <data key="d7">1.0</data>
      <data key="d8">动态时序图神经网络模型是本文提出的用于检测信用卡欺诈的新方法。</data>
      <data key="d9">addresses,detection method</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006358</data>
      <data key="d13" />
    </edge>
    <edge source="信用卡欺诈" target="图神经网络">
      <data key="d7">1.0</data>
      <data key="d8">图神经网络是一种用于信用卡欺诈检测的方法。</data>
      <data key="d9">addresses,detection method</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006371</data>
      <data key="d13" />
    </edge>
    <edge source="信用卡欺诈" target="金融科技">
      <data key="d7">1.0</data>
      <data key="d8">信用卡欺诈是金融科技领域内的一个重大挑战。</data>
      <data key="d9">challenge within,domain</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006382</data>
      <data key="d13" />
    </edge>
    <edge source="动态时序图神经网络模型" target="DTGNN-FD">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD是动态时序图神经网络模型的简称。</data>
      <data key="d9">abbreviation,refers to</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006360</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="连续时间动态图">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型采用连续时间动态图作为其核心范式。</data>
      <data key="d9">employs,paradigm</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006363</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="门控记忆机制">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型采用门控记忆机制来更新用户表征。</data>
      <data key="d9">component,employs</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006366</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="时间感知注意力">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型采用时间感知注意力来更新用户表征。</data>
      <data key="d9">component,employs</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006370</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="用户表征">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型持续更新用户表征以进行风险建模。</data>
      <data key="d9">object,updates</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006378</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="流式交易">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型对流式交易进行实时风险建模。</data>
      <data key="d9">models,object</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006371</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="实时风险建模">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型执行实时风险建模功能。</data>
      <data key="d9">function,performs</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006371</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="金融欺诈数据集">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型在两个真实金融欺诈数据集上进行了实验评估。</data>
      <data key="d9">evaluated on,performance</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006372</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="F1-Score">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型在F1-Score指标上优于基线模型。</data>
      <data key="d9">metric,outperforms in</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006373</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="Recall">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型在Recall指标上优于基线模型。</data>
      <data key="d9">metric,outperforms in</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006374</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="基线模型">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型的性能与多种基线模型进行了比较。</data>
      <data key="d9">benchmark,compared to</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006375</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="复杂时序模式">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型表现出识别复杂时序模式的潜力。</data>
      <data key="d9">identifies,potential</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006375</data>
      <data key="d13" />
    </edge>
    <edge source="DTGNN-FD" target="实时信用卡欺诈检测">
      <data key="d7">1.0</data>
      <data key="d8">DTGNN-FD模型为实时信用卡欺诈检测提供了一种有效的解决方案。</data>
      <data key="d9">application,provides solution for</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006377</data>
      <data key="d13" />
    </edge>
    <edge source="图神经网络" target="静态快照">
      <data key="d7">1.0</data>
      <data key="d8">基于静态快照的图神经网络方法存在难以捕捉动态演化的局限性。</data>
      <data key="d9">approach,limitation of</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006372</data>
      <data key="d13" />
    </edge>
    <edge source="静态快照" target="时序信息丢失">
      <data key="d7">1.0</data>
      <data key="d8">将动态交易流离散化为静态快照的方法会导致时序信息丢失。</data>
      <data key="d9">causes,problem</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006375</data>
      <data key="d13" />
    </edge>
    <edge source="静态快照" target="检测延迟">
      <data key="d7">1.0</data>
      <data key="d8">将动态交易流离散化为静态快照的方法会导致检测延迟。</data>
      <data key="d9">causes,problem</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006377</data>
      <data key="d13" />
    </edge>
    <edge source="DOI: 10.12677/csa.2025.1511295" target="基于动态时序图神经网络的信用卡欺诈检测方法研究">
      <data key="d7">1.0</data>
      <data key="d8">DOI: 10.12677/csa.2025.1511295唯一标识了论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》。</data>
      <data key="d9">identifier,uniquely identifies</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006376</data>
      <data key="d13" />
    </edge>
    <edge source="基于动态时序图神经网络的信用卡欺诈检测方法研究" target="Credit Card Fraud Detection Approach Based on a Dynamic Temporal Graph Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Credit Card Fraud Detection Approach Based on a Dynamic Temporal Graph Neural Network是论文标题《基于动态时序图神经网络的信用卡欺诈检测方法研究》的英文翻译。</data>
      <data key="d9">equivalent title,translation</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006377</data>
      <data key="d13" />
    </edge>
    <edge source="基于动态时序图神经网络的信用卡欺诈检测方法研究" target="计算机科学与应用">
      <data key="d7">1.0</data>
      <data key="d8">论文《基于动态时序图神经网络的信用卡欺诈检测方法研究》发表在《计算机科学与应用》上。</data>
      <data key="d9">publication,published in</data>
      <data key="d10">chunk-f8a385ef6ec16dbfeda21e87bfc82a5e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006378</data>
      <data key="d13" />
    </edge>
    <edge source="NNLM模型" target="统计语言模型">
      <data key="d7">1.0</data>
      <data key="d8">NNLM模型的建模思路与统计语言模型保持一致。</data>
      <data key="d9">建模方法,思路一致</data>
      <data key="d10">chunk-fd544a0511ae2b1911f2ec7bdc2235ae</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006394</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="文本表示">
      <data key="d7">1.0</data>
      <data key="d8">Natural language processing relies on text representation as a foundational element for understanding and processing language.</data>
      <data key="d9">application,foundation</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006470</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="8.3节">
      <data key="d7">1.0</data>
      <data key="d8">Section 8.3 provides language models as a practical example of natural language processing techniques.</data>
      <data key="d9">application,example</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006472</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="9.5节">
      <data key="d7">1.0</data>
      <data key="d8">Section 9.5 provides machine translation models as a practical example of natural language processing techniques.</data>
      <data key="d9">application,example</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006473</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="Plaster">
      <data key="d7">1.0</data>
      <data key="d8">The text uses the word "plaster" as an example to illustrate the challenge of language disambiguation that Natural Language Processing aims to solve.</data>
      <data key="d9">disambiguation example,language complexity</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006618</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="计算语言学">
      <data key="d7">2.0</data>
      <data key="d8">Natural language processing incorporates computational linguistics as one of its foundational components.&lt;SEP&gt;自然语言处理通过结合计算语言学(基于规则的语言建模)来处理语言。</data>
      <data key="d9">combination,foundation,组成部分,结合</data>
      <data key="d10">chunk-b572e7e95c9e5e07043de0b3cb587187&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007481</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="文本挖掘">
      <data key="d7">2.0</data>
      <data key="d8">文本挖掘是自然语言处理的一个应用方向，旨在从文本中提取信息。&lt;SEP&gt;自然语言处理使用文本挖掘技术从非结构化文本数据中提取洞察信息。</data>
      <data key="d9">使用,包含,应用方向,技术</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade&lt;SEP&gt;chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007493</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="机器翻译">
      <data key="d7">1.0</data>
      <data key="d8">机器翻译是自然语言处理领域的早期和核心应用之一。</data>
      <data key="d9">早期应用,核心任务</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007011</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="规则引擎">
      <data key="d7">1.0</data>
      <data key="d8">在自然语言处理发展早期，系统主要基于规则引擎等人工规则方法。</data>
      <data key="d9">依赖,历史方法</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007014</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="统计机器学习">
      <data key="d7">1.0</data>
      <data key="d8">统计机器学习技术的出现是自然语言处理领域的第一次重大突破。</data>
      <data key="d9">技术革新,推动</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007018</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="知识图谱">
      <data key="d7">1.0</data>
      <data key="d8">知识图谱是自然语言处理中的一个重要应用，无论是生成知识图谱还是利用它进行问答等。</data>
      <data key="d9">关联,重要应用</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007029</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="商用工具">
      <data key="d7">1.0</data>
      <data key="d8">商用工具为自然语言处理任务提供了现成的解决方案，在精度要求不特别高的情况下可以使用。</data>
      <data key="d9">工具应用,提供方案</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007036</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="统计建模">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理结合统计建模来分析语言。</data>
      <data key="d9">方法,结合</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007483</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="搜索引擎">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理为搜索引擎提供支持。</data>
      <data key="d9">应用,支持</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007486</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="聊天机器人">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理为聊天机器人(如Alexa、Siri、Cortana)提供支持。</data>
      <data key="d9">应用,支持</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007489</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="客户支持">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理在自动化客户支持任务中特别有用。</data>
      <data key="d9">应用,自动化</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007491</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="数据输入">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理可以部分自动化数据输入任务。</data>
      <data key="d9">应用,自动化</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007494</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="文档处理">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理工具可以自动分类、提取信息和汇总文档内容。</data>
      <data key="d9">应用,自动化</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007487</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="语言翻译">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理有助于语言翻译，保留含义和上下文。</data>
      <data key="d9">应用,有助于</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007491</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="意图理解">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理使系统能够理解用户查询背后的意图。</data>
      <data key="d9">提供支持,能力</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007494</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="GPT-4">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理为GPT-4等高级语言模型提供支持，以生成类人文本。</data>
      <data key="d9">提供支持,模型</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007497</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="基于规则的NLP">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理结合基于规则的NLP方法。</data>
      <data key="d9">方法,结合</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007498</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="统计NLP">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理结合统计NLP方法，利用机器学习。</data>
      <data key="d9">方法,结合</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007499</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="命名实体识别">
      <data key="d7">1.0</data>
      <data key="d8">命名实体识别是自然语言处理中帮助处理文本数据的任务之一。</data>
      <data key="d9">任务,包括</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007500</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="文本预处理">
      <data key="d7">1.0</data>
      <data key="d8">文本预处理是自然语言处理中将原始文本转换为可分析格式的步骤。</data>
      <data key="d9">包括,步骤</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007502</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="语音命令">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理系统可以响应语音命令。</data>
      <data key="d9">响应,应用</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007509</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="语音操作的GPS系统">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理为语音操作的GPS系统提供支持。</data>
      <data key="d9">应用,支持</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007515</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="问题解答数字助理">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理为智能手机上的问题解答数字助理提供支持。</data>
      <data key="d9">应用,支持</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007518</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="数据">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理用于分析和处理数据。</data>
      <data key="d9">分析,处理</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007521</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="网络搜索">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理有助于改善网络搜索的用户体验。</data>
      <data key="d9">应用,改善</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007529</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="文档检索">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理有助于改善文档检索的用户体验。</data>
      <data key="d9">应用,改善</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007534</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="企业数据系统">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理有助于改善企业数据系统中的用户体验。</data>
      <data key="d9">应用,改善</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007538</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="电子邮件">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理提供支持的工具可以协助起草电子邮件。</data>
      <data key="d9">协助起草,应用</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007541</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="法律文书">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理提供支持的工具可以协助法律文书协作。</data>
      <data key="d9">协助协作,应用</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007545</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="语气">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理可以理解文本的语气。</data>
      <data key="d9">理解,能力</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007548</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="风格">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理可以理解文本的风格。</data>
      <data key="d9">理解,能力</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007552</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="连贯性">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理确保生成的内容具有连贯性。</data>
      <data key="d9">确保,质量</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007554</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="相关性">
      <data key="d7">1.0</data>
      <data key="d8">自然语言处理确保生成的内容具有相关性。</data>
      <data key="d9">确保,质量</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007557</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="自然语言理解">
      <data key="d7">1.0</data>
      <data key="d8">自然语言理解是自然语言处理的一个核心组成部分和应用场景。</data>
      <data key="d9">核心能力,组成部分</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008530</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="自然语言生成">
      <data key="d7">1.0</data>
      <data key="d8">自然语言生成是自然语言处理的一个核心组成部分和应用场景。</data>
      <data key="d9">核心能力,组成部分</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008534</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="大语言模型">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型是人工智能在自然语言处理领域的一种应用，是自然语言处理的重要组成部分。</data>
      <data key="d9">应用领域,组成部分</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008551</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="AIGC">
      <data key="d7">1.0</data>
      <data key="d8">AIGC涉及到的领域很广泛，其中自然语言处理是一项很重要的技术。</data>
      <data key="d9">包含关系,重要技术</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008565</data>
      <data key="d13" />
    </edge>
    <edge source="自然语言处理" target="大模型">
      <data key="d7">1.0</data>
      <data key="d8">Large Models, particularly LLMs, are key enabling technologies that power advanced applications in Natural Language Processing.</data>
      <data key="d9">application,enabling technology</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008590</data>
      <data key="d13" />
    </edge>
    <edge source="词元" target="Word2vec">
      <data key="d7">1.0</data>
      <data key="d8">The word2vec model is used to pre-train the representation of tokens.</data>
      <data key="d9">embedding,pre-training</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006470</data>
      <data key="d13" />
    </edge>
    <edge source="词元" target="GloVe">
      <data key="d7">1.0</data>
      <data key="d8">The GloVe model is used to pre-train the representation of tokens.</data>
      <data key="d9">embedding,pre-training</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006471</data>
      <data key="d13" />
    </edge>
    <edge source="词元" target="子词嵌入模型">
      <data key="d7">1.0</data>
      <data key="d8">Subword embedding models are used to pre-train the representation of tokens.</data>
      <data key="d9">embedding,pre-training</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006472</data>
      <data key="d13" />
    </edge>
    <edge source="词元" target="文本表示">
      <data key="d7">1.0</data>
      <data key="d8">A token is the basic unit for which a text representation (vector) is learned during pre-training.</data>
      <data key="d9">representation,unit</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006472</data>
      <data key="d13" />
    </edge>
    <edge source="文本表示" target="深度学习架构">
      <data key="d7">1.0</data>
      <data key="d8">Pre-trained text representations are components that can be integrated into various deep learning architectures.</data>
      <data key="d9">component,integration</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006474</data>
      <data key="d13" />
    </edge>
    <edge source="文本表示" target="图14.1">
      <data key="d7">1.0</data>
      <data key="d8">Figure 14.1 visually emphasizes the concept of pre-training text representations.</data>
      <data key="d9">conceptual illustration,visualization</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006474</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习架构" target="自然语言处理任务">
      <data key="d7">1.0</data>
      <data key="d8">Deep learning architectures are applied to execute various natural language processing tasks using pre-trained representations.</data>
      <data key="d9">application,task execution</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006471</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习架构" target="15节">
      <data key="d7">1.0</data>
      <data key="d8">Section 15 introduces the various deep learning architectures that utilize pre-trained text representations.</data>
      <data key="d9">application context,introduction</data>
      <data key="d10">chunk-747e06575d3f3c246eac89670d12c86e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006473</data>
      <data key="d13" />
    </edge>
    <edge source="孙民" target="Appier">
      <data key="d7">1.0</data>
      <data key="d8">孙民是Appier公司的首席人工智能科学家，他的观点代表了该公司的技术见解。</data>
      <data key="d9">专家观点,职业隶属</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006613</data>
      <data key="d13" />
    </edge>
    <edge source="孙民" target="传统方法">
      <data key="d7">1.0</data>
      <data key="d8">孙民指出传统方法依赖人为干预且缺乏可扩展性，难以适应不断演变的语言环境。</data>
      <data key="d9">专家评论,方法批判</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006618</data>
      <data key="d13" />
    </edge>
    <edge source="Appier" target="Appier Blog">
      <data key="d7">1.0</data>
      <data key="d8">Appier publishes and maintains the Appier Blog to share insights and trends.</data>
      <data key="d9">content creation,publication</data>
      <data key="d10">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006622</data>
      <data key="d13" />
    </edge>
    <edge source="Appier" target="AI Solution">
      <data key="d7">1.0</data>
      <data key="d8">Appier provides an AI solution that is positioned as more proactive than standard chatbots and Co-pilots.</data>
      <data key="d9">product development,service offering</data>
      <data key="d10">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006626</data>
      <data key="d13" />
    </edge>
    <edge source="Appier" target="白皮書">
      <data key="d7">1.0</data>
      <data key="d8">Appier發布了名為「鎖定高價值應用程式使用者: 運用深度學習提高獲取新客的行銷成效」的白皮書，提供深度學習在行銷應用的洞察。</data>
      <data key="d9">內容發布,知識分享</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006653</data>
      <data key="d13" />
    </edge>
    <edge source="Appier" target="Appier部落格">
      <data key="d7">1.0</data>
      <data key="d8">Appier運營著一個部落格，用於發布和傳播關於行銷科技趨勢、自動化行銷等領域的資訊和觀點。</data>
      <data key="d9">平台運營,資訊傳播</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006655</data>
      <data key="d13" />
    </edge>
    <edge source="词向量" target="关键词营销">
      <data key="d7">1.0</data>
      <data key="d8">词向量的概念在关键词营销上作用明显，可以帮助在向量空间中自动寻找相似的扩展关键词。</data>
      <data key="d9">优化工具,概念应用</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006623</data>
      <data key="d13" />
    </edge>
    <edge source="词向量" target="Vector Space">
      <data key="d7">1.0</data>
      <data key="d8">The concept of word vectors involves mapping similar words into a vector space to observe their proximity and semantic similarity.</data>
      <data key="d9">mathematical representation,similarity mapping</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006622</data>
      <data key="d13" />
    </edge>
    <edge source="语料库" target="Reddit">
      <data key="d7">1.0</data>
      <data key="d8">用于深度学习训练的语料库通常包含来自Reddit网站上的评论。</data>
      <data key="d9">数据来源,组成部分</data>
      <data key="d10">chunk-5ec46d561fc83169cc4cb16171e4b90d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006615</data>
      <data key="d13" />
    </edge>
    <edge source="语料库" target="统计机器学习">
      <data key="d7">1.0</data>
      <data key="d8">统计机器学习模型的有效应用依赖于优质语料库的建设。</data>
      <data key="d9">依赖,数据基础</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007025</data>
      <data key="d13" />
    </edge>
    <edge source="Appier Blog" target="Contextual Advertising">
      <data key="d7">1.0</data>
      <data key="d8">The Appier Blog covers topics such as Contextual Advertising as part of its content on marketing technology.</data>
      <data key="d9">information dissemination,topic coverage</data>
      <data key="d10">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006626</data>
      <data key="d13" />
    </edge>
    <edge source="Appier Blog" target="Marketing Technology Trends">
      <data key="d7">1.0</data>
      <data key="d8">The Appier Blog covers the latest marketing technology trends.</data>
      <data key="d9">information dissemination,topic coverage</data>
      <data key="d10">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006630</data>
      <data key="d13" />
    </edge>
    <edge source="Appier Blog" target="Automated Marketing">
      <data key="d7">1.0</data>
      <data key="d8">The Appier Blog covers topics related to automated marketing.</data>
      <data key="d9">information dissemination,topic coverage</data>
      <data key="d10">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006635</data>
      <data key="d13" />
    </edge>
    <edge source="Appier Blog" target="Industry Trends">
      <data key="d7">1.0</data>
      <data key="d8">The Appier Blog covers industry trends.</data>
      <data key="d9">information dissemination,topic coverage</data>
      <data key="d10">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006651</data>
      <data key="d13" />
    </edge>
    <edge source="Appier Blog" target="Best Practice Cases">
      <data key="d7">1.0</data>
      <data key="d8">The Appier Blog covers best practice cases.</data>
      <data key="d9">information dissemination,topic coverage</data>
      <data key="d10">chunk-93d921ef5f299976a4f4ffe79dfe7521</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006658</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習" target="孫民">
      <data key="d7">1.0</data>
      <data key="d8">孫民提到深度學習可以幫助企業從種子資料中尋找相似關鍵字，並對自然語言處理的未來發展充滿信心。</data>
      <data key="d9">專家觀點,技術應用</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006645</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習" target="行銷自動化">
      <data key="d7">1.0</data>
      <data key="d8">基於深度學習的自然語言處理機制有助於節省人力資源，使行銷工作更具可擴充性，並推動未來的行銷自動化。</data>
      <data key="d9">可擴充性,技術推動</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006652</data>
      <data key="d13" />
    </edge>
    <edge source="深度學習" target="白皮書">
      <data key="d7">1.0</data>
      <data key="d8">Appier的白皮書主題是探討如何運用深度學習來提高獲取新客的行銷成效。</data>
      <data key="d9">主題探討,應用指南</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006656</data>
      <data key="d13" />
    </edge>
    <edge source="人工智慧" target="種子資料">
      <data key="d7">1.0</data>
      <data key="d8">企業將種子資料輸入人工智慧，人工智慧便能在向量空間中尋找相似的關鍵字，協助擴展行銷清單。</data>
      <data key="d9">資料輸入,關鍵字擴展</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006631</data>
      <data key="d13" />
    </edge>
    <edge source="人工智慧" target="情感分析">
      <data key="d7">1.0</data>
      <data key="d8">人工智慧透過情感分析，根據使用者搜尋的關鍵字組合(如「宿霧」和「地震」)來判定其是否為合適的行銷對象。</data>
      <data key="d9">判斷依據,受眾篩選</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006652</data>
      <data key="d13" />
    </edge>
    <edge source="人工智慧" target="聊天機器人">
      <data key="d7">1.0</data>
      <data key="d8">聊天機器人是人工智慧的應用形式之一，未來有望在經過微調後處理更複雜的查詢問題。</data>
      <data key="d9">應用形式,複雜查詢</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006650</data>
      <data key="d13" />
    </edge>
    <edge source="人工智慧" target="廣告創意素材">
      <data key="d7">1.0</data>
      <data key="d8">人工智慧可以用於打造廣告創意素材，從而實現「千人千面」的個性化顧客旅程。</data>
      <data key="d9">個性化行銷,內容生成</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006656</data>
      <data key="d13" />
    </edge>
    <edge source="人工智慧" target="Agentic AI">
      <data key="d7">1.0</data>
      <data key="d8">Agentic AI是人工智慧的一種進階解決方案，相較於聊天機器人和Co-pilot，具備更強的主動思考與行動能力。</data>
      <data key="d9">能力比較,進階類型</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006659</data>
      <data key="d13" />
    </edge>
    <edge source="關鍵字清單" target="旅遊公司">
      <data key="d7">1.0</data>
      <data key="d8">旅遊公司會根據行銷目標預先構思關鍵字清單，用於定義其目標市場和觸及潛在顧客。</data>
      <data key="d9">目標定義,行銷工具</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006645</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="文本分类">
      <data key="d7">1.0</data>
      <data key="d8">文本分类和情感分析都属于深度学习中“多对一”类型的应用，即输入序列输出单一结果。</data>
      <data key="d9">多对一任务,自然语言处理</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007104</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="文本挖掘">
      <data key="d7">1.0</data>
      <data key="d8">情感分析是文本挖掘中使用的一种技术，用于提取文本中的主观特质。</data>
      <data key="d9">包括,技术</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007494</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="态度">
      <data key="d7">1.0</data>
      <data key="d8">情感分析可以从文本中提取态度等主观特质。</data>
      <data key="d9">提取,特质</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007521</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="情感">
      <data key="d7">1.0</data>
      <data key="d8">情感分析可以从文本中提取情感等主观特质。</data>
      <data key="d9">提取,特质</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007526</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="讽刺">
      <data key="d7">1.0</data>
      <data key="d8">情感分析可以从文本中提取讽刺等主观特质。</data>
      <data key="d9">提取,特质</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007529</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="困惑">
      <data key="d7">1.0</data>
      <data key="d8">情感分析可以从文本中提取困惑等主观特质。</data>
      <data key="d9">提取,特质</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007534</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="怀疑">
      <data key="d7">1.0</data>
      <data key="d8">情感分析可以从文本中提取怀疑等主观特质。</data>
      <data key="d9">提取,特质</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007538</data>
      <data key="d13" />
    </edge>
    <edge source="情感分析" target="通信路由">
      <data key="d7">1.0</data>
      <data key="d8">情感分析通常用于将通信路由到适当的系统或人员。</data>
      <data key="d9">应用,用于</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007541</data>
      <data key="d13" />
    </edge>
    <edge source="白皮書" target="獲取新客">
      <data key="d7">1.0</data>
      <data key="d8">該白皮書的核心內容是關於運用深度學習策略來提高企業獲取新客戶的成效。</data>
      <data key="d9">成效提升,目標聚焦</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006650</data>
      <data key="d13" />
    </edge>
    <edge source="廣告創意素材" target="千人千面">
      <data key="d7">1.0</data>
      <data key="d8">通過AI打造廣告創意素材，是實現「千人千面」顧客旅程的一種具體方法。</data>
      <data key="d9">實現手段,顧客體驗</data>
      <data key="d10">chunk-23a71ac8e1e391c0d5c2b9361cf23dc1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006651</data>
      <data key="d13" />
    </edge>
    <edge source="NLP预处理" target="原始文本">
      <data key="d7">1.0</data>
      <data key="d8">NLP预处理以原始文本作为输入，对其进行处理以准备后续分析。</data>
      <data key="d9">数据处理,输入转换</data>
      <data key="d10">chunk-38b1076024c94a070f64f72dcaea1102</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006693</data>
      <data key="d13" />
    </edge>
    <edge source="NLP预处理" target="程序">
      <data key="d7">1.0</data>
      <data key="d8">NLP预处理将文本准备好，以便程序能够对其进行分析。</data>
      <data key="d9">分析支持,数据准备</data>
      <data key="d10">chunk-38b1076024c94a070f64f72dcaea1102</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006687</data>
      <data key="d13" />
    </edge>
    <edge source="NLP预处理" target="机器学习模型">
      <data key="d7">1.0</data>
      <data key="d8">NLP预处理将文本准备好，以便机器学习模型能够对其进行分析。</data>
      <data key="d9">分析支持,数据准备</data>
      <data key="d10">chunk-38b1076024c94a070f64f72dcaea1102</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006688</data>
      <data key="d13" />
    </edge>
    <edge source="原始文本" target="文本预处理">
      <data key="d7">1.0</data>
      <data key="d8">文本预处理将原始文本转换成机器更容易理解的格式。</data>
      <data key="d9">转换,输入</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007549</data>
      <data key="d13" />
    </edge>
    <edge source="机器学习模型" target="LLM">
      <data key="d7">1.0</data>
      <data key="d8">LLM is a specific type of machine learning model with advanced language understanding and generation capabilities.</data>
      <data key="d9">category,instance</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009057</data>
      <data key="d13" />
    </edge>
    <edge source="计算语言学" target="人类语言">
      <data key="d7">1.0</data>
      <data key="d8">Computational linguistics is the scientific study and modeling of human language using computational tools.</data>
      <data key="d9">modeling,study</data>
      <data key="d10">chunk-b572e7e95c9e5e07043de0b3cb587187</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006724</data>
      <data key="d13" />
    </edge>
    <edge source="计算语言学" target="句法分析">
      <data key="d7">1.0</data>
      <data key="d8">计算语言学包括句法分析，通过解析语法来确定含义。</data>
      <data key="d9">分析方法,包括</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007487</data>
      <data key="d13" />
    </edge>
    <edge source="计算语言学" target="语义分析">
      <data key="d7">1.0</data>
      <data key="d8">计算语言学包括语义分析，从单词和句子结构中提取含义。</data>
      <data key="d9">分析方法,包括</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007491</data>
      <data key="d13" />
    </edge>
    <edge source="计算语言学" target="数据科学">
      <data key="d7">1.0</data>
      <data key="d8">计算语言学利用数据科学来分析语言和语音。</data>
      <data key="d9">利用,领域</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007546</data>
      <data key="d13" />
    </edge>
    <edge source="达观数据" target="人人都是产品经理">
      <data key="d7">1.0</data>
      <data key="d8">达观数据在人人都是产品经理平台上发布了本文。</data>
      <data key="d9">内容发布,平台</data>
      <data key="d10">chunk-432af570193bd3df6d564434ee8bfbbb</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006995</data>
      <data key="d13" />
    </edge>
    <edge source="AlphaGo项目" target="David Silver">
      <data key="d7">1.0</data>
      <data key="d8">David Silver是AlphaGo项目的主要负责人。</data>
      <data key="d9">负责,领导</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769006999</data>
      <data key="d13" />
    </edge>
    <edge source="文本挖掘" target="非结构化文本数据">
      <data key="d7">1.0</data>
      <data key="d8">文本挖掘技术用于分析非结构化文本数据。</data>
      <data key="d9">分析,来源</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007515</data>
      <data key="d13" />
    </edge>
    <edge source="文本挖掘" target="模式">
      <data key="d7">1.0</data>
      <data key="d8">文本挖掘可以发现大型数据集中的模式。</data>
      <data key="d9">发现,结果</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007518</data>
      <data key="d13" />
    </edge>
    <edge source="文本挖掘" target="趋势">
      <data key="d7">1.0</data>
      <data key="d8">文本挖掘可以发现大型数据集中的趋势。</data>
      <data key="d9">发现,结果</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007522</data>
      <data key="d13" />
    </edge>
    <edge source="机器翻译" target="序列标注">
      <data key="d7">1.0</data>
      <data key="d8">机器翻译和序列标注都是“多对多”的深度学习应用，区别在于前者是异步的，后者是同步的。</data>
      <data key="d9">多对多任务,序列到序列</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007105</data>
      <data key="d13" />
    </edge>
    <edge source="中文分词" target="命名实体识别">
      <data key="d7">1.0</data>
      <data key="d8">中文分词和命名实体识别都属于中文自然语言处理中词级别的底层处理技术。</data>
      <data key="d9">基础处理,技术层级</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007019</data>
      <data key="d13" />
    </edge>
    <edge source="中文分词" target="开源工具">
      <data key="d7">1.0</data>
      <data key="d8">有很好的开源工具可以实现中文分词等功能，使得开发者无需从头开发底层技术。</data>
      <data key="d9">工具实现,提供支持</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007034</data>
      <data key="d13" />
    </edge>
    <edge source="依存文法分析" target="语义归一化">
      <data key="d7">1.0</data>
      <data key="d8">依存文法分析和语义归一化都是针对句子或段落级别文本的处理技术。</data>
      <data key="d9">并列关系,段落级技术</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007021</data>
      <data key="d13" />
    </edge>
    <edge source="依存文法分析" target="词位置分析">
      <data key="d7">1.0</data>
      <data key="d8">词位置分析与依存文法分析同属于针对句子或段落级别文本的自然语言处理技术。</data>
      <data key="d9">并列关系,段落级技术</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007038</data>
      <data key="d13" />
    </edge>
    <edge source="达观" target="篇章">
      <data key="d7">1.0</data>
      <data key="d8">达观公司将自然语言处理中针对文章级别的应用称为“篇章”级应用。</data>
      <data key="d9">应用层级,术语定义</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007029</data>
      <data key="d13" />
    </edge>
    <edge source="篇章" target="主题模型">
      <data key="d7">1.0</data>
      <data key="d8">主题模型是应用于篇章级别文本的一种高层次自然语言处理技术。</data>
      <data key="d9">应用技术,服务于层级</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007031</data>
      <data key="d13" />
    </edge>
    <edge source="篇章" target="文章建模">
      <data key="d7">1.0</data>
      <data key="d8">文章建模是应用于篇章级别文本的一种高层次自然语言处理技术。</data>
      <data key="d9">应用技术,服务于层级</data>
      <data key="d10">chunk-ba24370cf2cd1eb19282998e57cddade</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007036</data>
      <data key="d13" />
    </edge>
    <edge source="Knowledge Base" target="RAG">
      <data key="d7">1.0</data>
      <data key="d8">RAG retrieves relevant information from a Knowledge Base to generate precise answers.</data>
      <data key="d9">information source,retrieval</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008776</data>
      <data key="d13" />
    </edge>
    <edge source="Knowledge Base" target="Retrieval-Augmented Generation">
      <data key="d7">1.0</data>
      <data key="d8">Retrieval-Augmented Generation works by first retrieving relevant information from an external Knowledge Base.</data>
      <data key="d9">external data,information retrieval</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008799</data>
      <data key="d13" />
    </edge>
    <edge source="文本分类" target="卷积">
      <data key="d7">1.0</data>
      <data key="d8">卷积不仅在图像处理中应用，在文本分类等自然语言处理任务中也用得非常好。</data>
      <data key="d9">应用广泛,特征提取</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007110</data>
      <data key="d13" />
    </edge>
    <edge source="Word2Vec" target="表示学习">
      <data key="d7">1.0</data>
      <data key="d8">Word2Vec是将字或词变成向量来表示的代表性工作，属于表示学习。</data>
      <data key="d9">代表性工作,向量表示</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007042</data>
      <data key="d13" />
    </edge>
    <edge source="Word2Vec" target="One-Hot编码">
      <data key="d7">1.0</data>
      <data key="d8">在Word2Vec之前，词的表示方式几乎都是one hot，而Word2Vec克服了其不能计算相似度的缺点。</data>
      <data key="d9">对比,改进</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007048</data>
      <data key="d13" />
    </edge>
    <edge source="Word2Vec" target="语义计算">
      <data key="d7">1.0</data>
      <data key="d8">有了Word2Vec的向量表示之后，可以进行语义计算，例如判断类比关系。</data>
      <data key="d9">关系推断,应用</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007056</data>
      <data key="d13" />
    </edge>
    <edge source="Word2Vec" target="泛化能力">
      <data key="d7">1.0</data>
      <data key="d8">Word2Vec的向量表示增强了模型的泛化能力。</data>
      <data key="d9">提供好处,能力增强</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007060</data>
      <data key="d13" />
    </edge>
    <edge source="Word2Vec" target="向量相似度">
      <data key="d7">1.0</data>
      <data key="d8">Word2Vec产生的低维稠密向量支持计算相似度，从而判断词或实体之间的关系。</data>
      <data key="d9">关系判断,支持计算</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007065</data>
      <data key="d13" />
    </edge>
    <edge source="Word2Vec" target="Feature Extraction">
      <data key="d7">1.0</data>
      <data key="d8">Word2Vec is an advanced word embedding method used for feature extraction to capture semantic meaning.</data>
      <data key="d9">advanced method,semantic representation</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007452</data>
      <data key="d13" />
    </edge>
    <edge source="Bi-LSTM" target="Sequence Labeling">
      <data key="d7">1.0</data>
      <data key="d8">Bi-LSTM is a recommended deep learning approach for sequence labeling in practical applications due to its ability to capture long context and balance performance with complexity.</data>
      <data key="d9">deep learning model,employs</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007072</data>
      <data key="d13" />
    </edge>
    <edge source="Bi-LSTM" target="CRF">
      <data key="d7">1.0</data>
      <data key="d8">A model structure combines Bi-LSTM for feature engineering and CRF for label output, representing a perfect integration of deep learning and traditional methods to capture sequence dependencies.</data>
      <data key="d9">hybrid architecture,integration</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007079</data>
      <data key="d13" />
    </edge>
    <edge source="Bi-LSTM" target="Sequence Dependency">
      <data key="d7">1.0</data>
      <data key="d8">When used alone for sequence labeling, Bi-LSTM does not model dependencies between output labels, which is a limitation addressed by adding a CRF layer.</data>
      <data key="d9">label relationship,lacks</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007094</data>
      <data key="d13" />
    </edge>
    <edge source="卷积" target="过滤器">
      <data key="d7">1.0</data>
      <data key="d8">卷积操作使用过滤器(如九宫格)与输入矩阵相乘以提取特征。</data>
      <data key="d9">使用工具,特征提取</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007051</data>
      <data key="d13" />
    </edge>
    <edge source="卷积" target="步长">
      <data key="d7">1.0</data>
      <data key="d8">卷积操作中，过滤器平移的步长是可选择的参数。</data>
      <data key="d9">参数,平移间隔</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007056</data>
      <data key="d13" />
    </edge>
    <edge source="达观杯算法大赛" target="Baseline">
      <data key="d7">1.0</data>
      <data key="d8">In the "达观杯" algorithm competition, many participants used the baseline model, which performed surprisingly well.</data>
      <data key="d9">competition,reference model</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007105</data>
      <data key="d13" />
    </edge>
    <edge source="威海" target="潍坊">
      <data key="d7">1.0</data>
      <data key="d8">在Word2Vec向量空间中，威海和潍坊这两个城市的向量表示距离非常近。</data>
      <data key="d9">向量相似,空间邻近</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007052</data>
      <data key="d13" />
    </edge>
    <edge source="威海" target="枣庄">
      <data key="d7">1.0</data>
      <data key="d8">在Word2Vec向量空间中，威海和枣庄这两个城市的向量表示距离非常近。</data>
      <data key="d9">向量相似,空间邻近</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007060</data>
      <data key="d13" />
    </edge>
    <edge source="威海" target="山东">
      <data key="d7">1.0</data>
      <data key="d8">在语义计算中，山东与威海的关系构成了一个语义对。</data>
      <data key="d9">类比推理,语义关系</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007065</data>
      <data key="d13" />
    </edge>
    <edge source="潍坊" target="枣庄">
      <data key="d7">1.0</data>
      <data key="d8">在Word2Vec向量空间中，潍坊和枣庄这两个城市的向量表示距离非常近。</data>
      <data key="d9">向量相似,空间邻近</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007056</data>
      <data key="d13" />
    </edge>
    <edge source="广东" target="佛山">
      <data key="d7">1.0</data>
      <data key="d8">在语义计算中，广东与佛山的关系构成了一个语义对。</data>
      <data key="d9">类比推理,语义关系</data>
      <data key="d10">chunk-012b11b19422c013994d2348ab5422de</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007056</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Pyramid CNN" target="Block N">
      <data key="d7">1.0</data>
      <data key="d8">The Deep Pyramid CNN architecture is built by stacking multiple instances of a structural unit referred to as Block N.</data>
      <data key="d9">composed of,structural unit</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007077</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Pyramid CNN" target="Semantic Level">
      <data key="d7">1.0</data>
      <data key="d8">The Deep Pyramid CNN model achieves partial interpretability by learning and indicating which semantic features contribute most to classification at the semantic level.</data>
      <data key="d9">achieves,interpretability</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007084</data>
      <data key="d13" />
    </edge>
    <edge source="Embedding" target="Transformer Encoder">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer Encoder applies an Embedding process to convert input tokens into vector representations, which are then scaled and combined with positional encoding.</data>
      <data key="d9">feature extraction,input transformation</data>
      <data key="d10">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007842</data>
      <data key="d13" />
    </edge>
    <edge source="Embedding" target="Token">
      <data key="d7">1.0</data>
      <data key="d8">A token is represented numerically as an embedding, which is then used for further processing.</data>
      <data key="d9">representation,transformation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008207</data>
      <data key="d13" />
    </edge>
    <edge source="Embedding" target="Query, Key, Value Vectors">
      <data key="d7">1.0</data>
      <data key="d8">Query, key, and value vectors are generated by transforming the original token embedding through specific weight matrices.</data>
      <data key="d9">generation,transformation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008214</data>
      <data key="d13" />
    </edge>
    <edge source="Sequence Labeling" target="BMES">
      <data key="d7">1.0</data>
      <data key="d8">Sequence labeling tasks commonly use the BMES tag system to define the label schema.</data>
      <data key="d9">tagging system,utilizes</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007060</data>
      <data key="d13" />
    </edge>
    <edge source="Sequence Labeling" target="CRF">
      <data key="d7">1.0</data>
      <data key="d8">Traditional CRF models are effectively used for sequence labeling tasks.</data>
      <data key="d9">employs,traditional model</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007066</data>
      <data key="d13" />
    </edge>
    <edge source="Sequence Labeling" target="Label System">
      <data key="d7">1.0</data>
      <data key="d8">Performing sequence labeling requires first defining a label system or tag set.</data>
      <data key="d9">definition,requires</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007081</data>
      <data key="d13" />
    </edge>
    <edge source="Char-Level Embedding" target="Word-Level Embedding">
      <data key="d7">1.0</data>
      <data key="d8">In the described model, character-level embeddings (learned via RNN/CNN) are merged and then concatenated with word-level embeddings to form a comprehensive input representation.</data>
      <data key="d9">combination,feature fusion</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007067</data>
      <data key="d13" />
    </edge>
    <edge source="Char-Level Embedding" target="Manual Features">
      <data key="d7">1.0</data>
      <data key="d8">Character-level embeddings and word-level embeddings can be combined with manually crafted features based on the model designer's choice.</data>
      <data key="d9">combination,feature fusion</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007072</data>
      <data key="d13" />
    </edge>
    <edge source="Generative Summarization" target="Beam Search">
      <data key="d7">1.0</data>
      <data key="d8">During the decoding phase of generative tasks like headline generation, beam search is used to find the best output sequence.</data>
      <data key="d9">decoding algorithm,utilizes</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007077</data>
      <data key="d13" />
    </edge>
    <edge source="Generative Summarization" target="News Headline Generation">
      <data key="d7">1.0</data>
      <data key="d8">The task of generating a news headline from the first paragraph of an article is given as a simpler, practical example of generative summarization.</data>
      <data key="d9">exemplified by,practical application</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007094</data>
      <data key="d13" />
    </edge>
    <edge source="Generative Summarization" target="Decoding">
      <data key="d7">1.0</data>
      <data key="d8">The process of generative summarization involves a decoding step to produce the final output sequence, such as a summary or headline.</data>
      <data key="d9">involves,output generation</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007101</data>
      <data key="d13" />
    </edge>
    <edge source="Max-Pooling" target="单层CNN">
      <data key="d7">1.0</data>
      <data key="d8">The single-layer CNN uses max-pooling to obtain the largest feature from each feature map as its final output.</data>
      <data key="d9">feature selection,network layer</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007104</data>
      <data key="d13" />
    </edge>
    <edge source="News Headline Generation" target="News Website">
      <data key="d7">1.0</data>
      <data key="d8">News headline generation models can be trained using data crawled from news websites, using the first paragraph as input and the title as output.</data>
      <data key="d9">data source,uses data from</data>
      <data key="d10">chunk-330f64bec90f2f131895d2de62adeb6f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007101</data>
      <data key="d13" />
    </edge>
    <edge source="细胞状态" target="Ct-1">
      <data key="d7">1.0</data>
      <data key="d8">Ct-1 represents the cell state from the previous time step, which is a component of the overall cell state concept.</data>
      <data key="d9">previous step,state component</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007102</data>
      <data key="d13" />
    </edge>
    <edge source="细胞状态" target="Ct">
      <data key="d7">1.0</data>
      <data key="d8">Ct is the updated value of the cell state after combining retained information from Ct-1 and new input information.</data>
      <data key="d9">current step,state update</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007108</data>
      <data key="d13" />
    </edge>
    <edge source="单层CNN" target="Deep Pyramin CNN">
      <data key="d7">1.0</data>
      <data key="d8">单层CNN是结构简单的卷积网络，而Deep Pyramin CNN是其深度扩展的版本。</data>
      <data key="d9">深度扩展,网络结构</data>
      <data key="d10">chunk-c19e0a082e14fb0e3e54b47fab68066a</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007107</data>
      <data key="d13" />
    </edge>
    <edge source="Feature Extraction" target="Bag Of Words">
      <data key="d7">1.0</data>
      <data key="d8">Bag of Words is a specific technique used in the feature extraction process to quantify word presence.</data>
      <data key="d9">quantification,technique</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007454</data>
      <data key="d13" />
    </edge>
    <edge source="Feature Extraction" target="Tf-Idf">
      <data key="d7">1.0</data>
      <data key="d8">TF-IDF is a specific technique used in the feature extraction process to quantify word importance.</data>
      <data key="d9">importance weighting,technique</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007449</data>
      <data key="d13" />
    </edge>
    <edge source="Feature Extraction" target="Glove">
      <data key="d7">1.0</data>
      <data key="d8">GloVe is an advanced word embedding method used for feature extraction to capture semantic meaning.</data>
      <data key="d9">advanced method,semantic representation</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007456</data>
      <data key="d13" />
    </edge>
    <edge source="Feature Extraction" target="Contextual Embeddings">
      <data key="d7">1.0</data>
      <data key="d8">Contextual embeddings are an advanced approach that enhances the feature extraction process by considering word context.</data>
      <data key="d9">context-aware representation,enhancement</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007462</data>
      <data key="d13" />
    </edge>
    <edge source="Text Analysis" target="Part-Of-Speech Tagging">
      <data key="d7">1.0</data>
      <data key="d8">Part-of-speech tagging is a specific task performed during text analysis to identify word grammar.</data>
      <data key="d9">grammatical analysis,syntactic role</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007444</data>
      <data key="d13" />
    </edge>
    <edge source="Text Analysis" target="Named Entity Recognition">
      <data key="d7">1.0</data>
      <data key="d8">Named Entity Recognition is a specific task performed during text analysis to identify key entities.</data>
      <data key="d9">entity detection,information extraction</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007449</data>
      <data key="d13" />
    </edge>
    <edge source="Text Analysis" target="Dependency Parsing">
      <data key="d7">1.0</data>
      <data key="d8">Dependency parsing is a specific task performed during text analysis to understand grammatical relationships.</data>
      <data key="d9">sentence structure,syntactic analysis</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007452</data>
      <data key="d13" />
    </edge>
    <edge source="Text Analysis" target="Sentiment Analysis">
      <data key="d7">1.0</data>
      <data key="d8">Sentiment analysis is a specific task performed during text analysis to determine emotional tone.</data>
      <data key="d9">opinion mining,tone assessment</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007456</data>
      <data key="d13" />
    </edge>
    <edge source="Text Analysis" target="Topic Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Topic modeling is a specific technique used in text analysis to uncover latent topics in documents.</data>
      <data key="d9">pattern discovery,theme identification</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007462</data>
      <data key="d13" />
    </edge>
    <edge source="Nlp Models" target="Human Language">
      <data key="d7">1.0</data>
      <data key="d8">NLP models face significant challenges due to the inherent ambiguity and complexity of human language.</data>
      <data key="d9">ambiguity challenge,complexity</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007457</data>
      <data key="d13" />
    </edge>
    <edge source="Ibm Granite" target="Ibm Embedded Ai">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite is a series of AI models that are part of IBM's offerings for embedding AI into applications.</data>
      <data key="d9">ai model series,application enhancement</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007458</data>
      <data key="d13" />
    </edge>
    <edge source="Ibm Granite" target="Ibm">
      <data key="d7">1.0</data>
      <data key="d8">IBM Granite is a series of AI models developed and owned by IBM.</data>
      <data key="d9">corporate ownership,product development</data>
      <data key="d10">chunk-59b5b5bb9f78f0060c833f3b8b091e05</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007464</data>
      <data key="d13" />
    </edge>
    <edge source="搜索引擎" target="关键字匹配">
      <data key="d7">1.0</data>
      <data key="d8">搜索引擎传统上依赖于关键字匹配来查找信息。</data>
      <data key="d9">使用,方法</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007529</data>
      <data key="d13" />
    </edge>
    <edge source="聊天机器人" target="Amazon Alexa">
      <data key="d7">1.0</data>
      <data key="d8">Amazon Alexa是聊天机器人的一个实例。</data>
      <data key="d9">实例,类型</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007491</data>
      <data key="d13" />
    </edge>
    <edge source="聊天机器人" target="Apple Siri">
      <data key="d7">1.0</data>
      <data key="d8">Apple Siri是聊天机器人的一个实例。</data>
      <data key="d9">实例,类型</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007494</data>
      <data key="d13" />
    </edge>
    <edge source="聊天机器人" target="Microsoft Cortana">
      <data key="d7">1.0</data>
      <data key="d8">Microsoft Cortana是聊天机器人的一个实例。</data>
      <data key="d9">实例,类型</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007487</data>
      <data key="d13" />
    </edge>
    <edge source="聊天机器人" target="LLM">
      <data key="d7">1.0</data>
      <data key="d8">LLMs can be implemented in chatbots to provide applications like 24/7 customer support.</data>
      <data key="d9">application,implementation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009070</data>
      <data key="d13" />
    </edge>
    <edge source="Apple Siri" target="Apple">
      <data key="d7">1.0</data>
      <data key="d8">Apple公司开发了Apple Siri语音助手。</data>
      <data key="d9">产品,开发</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007507</data>
      <data key="d13" />
    </edge>
    <edge source="Microsoft Cortana" target="Microsoft">
      <data key="d7">1.0</data>
      <data key="d8">Microsoft公司开发了Microsoft Cortana语音助手。</data>
      <data key="d9">产品,开发</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007508</data>
      <data key="d13" />
    </edge>
    <edge source="客户支持" target="LLM">
      <data key="d7">1.0</data>
      <data key="d8">LLMs can help supplement or fully undertake customer support tasks, automating this function.</data>
      <data key="d9">application,task automation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009059</data>
      <data key="d13" />
    </edge>
    <edge source="语言翻译" target="LLM">
      <data key="d7">1.0</data>
      <data key="d8">Language translation is one of the capabilities of LLMs.</data>
      <data key="d9">application,capability</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009075</data>
      <data key="d13" />
    </edge>
    <edge source="意图理解" target="用户查询">
      <data key="d7">1.0</data>
      <data key="d8">意图理解是系统理解用户查询背后意图的能力。</data>
      <data key="d9">对象,理解</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007527</data>
      <data key="d13" />
    </edge>
    <edge source="意图理解" target="上下文">
      <data key="d7">1.0</data>
      <data key="d8">意图理解考虑用户查询的上下文以提供更准确的结果。</data>
      <data key="d9">因素,考虑</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007531</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-4" target="报告">
      <data key="d7">1.0</data>
      <data key="d8">GPT-4可以根据提示生成报告。</data>
      <data key="d9">内容,生成</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007539</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-4" target="营销文案">
      <data key="d7">1.0</data>
      <data key="d8">GPT-4可以根据提示生成营销文案。</data>
      <data key="d9">内容,生成</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007542</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-4" target="产品描述">
      <data key="d7">1.0</data>
      <data key="d8">GPT-4可以根据提示生成产品描述。</data>
      <data key="d9">内容,生成</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007545</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-4" target="创意写作内容">
      <data key="d7">1.0</data>
      <data key="d8">GPT-4可以根据提示生成创意写作内容。</data>
      <data key="d9">内容,生成</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007548</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-4" target="Large Language Model">
      <data key="d7">1.0</data>
      <data key="d8">GPT-4 is a closed-source Large Language Model noted for its outstanding performance.</data>
      <data key="d9">example,performance</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008787</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-4" target="LLama 3.2">
      <data key="d7">1.0</data>
      <data key="d8">LLama 3.2 outperforms GPT-4 in various benchmark tests but is noted as less excellent in practical applications.</data>
      <data key="d9">benchmark comparison,performance</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008790</data>
      <data key="d13" />
    </edge>
    <edge source="基于规则的NLP" target="语法规则">
      <data key="d7">1.0</data>
      <data key="d8">基于规则的NLP使用预先编程的语法规则。</data>
      <data key="d9">使用,基础</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007548</data>
      <data key="d13" />
    </edge>
    <edge source="统计NLP" target="词性标注">
      <data key="d7">1.0</data>
      <data key="d8">统计NLP能够进行词性标注等复杂的语言学细分任务。</data>
      <data key="d9">任务,进行</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007500</data>
      <data key="d13" />
    </edge>
    <edge source="文本预处理" target="标记化">
      <data key="d7">1.0</data>
      <data key="d8">标记化是文本预处理中将文本拆分为更小单位的第一步。</data>
      <data key="d9">包括,步骤</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007503</data>
      <data key="d13" />
    </edge>
    <edge source="文本预处理" target="停用词删除">
      <data key="d7">1.0</data>
      <data key="d8">停用词删除是文本预处理中过滤掉常见词的步骤。</data>
      <data key="d9">包括,步骤</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007507</data>
      <data key="d13" />
    </edge>
    <edge source="文本预处理" target="词干提取">
      <data key="d7">1.0</data>
      <data key="d8">词干提取是文本预处理中将单词简化为词根形式的步骤。</data>
      <data key="d9">包括,步骤</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007512</data>
      <data key="d13" />
    </edge>
    <edge source="文本预处理" target="词形还原">
      <data key="d7">1.0</data>
      <data key="d8">词形还原是文本预处理中将单词还原为原形的步骤。</data>
      <data key="d9">包括,步骤</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007525</data>
      <data key="d13" />
    </edge>
    <edge source="文本预处理" target="小写转换">
      <data key="d7">1.0</data>
      <data key="d8">小写转换是文本预处理中进行文本标准化的一个步骤。</data>
      <data key="d9">包括,步骤</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007553</data>
      <data key="d13" />
    </edge>
    <edge source="文本预处理" target="文本清理">
      <data key="d7">1.0</data>
      <data key="d8">文本清理是文本预处理中删除不需要元素的步骤。</data>
      <data key="d9">包括,步骤</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007556</data>
      <data key="d13" />
    </edge>
    <edge source="非结构化文本数据" target="客户评论">
      <data key="d7">1.0</data>
      <data key="d8">客户评论是非结构化文本数据的一种类型。</data>
      <data key="d9">包括,类型</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007518</data>
      <data key="d13" />
    </edge>
    <edge source="非结构化文本数据" target="社交媒体帖子">
      <data key="d7">1.0</data>
      <data key="d8">社交媒体帖子是非结构化文本数据的一种类型。</data>
      <data key="d9">包括,类型</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007521</data>
      <data key="d13" />
    </edge>
    <edge source="非结构化文本数据" target="新闻文章">
      <data key="d7">1.0</data>
      <data key="d8">新闻文章是非结构化文本数据的一种类型。</data>
      <data key="d9">包括,类型</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007526</data>
      <data key="d13" />
    </edge>
    <edge source="情感" target="魏犇群">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun mentions that re-understanding human uniqueness in the AI era includes re-understanding emotion.</data>
      <data key="d9">human uniqueness,re-understanding</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011195</data>
      <data key="d13" />
    </edge>
    <edge source="文本清理" target="标点符号">
      <data key="d7">1.0</data>
      <data key="d8">文本清理会删除可能使分析混乱的标点符号。</data>
      <data key="d9">删除,对象</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007559</data>
      <data key="d13" />
    </edge>
    <edge source="文本清理" target="特殊字符">
      <data key="d7">1.0</data>
      <data key="d8">文本清理会删除可能使分析混乱的特殊字符。</data>
      <data key="d9">删除,对象</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007560</data>
      <data key="d13" />
    </edge>
    <edge source="文本清理" target="数字">
      <data key="d7">1.0</data>
      <data key="d8">文本清理会删除可能使分析混乱的数字。</data>
      <data key="d9">删除,对象</data>
      <data key="d10">chunk-0e7e40a218a89d1fc6c27eae7e866792</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007561</data>
      <data key="d13" />
    </edge>
    <edge source="Encoder Block" target="Multi-Head Attention">
      <data key="d7">1.0</data>
      <data key="d8">An Encoder block contains one Multi-Head Attention layer as a core component for self-attention.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007695</data>
      <data key="d13" />
    </edge>
    <edge source="Encoder Block" target="Add &amp; Norm Layer">
      <data key="d7">1.0</data>
      <data key="d8">An Encoder block contains an Add &amp; Norm layer following the Multi-Head Attention and Feed Forward layers.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007690</data>
      <data key="d13" />
    </edge>
    <edge source="Encoder Block" target="Output Matrix O">
      <data key="d7">1.0</data>
      <data key="d8">An Encoder block processes the Input Matrix X and produces the Output Matrix O.</data>
      <data key="d9">output,produces</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007702</data>
      <data key="d13" />
    </edge>
    <edge source="Decoder Block" target="Multi-Head Attention">
      <data key="d7">1.0</data>
      <data key="d8">A Decoder block contains two Multi-Head Attention layers, one of which is a Masked Multi-Head Attention.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007690</data>
      <data key="d13" />
    </edge>
    <edge source="Decoder Block" target="Add &amp; Norm Layer">
      <data key="d7">1.0</data>
      <data key="d8">A Decoder block contains Add &amp; Norm layers following its attention mechanisms.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007693</data>
      <data key="d13" />
    </edge>
    <edge source="Decoder Block" target="Input Matrix X">
      <data key="d7">1.0</data>
      <data key="d8">The first Decoder block processes the Input Matrix X (or embeddings) as its initial input.</data>
      <data key="d9">input,processes</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007710</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-Head Attention" target="Self-Attention">
      <data key="d7">1.0</data>
      <data key="d8">Multi-Head Attention is composed of multiple parallel Self-Attention mechanisms.</data>
      <data key="d9">composition,consists of</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007685</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-Head Attention" target="Linear Layer">
      <data key="d7">1.0</data>
      <data key="d8">Multi-Head Attention uses a Linear Layer to project the concatenated outputs from its multiple heads into the final output.</data>
      <data key="d9">projection,uses</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007693</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-Head Attention" target="Output Matrices Z1 to Z8">
      <data key="d7">1.0</data>
      <data key="d8">Multi-Head Attention generates multiple Output Matrices (Z1 to Z8), one from each attention head.</data>
      <data key="d9">generates,intermediate output</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007702</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-Head Attention" target="Final Output Z">
      <data key="d7">1.0</data>
      <data key="d8">Multi-Head Attention produces its Final Output Z by concatenating the head outputs and applying a Linear layer.</data>
      <data key="d9">final output,produces</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007709</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-Head Attention" target="Concat">
      <data key="d7">1.0</data>
      <data key="d8">Multi-Head Attention employs the Concat operation to combine the outputs from its multiple attention heads.</data>
      <data key="d9">employs,operation</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007716</data>
      <data key="d13" />
    </edge>
    <edge source="Multi-Head Attention" target="Self-Attention Mechanism">
      <data key="d7">1.0</data>
      <data key="d8">Multi-head attention is a specific technique used within the self-attention mechanism that enhances the model's performance.</data>
      <data key="d9">enhancement,technique</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008196</data>
      <data key="d13" />
    </edge>
    <edge source="Self-Attention" target="Attention Mechanism">
      <data key="d7">1.0</data>
      <data key="d8">Self-Attention is a specific type of Attention Mechanism used within the encoder and decoder.</data>
      <data key="d9">instance,type</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007695</data>
      <data key="d13" />
    </edge>
    <edge source="Add &amp; Norm Layer" target="Residual Connection">
      <data key="d7">1.0</data>
      <data key="d8">The 'Add' part of the Add &amp; Norm layer implements the Residual Connection technique.</data>
      <data key="d9">implements,technique</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007699</data>
      <data key="d13" />
    </edge>
    <edge source="Add &amp; Norm Layer" target="Layer Normalization">
      <data key="d7">1.0</data>
      <data key="d8">The 'Norm' part of the Add &amp; Norm layer implements the Layer Normalization technique.</data>
      <data key="d9">implements,technique</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007707</data>
      <data key="d13" />
    </edge>
    <edge source="Masked Multi-Head Attention" target="Mask Matrix">
      <data key="d7">1.0</data>
      <data key="d8">Masked Multi-Head Attention utilizes a Mask Matrix to restrict attention to only previous positions in the sequence.</data>
      <data key="d9">masking,utilizes</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007699</data>
      <data key="d13" />
    </edge>
    <edge source="Linear Layer" target="Weight Matrix WQ">
      <data key="d7">1.0</data>
      <data key="d8">The linear layer contains parallel subsets, one of which includes the unique weight matrix WQ.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008224</data>
      <data key="d13" />
    </edge>
    <edge source="Linear Layer" target="Weight Matrix WK">
      <data key="d7">1.0</data>
      <data key="d8">Another parallel subset of the linear layer contains the unique weight matrix WK.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008228</data>
      <data key="d13" />
    </edge>
    <edge source="Linear Layer" target="Weight Matrix WV">
      <data key="d7">1.0</data>
      <data key="d8">Another parallel subset of the linear layer contains the unique weight matrix WV.</data>
      <data key="d9">component,contains</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008235</data>
      <data key="d13" />
    </edge>
    <edge source="Attention Mechanism" target="Cross-Attention">
      <data key="d7">1.0</data>
      <data key="d8">Cross-Attention is a specific type of Attention Mechanism used in the decoder to attend to encoder outputs.</data>
      <data key="d9">instance,type</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007702</data>
      <data key="d13" />
    </edge>
    <edge source="Attention Mechanism" target="Article">
      <data key="d7">1.0</data>
      <data key="d8">The attention mechanism can be referenced for understanding in the mentioned article.</data>
      <data key="d9">explanation,reference</data>
      <data key="d10">chunk-778f83860f7db1907e0da6e0cb412723</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007740</data>
      <data key="d13" />
    </edge>
    <edge source="Cross-Attention" target="Query (Q)">
      <data key="d7">1.0</data>
      <data key="d8">In Cross-Attention, the Query (Q) is calculated from the previous Decoder block's output.</data>
      <data key="d9">calculation,uses</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007708</data>
      <data key="d13" />
    </edge>
    <edge source="Cross-Attention" target="Key (K)">
      <data key="d7">1.0</data>
      <data key="d8">In Cross-Attention, the Key (K) is calculated from the Encoder's output matrix C.</data>
      <data key="d9">calculation,uses</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007713</data>
      <data key="d13" />
    </edge>
    <edge source="Cross-Attention" target="Value (V)">
      <data key="d7">1.0</data>
      <data key="d8">In Cross-Attention, the Value (V) is calculated from the Encoder's output matrix C.</data>
      <data key="d9">calculation,uses</data>
      <data key="d10">chunk-3ac3b580cca11b5e1d0122810a6ec5f5</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007717</data>
      <data key="d13" />
    </edge>
    <edge source="Self-Attention Mechanism" target="Transformer Model">
      <data key="d7">1.0</data>
      <data key="d8">The self-attention mechanism is the core functional component that gives the transformer model its power to detect relationships in sequences.</data>
      <data key="d9">core component,functionality</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008186</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer模型" target="自注意力">
      <data key="d7">1.0</data>
      <data key="d8">自注意力是Transformer模型的核心机制之一，是构成该模型的基础组件。</data>
      <data key="d9">核心机制,组成部分</data>
      <data key="d10">chunk-e77bf0e5ecd6a42625cc947b20dfaca8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007759</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer模型" target="多头注意力">
      <data key="d7">1.0</data>
      <data key="d8">多头注意力是Transformer模型的核心机制之一，是构成该模型的基础组件。</data>
      <data key="d9">核心机制,组成部分</data>
      <data key="d10">chunk-e77bf0e5ecd6a42625cc947b20dfaca8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007760</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Encoder Block" target="Transformer Encoder">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer Encoder is constructed from multiple Transformer Encoder Block components.</data>
      <data key="d9">architecture,composition</data>
      <data key="d10">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007827</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Encoder" target="EncoderBlock">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer Encoder is constructed from and contains multiple EncoderBlock layers as its core components.</data>
      <data key="d9">composition,module integration</data>
      <data key="d10">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007836</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Encoder" target="Positional Encoding">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer Encoder utilizes Positional Encoding to incorporate sequence order information into its input embeddings by adding them together.</data>
      <data key="d9">data processing,sequence encoding</data>
      <data key="d10">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007837</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Encoder" target="Forward Method">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer Encoder uses its Forward Method to define the sequence of computations for processing input data X and valid lengths.</data>
      <data key="d9">computation flow,execution</data>
      <data key="d10">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007838</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Encoder" target="Call Method">
      <data key="d7">1.0</data>
      <data key="d8">One implementation of the Transformer Encoder uses a Call Method to perform its operations on input data X and valid lengths.</data>
      <data key="d9">execution,layer operation</data>
      <data key="d10">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007840</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Encoder" target="Valid Lengths">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer Encoder receives and processes Valid Lengths (valid_lens) as an input parameter to manage sequence attention.</data>
      <data key="d9">input processing,parameter handling</data>
      <data key="d10">chunk-ad8f11550a8a8807684e7ecc93a2a801</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007841</data>
      <data key="d13" />
    </edge>
    <edge source="Positional Encoding" target="Transformer Model">
      <data key="d7">1.0</data>
      <data key="d8">Positional encoding is a technique used in transformer models to incorporate information about the order of tokens.</data>
      <data key="d9">information addition,technique</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008196</data>
      <data key="d13" />
    </edge>
    <edge source="Positional Encoding" target="Attention Head">
      <data key="d7">1.0</data>
      <data key="d8">After positional encoding is applied, the updated token embeddings are processed by attention heads.</data>
      <data key="d9">input preparation,processing</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008193</data>
      <data key="d13" />
    </edge>
    <edge source="Supervised Learning" target="Self-Supervised Learning">
      <data key="d7">1.0</data>
      <data key="d8">Self-supervised learning is a learning paradigm related to supervised learning, but it generates labels from the data itself.</data>
      <data key="d9">label generation,paradigm</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009230</data>
      <data key="d13" />
    </edge>
    <edge source="Learning Curve (Machine Learning)" target="Model Diagnostics">
      <data key="d7">1.0</data>
      <data key="d8">Learning Curve is a specific diagnostic tool used within the broader category of Model Diagnostics.</data>
      <data key="d9">diagnostic method,evaluation tool</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007979</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning (Journal)" target="Conferences And Publications">
      <data key="d7">1.0</data>
      <data key="d8">Machine Learning (Journal) is an academic journal included under the category of Conferences and Publications.</data>
      <data key="d9">academic publication,category inclusion</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007994</data>
      <data key="d13" />
    </edge>
    <edge source="Lili Chen" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Lili Chen is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007971</data>
      <data key="d13" />
    </edge>
    <edge source="Kevin Lu" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Kevin Lu is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007972</data>
      <data key="d13" />
    </edge>
    <edge source="Aravind Rajeswaran" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Aravind Rajeswaran is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007973</data>
      <data key="d13" />
    </edge>
    <edge source="Kimin Lee" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Kimin Lee is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007974</data>
      <data key="d13" />
    </edge>
    <edge source="Aditya Grover" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Aditya Grover is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007977</data>
      <data key="d13" />
    </edge>
    <edge source="Michael Laskin" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Michael Laskin is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007979</data>
      <data key="d13" />
    </edge>
    <edge source="Pieter Abbeel" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Pieter Abbeel is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007983</data>
      <data key="d13" />
    </edge>
    <edge source="Aravind Srinivas" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Aravind Srinivas is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007986</data>
      <data key="d13" />
    </edge>
    <edge source="Igor Mordatch" target="Decision Transformer: Reinforcement Learning via Sequence Modeling">
      <data key="d7">1.0</data>
      <data key="d8">Igor Mordatch is a co-author of the research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling".</data>
      <data key="d9">authorship,research</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007988</data>
      <data key="d13" />
    </edge>
    <edge source="Decision Transformer: Reinforcement Learning via Sequence Modeling" target="arXiv">
      <data key="d7">1.0</data>
      <data key="d8">The research paper "Decision Transformer: Reinforcement Learning via Sequence Modeling" is hosted on the arXiv preprint repository.</data>
      <data key="d9">publication,repository</data>
      <data key="d10">chunk-0724c887b70d220c530dcfaee28003c1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769007991</data>
      <data key="d13" />
    </edge>
    <edge source="NLP" target="Transformer Model">
      <data key="d7">1.0</data>
      <data key="d8">Transformer models are commonly associated with and applied in the field of Natural Language Processing.</data>
      <data key="d9">application,association</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008228</data>
      <data key="d13" />
    </edge>
    <edge source="GPT" target="Transformers Library">
      <data key="d7">1.0</data>
      <data key="d8">The rise of the GPT model contributed to the increased adoption of the Transformers library.</data>
      <data key="d9">adoption,influence</data>
      <data key="d10">chunk-07c6d2ca0b23fef78261afa6105b1fe0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008028</data>
      <data key="d13" />
    </edge>
    <edge source="GPT" target="大语言模型">
      <data key="d7">2.0</data>
      <data key="d8">GPT是大型语言模型的一个具体实例和代表性模型。&lt;SEP&gt;GPT是大语言模型的一种具体实现。</data>
      <data key="d9">代表性模型,具体实现,实例,模型类型</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008511</data>
      <data key="d13" />
    </edge>
    <edge source="GPT" target="多模态通信">
      <data key="d7">1.0</data>
      <data key="d8">GPT等大型语言模型正在逐渐演变为能够进行多模态通信的综合性系统。</data>
      <data key="d9">功能扩展,能力演变</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008527</data>
      <data key="d13" />
    </edge>
    <edge source="GPT" target="推理">
      <data key="d7">1.0</data>
      <data key="d8">GPT等大型语言模型正在逐渐演变为能够进行推理的综合性系统。</data>
      <data key="d9">功能扩展,能力演变</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008537</data>
      <data key="d13" />
    </edge>
    <edge source="GPT" target="规划">
      <data key="d7">1.0</data>
      <data key="d8">GPT等大型语言模型正在逐渐演变为能够进行规划的综合性系统。</data>
      <data key="d9">功能扩展,能力演变</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008534</data>
      <data key="d13" />
    </edge>
    <edge source="GPT" target="Large Language Model">
      <data key="d7">1.0</data>
      <data key="d8">GPT is a common example of a Large Language Model.</data>
      <data key="d9">example,type</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008781</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Model" target="Large Language Model (LLM)">
      <data key="d7">1.0</data>
      <data key="d8">The transformer model is a neural network architecture that forms the foundation for most modern large language models.</data>
      <data key="d9">architecture,foundation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008183</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Model" target="Machine Translation">
      <data key="d7">1.0</data>
      <data key="d8">The transformer architecture was originally developed for the use case of machine translation.</data>
      <data key="d9">development purpose,initial application</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008193</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Model" target="Feedforward Neural Network Layer">
      <data key="d7">1.0</data>
      <data key="d8">The transformer architecture uses standard feedforward neural network layers in addition to attention layers.</data>
      <data key="d9">architecture component,uses</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008224</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model (LLM)" target="GPT-3">
      <data key="d7">1.0</data>
      <data key="d8">GPT-3 is a prominent example of a large language model and served as a catalyst for the modern generative AI era.</data>
      <data key="d9">catalyst,example</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008186</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model (LLM)" target="Token">
      <data key="d7">1.0</data>
      <data key="d8">Large language models process text using tokens as their fundamental linguistic units.</data>
      <data key="d9">processing unit,representation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008196</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model (LLM)" target="Claude">
      <data key="d7">1.0</data>
      <data key="d8">Claude is an example of a closed-source large language model.</data>
      <data key="d9">example,instance</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008207</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model (LLM)" target="Meta Llama">
      <data key="d7">1.0</data>
      <data key="d8">Meta Llama is an example of an open-source large language model.</data>
      <data key="d9">example,instance</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008211</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model (LLM)" target="Autoregressive Decoder-Only LLM">
      <data key="d7">1.0</data>
      <data key="d8">Autoregressive decoder-only is a specific subcategory of large language model architecture.</data>
      <data key="d9">example,subcategory</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008227</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model (LLM)" target="Google AI">
      <data key="d7">1.0</data>
      <data key="d8">Google AI powers the large language models discussed, which are integral to the services provided by Google Cloud.</data>
      <data key="d9">AI development,model powering</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009422</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model (LLM)" target="Text Data">
      <data key="d7">1.0</data>
      <data key="d8">Large Language Models (LLMs) are trained on extensive text data, with their accuracy and performance directly dependent on the quantity of this data.</data>
      <data key="d9">performance dependency,training resource</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009424</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-3" target="OpenAI">
      <data key="d7">1.0</data>
      <data key="d8">GPT-3 was developed and created by the organization OpenAI.</data>
      <data key="d9">creation,development</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008189</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-3" target="ChatGPT">
      <data key="d7">1.0</data>
      <data key="d8">GPT-3 and similar models power the functionality of the AI chatbot ChatGPT.</data>
      <data key="d9">enabling,powering</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008203</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-3" target="Autoregressive Decoder-Only LLM">
      <data key="d7">1.0</data>
      <data key="d8">GPT-3 is an example of an autoregressive decoder-only large language model.</data>
      <data key="d9">example of,instance</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008234</data>
      <data key="d13" />
    </edge>
    <edge source="GPT-3" target="LLM">
      <data key="d7">1.0</data>
      <data key="d8">GPT-3 is a specific, well-known instance of a Large Language Model.</data>
      <data key="d9">example,instance</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008590</data>
      <data key="d13" />
    </edge>
    <edge source="Token" target="Tokenization">
      <data key="d7">1.0</data>
      <data key="d8">Tokenization is the process that converts raw text into tokens for model processing.</data>
      <data key="d9">conversion,process</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008185</data>
      <data key="d13" />
    </edge>
    <edge source="Token" target="Query, Key, Value Vectors">
      <data key="d7">1.0</data>
      <data key="d8">Query, key, and value vectors are generated from the original token embeddings through linear transformations.</data>
      <data key="d9">generation,transformation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008193</data>
      <data key="d13" />
    </edge>
    <edge source="Anthropic" target="Claude">
      <data key="d7">1.0</data>
      <data key="d8">Claude was developed and created by the organization Anthropic.</data>
      <data key="d9">creation,development</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008212</data>
      <data key="d13" />
    </edge>
    <edge source="ChatGPT" target="大语言模型">
      <data key="d7">2.0</data>
      <data key="d8">ChatGPT是大语言模型的一种具体实现和应用实例，用于智能客服。&lt;SEP&gt;The popularity of ChatGPT brought significant attention to the concept and capabilities of large language models.</data>
      <data key="d9">catalyst,popularization,具体实现,应用实例</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008559</data>
      <data key="d13" />
    </edge>
    <edge source="Claude" target="Autoregressive Decoder-Only LLM">
      <data key="d7">1.0</data>
      <data key="d8">Claude is an example of an autoregressive decoder-only large language model.</data>
      <data key="d9">example of,instance</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008227</data>
      <data key="d13" />
    </edge>
    <edge source="Weight Matrix WQ" target="Query Vector">
      <data key="d7">1.0</data>
      <data key="d8">The weight matrix WQ is multiplied by the embedding value to calculate the query vector (Q).</data>
      <data key="d9">calculation,generation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008217</data>
      <data key="d13" />
    </edge>
    <edge source="Weight Matrix WK" target="Key Vector">
      <data key="d7">1.0</data>
      <data key="d8">The weight matrix WK is multiplied by the embedding value to calculate the key vector (K).</data>
      <data key="d9">calculation,generation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008221</data>
      <data key="d13" />
    </edge>
    <edge source="Weight Matrix WV" target="Value Vector">
      <data key="d7">1.0</data>
      <data key="d8">The weight matrix WV is multiplied by the embedding value to calculate the value vector (V).</data>
      <data key="d9">calculation,generation</data>
      <data key="d10">chunk-670e03b55717cd9c769f3cf5e85b2686</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008221</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Generative Ai">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai is a platform designed to train, validate, tune, and deploy generative AI models.</data>
      <data key="d9">deployment,platform capability</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008229</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Ai Development Lifecycle">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai provides one-stop access to functionalities spanning the entire AI development lifecycle.</data>
      <data key="d9">development support,unified access</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008230</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="User-Friendly Interface">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai offers a user-friendly interface to facilitate AI solution building.</data>
      <data key="d9">ease of use,platform feature</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008232</data>
      <data key="d13" />
    </edge>
    <edge source="IBM Watsonx.Ai" target="Industry Standard Apis And Sdks">
      <data key="d7">1.0</data>
      <data key="d8">IBM Watsonx.Ai provides access to industry standard APIs and SDKs for building powerful AI solutions.</data>
      <data key="d9">development enablement,tool integration</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008233</data>
      <data key="d13" />
    </edge>
    <edge source="Generative Ai" target="Ceos">
      <data key="d7">1.0</data>
      <data key="d8">CEOs must balance the value generative AI can create with the necessary investments and risks.</data>
      <data key="d9">strategic balance,value creation</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008236</data>
      <data key="d13" />
    </edge>
    <edge source="Generative Ai" target="Ai Builders">
      <data key="d7">1.0</data>
      <data key="d8">AI Builders use generative AI to build and deliver innovative new solutions.</data>
      <data key="d9">innovation,solution development</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008230</data>
      <data key="d13" />
    </edge>
    <edge source="Ai Investment" target="Survey Of 2,000 Organizations">
      <data key="d7">1.0</data>
      <data key="d8">The survey of 2,000 organizations provides insights into AI plans and investment effectiveness.</data>
      <data key="d9">market research,strategy insight</data>
      <data key="d10">chunk-833d835632b095e419f4a96b3c5dac04</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008236</data>
      <data key="d13" />
    </edge>
    <edge source="Hung-yi Lee" target="Lecture Video">
      <data key="d7">1.0</data>
      <data key="d8">Hung-yi Lee is the creator and presenter of the lecture video published on his YouTube channel.</data>
      <data key="d9">creation,publication</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008296</data>
      <data key="d13" />
    </edge>
    <edge source="Hung-yi Lee" target="YouTube Channel">
      <data key="d7">1.0</data>
      <data key="d8">The YouTube channel is owned by Hung-yi Lee and is used to distribute his educational content.</data>
      <data key="d9">content distribution,ownership</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008297</data>
      <data key="d13" />
    </edge>
    <edge source="Machine Learning 2021" target="Lecture Video">
      <data key="d7">1.0</data>
      <data key="d8">The lecture video on Transformer is part of the "Machine Learning 2021" course content.</data>
      <data key="d9">educational content,part of</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008289</data>
      <data key="d13" />
    </edge>
    <edge source="Lecture Slides" target="Lecture Video">
      <data key="d7">1.0</data>
      <data key="d8">The lecture slides are the supporting presentation material used in the lecture video.</data>
      <data key="d9">presentation,supporting material</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008291</data>
      <data key="d13" />
    </edge>
    <edge source="Lecture Video" target="354000 Subscribers">
      <data key="d7">1.0</data>
      <data key="d8">The lecture video is hosted on a YouTube channel that has 354,000 subscribers.</data>
      <data key="d9">metrics,popularity</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008292</data>
      <data key="d13" />
    </edge>
    <edge source="Lecture Video" target="2878 Likes">
      <data key="d7">1.0</data>
      <data key="d8">The lecture video received 2,878 likes as a form of viewer engagement.</data>
      <data key="d9">engagement,feedback</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008301</data>
      <data key="d13" />
    </edge>
    <edge source="Lecture Video" target="283126 Views">
      <data key="d7">1.0</data>
      <data key="d8">The lecture video has been viewed 283,126 times, indicating its reach and popularity.</data>
      <data key="d9">popularity,reach</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008294</data>
      <data key="d13" />
    </edge>
    <edge source="Lecture Video" target="26 Mar 2021">
      <data key="d7">1.0</data>
      <data key="d8">The lecture video was published on the date of March 26, 2021.</data>
      <data key="d9">publication,timing</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008297</data>
      <data key="d13" />
    </edge>
    <edge source="Lecture Video" target="125 Comments">
      <data key="d7">1.0</data>
      <data key="d8">The lecture video has generated 125 comments, facilitating viewer discussion.</data>
      <data key="d9">discussion,engagement</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008299</data>
      <data key="d13" />
    </edge>
    <edge source="Lecture Video" target="DOC_ID: chunk-6db04701">
      <data key="d7">1.0</data>
      <data key="d8">The document chunk with ID chunk-6db04701 contains the metadata and description of the lecture video.</data>
      <data key="d9">document reference,metadata</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008300</data>
      <data key="d13" />
    </edge>
    <edge source="DOC_ID: chunk-6db04701" target="Linguistics">
      <data key="d7">1.0</data>
      <data key="d8">The document chunk is classified under the domain of Linguistics according to its metadata.</data>
      <data key="d9">domain classification,metadata</data>
      <data key="d10">chunk-a6f32e4615a0137e965400eba7166c47</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008301</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="Transformer架构">
      <data key="d7">2.0</data>
      <data key="d8">大语言模型是基于Transformer架构的神经网络语言模型。&lt;SEP&gt;大语言模型是基于Transformer架构构建的。</data>
      <data key="d9">基于,基于关系,技术基础,技术实现</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3&lt;SEP&gt;chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008508</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="预训练">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型通过在海量文本数据上进行预训练来获得语言理解和生成能力。</data>
      <data key="d9">数据学习,训练方法</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008509</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="具身人工智能">
      <data key="d7">1.0</data>
      <data key="d8">大型语言模型对具身人工智能的发展具有推动作用并带来挑战。</data>
      <data key="d9">发展挑战,技术推动</data>
      <data key="d10">chunk-48a8f8eb7c58289118bd89b3aa9c47b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008537</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="Scaling Law">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型的兴起依赖Scaling Law，即模型性能随数据量、参数规模提升而提升。</data>
      <data key="d9">依赖关系,性能法则</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008555</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="GitHub Copilot">
      <data key="d7">1.0</data>
      <data key="d8">GitHub Copilot是大语言模型的一种具体实现和应用实例，用于代码生成。</data>
      <data key="d9">具体实现,应用实例</data>
      <data key="d10">chunk-6003c974467b7a903cb83abef6cc2e24</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008563</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="语言模型">
      <data key="d7">1.0</data>
      <data key="d8">Large language models are a specific, advanced type of language model.</data>
      <data key="d9">generalization,specific type</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008606</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="大数据模型">
      <data key="d7">1.0</data>
      <data key="d8">Large language models are often discussed and compared with big data models in terms of their relationships and synergies.</data>
      <data key="d9">comparison,conceptual relationship</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008611</data>
      <data key="d13" />
    </edge>
    <edge source="大语言模型" target="自监督学习方法">
      <data key="d7">1.0</data>
      <data key="d8">大语言模型使用自监督学习方法进行训练。</data>
      <data key="d9">使用,训练</data>
      <data key="d10">chunk-3678971988880bb3960a90e15878444d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008639</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer架构" target="LLM">
      <data key="d7">1.0</data>
      <data key="d8">The Transformer architecture, with its millions/billions of parameters, is the core technology that enables LLMs to capture complex language patterns.</data>
      <data key="d9">architecture,enabling technology</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009052</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="AI黑话揭秘">
      <data key="d7">1.0</data>
      <data key="d8">文章《AI黑话揭秘》旨在解释LLM(大语言模型)及其相关概念。</data>
      <data key="d9">概念澄清,解释</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008563</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="大模型">
      <data key="d7">1.0</data>
      <data key="d8">Large Language Models (LLMs) are a specific and prominent type of Large Model focused on language tasks.</data>
      <data key="d9">specialization,type</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008587</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="RAG">
      <data key="d7">1.0</data>
      <data key="d8">RAG enhances LLMs by integrating them with external knowledge retrieval to improve answer accuracy.</data>
      <data key="d9">enhancement,integration</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008769</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="红帽AI">
      <data key="d7">1.0</data>
      <data key="d8">红帽AI提供对LLM等第三方模型库的访问权限。</data>
      <data key="d9">平台服务,模型访问</data>
      <data key="d10">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009032</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="SLM">
      <data key="d7">1.0</data>
      <data key="d8">LLM和SLM是两种不同类型的语言模型，常被放在一起进行对比。</data>
      <data key="d9">模型对比,类型差异</data>
      <data key="d10">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009047</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="数据准备">
      <data key="d7">1.0</data>
      <data key="d8">Data preparation is the foundational step for collecting, cleaning, and organizing the raw data used to train LLMs.</data>
      <data key="d9">preprocessing,training</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009051</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="检索增强生成(RAG)">
      <data key="d7">1.0</data>
      <data key="d8">RAG is an architecture designed to augment the knowledge of LLMs by connecting them to external data sources.</data>
      <data key="d9">architecture,knowledge augmentation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009057</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="代理式AI">
      <data key="d7">1.0</data>
      <data key="d8">Agent AI combines with LLMs to enhance their capabilities, allowing for automated reasoning and interaction with tools.</data>
      <data key="d9">automation,reasoning enhancement</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009060</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="GDPR">
      <data key="d7">1.0</data>
      <data key="d8">Organizations deploying LLMs must ensure compliance with data privacy laws like GDPR.</data>
      <data key="d9">compliance,data privacy</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009054</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="HIPAA">
      <data key="d7">1.0</data>
      <data key="d8">Organizations deploying LLMs must ensure compliance with data privacy laws like HIPAA.</data>
      <data key="d9">compliance,data privacy</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009055</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="人机回圈">
      <data key="d7">1.0</data>
      <data key="d8">Human-in-the-loop strategies are crucial for establishing accountability and oversight in the development and deployment of LLMs.</data>
      <data key="d9">accountability,oversight</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009056</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="数据分析">
      <data key="d7">1.0</data>
      <data key="d8">LLMs can help supplement or fully undertake data analysis tasks, automating this function.</data>
      <data key="d9">application,task automation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009059</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="内容生成">
      <data key="d7">1.0</data>
      <data key="d8">LLMs can help supplement or fully undertake content generation tasks, automating this function.</data>
      <data key="d9">application,task automation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009061</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="运维成本">
      <data key="d7">1.0</data>
      <data key="d8">The automation of language-related tasks by LLMs can lower operational costs.</data>
      <data key="d9">cost reduction,efficiency</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009062</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="市场趋势">
      <data key="d7">1.0</data>
      <data key="d8">LLMs enable businesses to better understand market trends by scanning large volumes of text data.</data>
      <data key="d9">business intelligence,insight generation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009063</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="客户反馈">
      <data key="d7">1.0</data>
      <data key="d8">LLMs enable businesses to better understand customer feedback by scanning large volumes of text data.</data>
      <data key="d9">business intelligence,insight generation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009065</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="个性化内容">
      <data key="d7">1.0</data>
      <data key="d8">LLMs help businesses provide highly personalized content to customers, improving engagement and experience.</data>
      <data key="d9">customer engagement,personalization</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009069</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="营销信息">
      <data key="d7">1.0</data>
      <data key="d8">LLMs can be used to tailor marketing messages to specific user personas.</data>
      <data key="d9">application,customization</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009073</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="跨文化交流">
      <data key="d7">1.0</data>
      <data key="d8">LLMs facilitate cross-cultural communication through capabilities like translation.</data>
      <data key="d9">application,facilitation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009078</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="客户信息">
      <data key="d7">1.0</data>
      <data key="d8">LLMs may need to access customer information, which raises privacy concerns, especially with third-party providers.</data>
      <data key="d9">data access,privacy concern</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009083</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="专有的商业数据">
      <data key="d7">1.0</data>
      <data key="d8">LLMs may need to access proprietary business data, which raises security concerns, especially with third-party providers.</data>
      <data key="d9">data access,security concern</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009086</data>
      <data key="d13" />
    </edge>
    <edge source="LLM" target="第三方提供商">
      <data key="d7">1.0</data>
      <data key="d8">When LLMs are deployed or accessed via third-party providers, it necessitates special caution regarding data security.</data>
      <data key="d9">deployment,risk management</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009089</data>
      <data key="d13" />
    </edge>
    <edge source="Agent" target="AI黑话揭秘">
      <data key="d7">1.0</data>
      <data key="d8">文章《AI黑话揭秘》旨在解释Agent及其相关概念。</data>
      <data key="d9">概念澄清,解释</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008569</data>
      <data key="d13" />
    </edge>
    <edge source="Agent" target="Llm Powered Autonomous Agents">
      <data key="d7">1.0</data>
      <data key="d8">The article "LLM Powered Autonomous Agents" is an early and notable work on the Agent paradigm.</data>
      <data key="d9">article,early work</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009328</data>
      <data key="d13" />
    </edge>
    <edge source="大模型" target="浙江大学人工智能教育教学研究中心">
      <data key="d7">1.0</data>
      <data key="d8">该研究中心的研究展示了大模型在模拟人类语言理解中的应用。</data>
      <data key="d9">应用,研究</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008542</data>
      <data key="d13" />
    </edge>
    <edge source="大模型" target="AI黑话揭秘">
      <data key="d7">1.0</data>
      <data key="d8">文章《AI黑话揭秘》旨在解释大模型及其相关概念。</data>
      <data key="d9">概念澄清,解释</data>
      <data key="d10">chunk-d59c5769fc2d8973bb797259108a6319</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008559</data>
      <data key="d13" />
    </edge>
    <edge source="大模型" target="预训练-微调范式">
      <data key="d7">1.0</data>
      <data key="d8">The Pre-training and Fine-tuning paradigm is a fundamental training approach characteristic of modern Large Models.</data>
      <data key="d9">paradigm,training approach</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008594</data>
      <data key="d13" />
    </edge>
    <edge source="垂直模型" target="通用人工智能">
      <data key="d7">1.0</data>
      <data key="d8">垂直模型只会做特定领域事情，而通用人工智能的目标是让AI什么都能干。</data>
      <data key="d9">发展目标,能力对比</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008596</data>
      <data key="d13" />
    </edge>
    <edge source="学习路线" target="系统资料">
      <data key="d7">1.0</data>
      <data key="d8">A Learning Path is designed to structure and organize the provided Systematic Materials for effective learning.</data>
      <data key="d9">resource organization,structuring</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008584</data>
      <data key="d13" />
    </edge>
    <edge source="学习路线" target="学习计划">
      <data key="d7">1.0</data>
      <data key="d8">A Learning Path serves as guidance for creating a customized Study Plan.</data>
      <data key="d9">guidance,plan creation</data>
      <data key="d10">chunk-c0eefe5184862c24ce2da501217562b3</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008587</data>
      <data key="d13" />
    </edge>
    <edge source="谭铁牛" target="求实">
      <data key="d7">1.0</data>
      <data key="d8">Academician Tan Tieniu published an article defining AI in the publication "求实".</data>
      <data key="d9">author contribution,publication</data>
      <data key="d10">chunk-bae01b8f0bc3c1509b035bf0d8ee1771</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008606</data>
      <data key="d13" />
    </edge>
    <edge source="自监督学习方法" target="无标记文本">
      <data key="d7">1.0</data>
      <data key="d8">自监督学习方法通过大量无标记文本进行训练。</data>
      <data key="d9">使用,训练</data>
      <data key="d10">chunk-3678971988880bb3960a90e15878444d</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008637</data>
      <data key="d13" />
    </edge>
    <edge source="RAG" target="Prompt Engineering">
      <data key="d7">1.0</data>
      <data key="d8">Prompt Engineering is contrasted with RAG as an alternative approach for generating model answers.</data>
      <data key="d9">answer generation,technique comparison</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008780</data>
      <data key="d13" />
    </edge>
    <edge source="Quantization" target="Precision Loss">
      <data key="d7">1.0</data>
      <data key="d8">Quantization involves scaling and rounding weights, which leads to precision loss as the original floating-point values cannot be fully recovered.</data>
      <data key="d9">accuracy trade-off,conversion</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008769</data>
      <data key="d13" />
    </edge>
    <edge source="Static KV-Cache" target="Torch.compile">
      <data key="d7">1.0</data>
      <data key="d8">Static KV-Cache, when combined with torch.compile, optimizes performance by enabling static allocation and avoiding recomputation.</data>
      <data key="d9">optimization,performance boost</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008769</data>
      <data key="d13" />
    </edge>
    <edge source="Torch.compile" target="Fine-Tuning">
      <data key="d7">1.0</data>
      <data key="d8">Fine-Tuning can be made more efficient by using torch.compile to optimize the model's runtime.</data>
      <data key="d9">efficiency,optimization</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008778</data>
      <data key="d13" />
    </edge>
    <edge source="Prompt Lookup Decoding" target="Speculative Decoding">
      <data key="d7">1.0</data>
      <data key="d8">Prompt Lookup Decoding serves as an alternative to traditional speculative decoding by using string matching instead of a draft model.</data>
      <data key="d9">alternative,efficiency</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008770</data>
      <data key="d13" />
    </edge>
    <edge source="Fine-Tuning" target="Prompt Engineering">
      <data key="d7">1.0</data>
      <data key="d8">Prompt Engineering is compared with Fine-Tuning as different techniques for adapting or guiding model behavior.</data>
      <data key="d9">model adaptation,technique comparison</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008784</data>
      <data key="d13" />
    </edge>
    <edge source="Fine-Tuning" target="Large Language Model">
      <data key="d7">1.0</data>
      <data key="d8">Fine-tuning is a common method used to adapt pre-trained large language models to specific tasks.</data>
      <data key="d9">adaptation,method</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009240</data>
      <data key="d13" />
    </edge>
    <edge source="PyTorch Scaled Dot Product Attention" target="Model Training">
      <data key="d7">1.0</data>
      <data key="d8">PyTorch Scaled Dot Product Attention accelerates model training and inference through hardware-accelerated, optimized computation graphs.</data>
      <data key="d9">acceleration,hardware optimization</data>
      <data key="d10">chunk-0222ac86b3d60100ac5d03d88a69654e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008775</data>
      <data key="d13" />
    </edge>
    <edge source="Prompt Engineering" target="Zero-Shot Learning">
      <data key="d7">1.0</data>
      <data key="d8">Zero-Shot Learning is a prompt strategy used within the broader method of Prompt Engineering.</data>
      <data key="d9">application,strategy</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008795</data>
      <data key="d13" />
    </edge>
    <edge source="Prompt Engineering" target="Few-Shot Learning">
      <data key="d7">1.0</data>
      <data key="d8">Few-Shot Learning is a prompt strategy used within the broader method of Prompt Engineering.</data>
      <data key="d9">application,strategy</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008797</data>
      <data key="d13" />
    </edge>
    <edge source="Prompt Engineering" target="Large Language Model">
      <data key="d7">1.0</data>
      <data key="d8">Prompt Engineering is a method used to integrate data when building applications with Large Language Models.</data>
      <data key="d9">application,integration method</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008803</data>
      <data key="d13" />
    </edge>
    <edge source="Prompt Engineering" target="Chatgpt Prompt Engineering For Developers">
      <data key="d7">1.0</data>
      <data key="d8">The resource "ChatGPT Prompt Engineering for Developers" serves as an introductory learning material for the concept of Prompt Engineering.</data>
      <data key="d9">introduction,learning resource</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009327</data>
      <data key="d13" />
    </edge>
    <edge source="Prompt Engineering" target="Brex's Prompt Engineering Guide">
      <data key="d7">1.0</data>
      <data key="d8">Brex's Prompt Engineering Guide is an introductory guide to the concept of Prompt Engineering.</data>
      <data key="d9">guide,introduction</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009332</data>
      <data key="d13" />
    </edge>
    <edge source="Prompt Engineering" target="A Survey Of Prompt Engineering Methods In Large Language Models For Different Nlp Tasks">
      <data key="d7">1.0</data>
      <data key="d8">The survey paper provides an overview of methods related to Prompt Engineering.</data>
      <data key="d9">methods,survey</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009337</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Transformer Architecture">
      <data key="d7">1.0</data>
      <data key="d8">Large Language Models are a class of models based on the Transformer architecture.</data>
      <data key="d9">architecture,foundation</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008778</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="LLaMA">
      <data key="d7">1.0</data>
      <data key="d8">LLaMA is a common example of a Large Language Model.</data>
      <data key="d9">example,type</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008785</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="LLama 3.3">
      <data key="d7">1.0</data>
      <data key="d8">LLama 3.3 is an open-source Large Language Model highly recommended.</data>
      <data key="d9">example,recommendation</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008790</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Supervised Fine-Tuning">
      <data key="d7">1.0</data>
      <data key="d8">Supervised Fine-Tuning is a method used to create conversational models, which are a type of Large Language Model application.</data>
      <data key="d9">application,training method</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008792</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Reward Model Training">
      <data key="d7">1.0</data>
      <data key="d8">Reward Model Training is a method used to train models that evaluate responses, related to Large Language Model development.</data>
      <data key="d9">evaluation,training method</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008794</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Encoder-Only Model">
      <data key="d7">1.0</data>
      <data key="d8">Encoder-Only Model is a type of model architecture relevant to understanding Large Language Models.</data>
      <data key="d9">category,model type</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008795</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Decoder-Only Model">
      <data key="d7">1.0</data>
      <data key="d8">Decoder-Only Model is a type of model architecture used for generative tasks within Large Language Models.</data>
      <data key="d9">category,model type</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008797</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Encoder-Decoder Model">
      <data key="d7">1.0</data>
      <data key="d8">Encoder-Decoder Model is a type of model architecture suitable for sequence-to-sequence tasks within Large Language Models.</data>
      <data key="d9">category,model type</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008799</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Multimodal Large Language Models">
      <data key="d7">1.0</data>
      <data key="d8">Multimodal Large Language Models are a specific category of Large Language Models.</data>
      <data key="d9">extension,subcategory</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008802</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Model Training and Fine-Tuning">
      <data key="d7">1.0</data>
      <data key="d8">Model Training and Fine-Tuning is a method used to integrate data when building applications with Large Language Models.</data>
      <data key="d9">application,integration method</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008812</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Retrieval-Augmented Generation">
      <data key="d7">1.0</data>
      <data key="d8">Retrieval-Augmented Generation is a technique that combines Large Language Models with external knowledge bases.</data>
      <data key="d9">enhancement,integration technique</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008805</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Modelscope-Classroom">
      <data key="d7">1.0</data>
      <data key="d8">Modelscope-Classroom is a resource provided for deeper learning about Large Language Model basics.</data>
      <data key="d9">learning resource,reference</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008806</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="NeOn-GPT">
      <data key="d7">1.0</data>
      <data key="d8">NeOn-GPT is a pipeline powered by large language models for the task of ontology learning.</data>
      <data key="d9">ontology learning,pipeline</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009224</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Hallucination">
      <data key="d7">1.0</data>
      <data key="d8">Hallucination is a known phenomenon and limitation associated with large language models.</data>
      <data key="d9">limitation,phenomenon</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009225</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Model Collapse">
      <data key="d7">1.0</data>
      <data key="d8">Model collapse is a risk of degradation for large language models trained on their own outputs.</data>
      <data key="d9">degradation,risk</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009229</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Foundation Model">
      <data key="d7">1.0</data>
      <data key="d8">Large language models are a type of foundation model, characterized by their large scale and broad training.</data>
      <data key="d9">category,scale</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009243</data>
      <data key="d13" />
    </edge>
    <edge source="Large Language Model" target="Deep Dive Into Llms Like Chatgpt">
      <data key="d7">1.0</data>
      <data key="d8">The video "Deep Dive into LLMs like ChatGPT" provides an explanation and introduction to Large Language Models.</data>
      <data key="d9">explanation,introduction</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009329</data>
      <data key="d13" />
    </edge>
    <edge source="Transformer Architecture" target="Vision Transformer">
      <data key="d7">1.0</data>
      <data key="d8">The vision transformer is an adaptation of the transformer architecture for computer vision tasks.</data>
      <data key="d9">adaptation,computer vision</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009231</data>
      <data key="d13" />
    </edge>
    <edge source="LLaMA" target="Meta">
      <data key="d7">1.0</data>
      <data key="d8">Meta is the organization that introduced the LLaMA model.</data>
      <data key="d9">development,introduction</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008787</data>
      <data key="d13" />
    </edge>
    <edge source="Mistral AI" target="Mistral Model">
      <data key="d7">1.0</data>
      <data key="d8">Mistral AI is the organization that released the Mistral model.</data>
      <data key="d9">development,release</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008780</data>
      <data key="d13" />
    </edge>
    <edge source="BigScience Team" target="BLOOM Model">
      <data key="d7">1.0</data>
      <data key="d8">The BigScience team is the organization that introduced the BLOOM model.</data>
      <data key="d9">development,introduction</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008782</data>
      <data key="d13" />
    </edge>
    <edge source="Encoder-Decoder Attention" target="Encoder-Decoder Model">
      <data key="d7">1.0</data>
      <data key="d8">Encoder-Decoder Attention is a key mechanism within the Encoder-Decoder Model structure.</data>
      <data key="d9">component,core mechanism</data>
      <data key="d10">chunk-4f9864ecff092ef091c227f6ebb2d69f</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769008787</data>
      <data key="d13" />
    </edge>
    <edge source="红帽AI" target="SLM">
      <data key="d7">2.0</data>
      <data key="d8">红帽AI提供对SLM等第三方模型库的访问权限。&lt;SEP&gt;Red Hat AI provides access to model libraries, facilitating comparisons and decisions between different model types like LLMs and SLMs.</data>
      <data key="d9">model comparison,platform access,平台服务,模型访问</data>
      <data key="d10">chunk-4d514ef014c3cb4cb7fc652928e9a4a4&lt;SEP&gt;chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009036</data>
      <data key="d13" />
    </edge>
    <edge source="红帽AI" target="容量指导规划">
      <data key="d7">1.0</data>
      <data key="d8">Red Hat AI's ready-made models can be applied to capacity guidance planning scenarios to support informed decisions.</data>
      <data key="d9">application,decision support</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009093</data>
      <data key="d13" />
    </edge>
    <edge source="红帽® 企业Linux® AI" target="Granite系列LLM">
      <data key="d7">1.0</data>
      <data key="d8">红帽® 企业Linux® AI是用于开发、测试和运行Granite系列LLM的基础平台。</data>
      <data key="d9">平台支持,模型运行</data>
      <data key="d10">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009032</data>
      <data key="d13" />
    </edge>
    <edge source="红帽® 企业Linux® AI" target="AI平台">
      <data key="d7">1.0</data>
      <data key="d8">红帽® 企业Linux® AI是构成AI平台的基础模型平台。</data>
      <data key="d9">基础组件,平台构成</data>
      <data key="d10">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009036</data>
      <data key="d13" />
    </edge>
    <edge source="AI平台" target="模型上下文协议(MCP)">
      <data key="d7">1.0</data>
      <data key="d8">模型上下文协议(MCP)是AI平台中用于将AI应用连接到外部数据源的协议。</data>
      <data key="d9">协议功能,数据连接</data>
      <data key="d10">chunk-4d514ef014c3cb4cb7fc652928e9a4a4</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009047</data>
      <data key="d13" />
    </edge>
    <edge source="代理式AI" target="编排">
      <data key="d7">1.0</data>
      <data key="d8">The communication between Agent AI and tools involves orchestration, with processes varying by framework.</data>
      <data key="d9">communication process,framework dependency</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009090</data>
      <data key="d13" />
    </edge>
    <edge source="数据准备" target="词元化">
      <data key="d7">1.0</data>
      <data key="d8">Tokenization is a specific step within the data preparation process for LLMs, breaking text into understandable units.</data>
      <data key="d9">data preprocessing,text processing</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009052</data>
      <data key="d13" />
    </edge>
    <edge source="llm-d" target="分布式推理">
      <data key="d7">1.0</data>
      <data key="d8">The llm-d open-source framework utilizes distributed inference technology to efficiently handle the computational demands of large models like LLMs.</data>
      <data key="d9">efficiency,framework implementation</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009038</data>
      <data key="d13" />
    </edge>
    <edge source="分布式推理" target="AI工作负载">
      <data key="d7">1.0</data>
      <data key="d8">Distributed inference helps AI workloads run efficiently by distributing tasks across multiple hardware devices.</data>
      <data key="d9">efficiency,task distribution</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009066</data>
      <data key="d13" />
    </edge>
    <edge source="训练数据" target="统计学上的偏差">
      <data key="d7">1.0</data>
      <data key="d8">If training data contains statistical bias, it becomes a flawed input for AI models.</data>
      <data key="d9">data quality,risk factor</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009070</data>
      <data key="d13" />
    </edge>
    <edge source="训练数据" target="人类偏见">
      <data key="d7">1.0</data>
      <data key="d8">Existing human biases can be transferred to AI systems through the training data.</data>
      <data key="d9">bias transfer,risk factor</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009073</data>
      <data key="d13" />
    </edge>
    <edge source="训练数据" target="包容性">
      <data key="d7">1.0</data>
      <data key="d8">Upholding inclusivity throughout the design process is a strategy to help minimize bias in training data and AI systems.</data>
      <data key="d9">design principle,mitigation strategy</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009076</data>
      <data key="d13" />
    </edge>
    <edge source="训练数据" target="多样性">
      <data key="d7">1.0</data>
      <data key="d8">Ensuring the collected data represents sufficient diversity is a strategy to minimize bias in training data.</data>
      <data key="d9">data quality,mitigation strategy</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009080</data>
      <data key="d13" />
    </edge>
    <edge source="检索增强生成(RAG)" target="知识源">
      <data key="d7">1.0</data>
      <data key="d8">RAG augments LLM knowledge by integrating data from selected knowledge sources.</data>
      <data key="d9">augmentation,data integration</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009089</data>
      <data key="d13" />
    </edge>
    <edge source="GDPR" target="AI监管">
      <data key="d7">1.0</data>
      <data key="d8">AI regulation involves ensuring compliance with data privacy laws like GDPR.</data>
      <data key="d9">compliance requirement,legal framework</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009083</data>
      <data key="d13" />
    </edge>
    <edge source="HIPAA" target="AI监管">
      <data key="d7">1.0</data>
      <data key="d8">AI regulation involves ensuring compliance with data privacy laws like HIPAA.</data>
      <data key="d9">compliance requirement,legal framework</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009086</data>
      <data key="d13" />
    </edge>
    <edge source="人机回圈" target="AI监管">
      <data key="d7">1.0</data>
      <data key="d8">AI regulation emphasizes the importance of human-in-the-loop strategies for key decisions.</data>
      <data key="d9">oversight,strategy</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009098</data>
      <data key="d13" />
    </edge>
    <edge source="LLM提示词" target="计算资源">
      <data key="d7">1.0</data>
      <data key="d8">The complexity and non-uniform nature of LLM prompts contribute to the high demand for computational resources.</data>
      <data key="d9">complexity,resource demand</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009063</data>
      <data key="d13" />
    </edge>
    <edge source="LLM提示词" target="存储支持">
      <data key="d7">1.0</data>
      <data key="d8">The complexity and non-uniform nature of LLM prompts contribute to the high demand for storage support.</data>
      <data key="d9">complexity,resource demand</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009065</data>
      <data key="d13" />
    </edge>
    <edge source="人类偏见" target="歧视性算法">
      <data key="d7">1.0</data>
      <data key="d8">Human bias transferred to AI can result in the creation of discriminatory algorithms.</data>
      <data key="d9">cause and effect,risk</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009075</data>
      <data key="d13" />
    </edge>
    <edge source="人类偏见" target="偏见输出">
      <data key="d7">1.0</data>
      <data key="d8">Human bias transferred to AI can result in the generation of biased output.</data>
      <data key="d9">cause and effect,risk</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009078</data>
      <data key="d13" />
    </edge>
    <edge source="黑箱" target="透明度">
      <data key="d7">1.0</data>
      <data key="d8">The "black box" nature of many LLMs acts as a hindrance to transparency.</data>
      <data key="d9">characteristic,hindrance</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009078</data>
      <data key="d13" />
    </edge>
    <edge source="黑箱" target="可解释性">
      <data key="d7">1.0</data>
      <data key="d8">The "black box" nature of many LLMs acts as a hindrance to explainability.</data>
      <data key="d9">characteristic,hindrance</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009083</data>
      <data key="d13" />
    </edge>
    <edge source="可解释性" target="深度学习方法">
      <data key="d7">1.0</data>
      <data key="d8">Scholars have conducted in-depth discussions on the interpretability of deep learning methods.</data>
      <data key="d9">discussion,research</data>
      <data key="d10">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010204</data>
      <data key="d13" />
    </edge>
    <edge source="AI监管" target="数据监管">
      <data key="d7">1.0</data>
      <data key="d8">New AI-specific regulations often require strict data governance for AI systems.</data>
      <data key="d9">governance,regulatory requirement</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009089</data>
      <data key="d13" />
    </edge>
    <edge source="AI监管" target="人工监督">
      <data key="d7">1.0</data>
      <data key="d8">New AI-specific regulations often require human oversight of AI systems.</data>
      <data key="d9">oversight,regulatory requirement</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009093</data>
      <data key="d13" />
    </edge>
    <edge source="AI监管" target="AI系统安全防护">
      <data key="d7">1.0</data>
      <data key="d8">New AI-specific regulations often require strong security protections for AI systems.</data>
      <data key="d9">regulatory requirement,security</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009096</data>
      <data key="d13" />
    </edge>
    <edge source="AI监管" target="问责框架">
      <data key="d7">1.0</data>
      <data key="d8">AI regulation makes establishing clear accountability frameworks crucial for LLM development and deployment.</data>
      <data key="d9">accountability,establishment</data>
      <data key="d10">chunk-1b739ad6a105eb84f8c6e5dd40826bdc</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009097</data>
      <data key="d13" />
    </edge>
    <edge source="NeOn-GPT" target="PDF">
      <data key="d7">1.0</data>
      <data key="d8">The NeOn-GPT pipeline and its details are presented in a PDF document.</data>
      <data key="d9">document format,publication</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009236</data>
      <data key="d13" />
    </edge>
    <edge source="DIKWP Research Group" target="Cultural Bias">
      <data key="d7">1.0</data>
      <data key="d8">The DIKWP Research Group conducts international standard evaluations for cultural bias in large language models.</data>
      <data key="d9">evaluation,standard</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009224</data>
      <data key="d13" />
    </edge>
    <edge source="DIKWP Research Group" target="Regional Bias">
      <data key="d7">1.0</data>
      <data key="d8">The DIKWP Research Group conducts international standard evaluations for regional bias in large language models.</data>
      <data key="d9">evaluation,standard</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009225</data>
      <data key="d13" />
    </edge>
    <edge source="DIKWP Research Group" target="Age Bias">
      <data key="d7">1.0</data>
      <data key="d8">The DIKWP Research Group conducts international standard evaluations for age bias in large language models.</data>
      <data key="d9">evaluation,standard</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009229</data>
      <data key="d13" />
    </edge>
    <edge source="DIKWP Research Group" target="Occupational Bias">
      <data key="d7">1.0</data>
      <data key="d8">The DIKWP Research Group conducts international standard evaluations for occupational bias in large language models.</data>
      <data key="d9">evaluation,standard</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009243</data>
      <data key="d13" />
    </edge>
    <edge source="DIKWP Research Group" target="International Standard Evaluation">
      <data key="d7">1.0</data>
      <data key="d8">The DIKWP Research Group employs an international standard evaluation methodology for its bias assessments.</data>
      <data key="d9">assessment,methodology</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009240</data>
      <data key="d13" />
    </edge>
    <edge source="arXiv Papers" target="Topics, Authors, and Institutions">
      <data key="d7">1.0</data>
      <data key="d8">The study analyzes topics, authors, and institutions within a corpus of 17,000 arXiv papers on LLM research.</data>
      <data key="d9">analysis,research trends</data>
      <data key="d10">chunk-1bb6bf3f22f6625482a3700d160f6e81</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009236</data>
      <data key="d13" />
    </edge>
    <edge source="Openai Official Quickstart Documentation" target="Openai">
      <data key="d7">1.0</data>
      <data key="d8">The OpenAI Official Quickstart Documentation is created and provided by the OpenAI organization.</data>
      <data key="d9">creation,documentation</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009332</data>
      <data key="d13" />
    </edge>
    <edge source="Openai Official Quickstart Documentation" target="Api Reference">
      <data key="d7">1.0</data>
      <data key="d8">The OpenAI Official Quickstart Documentation includes an API Reference.</data>
      <data key="d9">includes,reference</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009330</data>
      <data key="d13" />
    </edge>
    <edge source="State Of Gpt" target="Andrej Karpathy">
      <data key="d7">1.0</data>
      <data key="d8">Andrej Karpathy is the creator of the presentation "State of GPT".</data>
      <data key="d9">creation,presentation</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009327</data>
      <data key="d13" />
    </edge>
    <edge source="State Of Gpt" target="Gpt">
      <data key="d7">1.0</data>
      <data key="d8">The presentation "State of GPT" explains and summarizes the GPT model.</data>
      <data key="d9">explanation,summary</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009335</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Dive Into Llms Like Chatgpt" target="Andrej Karpathy">
      <data key="d7">1.0</data>
      <data key="d8">Andrej Karpathy is the creator of the video "Deep Dive into LLMs like ChatGPT".</data>
      <data key="d9">creation,video</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009332</data>
      <data key="d13" />
    </edge>
    <edge source="Openai Cookbook" target="Openai">
      <data key="d7">1.0</data>
      <data key="d8">The OpenAI Cookbook is an official collection of resources created by the OpenAI organization.</data>
      <data key="d9">creation,resource</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009330</data>
      <data key="d13" />
    </edge>
    <edge source="Brex's Prompt Engineering Guide" target="Brex">
      <data key="d7">1.0</data>
      <data key="d8">Brex's Prompt Engineering Guide is created and published by the Brex organization.</data>
      <data key="d9">creation,publication</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009337</data>
      <data key="d13" />
    </edge>
    <edge source="Build A Large Language Model (From Scratch)" target="Large Model Application Development">
      <data key="d7">1.0</data>
      <data key="d8">The resource "Build a Large Language Model (From Scratch)" is a recommended educational material within the field of Large Model Application Development.</data>
      <data key="d9">educational resource,training</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009327</data>
      <data key="d13" />
    </edge>
    <edge source="A Survey Of Prompt Engineering Methods In Large Language Models For Different Nlp Tasks" target="Nlp Tasks">
      <data key="d7">1.0</data>
      <data key="d8">The survey paper covers the application of prompt engineering methods across different NLP Tasks.</data>
      <data key="d9">application,overview</data>
      <data key="d10">chunk-c73155a0054fe7510b458e0f7fe666b7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009334</data>
      <data key="d13" />
    </edge>
    <edge source="Gemini" target="Gemini API">
      <data key="d7">1.0</data>
      <data key="d8">The Gemini API provides an interface to access and utilize the advanced reasoning and generation functionalities of the Gemini model.</data>
      <data key="d9">functionality access,interface provision</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009428</data>
      <data key="d13" />
    </edge>
    <edge source="Gemini" target="AI-Driven Application">
      <data key="d7">1.0</data>
      <data key="d8">The Gemini model is used to build next-generation AI-driven applications by leveraging its advanced reasoning and generation capabilities.</data>
      <data key="d9">application building,model utilization</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009422</data>
      <data key="d13" />
    </edge>
    <edge source="Customer Engagement Suite with Google AI" target="Dialogflow">
      <data key="d7">1.0</data>
      <data key="d8">The Customer Engagement Suite includes Dialogflow as its conversational AI platform with intent-based and LLM features.</data>
      <data key="d9">conversational AI,platform inclusion</data>
      <data key="d10">chunk-f394bd66e077e288f0b983860f06c440</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009415</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像分析" target="国土资源管理">
      <data key="d7">1.0</data>
      <data key="d8">Remote sensing image analysis has application prospects in the field of land resource management.</data>
      <data key="d9">application,management</data>
      <data key="d10">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009450</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像分析" target="海洋监测">
      <data key="d7">1.0</data>
      <data key="d8">Remote sensing image analysis has application prospects in the field of marine monitoring.</data>
      <data key="d9">application,monitoring</data>
      <data key="d10">chunk-70cc6b4326bedb7c4b61745cce643075</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009452</data>
      <data key="d13" />
    </edge>
    <edge source="地球科学" target="遥感图像分类">
      <data key="d7">1.0</data>
      <data key="d8">遥感图像分类是地球科学领域中使用的一项关键技术。</data>
      <data key="d9">技术应用,领域工具</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009492</data>
      <data key="d13" />
    </edge>
    <edge source="本研究" target="国内外研究现状与进展">
      <data key="d7">1.0</data>
      <data key="d8">本研究分析了深度神经网络在遥感应用领域的国内外研究现状与进展。</data>
      <data key="d9">分析探讨,研究内容</data>
      <data key="d10">chunk-81494149ccc19d39342ca4e7f5dc4668</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009499</data>
      <data key="d13" />
    </edge>
    <edge source="Imbalanced Learning-Based Automatic SAR Images Change Detection" target="IEEE Geoscience and Remote Sensing Letters">
      <data key="d7">1.0</data>
      <data key="d8">The method was published in the IEEE Geoscience and Remote Sensing Letters journal.</data>
      <data key="d9">dissemination,publication</data>
      <data key="d10">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009537</data>
      <data key="d13" />
    </edge>
    <edge source="Imbalanced Learning-Based Automatic SAR Images Change Detection" target="Wang Y H">
      <data key="d7">1.0</data>
      <data key="d8">Wang Y H is an author who contributed to the development of the method.</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009538</data>
      <data key="d13" />
    </edge>
    <edge source="Imbalanced Learning-Based Automatic SAR Images Change Detection" target="Gao L R">
      <data key="d7">1.0</data>
      <data key="d8">Gao L R is an author who contributed to the development of the method.</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009539</data>
      <data key="d13" />
    </edge>
    <edge source="Imbalanced Learning-Based Automatic SAR Images Change Detection" target="Chen Z C">
      <data key="d7">1.0</data>
      <data key="d8">Chen Z C is an author who contributed to the development of the method.</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009548</data>
      <data key="d13" />
    </edge>
    <edge source="Imbalanced Learning-Based Automatic SAR Images Change Detection" target="Zhang B">
      <data key="d7">1.0</data>
      <data key="d8">Zhang B is an author who contributed to the development of the method.</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009541</data>
      <data key="d13" />
    </edge>
    <edge source="Imbalanced Learning-Based Automatic SAR Images Change Detection" target="SAR Images">
      <data key="d7">1.0</data>
      <data key="d8">The method is designed for detecting changes in SAR images.</data>
      <data key="d9">analysis,application</data>
      <data key="d10">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009543</data>
      <data key="d13" />
    </edge>
    <edge source="Imbalanced Learning-Based Automatic SAR Images Change Detection" target="Morphologically Supervised PCA-Net">
      <data key="d7">1.0</data>
      <data key="d8">The method utilizes the Morphologically Supervised PCA-Net architecture.</data>
      <data key="d9">component,utilization</data>
      <data key="d10">chunk-d03520804df199a76ce35edbbeca10f8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009544</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像目标检测" target="尺度不变性">
      <data key="d7">1.0</data>
      <data key="d8">尺度不变性是遥感图像目标检测方法需要解决的关键属性之一。</data>
      <data key="d9">方法属性,检测挑战</data>
      <data key="d10">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009584</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像目标检测" target="旋转不变性">
      <data key="d7">1.0</data>
      <data key="d8">旋转不变性是遥感图像目标检测方法需要解决的关键属性之一。</data>
      <data key="d9">方法属性,检测挑战</data>
      <data key="d10">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009585</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像目标检测" target="复杂背景干扰">
      <data key="d7">1.0</data>
      <data key="d8">应对复杂背景干扰是遥感图像目标检测方法需要解决的关键属性之一。</data>
      <data key="d9">方法属性,检测挑战</data>
      <data key="d10">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009586</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像目标检测" target="样本量少">
      <data key="d7">1.0</data>
      <data key="d8">在样本量少的情况下进行检测是遥感图像目标检测方法需要解决的关键属性之一。</data>
      <data key="d9">方法属性,检测挑战</data>
      <data key="d10">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009587</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像目标检测" target="多波段数据检测">
      <data key="d7">1.0</data>
      <data key="d8">利用多波段数据进行检测是遥感图像目标检测方法需要解决的关键属性之一。</data>
      <data key="d9">数据利用,方法属性</data>
      <data key="d10">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009588</data>
      <data key="d13" />
    </edge>
    <edge source="遥感图像目标检测" target="典型遥感图像目标">
      <data key="d7">1.0</data>
      <data key="d8">遥感图像目标检测方法应用于典型遥感图像目标，并总结其检测难点。</data>
      <data key="d9">应用对象,检测难点</data>
      <data key="d10">chunk-326a81b79c40b3a07062403d80063e34</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009598</data>
      <data key="d13" />
    </edge>
    <edge source="Global Features" target="Satellite Remote Sensing Image Retrieval">
      <data key="d7">1.0</data>
      <data key="d8">Global features are applied to satellite remote sensing image retrieval, providing a new and more effective way.</data>
      <data key="d9">performance improvement,task application</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009666</data>
      <data key="d13" />
    </edge>
    <edge source="Global Features" target="Satellite Remote Sensing Image Positioning">
      <data key="d7">1.0</data>
      <data key="d8">Global features are applied to satellite remote sensing image positioning, providing a new and more effective way.</data>
      <data key="d9">performance improvement,task application</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009668</data>
      <data key="d13" />
    </edge>
    <edge source="Global Features" target="Local Features">
      <data key="d7">1.0</data>
      <data key="d8">Global features extracted by deep learning models are compared to local features, showing higher effectiveness for the satellite image tasks.</data>
      <data key="d9">feature type,performance comparison</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009672</data>
      <data key="d13" />
    </edge>
    <edge source="Evaluation System" target="Precision@K">
      <data key="d7">1.0</data>
      <data key="d8">The evaluation system quantifies Precision@K as a key metric for measuring effectiveness.</data>
      <data key="d9">effectiveness measurement,metric quantification</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009664</data>
      <data key="d13" />
    </edge>
    <edge source="Evaluation System" target="Average Ranking">
      <data key="d7">1.0</data>
      <data key="d8">The evaluation system quantifies average ranking as a key metric for measuring effectiveness.</data>
      <data key="d9">effectiveness measurement,metric quantification</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009668</data>
      <data key="d13" />
    </edge>
    <edge source="Evaluation System" target="Feature Extraction Time">
      <data key="d7">1.0</data>
      <data key="d8">The evaluation system quantifies feature extraction time as a key metric for measuring efficiency.</data>
      <data key="d9">efficiency measurement,metric quantification</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009672</data>
      <data key="d13" />
    </edge>
    <edge source="Evaluation System" target="Feature Similarity Calculation Time">
      <data key="d7">1.0</data>
      <data key="d8">The evaluation system quantifies feature similarity calculation time as a key metric for measuring efficiency.</data>
      <data key="d9">efficiency measurement,metric quantification</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009677</data>
      <data key="d13" />
    </edge>
    <edge source="Evaluation System" target="Hardware Consumption">
      <data key="d7">1.0</data>
      <data key="d8">The evaluation system quantifies hardware consumption as a key metric for measuring efficiency.</data>
      <data key="d9">efficiency measurement,metric quantification</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009680</data>
      <data key="d13" />
    </edge>
    <edge source="DenseNet" target="Test Datasets">
      <data key="d7">1.0</data>
      <data key="d8">DenseNet's performance, including its highest Precision@K, is evaluated based on the test datasets.</data>
      <data key="d9">model evaluation,performance testing</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009673</data>
      <data key="d13" />
    </edge>
    <edge source="ResNet-18" target="Test Datasets">
      <data key="d7">1.0</data>
      <data key="d8">ResNet-18's relatively better performance is evaluated based on the test datasets.</data>
      <data key="d9">model evaluation,performance testing</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009677</data>
      <data key="d13" />
    </edge>
    <edge source="VggNet" target="Test Datasets">
      <data key="d7">1.0</data>
      <data key="d8">VggNet's relatively better performance is evaluated based on the test datasets.</data>
      <data key="d9">model evaluation,performance testing</data>
      <data key="d10">chunk-fb89c8462c112775ff8e6c43e7d050e8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009680</data>
      <data key="d13" />
    </edge>
    <edge source="Lavaan" target="Structural Equation Modeling (SEM)">
      <data key="d7">1.0</data>
      <data key="d8">Lavaan is a software package specifically designed for implementing structural equation modeling (SEM).</data>
      <data key="d9">software tool,statistical analysis</data>
      <data key="d10">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009841</data>
      <data key="d13" />
    </edge>
    <edge source="SWAP Agricultural Model" target="Climate Change">
      <data key="d7">1.0</data>
      <data key="d8">The SWAP agricultural model is applied to analyze the impacts of climate change.</data>
      <data key="d9">environmental simulation,impact analysis</data>
      <data key="d10">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009841</data>
      <data key="d13" />
    </edge>
    <edge source="SWAP Agricultural Model" target="Sensitivity Analysis">
      <data key="d7">1.0</data>
      <data key="d8">The SWAP agricultural model is applied in sensitivity analysis studies.</data>
      <data key="d9">application,model evaluation</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009864</data>
      <data key="d13" />
    </edge>
    <edge source="SWAP Agricultural Model" target="Climate Change Impact">
      <data key="d7">1.0</data>
      <data key="d8">The SWAP agricultural model is applied in climate change impact studies.</data>
      <data key="d9">application,impact assessment</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009869</data>
      <data key="d13" />
    </edge>
    <edge source="TRP Channel Protein" target="Water Transport">
      <data key="d7">1.0</data>
      <data key="d8">TRP channel proteins are studied in the context of their role in water transport.</data>
      <data key="d9">biological function,physiological process</data>
      <data key="d10">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009842</data>
      <data key="d13" />
    </edge>
    <edge source="Sustainable Resources" target="Biomedical New Materials">
      <data key="d7">1.0</data>
      <data key="d8">Sustainable resources are utilized in the development of biomedical new materials.</data>
      <data key="d9">material development,medical application</data>
      <data key="d10">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009842</data>
      <data key="d13" />
    </edge>
    <edge source="Archiver" target="Science Net">
      <data key="d7">1.0</data>
      <data key="d8">Archiver is associated with or operates the platform Science Net.</data>
      <data key="d9">content management,platform affiliation</data>
      <data key="d10">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009848</data>
      <data key="d13" />
    </edge>
    <edge source="Science Net" target="ICP Filing Number 07017567-12">
      <data key="d7">1.0</data>
      <data key="d8">Science Net holds the ICP Filing Number 07017567-12, which is its official registration identifier.</data>
      <data key="d9">legal compliance,website registration</data>
      <data key="d10">chunk-d0c5f3de9954bb6c66fcfdce01302cf9</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009843</data>
      <data key="d13" />
    </edge>
    <edge source="Remote Sensing Image" target="Mineral Exploration">
      <data key="d7">1.0</data>
      <data key="d8">Remote sensing images are applied in the field of mineral exploration.</data>
      <data key="d9">application,resource detection</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009850</data>
      <data key="d13" />
    </edge>
    <edge source="Remote Sensing Image" target="Precision Agriculture">
      <data key="d7">1.0</data>
      <data key="d8">Remote sensing images are applied in the field of precision agriculture.</data>
      <data key="d9">application,farming optimization</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009853</data>
      <data key="d13" />
    </edge>
    <edge source="Remote Sensing Image" target="Urban Planning">
      <data key="d7">1.0</data>
      <data key="d8">Remote sensing images are applied in the field of urban planning.</data>
      <data key="d9">application,development planning</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009864</data>
      <data key="d13" />
    </edge>
    <edge source="Remote Sensing Image" target="Disaster Monitoring">
      <data key="d7">1.0</data>
      <data key="d8">Remote sensing images are applied in the field of disaster monitoring.</data>
      <data key="d9">application,risk management</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009859</data>
      <data key="d13" />
    </edge>
    <edge source="Image Segmentation" target="FCN">
      <data key="d7">1.0</data>
      <data key="d8">FCN is mentioned as a model applicable to remote sensing image segmentation.</data>
      <data key="d9">model application</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009850</data>
      <data key="d13" />
    </edge>
    <edge source="Image Segmentation" target="SegNet">
      <data key="d7">1.0</data>
      <data key="d8">SegNet is mentioned as a model applicable to remote sensing image segmentation.</data>
      <data key="d9">model application</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009853</data>
      <data key="d13" />
    </edge>
    <edge source="Image Segmentation" target="U-Net">
      <data key="d7">1.0</data>
      <data key="d8">U-Net is mentioned as a model applicable to remote sensing image segmentation.</data>
      <data key="d9">model application</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009848</data>
      <data key="d13" />
    </edge>
    <edge source="R Language" target="Bayesian Model">
      <data key="d7">1.0</data>
      <data key="d8">The R language is used to implement Bayesian models for practical applications.</data>
      <data key="d9">implementation,statistical analysis</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009860</data>
      <data key="d13" />
    </edge>
    <edge source="R Language" target="Structural Equation Model (SEM)">
      <data key="d7">1.0</data>
      <data key="d8">The R language, via the 'lavaan' package, is used to implement Structural Equation Models.</data>
      <data key="d9">implementation,statistical analysis</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009865</data>
      <data key="d13" />
    </edge>
    <edge source="PLUS-InVEST Model" target="Ecosystem Service Assessment">
      <data key="d7">1.0</data>
      <data key="d8">The PLUS-InVEST model is used for ecosystem service assessment.</data>
      <data key="d9">application,environmental modeling</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009874</data>
      <data key="d13" />
    </edge>
    <edge source="PLUS-InVEST Model" target="Scenario Simulation">
      <data key="d7">1.0</data>
      <data key="d8">The PLUS-InVEST model is used for scenario simulation.</data>
      <data key="d9">application,predictive modeling</data>
      <data key="d10">chunk-b80301dc089946e283419441a33451d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009871</data>
      <data key="d13" />
    </edge>
    <edge source="地球观测卫星" target="气候数据">
      <data key="d7">1.0</data>
      <data key="d8">The increase in Earth observation satellites contributes to the generation of vast amounts of climate data.</data>
      <data key="d9">data collection,observation</data>
      <data key="d10">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009902</data>
      <data key="d13" />
    </edge>
    <edge source="气候模型" target="气候数据">
      <data key="d7">1.0</data>
      <data key="d8">The analysis of climate data aims to discover new climate models and improve weather forecasting.</data>
      <data key="d9">data foundation,model development</data>
      <data key="d10">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009904</data>
      <data key="d13" />
    </edge>
    <edge source="气候学" target="研究人员">
      <data key="d7">1.0</data>
      <data key="d8">Researchers are working within the field of climatology.</data>
      <data key="d9">application,field of study</data>
      <data key="d10">chunk-4a38cf117c062d1c34ec79abbff9e244</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009904</data>
      <data key="d13" />
    </edge>
    <edge source="DFS-M" target="DFS-S">
      <data key="d7">1.0</data>
      <data key="d8">Combining the DFS-M and DFS-S models for forecasts at different times can produce more balanced forecasting results.</data>
      <data key="d9">forecasting,model combination</data>
      <data key="d10">chunk-babf4b9b036bdc4286b6ed4dc016cba8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009936</data>
      <data key="d13" />
    </edge>
    <edge source="Weather And Climate Forecasting" target="This Study">
      <data key="d7">1.0</data>
      <data key="d8">This study provides new ideas for selecting methods in the field of weather and climate forecasting.</data>
      <data key="d9">method selection,research contribution</data>
      <data key="d10">chunk-babf4b9b036bdc4286b6ed4dc016cba8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769009936</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="Cresswell-Clay">
      <data key="d7">1.0</data>
      <data key="d8">Cresswell-Clay is the creator who developed the Deep Learning Earth System Model (DLESyM).</data>
      <data key="d9">creation,development</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010015</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="耦合模式比对计划第六阶段">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model's performance is comparable to or better than CMIP6 models, while requiring significantly lower computational cost.</data>
      <data key="d9">computational efficiency,performance comparison</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010017</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="热带气旋">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model simulates tropical cyclones better than CMIP6 models.</data>
      <data key="d9">simulation,superior performance</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010018</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="印度夏季季风">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model simulates the Indian summer monsoon better than CMIP6 models.</data>
      <data key="d9">simulation,superior performance</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010019</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="北半球大气阻塞事件">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model accurately captures the frequency and spatial distribution of Northern Hemisphere atmospheric blocking events.</data>
      <data key="d9">accuracy,capture</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010021</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="东北风暴">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model generates realistic storm simulations, such as a nor'easter whose structure closely matches an observed storm.</data>
      <data key="d9">realism,simulation</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010024</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="海洋">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model uses a neural network to simulate the ocean, updating its conditions every four model days.</data>
      <data key="d9">component,simulation</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010034</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="大气">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model uses a neural network to simulate the atmosphere, updating predictions every 12 model hours.</data>
      <data key="d9">component,simulation</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010027</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="气候">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model is designed to accurately simulate climate patterns and variability.</data>
      <data key="d9">prediction,simulation</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010029</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习地球系统模型" target="年际变化">
      <data key="d7">1.0</data>
      <data key="d8">The DLESyM model can accurately simulate interannual climate variations.</data>
      <data key="d9">capability,simulation</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010030</data>
      <data key="d13" />
    </edge>
    <edge source="耦合模式比对计划第六阶段" target="计算气候研究">
      <data key="d7">1.0</data>
      <data key="d8">CMIP6 models are widely used as a standard framework in computational climate research.</data>
      <data key="d9">application,standard</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010019</data>
      <data key="d13" />
    </edge>
    <edge source="北半球大气阻塞事件" target="极端天气">
      <data key="d7">1.0</data>
      <data key="d8">Atmospheric blocking events in the Northern Hemisphere can lead to extreme weather conditions.</data>
      <data key="d9">causation,impact</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010024</data>
      <data key="d13" />
    </edge>
    <edge source="AGU Advances" target="Eos">
      <data key="d7">1.0</data>
      <data key="d8">AGU Advances is the journal that published the article, which is a translation of an original Eos article.</data>
      <data key="d9">publication,source</data>
      <data key="d10">chunk-b7e84880c36323dbbf1d92748718a1d1</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010023</data>
      <data key="d13" />
    </edge>
    <edge source="Meteorological Elements Forecasting Method" target="Long Short Term Memory">
      <data key="d7">1.0</data>
      <data key="d8">Long Short Term Memory is listed as a key architectural technique relevant to the Meteorological Elements Forecasting Method.</data>
      <data key="d9">architecture,technique</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010138</data>
      <data key="d13" />
    </edge>
    <edge source="Monthly Rainfall Forecasting" target="One-Dimensional Deep Convolutional Neural Network">
      <data key="d7">1.0</data>
      <data key="d8">Monthly Rainfall Forecasting is performed using a One-Dimensional Deep Convolutional Neural Network as its model.</data>
      <data key="d9">application,model</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010127</data>
      <data key="d13" />
    </edge>
    <edge source="Ensemble Of Neural Networks" target="Weather Forecasting">
      <data key="d7">1.0</data>
      <data key="d8">An Ensemble Of Neural Networks is a method applied to the task of Weather Forecasting.</data>
      <data key="d9">application,prediction</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010127</data>
      <data key="d13" />
    </edge>
    <edge source="Weather Forecasting" target="LSTM Algorithm">
      <data key="d7">1.0</data>
      <data key="d8">Weather forecasting specifically employs the LSTM algorithm for time-series weather data prediction.</data>
      <data key="d9">methodology,prediction</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010289</data>
      <data key="d13" />
    </edge>
    <edge source="Weather Forecasting" target="Historical Data">
      <data key="d7">1.0</data>
      <data key="d8">Weather forecasting relies on historical weather data as a primary input for model training.</data>
      <data key="d9">data analysis,input</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010291</data>
      <data key="d13" />
    </edge>
    <edge source="Weather Forecasting" target="Real-Time Data">
      <data key="d7">1.0</data>
      <data key="d8">Weather forecasting incorporates real-time data to improve the accuracy of predictions.</data>
      <data key="d9">data analysis,input</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010300</data>
      <data key="d13" />
    </edge>
    <edge source="Weather Forecasting" target="Weather Forecast">
      <data key="d7">1.0</data>
      <data key="d8">The primary output of the weather forecasting process is the weather forecast itself.</data>
      <data key="d9">output,process</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010294</data>
      <data key="d13" />
    </edge>
    <edge source="Weather Forecasting" target="Extreme Weather Warning">
      <data key="d7">1.0</data>
      <data key="d8">Weather forecasting systems generate extreme weather warnings as a critical output for public safety.</data>
      <data key="d9">output,risk assessment</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010297</data>
      <data key="d13" />
    </edge>
    <edge source="Weather Forecasting" target="Life Index">
      <data key="d7">1.0</data>
      <data key="d8">Weather forecasting contributes to the calculation of life indices that inform daily activities.</data>
      <data key="d9">application,output</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010299</data>
      <data key="d13" />
    </edge>
    <edge source="Weather Forecasting" target="Visualization Dashboard">
      <data key="d7">1.0</data>
      <data key="d8">The visualization dashboard is used to display and monitor the results and data from weather forecasting.</data>
      <data key="d9">data presentation,monitoring</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010300</data>
      <data key="d13" />
    </edge>
    <edge source="Prediction Interval" target="Artificial Neural Network Hydrologic Models">
      <data key="d7">1.0</data>
      <data key="d8">Methods for quantifying Prediction Intervals are compared in the context of Artificial Neural Network Hydrologic Models.</data>
      <data key="d9">evaluation,uncertainty quantification</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010130</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network Modeling" target="Big Data Weather Forecasting">
      <data key="d7">1.0</data>
      <data key="d8">Deep Neural Network Modeling is the approach used for enabling Big Data Weather Forecasting.</data>
      <data key="d9">enabling technology,modeling approach</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010135</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network Modeling" target="Information Granularity">
      <data key="d7">1.0</data>
      <data key="d8">Information Granularity is a concept mentioned in the broader context of Deep Neural Network Modeling for big data.</data>
      <data key="d9">context,data consideration</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010140</data>
      <data key="d13" />
    </edge>
    <edge source="Deep Neural Network Modeling" target="Computational Intelligence">
      <data key="d7">1.0</data>
      <data key="d8">Computational Intelligence is the broader field within which Deep Neural Network Modeling for big data is situated.</data>
      <data key="d9">enabling discipline,field</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010144</data>
      <data key="d13" />
    </edge>
    <edge source="Hydrological Early Warning System" target="Deep Learning Runoff Model">
      <data key="d7">1.0</data>
      <data key="d8">A Deep Learning Runoff Model serves as the core predictive component within the Hydrological Early Warning System.</data>
      <data key="d9">core component,prediction engine</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010136</data>
      <data key="d13" />
    </edge>
    <edge source="Hydrological Early Warning System" target="Meteorological Forecast">
      <data key="d7">1.0</data>
      <data key="d8">The Hydrological Early Warning System is coupled with Meteorological Forecast data to provide comprehensive warnings.</data>
      <data key="d9">coupling,data integration</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010141</data>
      <data key="d13" />
    </edge>
    <edge source="Shi X J" target="Deep Learning In Neural Networks: An Overview">
      <data key="d7">1.0</data>
      <data key="d8">Shi X J is listed as an author of the work "Deep Learning In Neural Networks: An Overview".</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010141</data>
      <data key="d13" />
    </edge>
    <edge source="Shi X J" target="Chen Z R">
      <data key="d7">1.0</data>
      <data key="d8">Shi X J and Chen Z R are listed as co-authors on a research paper published in 2015.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010661</data>
      <data key="d13" />
    </edge>
    <edge source="Shi X J" target="Wang H">
      <data key="d7">1.0</data>
      <data key="d8">Shi X J and Wang H are listed as co-authors on a research paper published in 2015.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010664</data>
      <data key="d13" />
    </edge>
    <edge source="Shi Z R" target="Deep Learning In Neural Networks: An Overview">
      <data key="d7">1.0</data>
      <data key="d8">Shi Z R is listed as an author of the work "Deep Learning In Neural Networks: An Overview".</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010146</data>
      <data key="d13" />
    </edge>
    <edge source="Wan H G" target="Deep Learning In Neural Networks: An Overview">
      <data key="d7">1.0</data>
      <data key="d8">Wan H G is listed as an author of the work "Deep Learning In Neural Networks: An Overview".</data>
      <data key="d9">authorship,contribution</data>
      <data key="d10">chunk-ed300ee31268ac8e853d58a7e20740f0</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010146</data>
      <data key="d13" />
    </edge>
    <edge source="数值天气预报" target="天气现象预报方法">
      <data key="d7">1.0</data>
      <data key="d8">该预报方法利用数值天气预报产品作为输入数据。</data>
      <data key="d9">数据来源,方法结合</data>
      <data key="d10">chunk-506b50fbb39065edcc65dbbbc31a2bd7</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010179</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习方法" target="数值天气预报模式">
      <data key="d7">1.0</data>
      <data key="d8">Research is based on deep learning to improve numerical weather prediction models and forecasting.</data>
      <data key="d9">improvement,research</data>
      <data key="d10">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010206</data>
      <data key="d13" />
    </edge>
    <edge source="深度学习方法" target="学者">
      <data key="d7">1.0</data>
      <data key="d8">Scholars have conducted in-depth discussions on deep learning methods.</data>
      <data key="d9">discussion,research</data>
      <data key="d10">chunk-ffd1a702a5052372a15a2cc72ea7ca01</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010214</data>
      <data key="d13" />
    </edge>
    <edge source="直接预报模型" target="迭代预报模型">
      <data key="d7">1.0</data>
      <data key="d8">直接预报模型在整体预报时段的预报效果明显优于迭代预报模型。</data>
      <data key="d9">性能比较,预报方法</data>
      <data key="d10">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010229</data>
      <data key="d13" />
    </edge>
    <edge source="直接预报模型" target="RMSE">
      <data key="d7">1.0</data>
      <data key="d8">直接预报模型的RMSE比迭代预报模型低19%，是其性能优势的量化指标。</data>
      <data key="d9">性能指标,模型评估</data>
      <data key="d10">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010230</data>
      <data key="d13" />
    </edge>
    <edge source="迭代预报模型" target="预报误差">
      <data key="d7">1.0</data>
      <data key="d8">迭代预报模型的预报误差会随着预报时次的增加而累积。</data>
      <data key="d9">模型特性,误差累积</data>
      <data key="d10">chunk-a6b4a600bac8a52a4a59aa8136dc667e</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010230</data>
      <data key="d13" />
    </edge>
    <edge source="Historical Data" target="Hadoop">
      <data key="d7">1.0</data>
      <data key="d8">Hadoop is used for storing and processing large volumes of historical weather data.</data>
      <data key="d9">data processing,storage</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010300</data>
      <data key="d13" />
    </edge>
    <edge source="Historical Data" target="Hive">
      <data key="d7">1.0</data>
      <data key="d8">Hive is used to manage and query the historical weather data stored in data warehouses.</data>
      <data key="d9">data warehousing,querying</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010294</data>
      <data key="d13" />
    </edge>
    <edge source="Real-Time Data" target="Spark">
      <data key="d7">1.0</data>
      <data key="d8">Spark is utilized for processing and analyzing real-time weather data streams.</data>
      <data key="d9">analytics,data processing</data>
      <data key="d10">chunk-333ff749c2940b520a06027eb3c17eac</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010294</data>
      <data key="d13" />
    </edge>
    <edge source="智能气候预测" target="报告内容">
      <data key="d7">1.0</data>
      <data key="d8">The report content includes discussions on the concept and cases of intelligent climate prediction.</data>
      <data key="d9">overview,topic inclusion</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010510</data>
      <data key="d13" />
    </edge>
    <edge source="基于深度学习的北极地区格点化地表气温重建" target="北极地区">
      <data key="d7">1.0</data>
      <data key="d8">The study content focuses on reconstructing gridded surface air temperature specifically for the Arctic region.</data>
      <data key="d9">data reconstruction,research focus</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010488</data>
      <data key="d13" />
    </edge>
    <edge source="基于深度学习的北极地区格点化地表气温重建" target="极地缺测">
      <data key="d7">1.0</data>
      <data key="d8">The reconstruction study aims to address the problem of missing observations (缺测) in polar regions.</data>
      <data key="d9">data gap,problem addressing</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010494</data>
      <data key="d13" />
    </edge>
    <edge source="极地缺测" target="全球温度变化">
      <data key="d7">1.0</data>
      <data key="d8">Missing data in polar regions has a significant impact on the study of global temperature changes.</data>
      <data key="d9">impact,research limitation</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010488</data>
      <data key="d13" />
    </edge>
    <edge source="地表空气温度数据集" target="北极地区">
      <data key="d7">1.0</data>
      <data key="d8">The surface air temperature dataset is created to cover areas including the data-scarce Arctic region.</data>
      <data key="d9">coverage,data creation</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010494</data>
      <data key="d13" />
    </edge>
    <edge source="HadCRUT5" target="Huang et al.">
      <data key="d7">1.0</data>
      <data key="d8">Huang et al. analyzed the observation coverage of the HadCRUT5 dataset, noting its limitations in the Arctic.</data>
      <data key="d9">data evaluation,research analysis</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010488</data>
      <data key="d13" />
    </edge>
    <edge source="HadCRUT5" target="Morice et al.">
      <data key="d7">1.0</data>
      <data key="d8">Morice et al. are the researchers who developed or are cited for the HadCRUT5 dataset.</data>
      <data key="d9">authorship,development</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010495</data>
      <data key="d13" />
    </edge>
    <edge source="HadCRUT5" target="1850年至今HadCRUT5观测覆盖情况">
      <data key="d7">1.0</data>
      <data key="d8">The figure titled "1850年至今HadCRUT5观测覆盖情况" visualizes and analyzes the observation coverage of the HadCRUT5 dataset.</data>
      <data key="d9">coverage analysis,data visualization</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010505</data>
      <data key="d13" />
    </edge>
    <edge source="HadCRUT5" target="CRUTEM5">
      <data key="d7">1.0</data>
      <data key="d8">The HadCRUT5 dataset uses CRUTEM5 as its land temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010510</data>
      <data key="d13" />
    </edge>
    <edge source="HadCRUT5" target="HadSST4">
      <data key="d7">1.0</data>
      <data key="d8">The HadCRUT5 dataset uses HadSST4 as its sea surface temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010515</data>
      <data key="d13" />
    </edge>
    <edge source="GISTEMP v4" target="Lenssen et al.">
      <data key="d7">1.0</data>
      <data key="d8">Lenssen et al. are the researchers who developed or are cited for the GISTEMP v4 dataset.</data>
      <data key="d9">authorship,development</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010489</data>
      <data key="d13" />
    </edge>
    <edge source="GISTEMP v4" target="GHCN v4">
      <data key="d7">1.0</data>
      <data key="d8">The GISTEMP v4 dataset uses GHCN v4 as its land temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010509</data>
      <data key="d13" />
    </edge>
    <edge source="GISTEMP v4" target="ERSST v5">
      <data key="d7">1.0</data>
      <data key="d8">The GISTEMP v4 dataset uses ERSST v5 as its sea surface temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010513</data>
      <data key="d13" />
    </edge>
    <edge source="NOAAGlobalTemp-Interim" target="Vose et al.">
      <data key="d7">1.0</data>
      <data key="d8">Vose et al. are the researchers who developed or are cited for the NOAAGlobalTemp-Interim dataset.</data>
      <data key="d9">authorship,development</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010491</data>
      <data key="d13" />
    </edge>
    <edge source="NOAAGlobalTemp-Interim" target="GHCN v4">
      <data key="d7">1.0</data>
      <data key="d8">The NOAAGlobalTemp-Interim dataset uses GHCN v4 as its land temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010513</data>
      <data key="d13" />
    </edge>
    <edge source="NOAAGlobalTemp-Interim" target="ERSST v5">
      <data key="d7">1.0</data>
      <data key="d8">The NOAAGlobalTemp-Interim dataset uses ERSST v5 as its sea surface temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010517</data>
      <data key="d13" />
    </edge>
    <edge source="BEST" target="Rohde et al.">
      <data key="d7">1.0</data>
      <data key="d8">Rohde et al. are the researchers who developed or are cited for the BEST dataset.</data>
      <data key="d9">authorship,development</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010495</data>
      <data key="d13" />
    </edge>
    <edge source="BEST" target="Berkeley Earth">
      <data key="d7">1.0</data>
      <data key="d8">The Berkeley Earth organization produces the BEST global temperature dataset.</data>
      <data key="d9">organization,production</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010510</data>
      <data key="d13" />
    </edge>
    <edge source="BEST" target="GHCN v4">
      <data key="d7">1.0</data>
      <data key="d8">The BEST dataset uses GHCN v4 as its land temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010517</data>
      <data key="d13" />
    </edge>
    <edge source="BEST" target="ERSST v5">
      <data key="d7">1.0</data>
      <data key="d8">The BEST dataset uses ERSST v5 as its sea surface temperature data component.</data>
      <data key="d9">component,data composition</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010524</data>
      <data key="d13" />
    </edge>
    <edge source="20CRv3" target="Compo et al.">
      <data key="d7">1.0</data>
      <data key="d8">Compo et al. are the researchers who developed or are cited for the 20CRv3 reanalysis dataset.</data>
      <data key="d9">authorship,development</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010496</data>
      <data key="d13" />
    </edge>
    <edge source="ERA5" target="Hersbach et al.">
      <data key="d7">1.0</data>
      <data key="d8">Hersbach et al. are the researchers who developed or are cited for the ERA5 reanalysis dataset.</data>
      <data key="d9">authorship,development</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010497</data>
      <data key="d13" />
    </edge>
    <edge source="ERA5" target="ECMWF">
      <data key="d7">1.0</data>
      <data key="d8">The ECMWF organization produces the ERA5 reanalysis dataset.</data>
      <data key="d9">organization,production</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010504</data>
      <data key="d13" />
    </edge>
    <edge source="CERA-20C" target="Laloyaux et al.">
      <data key="d7">1.0</data>
      <data key="d8">Laloyaux et al. are the researchers who developed or are cited for the CERA-20C reanalysis dataset.</data>
      <data key="d9">authorship,development</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010501</data>
      <data key="d13" />
    </edge>
    <edge source="CERA-20C" target="ECMWF">
      <data key="d7">1.0</data>
      <data key="d8">The ECMWF organization produces the CERA-20C reanalysis dataset.</data>
      <data key="d9">organization,production</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010509</data>
      <data key="d13" />
    </edge>
    <edge source="Kadow et al." target="CRUTEM5">
      <data key="d7">1.0</data>
      <data key="d8">The work by Kadow et al. uses CRUTEM5 as a land temperature data component.</data>
      <data key="d9">component,data usage</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010514</data>
      <data key="d13" />
    </edge>
    <edge source="Kadow et al." target="HadSST4">
      <data key="d7">1.0</data>
      <data key="d8">The work by Kadow et al. uses HadSST4 as a sea surface temperature data component.</data>
      <data key="d9">component,data usage</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010517</data>
      <data key="d13" />
    </edge>
    <edge source="Vaccaro et al." target="CRUTEM4">
      <data key="d7">1.0</data>
      <data key="d8">The work by Vaccaro et al. uses CRUTEM4 as a land temperature data component.</data>
      <data key="d9">component,data usage</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010517</data>
      <data key="d13" />
    </edge>
    <edge source="Vaccaro et al." target="HadSST3">
      <data key="d7">1.0</data>
      <data key="d8">The work by Vaccaro et al. uses HadSST3 as a sea surface temperature data component.</data>
      <data key="d9">component,data usage</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010524</data>
      <data key="d13" />
    </edge>
    <edge source="Dahlgren et al." target="Most of the Arctic">
      <data key="d7">1.0</data>
      <data key="d8">The dataset or work by Dahlgren et al. covers most of the Arctic region.</data>
      <data key="d9">geographical scope,research coverage</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010519</data>
      <data key="d13" />
    </edge>
    <edge source="Rigor et al." target="optimal interpolation">
      <data key="d7">1.0</data>
      <data key="d8">Rigor et al. are associated with the application of the optimal interpolation method.</data>
      <data key="d9">method application,technique</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010521</data>
      <data key="d13" />
    </edge>
    <edge source="研究目的" target="北极缺测">
      <data key="d7">1.0</data>
      <data key="d8">The research purpose is defined as understanding the Arctic data gap situation and its impact.</data>
      <data key="d9">goal definition,problem focus</data>
      <data key="d10">chunk-5837f0d5dd6a7cba90da952aebd39e90</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010507</data>
      <data key="d13" />
    </edge>
    <edge source="Zheng Y G" target="Zhu W J">
      <data key="d7">1.0</data>
      <data key="d8">Zheng Y G and Zhu W J are listed as co-authors on a research paper published in 2016b.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010646</data>
      <data key="d13" />
    </edge>
    <edge source="Zheng Y G" target="Yao D">
      <data key="d7">1.0</data>
      <data key="d8">Zheng Y G and Yao D are listed as co-authors on a research paper published in 2016b.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010649</data>
      <data key="d13" />
    </edge>
    <edge source="Zheng Y G" target="Zhou K H">
      <data key="d7">1.0</data>
      <data key="d8">Zheng Y G and Zhou K H are listed as co-authors on a research paper published in 2015.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010655</data>
      <data key="d13" />
    </edge>
    <edge source="Zheng Y G" target="Sheng J">
      <data key="d7">1.0</data>
      <data key="d8">Zheng Y G and Sheng J are listed as co-authors on a research paper published in 2015.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010659</data>
      <data key="d13" />
    </edge>
    <edge source="Billet J" target="DeLisi M">
      <data key="d7">1.0</data>
      <data key="d8">Billet J and DeLisi M are listed as co-authors on a research paper published in 1997.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010646</data>
      <data key="d13" />
    </edge>
    <edge source="Billet J" target="Smith B G">
      <data key="d7">1.0</data>
      <data key="d8">Billet J and Smith B G are listed as co-authors on a research paper published in 1997.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010649</data>
      <data key="d13" />
    </edge>
    <edge source="Gagne II D J" target="McGovern A">
      <data key="d7">1.0</data>
      <data key="d8">Gagne II D J and McGovern A are listed as co-authors on research papers published in 2017 and 2019.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010647</data>
      <data key="d13" />
    </edge>
    <edge source="Gagne II D J" target="Haupt S E">
      <data key="d7">1.0</data>
      <data key="d8">Gagne II D J and Haupt S E are listed as co-authors on a research paper published in 2017.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010650</data>
      <data key="d13" />
    </edge>
    <edge source="McGovern A" target="Elmore K L">
      <data key="d7">1.0</data>
      <data key="d8">McGovern A and Elmore K L are listed as co-authors on a research paper published in 2017.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010651</data>
      <data key="d13" />
    </edge>
    <edge source="McGovern A" target="Lagerquist R">
      <data key="d7">1.0</data>
      <data key="d8">McGovern A and Lagerquist R are listed as co-authors on a research paper published in 2019.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010656</data>
      <data key="d13" />
    </edge>
    <edge source="Kim M" target="Im J">
      <data key="d7">1.0</data>
      <data key="d8">Kim M and Im J are listed as co-authors on a research paper published in 2017a.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010650</data>
      <data key="d13" />
    </edge>
    <edge source="Kim M" target="Park H">
      <data key="d7">1.0</data>
      <data key="d8">Kim M and Park H are listed as co-authors on a research paper published in 2017a.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010656</data>
      <data key="d13" />
    </edge>
    <edge source="Mecikalski J R" target="Li X L">
      <data key="d7">1.0</data>
      <data key="d8">Mecikalski J R and Li X L are listed as co-authors on a research paper published in 2013.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010656</data>
      <data key="d13" />
    </edge>
    <edge source="Mecikalski J R" target="Carey L D">
      <data key="d7">1.0</data>
      <data key="d8">Mecikalski J R and Carey L D are listed as co-authors on a research paper published in 2013.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010661</data>
      <data key="d13" />
    </edge>
    <edge source="Mecikalski J R" target="Mackenzie W M Jr">
      <data key="d7">1.0</data>
      <data key="d8">Mecikalski J R and Mackenzie W M Jr are listed as co-authors on research papers published in 2010a and 2010b.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010664</data>
      <data key="d13" />
    </edge>
    <edge source="Mecikalski J R" target="Köenig M">
      <data key="d7">1.0</data>
      <data key="d8">Mecikalski J R and Köenig M are listed as co-authors on a research paper published in 2010a.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010669</data>
      <data key="d13" />
    </edge>
    <edge source="Mecikalski J R" target="König M">
      <data key="d7">1.0</data>
      <data key="d8">Mecikalski J R and König M are listed as co-authors on a research paper published in 2010b.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010671</data>
      <data key="d13" />
    </edge>
    <edge source="Wang Y B" target="Long M S">
      <data key="d7">1.0</data>
      <data key="d8">Wang Y B and Long M S are listed as co-authors on a research paper published in 2017.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010662</data>
      <data key="d13" />
    </edge>
    <edge source="Wang Y B" target="Wang J M">
      <data key="d7">1.0</data>
      <data key="d8">Wang Y B and Wang J M are listed as co-authors on a research paper published in 2017.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010665</data>
      <data key="d13" />
    </edge>
    <edge source="Wilson J W" target="Feng Y R">
      <data key="d7">1.0</data>
      <data key="d8">Wilson J W and Feng Y R are listed as co-authors on a research paper published in 2010.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010664</data>
      <data key="d13" />
    </edge>
    <edge source="Wilson J W" target="Chen M">
      <data key="d7">1.0</data>
      <data key="d8">Wilson J W and Chen M are listed as co-authors on a research paper published in 2010.</data>
      <data key="d9">co-authorship,scientific collaboration</data>
      <data key="d10">chunk-44aa5ced4dbdd708f5b101c55c7bb894</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010669</data>
      <data key="d13" />
    </edge>
    <edge source="技术哲学" target="关键词">
      <data key="d7">1.0</data>
      <data key="d8">“技术哲学”是论文关键词列表中的一个核心术语。</data>
      <data key="d9">主题概括,内容索引</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010755</data>
      <data key="d13" />
    </edge>
    <edge source="技术哲学" target="哲学">
      <data key="d7">1.0</data>
      <data key="d8">The philosophy of technology becomes a new field restructuring the internal landscape of philosophy, comparable to traditional fields.</data>
      <data key="d9">内部版图,领域重组</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011222</data>
      <data key="d13" />
    </edge>
    <edge source="技术哲学" target="形而上学">
      <data key="d7">1.0</data>
      <data key="d8">技术哲学会逐渐成为与形而上学、知识论、伦理学等传统哲学领域并驾齐驱的新领域，意味着哲学内部版图将被重组。</data>
      <data key="d9">版图重组,领域并立</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011264</data>
      <data key="d13" />
    </edge>
    <edge source="技术哲学" target="知识论">
      <data key="d7">1.0</data>
      <data key="d8">技术哲学会逐渐成为与形而上学、知识论、伦理学等传统哲学领域并驾齐驱的新领域，意味着哲学内部版图将被重组。</data>
      <data key="d9">版图重组,领域并立</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011270</data>
      <data key="d13" />
    </edge>
    <edge source="技术哲学" target="伦理学">
      <data key="d7">1.0</data>
      <data key="d8">技术哲学会逐渐成为与形而上学、知识论、伦理学等传统哲学领域并驾齐驱的新领域，意味着哲学内部版图将被重组。</data>
      <data key="d9">版图重组,领域并立</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011273</data>
      <data key="d13" />
    </edge>
    <edge source="杨媛" target="华南师范大学马克思主义学院">
      <data key="d7">1.0</data>
      <data key="d8">杨媛隶属于华南师范大学马克思主义学院。</data>
      <data key="d9">学术隶属,机构归属</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010741</data>
      <data key="d13" />
    </edge>
    <edge source="杨媛" target="哲学进展">
      <data key="d7">1.0</data>
      <data key="d8">杨媛的论文《深度学习的技术路径与哲学审视》发表在《哲学进展》期刊上。</data>
      <data key="d9">学术发表,成果发布</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010743</data>
      <data key="d13" />
    </edge>
    <edge source="杨媛" target="DOI: 10.12677/acpp.2025.145279">
      <data key="d7">1.0</data>
      <data key="d8">杨媛是拥有该DOI的论文的作者。</data>
      <data key="d9">学术成果,标识归属</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010750</data>
      <data key="d13" />
    </edge>
    <edge source="华南师范大学马克思主义学院" target="广东广州">
      <data key="d7">1.0</data>
      <data key="d8">华南师范大学马克思主义学院位于广东省广州市。</data>
      <data key="d9">所在地,机构位置</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010743</data>
      <data key="d13" />
    </edge>
    <edge source="华南师范大学马克思主义学院" target="School of Marxism, South China Normal University">
      <data key="d7">1.0</data>
      <data key="d8">这是“华南师范大学马克思主义学院”的英文名称。</data>
      <data key="d9">名称对应,机构翻译</data>
      <data key="d10">chunk-ea37ab1462f7ff56b1e76b106d6df9dd</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010748</data>
      <data key="d13" />
    </edge>
    <edge source="Cameron J. Buckner" target="From Deep Learning to Rational Machines">
      <data key="d7">1.0</data>
      <data key="d8">Cameron J. Buckner is the author who wrote the book "From Deep Learning to Rational Machines".</data>
      <data key="d9">authorship,creation</data>
      <data key="d10">chunk-520def31c8675778cae230b17d8f6b02</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769010779</data>
      <data key="d13" />
    </edge>
    <edge source="张颖天" target="戴宁馨">
      <data key="d7">1.0</data>
      <data key="d8">张颖天and戴宁馨are co-authors of the article "Philosophical Reflections in the Age of Artificial Intelligence".</data>
      <data key="d9">co-authorship,collaboration</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011139</data>
      <data key="d13" />
    </edge>
    <edge source="张颖天" target="光明日报">
      <data key="d7">1.0</data>
      <data key="d8">张颖天co-authored an article that was published in the Guangming Daily.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011151</data>
      <data key="d13" />
    </edge>
    <edge source="戴宁馨" target="光明日报">
      <data key="d7">1.0</data>
      <data key="d8">戴宁馨co-authored an article that was published in the Guangming Daily.</data>
      <data key="d9">authorship,publication</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011146</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能时代" target="哲学">
      <data key="d7">2.0</data>
      <data key="d8">哲学总会以批判性反思的姿态在场并介入时代，并在与技术和时代的动态关系中演化出新形态，迈向新阶段。&lt;SEP&gt;The Age of Artificial Intelligence serves as the contemporary context that prompts and shapes philosophical reflection on technology and the human future.</data>
      <data key="d9">context,reflection,形态演化,时代介入</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63&lt;SEP&gt;chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011148</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能时代" target="三位青年学者">
      <data key="d7">1.0</data>
      <data key="d8">The three young scholars participate in a discussion organized around the theme of philosophical research in the Age of Artificial Intelligence.</data>
      <data key="d9">participation,thematic discussion</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011158</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能时代" target="赵立">
      <data key="d7">1.0</data>
      <data key="d8">赵立认为基于哲学的批判性反思可以全面观照人工智能技术，从而校准其与哲学思考的发展方向。</data>
      <data key="d9">方向校准,问题分析</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011210</data>
      <data key="d13" />
    </edge>
    <edge source="哲学" target="逻辑">
      <data key="d7">1.0</data>
      <data key="d8">Philosophy includes logic as part of the doctrine of the laws of the thinking process itself.</data>
      <data key="d9">doctrine,thinking process</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011162</data>
      <data key="d13" />
    </edge>
    <edge source="哲学" target="辩证法">
      <data key="d7">1.0</data>
      <data key="d8">Philosophy includes dialectics as part of the doctrine of the laws of the thinking process itself. Dialectical thinking is the methodological premise of scientific thinking.</data>
      <data key="d9">doctrine,methodology,thinking process</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011171</data>
      <data key="d13" />
    </edge>
    <edge source="哲学" target="技术决定论">
      <data key="d7">1.0</data>
      <data key="d8">哲学的价值需要被重视和发掘，以避免走向“唯算法”的技术决定论一端。</data>
      <data key="d9">价值平衡,批判警示</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011200</data>
      <data key="d13" />
    </edge>
    <edge source="哲学" target="魏犇群">
      <data key="d7">1.0</data>
      <data key="d8">魏犇群从提出深刻问题、关注意义与价值、保持对复杂性敏感三个方面阐述了哲学思考的不可替代性。</data>
      <data key="d9">独特性分析,观点阐述</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011210</data>
      <data key="d13" />
    </edge>
    <edge source="哲学" target="主持人">
      <data key="d7">1.0</data>
      <data key="d8">主持人提出问题，引导讨论聚焦于哲学思考的不可替代性这一真问题。</data>
      <data key="d9">讨论聚焦,问题引导</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011214</data>
      <data key="d13" />
    </edge>
    <edge source="哲学" target="唯算法">
      <data key="d7">1.0</data>
      <data key="d8">Valuing and发掘ing philosophical value is important to avoid falling into 'algorithm-only' technological determinism.</data>
      <data key="d9">价值发掘,避免倾向</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011245</data>
      <data key="d13" />
    </edge>
    <edge source="哲学" target="哲学史">
      <data key="d7">1.0</data>
      <data key="d8">哲学研究尤其依赖对于哲学史的长期积累过程。</data>
      <data key="d9">历史积累,研究依赖</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011257</data>
      <data key="d13" />
    </edge>
    <edge source="哲学研究" target="哲学是世界观和方法论的统一">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical research is grounded in the principle that "philosophy is the unity of worldview and methodology."</data>
      <data key="d9">definition,foundational principle</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011151</data>
      <data key="d13" />
    </edge>
    <edge source="哲学研究" target="赵立">
      <data key="d7">1.0</data>
      <data key="d8">Zhao Li states that philosophical research in the AI era must be "based on humans, centered on humans, and for humans."</data>
      <data key="d9">focus,human-centric,states</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011179</data>
      <data key="d13" />
    </edge>
    <edge source="哲学研究" target="人类的思维劳动生产活动">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical research means the productive activity of human mental labor.</data>
      <data key="d9">内涵,等同</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011222</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="中共北京市委党校〔北京行政学院〕哲学与文化教研部">
      <data key="d7">1.0</data>
      <data key="d8">王田is employed as a lecturer at the Department of Philosophy and Culture, Party School of the Beijing Municipal Committee of the CPC (Beijing Administrative College).</data>
      <data key="d9">affiliation,employment</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011139</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="主动性和被动性的悖论">
      <data key="d7">1.0</data>
      <data key="d8">王田expounds on "the paradox of initiative and passivity" as a specific challenge AI poses to the traditional concept of the rational subject in philosophy.</data>
      <data key="d9">conceptual challenge,exposition</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011158</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="霍克海默">
      <data key="d7">1.0</data>
      <data key="d8">Wang Tian cites the German philosopher Horkheimer's point about understanding the crisis of science.</data>
      <data key="d9">cites,philosopher,theory reference</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011177</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="资本逻辑">
      <data key="d7">1.0</data>
      <data key="d8">Wang Tian states that developing AI's "philosophy" requires ensuring innovation is not dominated by capital logic.</data>
      <data key="d9">avoidance of domination,development principle</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011191</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="技术逻辑">
      <data key="d7">1.0</data>
      <data key="d8">Wang Tian states that developing AI's "philosophy" requires ensuring innovation is not dominated by technological logic.</data>
      <data key="d9">avoidance of domination,development principle</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011195</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="人类尺度">
      <data key="d7">1.0</data>
      <data key="d8">Wang Tian emphasizes that when repositioning the human-AI relationship, the human scale must not be abandoned to ensure AI serves humanity.</data>
      <data key="d9">relationship repositioning,service guarantee</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011198</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="辩证思维方法">
      <data key="d7">1.0</data>
      <data key="d8">王田引用恩格斯观点，强调辩证思维方法是哲学思考不可替代性的体现，是科学思维方法的方法论前提并能对其进行提升。</data>
      <data key="d9">方法论阐述,观点引用</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011208</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="劳动价值论">
      <data key="d7">1.0</data>
      <data key="d8">Wang Tian argues that the tension's theoretical essence is a re-examination of the labor theory of value in the AI era.</data>
      <data key="d9">本质分析,理论审视</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011232</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="主动性被动性悖论">
      <data key="d7">1.0</data>
      <data key="d8">王田分析了人工智能发展中出现的主动性被动性悖论。</data>
      <data key="d9">分析,阐述</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011248</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="知识获取加速化知识增量受限悖论">
      <data key="d7">1.0</data>
      <data key="d8">王田阐述了人工智能导致的知識獲取加速化與知識增量受限的悖論。</data>
      <data key="d9">分析,阐述</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011254</data>
      <data key="d13" />
    </edge>
    <edge source="王田" target="人与机器身份悖论">
      <data key="d7">1.0</data>
      <data key="d8">王田探讨了人工智能引发的人与机器身份悖论。</data>
      <data key="d9">分析,阐述</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011257</data>
      <data key="d13" />
    </edge>
    <edge source="主持人" target="人机协同">
      <data key="d7">1.0</data>
      <data key="d8">The host believes that the development of philosophy can promote the sustainable development of human-machine collaboration.</data>
      <data key="d9">future belief,sustainable development</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011185</data>
      <data key="d13" />
    </edge>
    <edge source="主持人" target="马克思劳动价值论">
      <data key="d7">1.0</data>
      <data key="d8">The moderator raises a question based on Marx's labor theory of value.</data>
      <data key="d9">提问基础,理论依据</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011218</data>
      <data key="d13" />
    </edge>
    <edge source="哲学学者" target="主体性创造">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical scholars are concerned about the difficulties and challenges AI poses to human subjective creativity in philosophy.</data>
      <data key="d9">capacity threat,concern</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011144</data>
      <data key="d13" />
    </edge>
    <edge source="哲学学者" target="原创焦虑">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical scholars risk falling into a state of "originality anxiety" due to the efficient output of AI.</data>
      <data key="d9">psychological effect,risk</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011151</data>
      <data key="d13" />
    </edge>
    <edge source="哲学学者" target="深度求索">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical scholars risk losing the capacity for "deep inquiry" by becoming overly dependent on AI's pre-set frameworks and answers.</data>
      <data key="d9">capacity loss,risk</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011156</data>
      <data key="d13" />
    </edge>
    <edge source="赵立" target="黄昏起飞的密涅瓦猫头鹰">
      <data key="d7">1.0</data>
      <data key="d8">赵立invokes the metaphor of "Minerva's owl taking flight at dusk" to analyze the difficulty of philosophical contemplation in the fast-paced AI era.</data>
      <data key="d9">invocation,metaphorical analysis</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011156</data>
      <data key="d13" />
    </edge>
    <edge source="赵立" target="实证科学的思维方式">
      <data key="d7">1.0</data>
      <data key="d8">赵立contrasts philosophical thinking with the pervasive "思维方式of empirical science," which is reinforced by modern technological breakthroughs.</data>
      <data key="d9">contrast,ideological context</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011161</data>
      <data key="d13" />
    </edge>
    <edge source="赵立" target="科学技术">
      <data key="d7">1.0</data>
      <data key="d8">Zhao Li argues that philosophical thinking should "legislate" for the use of science and technology, providing guidance and controlling their direction.</data>
      <data key="d9">argues,control,guidance,legislation</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011187</data>
      <data key="d13" />
    </edge>
    <edge source="赵立" target="批判性反思">
      <data key="d7">1.0</data>
      <data key="d8">赵立指出批判性反思是哲学思考最本质和核心的特征，是应对人工智能技术困境的关键。</data>
      <data key="d9">核心特征,观点阐述</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011205</data>
      <data key="d13" />
    </edge>
    <edge source="赵立" target="人工智能技术">
      <data key="d7">1.0</data>
      <data key="d8">Zhao Li discusses how AI technology shapes the era and necessitates philosophical thinking and response.</data>
      <data key="d9">哲学回应,时代塑造</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011214</data>
      <data key="d13" />
    </edge>
    <edge source="赵立" target="人与技术的关系">
      <data key="d7">1.0</data>
      <data key="d8">Zhao Li mentions rethinking the human-technology relationship in interdisciplinary dialogue.</data>
      <data key="d9">跨学科对话,重思问题</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011218</data>
      <data key="d13" />
    </edge>
    <edge source="哲学思考" target="技术逻辑">
      <data key="d7">1.0</data>
      <data key="d8">Human philosophical thought must transcend the technological logic of AI to confirm the unique subjective value of human thinking.</data>
      <data key="d9">transcendence,value confirmation</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011148</data>
      <data key="d13" />
    </edge>
    <edge source="哲学思考" target="无人之境">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical thinking is characterized as a journey into "uncharted territory," emphasizing its solitary and exploratory nature.</data>
      <data key="d9">characterization,metaphorical description</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011154</data>
      <data key="d13" />
    </edge>
    <edge source="哲学思考" target="古希腊哲人">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical thinking, through its speculative power, provided conditions for transforming the world, as seen in ancient Greek philosophers' discussions on the world's origin.</data>
      <data key="d9">speculative power,world transformation</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011167</data>
      <data key="d13" />
    </edge>
    <edge source="哲学思考" target="近代启蒙思想家">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical thinking, through its speculative power, inspired action, as seen in modern Enlightenment thinkers inspiring the pursuit of ideals.</data>
      <data key="d9">inspiration,speculative power</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011176</data>
      <data key="d13" />
    </edge>
    <edge source="哲学思考" target="马克思主义">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical thinking, through its speculative power, provided conditions for transforming the world, as seen in Marxism revealing societal laws and providing guidance.</data>
      <data key="d9">guidance,revelation,speculative power</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011185</data>
      <data key="d13" />
    </edge>
    <edge source="技术逻辑" target="哲学逻辑">
      <data key="d7">1.0</data>
      <data key="d8">技术逻辑与哲学逻辑的争锋贯穿历史，在人工智能时代有必要重启两者的深层次对话以实现动态平衡。</data>
      <data key="d9">动态平衡,历史争锋</data>
      <data key="d10">chunk-1583b867ca44e12600f0775616185d52</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011202</data>
      <data key="d13" />
    </edge>
    <edge source="技术逻辑" target="哲学逻">
      <data key="d7">1.0</data>
      <data key="d8">Historically, technological logic and philosophical logic have interacted, as indicated by the final sentence fragment.</data>
      <data key="d9">历史互动,逻辑关系</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011245</data>
      <data key="d13" />
    </edge>
    <edge source="三位青年学者" target="专家">
      <data key="d7">1.0</data>
      <data key="d8">Experts are invited to provide commentary and evaluation on the discussion held by the three young scholars.</data>
      <data key="d9">evaluation,invited commentary</data>
      <data key="d10">chunk-dd306af31a739643f5fdb50f2073ec63</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011163</data>
      <data key="d13" />
    </edge>
    <edge source="辩证法" target="科学思维方法">
      <data key="d7">1.0</data>
      <data key="d8">Dialectical thinking is the methodological premise of scientific thinking methods and can absorb, reference, and elevate them.</data>
      <data key="d9">absorption,elevation,methodological premise</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011165</data>
      <data key="d13" />
    </edge>
    <edge source="古希腊哲人" target="早期科学与数学">
      <data key="d7">1.0</data>
      <data key="d8">Ancient Greek philosophers' discussions on the origin of the world gave birth to early science and mathematics.</data>
      <data key="d9">birth,discussion,origin</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011181</data>
      <data key="d13" />
    </edge>
    <edge source="近代启蒙思想家" target="自由、平等与民主理念">
      <data key="d7">1.0</data>
      <data key="d8">Modern Enlightenment thinkers inspired people's pursuit of the ideals of freedom, equality, and democracy.</data>
      <data key="d9">inspired,pursuit</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011171</data>
      <data key="d13" />
    </edge>
    <edge source="马克思主义" target="人类社会">
      <data key="d7">1.0</data>
      <data key="d8">Marxism revealed the development laws and future direction of human society.</data>
      <data key="d9">development laws,future direction,revealed</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011181</data>
      <data key="d13" />
    </edge>
    <edge source="魏犇群" target="人工智能的哲学">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun explains the two meanings of "AI's philosophy": philosophy about AI and philosophy created by AI.</data>
      <data key="d9">defines,explains,two meanings</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011174</data>
      <data key="d13" />
    </edge>
    <edge source="魏犇群" target="意识">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun mentions that re-understanding human uniqueness in the AI era includes re-understanding consciousness.</data>
      <data key="d9">human uniqueness,re-understanding</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011188</data>
      <data key="d13" />
    </edge>
    <edge source="魏犇群" target="理性">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun mentions that re-understanding human uniqueness in the AI era includes re-understanding reason.</data>
      <data key="d9">human uniqueness,re-understanding</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011191</data>
      <data key="d13" />
    </edge>
    <edge source="魏犇群" target="道德">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun mentions that re-understanding human uniqueness in the AI era includes re-understanding morality.</data>
      <data key="d9">human uniqueness,re-understanding</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011198</data>
      <data key="d13" />
    </edge>
    <edge source="魏犇群" target="社会">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun mentions that re-understanding human uniqueness in the AI era includes re-understanding society.</data>
      <data key="d9">human uniqueness,re-understanding</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011205</data>
      <data key="d13" />
    </edge>
    <edge source="魏犇群" target="算法价值">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun explains that algorithmic value is currently a product of human mental labor.</data>
      <data key="d9">来源,解释</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011228</data>
      <data key="d13" />
    </edge>
    <edge source="魏犇群" target="哲学价值">
      <data key="d7">1.0</data>
      <data key="d8">Wei Benqun explains that philosophical value is manifested in critical insight and meaning creation.</data>
      <data key="d9">表现,解释</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011230</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能的哲学" target="人的哲学">
      <data key="d7">1.0</data>
      <data key="d8">According to Wei Benqun, AI's philosophy (in the sense of philosophy about AI) belongs to human philosophy and should guide technology with humanistic reflection.</data>
      <data key="d9">belongs to,humanistic guidance,subset</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011179</data>
      <data key="d13" />
    </edge>
    <edge source="全国哲学社会科学工作办公室" target="人民网">
      <data key="d7">1.0</data>
      <data key="d8">The National Office for Philosophy and Social Sciences is the organizer and sponsor, and People's Daily Online is the undertaker of the content.</data>
      <data key="d9">organizer,sponsor,undertaker</data>
      <data key="d10">chunk-9443f3ff3d63c86fe69beb12e077ee15</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011182</data>
      <data key="d13" />
    </edge>
    <edge source="人" target="哲学母题">
      <data key="d7">1.0</data>
      <data key="d8">The question 'what is a human' becomes the central philosophical theme in the AI era.</data>
      <data key="d9">时代主题,核心问题</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011218</data>
      <data key="d13" />
    </edge>
    <edge source="人工智能技术" target="高度数学形式化的算法">
      <data key="d7">1.0</data>
      <data key="d8">Highly mathematically formalized algorithms are the key tool of AI technology.</data>
      <data key="d9">关键工具,核心构成</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011240</data>
      <data key="d13" />
    </edge>
    <edge source="马克思劳动价值论" target="数据要素">
      <data key="d7">1.0</data>
      <data key="d8">According to Marx's labor theory of value, the value of data elements condenses in human labor.</data>
      <data key="d9">价值凝结,理论应用</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011224</data>
      <data key="d13" />
    </edge>
    <edge source="马克思劳动价值论" target="人类劳动">
      <data key="d7">1.0</data>
      <data key="d8">Marx's labor theory of value posits that human living labor is the sole source of value.</data>
      <data key="d9">价值源泉,核心要义</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011228</data>
      <data key="d13" />
    </edge>
    <edge source="算法价值" target="哲学价值">
      <data key="d7">1.0</data>
      <data key="d8">There is a tension and distinction between the value created by algorithms and the value of philosophy.</data>
      <data key="d9">区别,张力</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011231</data>
      <data key="d13" />
    </edge>
    <edge source="算法价值" target="信息处理">
      <data key="d7">1.0</data>
      <data key="d8">Algorithmic value is mainly manifested in information processing.</data>
      <data key="d9">主要表现,功能领域</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011230</data>
      <data key="d13" />
    </edge>
    <edge source="算法价值" target="劳作">
      <data key="d7">1.0</data>
      <data key="d8">Algorithmic value aims to potentially replace human 'labor'.</data>
      <data key="d9">功能指向,替代目标</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011235</data>
      <data key="d13" />
    </edge>
    <edge source="算法价值" target="劳动解放论">
      <data key="d7">1.0</data>
      <data key="d8">Basing on the theory of labor liberation is necessary to achieve the dialectical unity of algorithmic and philosophical values.</data>
      <data key="d9">实现基础,辩证统一</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011238</data>
      <data key="d13" />
    </edge>
    <edge source="哲学价值" target="批判性洞察">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical value is embodied in critical insight.</data>
      <data key="d9">价值体现,功能领域</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011235</data>
      <data key="d13" />
    </edge>
    <edge source="哲学价值" target="意义创造">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical value is embodied in meaning creation.</data>
      <data key="d9">价值体现,功能领域</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011238</data>
      <data key="d13" />
    </edge>
    <edge source="哲学价值" target="类本质">
      <data key="d7">1.0</data>
      <data key="d8">Philosophical value helps humans grasp their 'species-essence' in consciousness.</data>
      <data key="d9">功能指向,把握帮助</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011244</data>
      <data key="d13" />
    </edge>
    <edge source="哲学价值" target="人的自由全面发展">
      <data key="d7">1.0</data>
      <data key="d8">Basing on the free and comprehensive development of humans is necessary to achieve the dialectical unity of algorithmic and philosophical values.</data>
      <data key="d9">实现基础,辩证统一</data>
      <data key="d10">chunk-47b980b33218327b53ee86797118fbb8</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011252</data>
      <data key="d13" />
    </edge>
    <edge source="人与机器身份悖论" target="索菲娅">
      <data key="d7">1.0</data>
      <data key="d8">AI机器人索菲娅获得法律上的公民身份，是人与机器身份悖论的一个具体实例，迫使哲学对“人是什么”进行深刻反思。</data>
      <data key="d9">实例,引发反思</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011262</data>
      <data key="d13" />
    </edge>
    <edge source="数据安全性" target="大数据技术">
      <data key="d7">1.0</data>
      <data key="d8">大数据技术是数据采集、存储和分析的基础，其应用可能引发个人隐私泄露的数据安全性风险。</data>
      <data key="d9">引发风险,技术基础</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011262</data>
      <data key="d13" />
    </edge>
    <edge source="数字偏见" target="数字鸿沟">
      <data key="d7">1.0</data>
      <data key="d8">数字偏见导致了接触、使用和融合人工智能的机会与能力不均等，形成了“数字鸿沟”这一不争的事实。</data>
      <data key="d9">事实表现,导致</data>
      <data key="d10">chunk-c9369fc176f49069a39d1f5e88729d68</data>
      <data key="d11">unknown_source</data>
      <data key="d12">1769011268</data>
      <data key="d13" />
    </edge>
  </graph>
</graphml>

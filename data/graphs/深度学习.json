{
  "concept": "深度学习",
  "nodes": [
    {
      "id": "基于规则的NLP",
      "label": "基于规则的NLP",
      "description": "基于规则的NLP是使用预先编程的语法规则来处理语言的方法。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "二维卷积层",
      "label": "二维卷积层",
      "description": "二维卷积层是卷积神经网络中最常见的卷积层，有高和宽两个空间维度，用于处理图像数据。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-61775650edeed94f49f7144412443478"
      ],
      "size": 2
    },
    {
      "id": "LLM",
      "label": "LLM",
      "description": "{\"entities\": [\"大型语言模型\", \"人工智能\", \"GPT\", \"智能体\", \"工作流\", \"检索增强生成\", \"机器学习模型\"]}",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771",
        "chunk-3678971988880bb3960a90e15878444d",
        "chunk-0222ac86b3d60100ac5d03d88a69654e",
        "chunk-4d514ef014c3cb4cb7fc652928e9a4a4",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 21
    },
    {
      "id": "研究",
      "label": "研究",
      "description": "这项研究深入探讨了深度学习中的优化机制。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-88c27f8b7b31c4aea51cfc3d8f79a013"
      ],
      "size": 3
    },
    {
      "id": "卷积核",
      "label": "卷积核",
      "description": "卷积核是卷积层中用于与输入图像进行卷积操作的工具。<SEP>卷积核是卷积层中进行特征提取的小矩阵(如3x3)，通过二维离散卷积操作实现高效的图像特征提取，并具备空间平移不变性。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 3
    },
    {
      "id": "高强度计算平台",
      "label": "高强度计算平台",
      "description": "A single, high-intensity computing platform that integrates database and GPU hardware for financial analysis.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-858e73004375c211a45ff338fb81b219"
      ],
      "size": 2
    },
    {
      "id": "Attention",
      "label": "Attention",
      "description": "A mechanism that focuses on specific parts of the input based on their contextual importance relative to other parts of the sequence.<SEP>Attention is a mechanism used in AlphaFold2 to integrate 1D and 2D information.<SEP>A mechanism added before transitioning from the word level to the sentence level to identify the most important words within a sentence. Another Attention layer is added before the final output to learn which sentences are most important.",
      "domains": [
        "生物信息学",
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-eb903a35c2a682651dd2704f765bb4c6",
        "chunk-224a7273b9442fd233a7ec61f799fa44",
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 5
    },
    {
      "id": "主持人",
      "label": "主持人",
      "description": "主持人提出关于哲学思考不可替代性的问题，引导讨论聚焦于真问题。<SEP>The host moderates the discussion, posing questions about the challenges AI development brings to philosophical research, specifically regarding human subjectivity and creativity.<SEP>The moderator who raises a question about the tension between the algorithmic value and philosophical value of AI technology based on Marx's labor theory of value.<SEP>The host poses a question about the future development of philosophy and its role in sustainable human-machine collaboration, specifically asking how to develop human philosophy and AI's \"philosophy\" and what the starting point and standpoint for philosophical research in the AI era are.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-1583b867ca44e12600f0775616185d52",
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 4
    },
    {
      "id": "Artificial Intelligence",
      "label": "Artificial Intelligence",
      "description": "The broader field of study that encompasses neural networks and deep learning.<SEP>Artificial Intelligence is a field that was significantly advanced by the abstract modeling of neural systems.<SEP>Artificial Intelligence is a field of technology that current fraud detection systems rely on, though it has not fully addressed all related challenges.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c",
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 4
    },
    {
      "id": "Geoffrey Hinton",
      "label": "Geoffrey Hinton",
      "description": "Geoffrey Hinton is a co-author of the 2015 Nature review article on deep learning.<SEP>Geoffrey Hinton is a researcher who made significant contributions to training artificial neural networks and the deep learning revolution.<SEP>A foundational figure in deep learning who made outstanding contributions. He was born in the UK, educated in Christian schools, and co-invented the Boltzmann machine with Terry Sejnowski around 1982. He also promoted the widespread use of the Back-propagation algorithm and invented deep learning training methods in 2006.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837"
      ],
      "size": 10
    },
    {
      "id": "情感分析",
      "label": "情感分析",
      "description": "情感分析是自然語言處理的一項功能，能根據關鍵字判斷使用者在搜尋當下的正面或負面感受。<SEP>情感分析是一种深度学习应用，用于分析文本序列所表达的情感倾向，属于多对一问题。<SEP>深度学习的一个应用方向。<SEP>情感分析是从文本中提取主观特质(如态度、情感)的技术。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 6
    },
    {
      "id": "非线性激活函数",
      "label": "非线性激活函数",
      "description": "非线性激活函数是神经网络中的一种函数，用于引入非线性变换，使网络能够学习和表示更复杂的关系。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-6d725020748a8a4cbf40cdbf97928919"
      ],
      "size": 2
    },
    {
      "id": "VggNet",
      "label": "VggNet",
      "description": "A deep learning model whose performance on test datasets is relatively better.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-fb89c8462c112775ff8e6c43e7d050e8"
      ],
      "size": 3
    },
    {
      "id": "并行计算",
      "label": "并行计算",
      "description": "并行计算是一种计算类型，其中许多计算或进程同时执行，GPU是实现并行计算的关键硬件，显著加速了深度学习算法的训练。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade"
      ],
      "size": 2
    },
    {
      "id": "Recycling多轮迭代",
      "label": "Recycling多轮迭代",
      "description": "Recycling multi-round iteration is a process in AlphaFold2 where the model refines its predictions through multiple cycles.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 2
    },
    {
      "id": "关键词",
      "label": "关键词",
      "description": "论文中用于概括核心内容的术语列表，包括“深度学习”、“人工智能”、“技术哲学”。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 4
    },
    {
      "id": "Cross-Attention",
      "label": "Cross-Attention",
      "description": "Cross-Attention is an attention mechanism in the Decoder block where queries come from the decoder's previous layer, and keys and values come from the Encoder's output.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 2
    },
    {
      "id": "参数",
      "label": "参数",
      "description": "参数是神经网络中需要通过学习进行调整的变量，如权重矩阵。<SEP>Parameters, in the context of LLMs and Transformers, refer to the millions or billions of adjustable elements that enable the model to learn complex patterns.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-3a728b359622810cd77efd2985a7fcfd",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "Sigmoid",
      "label": "Sigmoid",
      "description": "Sigmoid is an activation function in neural networks, with its gradient being a key property for backpropagation.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-8bed972d3227719ebad6c051fae785c9"
      ],
      "size": 4
    },
    {
      "id": "机器学习模型",
      "label": "机器学习模型",
      "description": "机器学习模型是用于分析经过NLP预处理后的文本的算法模型。<SEP>Machine learning models, such as LLMs, are systems that can generate text, summarize content, translate, rewrite, classify, and analyze.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-38b1076024c94a070f64f72dcaea1102",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "长短期记忆网络",
      "label": "长短期记忆网络",
      "description": "Long Short-Term Memory networks (LSTM) are a variant of RNNs that are particularly effective for capturing complex nonlinear relationships and long-term dependencies in time series data.<SEP>长短期记忆网络是一种深度学习模型，能够记忆长距离和短距离的语义信息，对特征选择和模型输出有帮助。",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 6
    },
    {
      "id": "Panel_Trader",
      "label": "Panel_Trader",
      "description": "A user with a达人认证(expert certification) who commented on the branches of machine learning suitable for different data frequencies.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 3
    },
    {
      "id": "象牙山李宝库",
      "label": "象牙山李宝库",
      "description": "A user who discussed quantitative trading at Goldman Sachs, high-frequency trading, fundamental quantitative investing, and the use of Python for data analysis.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 5
    },
    {
      "id": "反向传播算法",
      "label": "反向传播算法",
      "description": "反向传播算法是一种用于训练人工神经网络的算法，通过计算损失函数对网络参数的梯度来优化网络权重。<SEP>Backpropagation algorithm is a training method used to train Convolutional Neural Networks and other deep learning structures by adjusting weights based on error.<SEP>反向传播算法是一种训练神经网络的算法，在1980年代推动了多层感知机的重大进展。<SEP>Also known as the Back-propagation (BP) algorithm, it is a method for training artificial neural networks. Geoffrey Hinton and his peers promoted its widespread application.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-95faa80d73b4394851b10e9cc65232d2",
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-93860b80c6ea559ea9b38a8562c8df8c",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c"
      ],
      "size": 12
    },
    {
      "id": "LLaMA",
      "label": "LLaMA",
      "description": "A common example of a Large Language Model, introduced by Meta.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4f9864ecff092ef091c227f6ebb2d69f"
      ],
      "size": 2
    },
    {
      "id": "Feature Map",
      "label": "Feature Map",
      "description": "The output resulting from applying a convolution kernel to an input image.<SEP>The output of applying a filter (kernel) to the input data during the convolution operation in a CNN.<SEP>A feature map is the output generated by applying a convolution filter to an input in a convolutional neural network.<SEP>Outputs created by convolutional layers in a CNN, from which max-pooling extracts the most significant features.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-330f64bec90f2f131895d2de62adeb6f",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 5
    },
    {
      "id": "TF-IDF",
      "label": "TF-IDF",
      "description": "一种用于计算特征值或进行特征过滤排序的方式。<SEP>TF-IDF是一种用于信息检索与文本挖掘的常用加权技术，用以评估一个词语对于一个文件集或一个语料库中的其中一份文件的重要程度。<SEP>TF-IDF是一种评估单词在文档集合中重要性的特征提取技术。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 3
    },
    {
      "id": "性能",
      "label": "性能",
      "description": "Performance refers to the effectiveness and efficiency of an AI model in completing its intended tasks.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "数学方程",
      "label": "数学方程",
      "description": "数学方程是文章中包含的用于解释卷积神经网络原理的复杂公式。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-61775650edeed94f49f7144412443478"
      ],
      "size": 2
    },
    {
      "id": "L2正则化",
      "label": "L2正则化",
      "description": "L2正则化是一种通过添加权重平方和作为惩罚项的正则化方法。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-3a728b359622810cd77efd2985a7fcfd"
      ],
      "size": 2
    },
    {
      "id": "Global Features",
      "label": "Global Features",
      "description": "Features extracted by deep learning models for satellite remote sensing image retrieval and positioning, showing higher effectiveness compared to local features.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-fb89c8462c112775ff8e6c43e7d050e8"
      ],
      "size": 2
    },
    {
      "id": "自动编码器",
      "label": "自动编码器",
      "description": "自动编码器是一种神经网络，通常包括编码器和解码器两部分，它们串联合作以实现数据降维或特征学习，并广泛用于生成模型。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-0a82bdcf222bdb547252e178dfe4d622"
      ],
      "size": 4
    },
    {
      "id": "廣告創意素材",
      "label": "廣告創意素材",
      "description": "廣告創意素材是行銷中用於實現「千人千面」顧客旅程的內容，可以通過AI進行個性化打造。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1"
      ],
      "size": 2
    },
    {
      "id": "AlphaFold 2",
      "label": "AlphaFold 2",
      "description": "AlphaFold 2 is an AI algorithm that successfully predicts protein structures based on amino acid sequences, solving a long-standing biological challenge.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-d23247c8edaf8929e7855d9186007c46"
      ],
      "size": 4
    },
    {
      "id": "哲学",
      "label": "哲学",
      "description": "哲学具有批判性反思的本质，能够与技术逻辑进行对话，关注意义、价值、复杂性和不可通约性，其思考具有不可替代性。<SEP>哲学在人工智能时代需要反思主体概念、技术安全性以及基础概念(如意识、理解)的内涵，其内部研究版图可能因技术哲学兴起而重组。<SEP>Philosophy is defined as the unity of worldview and methodology, and is the subject of reflection regarding its challenges and irreplaceability in the AI era.<SEP>Philosophy is described as a realm of pure thought, focusing on the laws of the thinking process itself, such as logic and dialectics. Its irreplaceability lies in its dialectical thinking method.<SEP>The discipline of human wisdom, involving critical thinking and meaning creation, whose internal landscape is being restructured in the age of AI.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-1583b867ca44e12600f0775616185d52",
        "chunk-47b980b33218327b53ee86797118fbb8",
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 8
    },
    {
      "id": "Jumper, J",
      "label": "Jumper, J",
      "description": "Jumper, J is an author of the 2021 Nature paper detailing the AlphaFold2 architecture.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "损失函数",
      "label": "损失函数",
      "description": "损失函数是用于衡量模型预测与真实值之间差异的函数，其梯度用于参数更新。<SEP>损失函数用于衡量神经网络预测值与真实值之间的误差，文中以均方误差为例。<SEP>损失函数用于衡量神经网络模型的预测误差，是反向传播过程中计算梯度以更新权重的关键组成部分。<SEP>损失函数用于计算模型预测值与真实标签之间的差异。<SEP>损失函数用于衡量神经网络输出与真实值之间的差异，是反向传播算法中梯度计算的起点。<SEP>损失函数用于衡量神经网络输出与真实标签之间的差异，其值通过正向传播求得，并作为反向传播的起点。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-29234d7a518b3ee30e3ee9cbc39d7e68",
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-3a728b359622810cd77efd2985a7fcfd",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a",
        "chunk-95faa80d73b4394851b10e9cc65232d2"
      ],
      "size": 6
    },
    {
      "id": "Alphafold2",
      "label": "Alphafold2",
      "description": "AlphaFold2 is an end-to-end deep learning model for protein structure prediction, featuring attention mechanisms and 3D equivariance.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 8
    },
    {
      "id": "敬畏常识",
      "label": "敬畏常识",
      "description": "A user who commented that much stock information cannot be quantified, leading to model input distortion, and that machine learning is merely a modifier of knowledge.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 3
    },
    {
      "id": "输入",
      "label": "输入",
      "description": "Input refers to the data fed into the Structure Module of AlphaFold2.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 4
    },
    {
      "id": "人工智慧",
      "label": "人工智慧",
      "description": "人工智慧是一種工具，可以處理自然語言，用於關鍵字擴展、情感分析和目標受眾識別。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1"
      ],
      "size": 3
    },
    {
      "id": "Prompt Engineering",
      "label": "Prompt Engineering",
      "description": "Prompt Engineering is a technique for guiding model outputs, contrasted with Fine-tuning and RAG.<SEP>A common method for integrating proprietary and domain-specific data when building LLM applications.<SEP>The practice of designing and optimizing prompts for language models.<SEP>A development paradigm for large model applications, mentioned as a topic in learning paths and guides.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0222ac86b3d60100ac5d03d88a69654e",
        "chunk-4f9864ecff092ef091c227f6ebb2d69f",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81",
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 6
    },
    {
      "id": "Natural Language Processing",
      "label": "Natural Language Processing",
      "description": "A subfield of AI focused on enabling computers to understand, interpret, and generate human language.<SEP>A research direction applied in biomedicine by Nankai Statistics.<SEP>Natural Language Processing (NLP) is a field of artificial intelligence focused on enabling computers to understand, interpret, and generate human language.",
      "domains": [
        "生物信息学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-95ce0b0b365782f95d313a054721a437",
        "chunk-59b5b5bb9f78f0060c833f3b8b091e05"
      ],
      "size": 5
    },
    {
      "id": "语音助手",
      "label": "语音助手",
      "description": "语音助手是深度学习的一个应用领域，例如使用循环神经网络。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-6003c974467b7a903cb83abef6cc2e24"
      ],
      "size": 2
    },
    {
      "id": "多层感知机",
      "label": "多层感知机",
      "description": "多层感知机是一种前馈神经网络，最早由Frank Rosenblatt在1950年代提出，并在1980年代通过反向传播算法取得重大进展。<SEP>A type of deep network composed of multiple layers of neurons, where each layer is connected to the layers below (receiving input) and above (influencing the current layer).<SEP>多层感知机是一种前馈人工神经网络，包含一个或多个隐含层，用于增强模型的表达能力。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-93860b80c6ea559ea9b38a8562c8df8c",
        "chunk-2bd963b40a794cdd2a7befd072b521f8",
        "chunk-6d725020748a8a4cbf40cdbf97928919"
      ],
      "size": 8
    },
    {
      "id": "风险",
      "label": "风险",
      "description": "Risk refers to potential negative outcomes or uncertainties associated with deploying and using AI models.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 4
    },
    {
      "id": "Encoder-Decoder Model",
      "label": "Encoder-Decoder Model",
      "description": "A model structure suitable for tasks that map an input sequence to an output sequence, such as machine translation and text summarization, consisting of an encoder for understanding and a decoder for generation.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4f9864ecff092ef091c227f6ebb2d69f"
      ],
      "size": 2
    },
    {
      "id": "Lecture Video",
      "label": "Lecture Video",
      "description": "The lecture video titled \"【機器學習2021】Transformer (上)\" was published on March 26, 2021, and has 283,126 views.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-a6f32e4615a0137e965400eba7166c47"
      ],
      "size": 3
    },
    {
      "id": "NeOn-GPT",
      "label": "NeOn-GPT",
      "description": "A large language model-powered pipeline for ontology learning.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 2
    },
    {
      "id": "CASP",
      "label": "CASP",
      "description": "CASP是国际公认的世界级蛋白质结构预测权威竞赛，被誉为“蛋白质结构预测的奥林匹克竞赛”，D-I-TASSER在第15届比赛中获得两项第一。<SEP>CASP is an organization that issued press releases regarding AlphaFold 2's success.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8",
        "chunk-d23247c8edaf8929e7855d9186007c46"
      ],
      "size": 3
    },
    {
      "id": "Nankai Statistics",
      "label": "Nankai Statistics",
      "description": "An academic unit at Nankai University focusing on interdisciplinary biomedical research.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-95ce0b0b365782f95d313a054721a437"
      ],
      "size": 10
    },
    {
      "id": "指南面向CEO的生成式AI指南",
      "label": "指南面向CEO的生成式AI指南",
      "description": "A guide for CEOs on generative AI, focusing on balancing value, investment, and risk.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "人工智能时代",
      "label": "人工智能时代",
      "description": "人工智能时代是人类历史发展的一个阶段，算法在其中狂飙突进，引发了社会生活、伦理规范与思想意识等方面的诸多争议。<SEP>The Age of Artificial Intelligence is the contemporary era characterized by the development and impact of AI, serving as the central context for the philosophical discussion.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-1583b867ca44e12600f0775616185d52"
      ],
      "size": 5
    },
    {
      "id": "Add & Norm Layer",
      "label": "Add & Norm Layer",
      "description": "Add & Norm Layer combines a Residual Connection to prevent network degradation and Layer Normalization to normalize activation values in each layer.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 3
    },
    {
      "id": "Protein Design",
      "label": "Protein Design",
      "description": "Protein design is a field of bioinformatics and scientific research.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df"
      ],
      "size": 3
    },
    {
      "id": "红帽AI",
      "label": "红帽AI",
      "description": "红帽AI提供对第三方模型库的访问权限，这些模型经过验证，可以在其平台上高效运行。<SEP>Red Hat AI provides access to third-party model libraries that are verified to run efficiently on its platform, offering ready-made models for capacity planning scenarios.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4d514ef014c3cb4cb7fc652928e9a4a4",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "Rectified Linear Unit (ReLU)",
      "label": "Rectified Linear Unit (ReLU)",
      "description": "A transformation applied to the feature map after each convolution operation to introduce non-linearity into the CNN model.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0"
      ],
      "size": 2
    },
    {
      "id": "白皮書",
      "label": "白皮書",
      "description": "白皮書是Appier發布的一份文件，標題為「鎖定高價值應用程式使用者: 運用深度學習提高獲取新客的行銷成效」，提供關於深度學習在行銷應用的深入洞察。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1"
      ],
      "size": 3
    },
    {
      "id": "本研究",
      "label": "本研究",
      "description": "本研究系统地综述了深度神经网络在遥感关键任务中的应用，并分析了国内外研究现状与进展。",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-81494149ccc19d39342ca4e7f5dc4668"
      ],
      "size": 2
    },
    {
      "id": "GPT-4",
      "label": "GPT-4",
      "description": "GPT-4是一个预训练的大型语言模型，能够根据提示生成类人文本。<SEP>A closed-source Large Language Model noted for its outstanding performance by the end of 2024.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-4f9864ecff092ef091c227f6ebb2d69f"
      ],
      "size": 4
    },
    {
      "id": "数据管理",
      "label": "数据管理",
      "description": "数据管理涉及构建系统来管理数据，包括存储、清理和控制偏差，是实现AI目标的前提。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0"
      ],
      "size": 2
    },
    {
      "id": "Class Imbalance",
      "label": "Class Imbalance",
      "description": "A challenge in fraud detection where fraudulent transactions are significantly outnumbered by legitimate ones, complicating model training.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 3
    },
    {
      "id": "Andrej Karpathy",
      "label": "Andrej Karpathy",
      "description": "A person who created presentations and videos on GPT and LLMs, such as \"State of GPT\" and \"Deep Dive into LLMs like ChatGPT\".",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 3
    },
    {
      "id": "计算语言学",
      "label": "计算语言学",
      "description": "A scientific discipline that uses computers and software tools to understand and build models of human language.<SEP>计算语言学是基于规则的人类语言建模，是自然语言处理的一个组成部分。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-b572e7e95c9e5e07043de0b3cb587187",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "序列信息",
      "label": "序列信息",
      "description": "Sequence information refers to the amino acid sequence of the target protein, used as input to AlphaFold2.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "Federated Learning",
      "label": "Federated Learning",
      "description": "Federated Learning is a technology that protects data privacy and is important for collaboration among financial institutions.<SEP>A privacy-preserving machine learning technique that may facilitate collaboration between financial institutions by training models across decentralized data sources.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-2dc1c848682669d15114cbb84e3cd6b4",
        "chunk-d9ecda3ea425b03f3129938c0ba44219"
      ],
      "size": 2
    },
    {
      "id": "欺诈应用检测方法",
      "label": "欺诈应用检测方法",
      "description": "A detection method for fraudulent applications, specifically based on deep learning techniques.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-a6a52780a97b8eca9204ad8ed2f86840"
      ],
      "size": 4
    },
    {
      "id": "Gradient",
      "label": "Gradient",
      "description": "A gradient represents the partial derivative of a function with respect to its parameters, indicating the direction of steepest ascent.<SEP>Gradient refers to the derivative of a function, crucial for optimization algorithms like backpropagation in neural networks.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-22b82197e907c906b6de43d41ffe2efe",
        "chunk-8bed972d3227719ebad6c051fae785c9"
      ],
      "size": 4
    },
    {
      "id": "卷积操作",
      "label": "卷积操作",
      "description": "Convolution operation refers to the mathematical process of performing an inner product between image data (from different windows) and a convolution kernel (a set of fixed weights/filters), which gives the CNN its name.<SEP>卷积操作是卷积层中卷积核与输入图像进行的数学运算过程。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-61775650edeed94f49f7144412443478"
      ],
      "size": 3
    },
    {
      "id": "训练数据",
      "label": "训练数据",
      "description": "Training data is the information used to train deep learning models; if it contains statistical biases or does not accurately represent the population, the output may be flawed.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "Tanh",
      "label": "Tanh",
      "description": "Tanh is an activation function in neural networks, with its gradient being a key property for backpropagation.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-8bed972d3227719ebad6c051fae785c9"
      ],
      "size": 4
    },
    {
      "id": "全原子的位置坐标",
      "label": "全原子的位置坐标",
      "description": "Full atomic position coordinates are the 3D coordinates of all atoms in the predicted protein structure, output by AlphaFold2.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "梯度下降",
      "label": "梯度下降",
      "description": "梯度下降是一种优化算法，利用反向传播计算出的梯度来更新网络参数。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-95faa80d73b4394851b10e9cc65232d2"
      ],
      "size": 2
    },
    {
      "id": "Internal Data Science Laboratory",
      "label": "Internal Data Science Laboratory",
      "description": "A facility, akin to a supercomputer, developed under the HKMA's 'Digitalisation Programme' to handle massive computational tasks.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3"
      ],
      "size": 2
    },
    {
      "id": "非结构化文本数据",
      "label": "非结构化文本数据",
      "description": "非结构化文本数据是没有预定义格式的文本信息，如客户评论和社交媒体帖子。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "序列",
      "label": "序列",
      "description": "序列是需要被编码的数据形式，是深度学习中卷积神经网络或循环神经网络处理的对象。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8"
      ],
      "size": 3
    },
    {
      "id": "IPA (Invariant Point Attention)",
      "label": "IPA (Invariant Point Attention)",
      "description": "Invariant Point Attention is a key architecture within the Structure Module that achieves 3D equivariance.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "气候学",
      "label": "气候学",
      "description": "Climatology is the scientific field being combined with artificial intelligence for data analysis.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-4a38cf117c062d1c34ec79abbff9e244"
      ],
      "size": 3
    },
    {
      "id": "AI Agent风控模型",
      "label": "AI Agent风控模型",
      "description": "AI Agent风控模型是一种基于深度学习的实时欺诈检测算法实现。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-c00652dd3948d32546676fffc8064300"
      ],
      "size": 2
    },
    {
      "id": "State Of Gpt",
      "label": "State Of Gpt",
      "description": "A presentation by Andrej Karpathy that summarizes the training and application of GPT, highly recommended.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 2
    },
    {
      "id": "计算神经科学",
      "label": "计算神经科学",
      "description": "A field of study considered foundational for achieving world-class innovation in brain-inspired artificial intelligence.<SEP>计算神经科学是一个研究领域，旨在加深对其的理解。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-92f537cdcce6583c2c63c400d634feaf",
        "chunk-9ed0526c7eff8b1a424224e53050b149"
      ],
      "size": 3
    },
    {
      "id": "成本",
      "label": "成本",
      "description": "Cost refers to the financial expenditure associated with developing, training, deploying, and maintaining an AI model.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "无监督学习",
      "label": "无监督学习",
      "description": "无监督学习是一种机器学习方法，不依赖标记数据集，可以处理原始非结构化数据。<SEP>无监督学习是一种机器学习任务类型，自编码器是执行此类任务的结构。<SEP>Unsupervised learning is a machine learning paradigm where models find patterns in unlabeled data.<SEP>机器学习的一种范式。<SEP>Unsupervised Learning is a type of machine learning where models find patterns and structures in unlabeled data without predefined outputs.<SEP>Unsupervised learning is the process that guides LLMs, facilitated by the Transformer architecture and its parameters.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-e101b215c048456f8049a66e9ebd2c54",
        "chunk-80c468f42f64d269b4538a150a4f94cd",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 6
    },
    {
      "id": "SLM",
      "label": "SLM",
      "description": "SLM是小语言模型，是语言模型的一种类型，常与LLM进行对比。<SEP>SLM (Small Language Model) is contrasted with LLM (Large Language Model) in terms of language model comparison.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4d514ef014c3cb4cb7fc652928e9a4a4",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "Time Series Forecasting",
      "label": "Time Series Forecasting",
      "description": "Time series forecasting is a technique for predicting future values based on previously observed values, covered as a complex topic in the resource.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-201fcd200de194e722ae83a479174b8b"
      ],
      "size": 3
    },
    {
      "id": "Agent",
      "label": "Agent",
      "description": "An Agent in AI refers to an entity that perceives its environment and takes actions to achieve goals, often involving learning and planning.<SEP>智能体的英文表述，与工作流、大语言模型并列为驱动智能化从“辅助工具”向“自主系统”演进的三个核心支柱之一。<SEP>Agent是人工智能领域的一个概念。<SEP>A development paradigm for large model applications, mentioned as part of a learning path and the subject of an article.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 3
    },
    {
      "id": "ResNet",
      "label": "ResNet",
      "description": "Residual Network, a CNN architecture featuring skip connections that enable the training of very deep networks.<SEP>A common CNN architecture suitable for image tasks with varying complexity and performance requirements.<SEP>ResNet是一种卷积神经网络，解决了网络模型的退化问题，允许神经网络变得更深。<SEP>ResNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.",
      "domains": [
        "地球科学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 4
    },
    {
      "id": "深度神经网络",
      "label": "深度神经网络",
      "description": "Deep neural networks possess powerful learning and pattern recognition capabilities, offering new perspectives and tools for quantitative trading.<SEP>一种用于构建大语言模型的网络结构。<SEP>深度神经网络是一种用于处理遥感图像分类、目标检测、语义分割和变化检测等任务的人工智能方法。",
      "domains": [
        "地球科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-3678971988880bb3960a90e15878444d",
        "chunk-81494149ccc19d39342ca4e7f5dc4668"
      ],
      "size": 4
    },
    {
      "id": "Dataset",
      "label": "Dataset",
      "description": "A dataset with known answers is used to train a model to estimate optimal weights and bias.<SEP>A collection of 2,913,272 loan observation results from April 2019 to March 2022, used after excluding incomplete loan data.",
      "domains": [
        "计算机科学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3"
      ],
      "size": 4
    },
    {
      "id": "文本清理",
      "label": "文本清理",
      "description": "文本清理是删除标点符号、特殊字符和数字等不需要元素的步骤。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "Output Layer Variable",
      "label": "Output Layer Variable",
      "description": "The final output variable o in ℝ^q of the neural network model, produced by the output layer.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-75a5bc7ce82bf1f70e397344566d62eb"
      ],
      "size": 2
    },
    {
      "id": "Weight Matrix WQ",
      "label": "Weight Matrix WQ",
      "description": "A unique weight matrix used to generate the query vector (Q) from a token embedding.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 2
    },
    {
      "id": "Faster R-CNN",
      "label": "Faster R-CNN",
      "description": "Faster R-CNN is a two-stage object detection model known for its high accuracy, suitable for precise detection tasks such as medical imaging.<SEP>Faster R-CNN is a two-stage object detection model mentioned as an example for implementation in remote sensing image object detection tasks.",
      "domains": [
        "地球科学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 3
    },
    {
      "id": "词向量",
      "label": "词向量",
      "description": "词向量是将相似单词映射到向量空间中的概念，用于判断在同一上下文中的不同单词在语义上是否相近。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-5ec46d561fc83169cc4cb16171e4b90d"
      ],
      "size": 2
    },
    {
      "id": "PNAS",
      "label": "PNAS",
      "description": "PNAS is a high-level SCI journal where over 50 articles have been published.<SEP>PNAS是郑伟教授发表过文章的高水平SCI期刊之一。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8",
        "chunk-95ce0b0b365782f95d313a054721a437"
      ],
      "size": 3
    },
    {
      "id": "Supervised Learning",
      "label": "Supervised Learning",
      "description": "A machine learning paradigm where models are trained on labeled data.<SEP>A machine learning paradigm where models are trained on labeled data.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0724c887b70d220c530dcfaee28003c1",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 2
    },
    {
      "id": "循环神经网络",
      "label": "循环神经网络",
      "description": "通常用于处理一维序列结构任务(如音频、文本和时间序列分析)的神经网络。<SEP>循环神经网络是一种深度学习系统，具有与卷积神经网络不同的架构。<SEP>循环神经网络是一种常用于深度学习的神经网络架构，用于对序列等数据进行编码。<SEP>Recurrent Neural Networks (RNN) are a type of deep learning model effective at capturing complex nonlinear relationships and long-term dependencies in time series data.<SEP>循环神经网络是一种深度学习模型，应用于语音助手等领域。",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-37f0a7ef7d63be3d8878c173058865c3",
        "chunk-c79065b95e8586e85c1d4a6dfcdb5d37",
        "chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8",
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-6003c974467b7a903cb83abef6cc2e24"
      ],
      "size": 7
    },
    {
      "id": "数字偏见",
      "label": "数字偏见",
      "description": "数字偏见源于接触、使用和融合人工智能的机会与能力不均等，导致了“数字鸿沟”，构成了哲学研究公平性问题的新视域。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 2
    },
    {
      "id": "算法价值",
      "label": "算法价值",
      "description": "The value created by AI and its algorithms as a new type of production factor, currently still a product of human mental labor.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 3
    },
    {
      "id": "交易员",
      "label": "交易员",
      "description": "Traders who utilize GPU and deep learning technology on a high-intensity computing platform.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-858e73004375c211a45ff338fb81b219"
      ],
      "size": 3
    },
    {
      "id": "资金分配模型",
      "label": "资金分配模型",
      "description": "Traditional capital allocation models are responsible for optimizing investment portfolios in hybrid strategies that incorporate deep learning.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 2
    },
    {
      "id": "卷积层",
      "label": "卷积层",
      "description": "构成卷积神经网络主干的基本元素，是执行卷积操作的核心组件。<SEP>The convolutional layer is a fundamental component of a CNN that performs convolution operations to extract features from input data using filters.<SEP>卷积层是卷积神经网络的一部分，将输入图像与卷积核进行卷积操作以学习特征。<SEP>Convolutional layers are components of a CNN that perform convolution operations to extract local features from input data, such as images.<SEP>卷积层是卷积神经网络中的一个层组，使用预配置的筛选条件从输入数据中提取信息。<SEP>卷积层是卷积神经网络中的一种网络层，使用卷积核进行特征提取，通过局部连接和共享权重大幅减少模型参数。<SEP>卷积层是卷积神经网络中的一种层，用于提取输入数据的局部特征。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-37f0a7ef7d63be3d8878c173058865c3",
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-c79065b95e8586e85c1d4a6dfcdb5d37",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 7
    },
    {
      "id": "指南",
      "label": "指南",
      "description": "A guide is a type of content that helps AI reach its full potential and build trust in the new AI era.<SEP>The guide provides instructions on how to leverage generative AI to improve investment returns.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-0e8d4ef62e491849bee6335c81b740ee"
      ],
      "size": 2
    },
    {
      "id": "Deep Learning Model",
      "label": "Deep Learning Model",
      "description": "A complex AI model requiring large, high-quality datasets for training, facing challenges like data noise, overfitting, and lack of interpretability in financial applications.<SEP>Deep learning model is a type of model to which the Transformer belongs.",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-2dc1c848682669d15114cbb84e3cd6b4",
        "chunk-778f83860f7db1907e0da6e0cb412723"
      ],
      "size": 5
    },
    {
      "id": "文章",
      "label": "文章",
      "description": "文章中包含了复杂的数学方程来解释卷积神经网络的原理。<SEP>文章是书面作品，GPT-4等模型可以生成文章。",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 3
    },
    {
      "id": "输出",
      "label": "输出",
      "description": "Output refers to the results produced by the Structure Module of AlphaFold2.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "Distance Map信息",
      "label": "Distance Map信息",
      "description": "Distance map information contains pairwise distance constraints between residues, used as input to AlphaFold2.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "连接",
      "label": "连接",
      "description": "连接是神经网络中节点之间的通路，模拟生物神经网络的突触。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-61775650edeed94f49f7144412443478"
      ],
      "size": 2
    },
    {
      "id": "AIGC",
      "label": "AIGC",
      "description": "人工智能生成内容，是基于大模型技术演进的重要应用方向。<SEP>AIGC涉及到的领域和技术很广泛，其中自然语言处理是一项很重要的技术。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-6003c974467b7a903cb83abef6cc2e24"
      ],
      "size": 3
    },
    {
      "id": "Apple Siri",
      "label": "Apple Siri",
      "description": "Apple Siri是苹果公司开发的语音助手，是一个聊天机器人的例子。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "福岛邦彦",
      "label": "福岛邦彦",
      "description": "福岛邦彦是日本学者，受生物视觉系统研究启发，提出了层级化的人工神经网络“神经认知模型”，被认为是卷积神经网络的前身。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878"
      ],
      "size": 3
    },
    {
      "id": "梯度下降法",
      "label": "梯度下降法",
      "description": "Gradient Descent is an optimization method used in deep learning to minimize the error loss function by updating network parameters.<SEP>梯度下降法是一种通过计算损失函数梯度来迭代更新模型权重以最小化损失函数的优化算法。<SEP>梯度下降法是一种优化算法，利用反向传播计算得到的梯度来更新神经网络的参数，以使损失函数逐步减小。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-ecf37963c494ecfacb6a6432c237dd3b",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a"
      ],
      "size": 6
    },
    {
      "id": "深度学习架构",
      "label": "深度学习架构",
      "description": "Deep learning architectures are frameworks into which pre-trained text representations can be placed for different natural language processing tasks.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-747e06575d3f3c246eac89670d12c86e"
      ],
      "size": 2
    },
    {
      "id": "Transformers Library",
      "label": "Transformers Library",
      "description": "The Transformers library is adopted by many companies and researchers following the rise of large language models.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-07c6d2ca0b23fef78261afa6105b1fe0"
      ],
      "size": 3
    },
    {
      "id": "气候数据",
      "label": "气候数据",
      "description": "Climate data is voluminous and is being analyzed to discover new models and improve weather forecasting.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-4a38cf117c062d1c34ec79abbff9e244"
      ],
      "size": 2
    },
    {
      "id": "模型风险管理",
      "label": "模型风险管理",
      "description": "Model risk management (MRM) is a critical factor for enterprises, involving the management of risks arising from the use of models in financial services such as pricing, valuation, fraud detection, and anti-money laundering.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-2103a1c2471cc6226897b2080204b309"
      ],
      "size": 3
    },
    {
      "id": "Transformer",
      "label": "Transformer",
      "description": "A model architecture used for solving problems involving sequences, such as text or time-series data.<SEP>Transformer model is known for its powerful sequence processing and parallel computing capabilities, recently introduced into financial time series prediction.<SEP>Transformer is a type of deep learning model mentioned alongside LSTM for predicting future price trends or judging short-term directions.<SEP>Transformer is a deep learning model architecture consisting of Encoder blocks and Decoder blocks, used for sequence-to-sequence tasks.<SEP>Transformer is a model that utilizes attention mechanisms to improve training speed and is a deep learning model entirely based on self-attention mechanisms.<SEP>Transformer is a neural network architecture that transforms input sequences into output sequences by learning content and tracking relationships between sequence elements.<SEP>Transformer is a machine learning model architecture introduced in the paper \"Attention Is All You Need\".",
      "domains": [
        "计算机科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-eb903a35c2a682651dd2704f765bb4c6",
        "chunk-82bdb1406dfe17a400fa95a5a4727859",
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5",
        "chunk-778f83860f7db1907e0da6e0cb412723",
        "chunk-f11a177649a52b5177411e9ce9bb9885",
        "chunk-a6f32e4615a0137e965400eba7166c47"
      ],
      "size": 12
    },
    {
      "id": "前向传播",
      "label": "前向传播",
      "description": "前向传播指的是按顺序从输入层到输出层计算和存储神经网络中每层结果的过程。<SEP>前向传播是神经网络中的计算过程，输入数据通过网络层逐层传递，最终产生输出。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-3a728b359622810cd77efd2985a7fcfd",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a"
      ],
      "size": 3
    },
    {
      "id": "Weight Coefficient",
      "label": "Weight Coefficient",
      "description": "A numerical parameter in a neural network that is adjusted during training to minimize error.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070"
      ],
      "size": 2
    },
    {
      "id": "自监督学习方法",
      "label": "自监督学习方法",
      "description": "一种用于训练大语言模型的学习方法。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3678971988880bb3960a90e15878444d"
      ],
      "size": 2
    },
    {
      "id": "Artificial Neural Network",
      "label": "Artificial Neural Network",
      "description": "An artificial neural network is a computational system composed of interconnected artificial neurons, designed to simulate cognitive processes like thinking.<SEP>An artificial neural network is a system where the modification of connection strengths enables learning.<SEP>Artificial neural network is a computational model used by AlphaFold to learn the relationship between sequences and structures.<SEP>Computational models designed to simulate the way biological neural networks work, used for flood forecasting and rainfall-runoff modeling.",
      "domains": [
        "地球科学",
        "生物信息学",
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-90d06b6fbc58cfba3d096615baf2b706",
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c",
        "chunk-13f6a612ad21f33701d7916a1d76aa3e",
        "chunk-ed300ee31268ac8e853d58a7e20740f0"
      ],
      "size": 4
    },
    {
      "id": "Image Segmentation",
      "label": "Image Segmentation",
      "description": "Image Segmentation is the process of partitioning an image into multiple segments, with models like FCN, SegNet, and U-Net mentioned for remote sensing applications.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 2
    },
    {
      "id": "Pooling Layer",
      "label": "Pooling Layer",
      "description": "A layer in a CNN that helps reduce complexity, improve efficiency, and limit the risk of overfitting, although it involves losing some information.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0"
      ],
      "size": 3
    },
    {
      "id": "Deep Neural Network",
      "label": "Deep Neural Network",
      "description": "A deep neural network is a trained model used to predict protein properties from gene sequences.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-7d901977dd7e6d929821ca079c401c7e"
      ],
      "size": 3
    },
    {
      "id": "人工神经网络",
      "label": "人工神经网络",
      "description": "人工神经网络是深度学习的基础结构，包含输入层、输出层和多个隐藏层，用于转换数据和进行预测。<SEP>人工神经网络是一种模仿生物神经网络结构和功能的计算模型，是反向传播算法训练的对象。<SEP>人工神经网络是卷积神经网络的简称，是一种算法数学模型。<SEP>A computational model inspired by biological neural networks. It faced a decline from the 1990s to 2006 due to issues like getting stuck in local minima, but was revived with the advent of deep learning.<SEP>Artificial Neural Networks (ANN) are computing systems inspired by biological neural networks, serving as the foundational architecture for deep learning models.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-95faa80d73b4394851b10e9cc65232d2",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-c0eefe5184862c24ce2da501217562b3"
      ],
      "size": 6
    },
    {
      "id": "Torch.compile",
      "label": "Torch.compile",
      "description": "Torch.compile is a PyTorch feature that, when combined with Static KV-Cache, can optimize performance by enabling static allocation.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0222ac86b3d60100ac5d03d88a69654e"
      ],
      "size": 2
    },
    {
      "id": "Reinforcement Learning",
      "label": "Reinforcement Learning",
      "description": "Reinforcement learning is a machine learning paradigm where an agent learns to make decisions by interacting with an environment, mentioned as a method utilizing financial data.<SEP>A machine learning paradigm where an agent learns by interacting with an environment to maximize reward.<SEP>A type of machine learning where an agent learns by interacting with an environment.",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-201fcd200de194e722ae83a479174b8b",
        "chunk-0724c887b70d220c530dcfaee28003c1",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 3
    },
    {
      "id": "统计套利策略",
      "label": "统计套利策略",
      "description": "Statistical arbitrage strategies can be seamlessly combined with deep learning models as part of a composite trading strategy.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 2
    },
    {
      "id": "大模型",
      "label": "大模型",
      "description": "Large Models, particularly in natural language processing (e.g., GPT-3, BERT), are advanced machine learning models trained on massive datasets, demonstrating significant potential in complex tasks.<SEP>大模型是人工智能领域的一个概念，与深度学习结合用于模拟人类的语言理解过程。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-c0eefe5184862c24ce2da501217562b3"
      ],
      "size": 9
    },
    {
      "id": "Sequence Labeling",
      "label": "Sequence Labeling",
      "description": "A task involving two main components: defining a tag system and applying models like CRF or deep learning for prediction.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 3
    },
    {
      "id": "Convolution Layer",
      "label": "Convolution Layer",
      "description": "A layer in a CNN that performs the convolution operation on the input image using convolution kernels.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794"
      ],
      "size": 3
    },
    {
      "id": "Python",
      "label": "Python",
      "description": "Python is a programming language mentioned as being of interest to students in data-related fields.<SEP>A programming language used for writing programs to scrape data and perform basic analysis.<SEP>Python is the programming language used to write the Natural Language Toolkit (NLTK).",
      "domains": [
        "计算机科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-6bc1d4e50f0179dd98e01918a3be7977",
        "chunk-59b5b5bb9f78f0060c833f3b8b091e05"
      ],
      "size": 3
    },
    {
      "id": "真实数据",
      "label": "真实数据",
      "description": "用于仿真验证模型性能的实际业务数据。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-98217948cb9ad0bfdb25f3db0b7cd900"
      ],
      "size": 3
    },
    {
      "id": "Partial Derivative",
      "label": "Partial Derivative",
      "description": "Partial derivatives describe the linear relationship between changes in the output (`Δσ`) and changes in weights or bias (`Δw`, `Δb`).<SEP>A mathematical derivative of a function with respect to one variable while holding others constant, used in calculating error gradients.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070"
      ],
      "size": 3
    },
    {
      "id": "IBM watsonx.ai",
      "label": "IBM watsonx.ai",
      "description": "IBM watsonx.ai is an enterprise-grade development platform for building, training, validating, tuning, and deploying generative AI, foundation models, and machine learning capabilities.<SEP>IBM watsonx.ai is a next-generation enterprise-grade development platform for training, validating, tuning, and deploying generative AI, foundation models, and machine learning capabilities.<SEP>IBM watsonx.ai是IBM面向AI构建者的新一代企业级开发平台，用于训练、验证和调整AI模型。<SEP>An enterprise-grade development platform from IBM for training, validating, tuning, and deploying generative AI and foundation models.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-0e8d4ef62e491849bee6335c81b740ee",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-261214465e9e66011cd2c39022b3dc6b"
      ],
      "size": 7
    },
    {
      "id": "Activation Function",
      "label": "Activation Function",
      "description": "An element-wise function φ applied to the intermediate variable z to produce the hidden layer variable h.<SEP>A function applied to a neuron's total net input to produce its output, such as sigmoid.<SEP>A function (e.g., ReLU) applied to the output of a convolution layer to introduce non-linearity.<SEP>Activation functions like ReLU, Sigmoid, and Tanh introduce non-linearity into neural networks.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-75a5bc7ce82bf1f70e397344566d62eb",
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070",
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-8bed972d3227719ebad6c051fae785c9"
      ],
      "size": 8
    },
    {
      "id": "解码器",
      "label": "解码器",
      "description": "解码器是转换器模型架构中的一个组成部分，通常负责基于编码器的输出生成目标序列。<SEP>解码器是自动编码器的一部分，负责从编码表示中重建或生成数据。",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-0a82bdcf222bdb547252e178dfe4d622"
      ],
      "size": 3
    },
    {
      "id": "上下文特征",
      "label": "上下文特征",
      "description": "上下文特征是深度学习LSTM模型能够学习的特征，用于解决长距离语义依赖问题。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-432af570193bd3df6d564434ee8bfbbb"
      ],
      "size": 3
    },
    {
      "id": "数据",
      "label": "数据",
      "description": "数据是信息的表现形式，自然语言处理用于分析和处理非结构化文本数据。<SEP>数据是AI模型发展离不开的支持，通过对大量数据的分析和学习，AI模型能够不断提升自身的性能和准确性。<SEP>人工智能系统处理、分析和解释以模拟人类智能行为的信息集合。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 4
    },
    {
      "id": "Embedding",
      "label": "Embedding",
      "description": "A technique used at the word level, involving various embedding methods to transform words into vector representations for input to the next hierarchical level.<SEP>Embedding is the process of converting discrete tokens (like words) into continuous vector representations, serving as the input to the Transformer.<SEP>A process referenced in the TransformerEncoder's forward and call methods where input tokens are converted into vectors, which are then scaled before being combined with positional encoding.<SEP>A numerical representation of a token, which is processed and transformed within the model.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-330f64bec90f2f131895d2de62adeb6f",
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5",
        "chunk-ad8f11550a8a8807684e7ecc93a2a801",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 5
    },
    {
      "id": "天气现象预报方法",
      "label": "天气现象预报方法",
      "description": "一种结合深度学习和数值天气预报产品进行天气现象预测的方法。",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-506b50fbb39065edcc65dbbbc31a2bd7"
      ],
      "size": 2
    },
    {
      "id": "AlphaFold",
      "label": "AlphaFold",
      "description": "AlphaFold is a system for protein structure prediction developed by DeepMind, with an initial version that was later improved.<SEP>AlphaFold is a method that builds models using deep neural networks to predict protein properties from gene sequences.<SEP>AlphaFold is a method that uses artificial neural networks to directly learn the complex relationship between sequences and structures.<SEP>AlphaFold is a technology that combines deep learning with bioinformatics to analyze protein sequences and structures.<SEP>AlphaFold is a system for protein structure prediction, with its initial version being re-examined and improved upon by a team.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f",
        "chunk-7d901977dd7e6d929821ca079c401c7e",
        "chunk-13f6a612ad21f33701d7916a1d76aa3e",
        "chunk-5899806c994fc2f391826abc901a8669",
        "chunk-3692370e0fbe26ddf6ddebef5657ecc2"
      ],
      "size": 8
    },
    {
      "id": "Brex's Prompt Engineering Guide",
      "label": "Brex's Prompt Engineering Guide",
      "description": "An introductory guide to prompt engineering by Brex.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 2
    },
    {
      "id": "传统机器学习",
      "label": "传统机器学习",
      "description": "传统机器学习方法需要大量特征工程，定制化程度高，不同领域间模型迁移困难，但某些领域效果很好。<SEP>一种机器学习范式，其90%的时间会花在特征工程上。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 3
    },
    {
      "id": "RLHF",
      "label": "RLHF",
      "description": "Reinforcement Learning from Human Feedback is a technique that aligns machine learning models with human preferences.<SEP>Reinforcement Learning from Human Feedback, a method for aligning AI with human values.",
      "domains": [
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-80c468f42f64d269b4538a150a4f94cd",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 3
    },
    {
      "id": "用户数据",
      "label": "用户数据",
      "description": "本发明方法处理的核心数据对象，包括结构化数据和非结构化数据。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-ead8239d6c7d35f7d27952face0dd715"
      ],
      "size": 2
    },
    {
      "id": "Bias",
      "label": "Bias",
      "description": "Bias, denoted as `b`, is defined as the negative of the threshold and is a parameter adjusted during model training.<SEP>An additive constant in a neuron's calculation that allows the activation function to be shifted.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070"
      ],
      "size": 3
    },
    {
      "id": "Data Processing Procedure",
      "label": "Data Processing Procedure",
      "description": "A procedure that requires immense computational power, typically beyond the capability of a standard desktop computer, and can be completed in minutes using specialized infrastructure.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3"
      ],
      "size": 3
    },
    {
      "id": "Weight Matrix WK",
      "label": "Weight Matrix WK",
      "description": "A unique weight matrix used to generate the key vector (K) from a token embedding.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 2
    },
    {
      "id": "检索增强生成(RAG)",
      "label": "检索增强生成(RAG)",
      "description": "Retrieval-Augmented Generation (RAG) is an architecture that augments an LLM's knowledge base by integrating data from selected knowledge sources such as data warehouses, text collections, or existing documents.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 2
    },
    {
      "id": "Michael Nielsen",
      "label": "Michael Nielsen",
      "description": "Michael Nielsen is the author of the open-source textbook \"Neural Networks and Deep Learning\".<SEP>Michael Nielsen是《神经网络与深度学习》在线教科书的作者，在书中比较了反向传播算法与计算梯度的直观方法。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-072c6009a64360fcdc975b14582a2c8c"
      ],
      "size": 2
    },
    {
      "id": "感知器",
      "label": "感知器",
      "description": "感知器是神经网络单元的数学模型，接收多个输入并产生一个输出。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-61775650edeed94f49f7144412443478"
      ],
      "size": 2
    },
    {
      "id": "Error",
      "label": "Error",
      "description": "The difference between the predicted output and the target output in a neural network.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070"
      ],
      "size": 2
    },
    {
      "id": "耦合模式比对计划第六阶段",
      "label": "耦合模式比对计划第六阶段",
      "description": "The Coupled Model Intercomparison Project Phase 6 (CMIP6), a framework widely used in computational climate research for model comparison.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-b7e84880c36323dbbf1d92748718a1d1"
      ],
      "size": 2
    },
    {
      "id": "模型风险管理监管指南",
      "label": "模型风险管理监管指南",
      "description": "The Model Risk Management Supervisory Guidance, issued by the Federal Reserve and OCC, serves as a benchmark for MRM frameworks.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-2103a1c2471cc6226897b2080204b309"
      ],
      "size": 2
    },
    {
      "id": "自然語言處理",
      "label": "自然語言處理",
      "description": "Natural Language Processing (NLP) is a branch of deep learning used to extract information like market sentiment and industry trends from unstructured text data.<SEP>自然語言處理是一種建立在深度學習上的機制，用於理解上下文、進行情感分析，並提高消費者情感分析的精確度。",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-82bdb1406dfe17a400fa95a5a4727859",
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1"
      ],
      "size": 4
    },
    {
      "id": "深脑",
      "label": "深脑",
      "description": "Also known as DeepMind, a company created by systems neuroscientists. It was acquired by Google. The company combines deep learning with concepts from reinforcement learning in neuroscience.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c"
      ],
      "size": 4
    },
    {
      "id": "研究人员",
      "label": "研究人员",
      "description": "Researchers are attempting to integrate artificial intelligence with climatology.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-4a38cf117c062d1c34ec79abbff9e244"
      ],
      "size": 3
    },
    {
      "id": "人机回圈",
      "label": "人机回圈",
      "description": "Human-in-the-loop is a strategy crucial for key decisions, establishing clear accountability frameworks for LLM performance and impact from development to deployment.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "DeepMind",
      "label": "DeepMind",
      "description": "DeepMind is a company that developed the AlphaFold system for protein structure prediction.<SEP>DeepMind is an organization that issued press releases regarding AlphaFold 2's success.<SEP>DeepMind is the organization whose researchers described the properties predicted by the neural networks.<SEP>DeepMind is a company that developed the AlphaFold system and later improved it to create AlphaFold2.<SEP>DeepMind is the AI research lab that developed AlphaFold2 and presented slides at CASP14.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f",
        "chunk-d23247c8edaf8929e7855d9186007c46",
        "chunk-7d901977dd7e6d929821ca079c401c7e",
        "chunk-3692370e0fbe26ddf6ddebef5657ecc2",
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 6
    },
    {
      "id": "Chio et al.",
      "label": "Chio et al.",
      "description": "Researchers who in 2016 pioneered the use of RNN-based methods for heart failure prediction using EHR data.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-fe2c7c19ec682c0e709a26a55e0b8005"
      ],
      "size": 3
    },
    {
      "id": "单层CNN",
      "label": "单层CNN",
      "description": "单层卷积神经网络是一种结构简单的深度学习模型，使用几种卷积类型生成特征图并通过最大池化输出特征。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 3
    },
    {
      "id": "技术逻辑",
      "label": "技术逻辑",
      "description": "技术逻辑与哲学逻辑存在争锋，已嵌入人类社会发展的各个阶段，需要在人工智能时代与哲学逻辑实现动态平衡。<SEP>Technological logic refers to the operational framework of AI, which philosophical human thought must transcend to confirm the unique value of human thinking.<SEP>The logic of technology, which historically interacts with philosophical logic.<SEP>Technological logic is mentioned by Wang Tian as a force that should not dominate technological innovation in the development of AI's \"philosophy.\"",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-1583b867ca44e12600f0775616185d52",
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 3
    },
    {
      "id": "因子",
      "label": "因子",
      "description": "A factor, such as value, momentum, or low volatility, is a characteristic used to explain asset returns.<SEP>因子是用于量化模型分析的特征或变量，文中提到中低频因子数量少，而高频日内因子可达上百个。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-82bdb1406dfe17a400fa95a5a4727859",
        "chunk-0ff265f7709913907a277247870f20cc"
      ],
      "size": 3
    },
    {
      "id": "三方工程师",
      "label": "三方工程师",
      "description": "Three-party engineers who conducted simulation verification for the new deep learning fraud detection model using real data.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-98217948cb9ad0bfdb25f3db0b7cd900"
      ],
      "size": 4
    },
    {
      "id": "数据分析",
      "label": "数据分析",
      "description": "数据分析is the process of examining data to draw conclusions, supporting the performance improvement of AI models.<SEP>Data analysis is a language-related task that LLMs can help supplement or fully undertake, potentially automating it.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 4
    },
    {
      "id": "迁移学习",
      "label": "迁移学习",
      "description": "迁移学习是一种技术，通过重新调整预训练模型的最终层用途，来减少训练新模型所需的时间、数据和计算资源。<SEP>迁移学习是一种前沿技术，属于机器学习领域。",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-432af570193bd3df6d564434ee8bfbbb"
      ],
      "size": 3
    },
    {
      "id": "搜索引擎",
      "label": "搜索引擎",
      "description": "搜索引擎是用于在互联网上查找信息的工具，自然语言处理为其提供支持。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "神经网络与深度学习",
      "label": "神经网络与深度学习",
      "description": "《神经网络与深度学习》是Michael Nielsen撰写的一本在线教科书，其中讨论了反向传播算法的效率。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-072c6009a64360fcdc975b14582a2c8c"
      ],
      "size": 3
    },
    {
      "id": "3D Equivariant Structure Module",
      "label": "3D Equivariant Structure Module",
      "description": "The 3D Equivariant Structure Module is a component of AlphaFold2 that outputs atomic coordinates with rotational and translational invariance.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 9
    },
    {
      "id": "Generative Summarization",
      "label": "Generative Summarization",
      "description": "A difficult task where the training set requires human-written summaries for articles, making annotation more challenging than tasks like word segmentation or classification.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 3
    },
    {
      "id": "Alphafold模型架构",
      "label": "Alphafold模型架构",
      "description": "Chapter2 of the document provides a detailed explanation of the AlphaFold model architecture.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 2
    },
    {
      "id": "辩证法",
      "label": "辩证法",
      "description": "Dialectics is mentioned as part of the doctrine of the laws of the thinking process itself, alongside logic. It is a thinking method that is the methodological premise of scientific thinking and can absorb and elevate modern scientific thinking methods.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 2
    },
    {
      "id": "GPT",
      "label": "GPT",
      "description": "GPT is a large-scale language model whose rise has increased adoption of the Transformers library.<SEP>一种大型语言模型，在大量文本数据集上训练得到，具备理解和生成人类语言的能力，并能演变为进行多模态通信、推理、规划以及解决问题的综合性系统。<SEP>GPT是大语言模型的一种具体实现。<SEP>A common example of a Large Language Model.<SEP>A language model known as Generative Pre-trained Transformer.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-07c6d2ca0b23fef78261afa6105b1fe0",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-4f9864ecff092ef091c227f6ebb2d69f",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 4
    },
    {
      "id": "图",
      "label": "图",
      "description": "A graph constructed based on the structural data to represent relationships.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-a6a52780a97b8eca9204ad8ed2f86840"
      ],
      "size": 2
    },
    {
      "id": "北半球大气阻塞事件",
      "label": "北半球大气阻塞事件",
      "description": "Atmospheric blocking events in the Northern Hemisphere that can lead to extreme weather, which DLESyM captures accurately.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-b7e84880c36323dbbf1d92748718a1d1"
      ],
      "size": 2
    },
    {
      "id": "Remote Sensing Image",
      "label": "Remote Sensing Image",
      "description": "Remote Sensing Images are data used in applications like mineral exploration, precision agriculture, urban planning, and disaster monitoring, and are processed using deep learning techniques.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 2
    },
    {
      "id": "Transformers",
      "label": "Transformers",
      "description": "A deep learning model architecture that relies on self-attention mechanisms, foundational for modern NLP.<SEP>Transformers is an NLP package developed by Hugging Face for loading most pre-trained models.",
      "domains": [
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-07c6d2ca0b23fef78261afa6105b1fe0"
      ],
      "size": 3
    },
    {
      "id": "Convolutional Layer",
      "label": "Convolutional Layer",
      "description": "The core building block of a CNN, responsible for performing most of the computations. It involves components like input data, filters, and feature maps, and performs the convolution operation by moving a filter across the receptive fields of an image.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0"
      ],
      "size": 5
    },
    {
      "id": "基础模型",
      "label": "基础模型",
      "description": "Foundation models are a type of AI model that can be deployed using platforms like IBM watsonx.ai.<SEP>Foundation models, large AI models trained on broad data that can be adapted to a wide range of tasks.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "数据安全性",
      "label": "数据安全性",
      "description": "数据安全性涉及大数据技术对个人隐私信息的全息记录与潜在泄露风险，是人工智能带来的社会困境之一，需要哲学反思和监管。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 2
    },
    {
      "id": "技术指标",
      "label": "技术指标",
      "description": "Technical indicators, such as moving averages and RSI, are examples of features traditionally engineered manually for quantitative trading strategies.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 2
    },
    {
      "id": "算法",
      "label": "算法",
      "description": "算法是用于蛋白质结构预测的常用计算工具。<SEP>人工智能系统用来从数据中学习并做出智能决策的计算过程或规则集。<SEP>算法是人类智慧的集体体现，以精确化、数字化、组织化的方式实现对当代社会的整体建构，拓展了人类文明发展的可能空间。<SEP>A tool that shapes inequality gaps and is a key instrument of AI technology.",
      "domains": [
        "哲学",
        "生物信息学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-c5eafae240ac5d07dadf7c4eb744e8eb",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-1583b867ca44e12600f0775616185d52",
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 6
    },
    {
      "id": "Talking Nets",
      "label": "Talking Nets",
      "description": "\"Talking Nets\" is a book published by MIT Press in 1998, authored by James Anderson and Edward Rosenfeld.<SEP>A 1998 MIT Press book by James Anderson and Edward Rosenfeld containing interview records, including those with Lettvin and Hinton, which are sources of information about Pitts and Hinton.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837"
      ],
      "size": 5
    },
    {
      "id": "Test Set",
      "label": "Test Set",
      "description": "A subset of the dataset, constituting 20% (582,655 observations) of the total data, used to evaluate the performance of the fully trained model.<SEP>A test set comprising 25% of the data was used to evaluate the Deep Auto-Encoder model in Experiment Two.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3",
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 4
    },
    {
      "id": "编码器",
      "label": "编码器",
      "description": "编码器是转换器模型架构中的一个组成部分，负责接收输入序列并将其转换为内部表示。<SEP>编码器是自动编码器的一部分，负责将输入数据转换为一种编码表示。",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-0a82bdcf222bdb547252e178dfe4d622"
      ],
      "size": 3
    },
    {
      "id": "Nature",
      "label": "Nature",
      "description": "Nature is a scientific journal that published the 2015 review article \"Deep learning\".<SEP>Nature is a specialist science press publication that covered the story of AlphaFold 2's success.<SEP>Nature is a weekly journal where the paper detailing AlphaFold2 was published online on July 15, 2021.<SEP>Nature is a scientific journal that published the 2020 and 2021 papers on AlphaFold2.",
      "domains": [
        "生物信息学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-e7712ad4739a66b6cf3b8376df6a6837",
        "chunk-d23247c8edaf8929e7855d9186007c46",
        "chunk-3692370e0fbe26ddf6ddebef5657ecc2",
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 5
    },
    {
      "id": "Nankai University",
      "label": "Nankai University",
      "description": "The university associated with Nankai Statistics and the news center.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-95ce0b0b365782f95d313a054721a437"
      ],
      "size": 2
    },
    {
      "id": "CAJ文档",
      "label": "CAJ文档",
      "description": "CAJ documents are a specific file format mentioned as containing research papers on CNN training, requiring a special tool to open.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-cb9ff55215bc8081de2f351af1fd25fe"
      ],
      "size": 2
    },
    {
      "id": "前馈神经网络",
      "label": "前馈神经网络",
      "description": "Feedforward Neural Networks, a type of artificial neural network where connections between nodes do not form cycles.<SEP>前馈神经网络是一种神经网络架构，其中连接不形成循环，信息单向向前传播。<SEP>前馈神经网络是一种有监督学习方法。<SEP>前馈神经网络是一种神经网络架构，多层感知机是其中的一种。",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-c79b805e7da972f5a80b0f9eb1144d75",
        "chunk-df57bc33c49fe522c66616c1a4be5336",
        "chunk-0c8c61555719c99f2248173e3fd5ae4f",
        "chunk-93860b80c6ea559ea9b38a8562c8df8c"
      ],
      "size": 4
    },
    {
      "id": "AI黑话揭秘",
      "label": "AI黑话揭秘",
      "description": "AI黑话揭秘是一篇旨在解释人工智能相关概念之间关系的文章。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-d59c5769fc2d8973bb797259108a6319"
      ],
      "size": 7
    },
    {
      "id": "哲学史",
      "label": "哲学史",
      "description": "哲学史是哲学研究依赖的长期积累过程，涉及哲学家与时代、思想发展史的“历时态”和“共时态”对话。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 3
    },
    {
      "id": "DOC_ID: chunk-6db04701",
      "label": "DOC_ID: chunk-6db04701",
      "description": "DOC_ID: chunk-6db04701 is a unique identifier for the document chunk being processed.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-a6f32e4615a0137e965400eba7166c47"
      ],
      "size": 2
    },
    {
      "id": "最佳模型",
      "label": "最佳模型",
      "description": "The best model refers to the optimal AI model selected after balancing various factors like performance, cost, and requirements.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 6
    },
    {
      "id": "Learning",
      "label": "Learning",
      "description": "Learning is recognized as important for both biological and computer behavior, with its basis in modifiable synapses.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c"
      ],
      "size": 3
    },
    {
      "id": "Traditional Fraud Detection Systems",
      "label": "Traditional Fraud Detection Systems",
      "description": "Traditional fraud detection systems are existing methods that face challenges like concept drift, class imbalance, and verification latency in identifying fraudulent activities.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 5
    },
    {
      "id": "From Deep Learning to Rational Machines",
      "label": "From Deep Learning to Rational Machines",
      "description": "\"From Deep Learning to Rational Machines\" is a book that discusses the philosophical implications of deep learning.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-520def31c8675778cae230b17d8f6b02"
      ],
      "size": 2
    },
    {
      "id": "财务分析",
      "label": "财务分析",
      "description": "Financial analysis, traditionally done manually by analysts but now accelerated through quantitative data analysis.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 2
    },
    {
      "id": "人",
      "label": "人",
      "description": "The subject of an ancient philosophical question about the basis of being human, whose uniqueness and irreplaceability need redefinition under the impact of AI.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 2
    },
    {
      "id": "目标函数",
      "label": "目标函数",
      "description": "目标函数是模型优化过程中需要最小化的函数，通常包括损失项和正则化项。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-3a728b359622810cd77efd2985a7fcfd"
      ],
      "size": 3
    },
    {
      "id": "梯度",
      "label": "梯度",
      "description": "梯度是反向传播方法计算的目标，用于指导模型参数的更新。<SEP>梯度是函数在某一点上变化率最大的方向，在深度学习中用于参数优化。<SEP>梯度是损失函数对网络参数的偏导数，在反向传播算法中用于更新权重和偏置。<SEP>梯度是损失函数相对于网络参数的偏导数向量，指示了参数调整的方向和幅度。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9fcf6610f361d14578f6d58fe5b5ea26",
        "chunk-3a728b359622810cd77efd2985a7fcfd",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a",
        "chunk-95faa80d73b4394851b10e9cc65232d2"
      ],
      "size": 5
    },
    {
      "id": "互联网时代",
      "label": "互联网时代",
      "description": "互联网时代是上个世纪末开始的时期，其特征是大量数据的电子化，为深度学习的发展提供了数据基础。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade"
      ],
      "size": 2
    },
    {
      "id": "Scikit-learn",
      "label": "Scikit-learn",
      "description": "A machine learning library whose algorithms were compared against the proposed deep learning methods using metrics like AUC score and confusion matrix.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 2
    },
    {
      "id": "Azure机器学习",
      "label": "Azure机器学习",
      "description": "Azure机器学习是微软提供的一个云平台，用于构建、训练和部署机器学习与深度学习模型。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4"
      ],
      "size": 3
    },
    {
      "id": "机器学习",
      "label": "机器学习",
      "description": "机器学习是人工智能（AI）的一个核心子集与实现路径，也是一种数据分析方法和方法论。其核心思想是让计算机系统能够从数据中“学习”经验并改进性能，而无需进行明确的编程。机器学习专注于设计算法，使计算机能够通过分析数据来自我学习，自动构建分析模型，识别模式，从而优化任务执行能力、做出预测或决策，例如最小化预测错误。\n\n该领域包含多种技术，其中深度学习是其一个重要分支。机器学习的应用范围极为广泛，包括但不限于商业领域的个性化产品推荐系统、科学研究的蛋白质结构预测、金融领域的量化交易（其算法在中低频和高频交易场景中均有应用，且在高频环境下可能更具优势），以及自然语言处理。它也被应用于模型风险管理，特别是在模型验证和实时模型监控阶段。此外，机器学习为脑科学研究提供了处理数据的新方法和模拟脑功能的新思路。\n\n作为一门成熟的学科，其基础知识已在多所高等学府的相关课程中被系统介绍。<SEP>A method used for weather prediction and climate simulation, noted for being faster and more energy-efficient than traditional models.",
      "domains": [
        "地球科学",
        "生物信息学",
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-92f537cdcce6583c2c63c400d634feaf",
        "chunk-c5eafae240ac5d07dadf7c4eb744e8eb",
        "chunk-dcad4a5abb7347f0e6403bab97eb576b",
        "chunk-0ff265f7709913907a277247870f20cc",
        "chunk-6bc1d4e50f0179dd98e01918a3be7977",
        "chunk-2103a1c2471cc6226897b2080204b309",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771",
        "chunk-b7e84880c36323dbbf1d92748718a1d1"
      ],
      "size": 25
    },
    {
      "id": "人工智能",
      "label": "人工智能",
      "description": "人工智能（Artificial Intelligence，简称AI）是一个广泛的科学领域与研究学科，其核心目标是创建能够模拟、延伸和扩展人类智能与认知功能的机器或软件系统，使其能够执行通常需要人类智能才能完成的任务。该领域旨在使计算机具备解决复杂问题的能力，例如推理、学习、问题解决、理解语言、面部识别、决策制定和语言翻译等。\n\n从研究本质上看，人工智能致力于探索如何使机器模拟人类的思维和意识，一些观点进一步将其与对生命智能的研究联系起来。它是一个内容丰富的综合性领域，整合了多种关键技术和方法，其中包括机器学习、深度学习（被视为其核心技术之一）以及卷积神经网络等。预测性人工智能和自然语言处理都是其重要的组成部分或子领域。\n\n人工智能的发展范式正从专注于特定任务的“狭义AI”向具备广泛能力的“通用AI”迈进。作为一个技术科学，其研究和应用范围不断扩展，例如有研究者正将其与气候学等领域相结合。总体而言，人工智能是一门专注于开发能展现智能行为、执行智能任务的人造系统的技术科学。<SEP>人工智能是一种技术，其迅猛发展对传统哲学的主体概念、社会安全性和哲学研究视域构成了多重挑战。<SEP>Artificial Intelligence, especially large language models and deep learning algorithms, presents challenges to philosophical research by affecting information processing and human thought patterns.<SEP>Artificial intelligence, whose development and application must consider social conditions and ensure it serves humanity, according to Wang Tian. It carries multiple values like ethics and culture.<SEP>A technology that is widely applied and is reshaping the era, prompting philosophical reflection.",
      "domains": [
        "哲学",
        "地球科学",
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-b572e7e95c9e5e07043de0b3cb587187",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771",
        "chunk-4a38cf117c062d1c34ec79abbff9e244",
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd",
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-47b980b33218327b53ee86797118fbb8",
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 38
    },
    {
      "id": "强化学习",
      "label": "强化学习",
      "description": "Reinforcement learning is a machine learning paradigm where an agent learns by interacting with an environment to maximize cumulative reward.<SEP>A concept from neuroscience integrated with deep learning by DeepMind. It was used to create AlphaGo.<SEP>强化学习是机器学习的一种范式，智能体通过与环境互动并基于奖励信号来学习采取行动。<SEP>强化学习是一种前沿技术，属于机器学习领域。<SEP>Reinforcement Learning is a type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties from the environment.",
      "domains": [
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-80c468f42f64d269b4538a150a4f94cd",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-432af570193bd3df6d564434ee8bfbbb",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-c0eefe5184862c24ce2da501217562b3"
      ],
      "size": 6
    },
    {
      "id": "线性模型",
      "label": "线性模型",
      "description": "线性模型是传统的量化建模方法，文中指出在中低频量化中，其表现优于尝试过的各种机器学习模型。<SEP>A branch of machine learning suitable for small-sample, low-frequency data.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-0ff265f7709913907a277247870f20cc",
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 4
    },
    {
      "id": "Training Phase",
      "label": "Training Phase",
      "description": "The phase where a machine learning algorithm randomly selects observations from a 'training set', builds a model to explain the output, and evaluates the model's performance with another batch of randomly selected data.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3"
      ],
      "size": 2
    },
    {
      "id": "学习率",
      "label": "学习率",
      "description": "学习率是梯度下降法中的一个超参数，用于控制权重更新的步长，通常是一个介于0和1之间的小数。<SEP>学习率是优化器SGD的一个参数，在示例中被设置为0.1。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878"
      ],
      "size": 3
    },
    {
      "id": "杨媛",
      "label": "杨媛",
      "description": "杨媛是华南师范大学马克思主义学院的学者，是论文《深度学习的技术路径与哲学审视》的作者。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 4
    },
    {
      "id": "Doctor of Philosophy",
      "label": "Doctor of Philosophy",
      "description": "Doctor of Philosophy is the highest academic degree, mentioned as a reason for the connection between science and art.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a815fcba7c08869c15a406f42f940fb2"
      ],
      "size": 2
    },
    {
      "id": "Fraud Detection",
      "label": "Fraud Detection",
      "description": "Fraud detection is the process of identifying fraudulent activities.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-ac1ed9e88e425ab885199259d92315e5"
      ],
      "size": 4
    },
    {
      "id": "人类偏见",
      "label": "人类偏见",
      "description": "Human bias is an existing prejudice that can be transferred to AI systems, risking discriminatory algorithms and biased outputs.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 2
    },
    {
      "id": "Computer Vision",
      "label": "Computer Vision",
      "description": "A field of computer science where Convolutional Neural Networks have achieved significant success.<SEP>A field of artificial intelligence (AI) that enables computers and systems to derive meaningful information from digital images, videos, and other visual inputs, and to take actions based on those inputs.<SEP>A research direction applied in biomedicine by Nankai Statistics.",
      "domains": [
        "生物信息学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-95ce0b0b365782f95d313a054721a437"
      ],
      "size": 5
    },
    {
      "id": "Zero-Padding",
      "label": "Zero-Padding",
      "description": "A technique of adding circles of zeros around the edges of an input image to facilitate convolution.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794"
      ],
      "size": 2
    },
    {
      "id": "MNIST模型",
      "label": "MNIST模型",
      "description": "MNIST模型是一个用于图像分类任务的卷积神经网络示例，其数据集已集成在主流框架中。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878"
      ],
      "size": 3
    },
    {
      "id": "大型语言模型",
      "label": "大型语言模型",
      "description": "大型语言模型是基于大量文本数据训练的语言模型，具有强大的交流技巧。<SEP>Large Language Models are a type of AI technology mentioned as part of the widespread application of AI that challenges philosophical research practices.",
      "domains": [
        "哲学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-dd306af31a739643f5fdb50f2073ec63"
      ],
      "size": 3
    },
    {
      "id": "Image Comparison Algorithm",
      "label": "Image Comparison Algorithm",
      "description": "An image comparison algorithm acts as a perceptron to analyze input like photos and produce a probability-based result.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917"
      ],
      "size": 2
    },
    {
      "id": "天善智能",
      "label": "天善智能",
      "description": "Tianshan Intelligence is a vertical community focused on business intelligence (BI), artificial intelligence (AI), big data analysis, and data mining, providing learning, Q&A, and job-seeking services.<SEP>Tianshan Intelligence is an organization focused on business intelligence (BI), artificial intelligence (AI), and big data analysis, mentioned as the publisher of a detailed explanation on CNN principles.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-cb9ff55215bc8081de2f351af1fd25fe"
      ],
      "size": 2
    },
    {
      "id": "模型",
      "label": "模型",
      "description": "Refers to mathematical or statistical models used in quantitative finance and machine learning.<SEP>用来帮助我们更好地理解和预测所描述对象的简化“影子”或“替身”，可以是实体的或虚拟的，是人工智能系统的核心。",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-6bc1d4e50f0179dd98e01918a3be7977",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3"
      ],
      "size": 4
    },
    {
      "id": "Self-Attention Mechanism",
      "label": "Self-Attention Mechanism",
      "description": "Self-attention mechanism is the core component upon which the Transformer model is completely built.<SEP>The core functionality of the transformer model, enabling it to detect relationships or dependencies between different parts of an input sequence.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-778f83860f7db1907e0da6e0cb412723",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 4
    },
    {
      "id": "特征工程",
      "label": "特征工程",
      "description": "Feature engineering is the traditional, manual process of selecting and designing predictive indicators, which is simplified by deep learning's automatic feature extraction.<SEP>传统机器学习中花费大量时间的过程，涉及根据TF-IDF、互信息、信息增益等方式计算特征值或对特征进行过滤排序。<SEP>特征工程是传统机器学习中的关键步骤，涉及从原始数据中手动创建、选择和转换特征，通常耗时很长。",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de"
      ],
      "size": 5
    },
    {
      "id": "IBM业界领先的AI专业知识和解决方案组合",
      "label": "IBM业界领先的AI专业知识和解决方案组合",
      "description": "IBM's industry-leading AI expertise and solution portfolio enables AI to function effectively within a business.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19"
      ],
      "size": 3
    },
    {
      "id": "Deep Learning",
      "label": "Deep Learning",
      "description": "深度学习是机器学习的一个子领域，它基于人工神经网络，特别是利用具有多层的神经网络来学习数据的表征。作为一种方法，它能够克服传统模型（如条件随机场在捕捉长距离上下文方面的局限性）的缺点。深度学习在多个具体应用领域中展现出强大的能力：在计算机视觉领域，它用于图像识别、对象检测和图像分割；在语音处理领域，它用于语音识别；在生物科学领域，它支撑了如AlphaFold这样的突破性工具；在金融领域，它被应用于量化交易和公司债券信用风险评估，以提高欺诈检测的准确性、实现实时检测并减少误报；在遥感领域，它用于提取卫星遥感图像的全局特征以进行检索和定位，并完成对象检测、模型优化等任务；在气象与气候科学领域，它被用于开发天气和气候预测技术。该领域的发展与关键研究人员如Yann LeCun、Yoshua Bengio和Geoffrey Hinton的贡献密不可分。<SEP>A subset of machine learning involving neural networks with multiple layers, used here for meteorological forecasting.<SEP>A subset of machine learning methods based on artificial neural networks.<SEP>Deep learning is a field of artificial intelligence that has fundamentally changed since around 2015.",
      "domains": [
        "哲学",
        "地球科学",
        "生物信息学",
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-c79b805e7da972f5a80b0f9eb1144d75",
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837",
        "chunk-5899806c994fc2f391826abc901a8669",
        "chunk-d9ecda3ea425b03f3129938c0ba44219",
        "chunk-2dc1c848682669d15114cbb84e3cd6b4",
        "chunk-6d22dc080f5fd339b89bf3f7732fc258",
        "chunk-fe2c7c19ec682c0e709a26a55e0b8005",
        "chunk-ac1ed9e88e425ab885199259d92315e5",
        "chunk-330f64bec90f2f131895d2de62adeb6f",
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81",
        "chunk-fb89c8462c112775ff8e6c43e7d050e8",
        "chunk-b80301dc089946e283419441a33451d1",
        "chunk-babf4b9b036bdc4286b6ed4dc016cba8",
        "chunk-ed300ee31268ac8e853d58a7e20740f0",
        "chunk-333ff749c2940b520a06027eb3c17eac",
        "chunk-520def31c8675778cae230b17d8f6b02"
      ],
      "size": 33
    },
    {
      "id": "GBDT→GRU→RF三明治结构",
      "label": "GBDT→GRU→RF三明治结构",
      "description": "一种结合了梯度提升决策树、门控循环单元和随机森林的复合模型结构，用于欺诈侦测。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-98217948cb9ad0bfdb25f3db0b7cd900"
      ],
      "size": 3
    },
    {
      "id": "特征图",
      "label": "特征图",
      "description": "特征图是卷积运算得到的结果，其上的每个点由上一层若干个点共同决定，点的集合范围称为感受野。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 2
    },
    {
      "id": "AI构建器",
      "label": "AI构建器",
      "description": "AI builders are individuals who use enterprise-grade development platforms like IBM watsonx.ai to create AI solutions.<SEP>AI builders are skilled personnel who can construct and deliver innovative new solutions.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-0e8d4ef62e491849bee6335c81b740ee"
      ],
      "size": 3
    },
    {
      "id": "经典因子模型",
      "label": "经典因子模型",
      "description": "Classical factor models, such as value and momentum factors, can be seamlessly integrated with deep learning models to form composite trading strategies.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 2
    },
    {
      "id": "Neuron",
      "label": "Neuron",
      "description": "A basic computational unit in a neural network that receives inputs, processes them, and produces an output.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070"
      ],
      "size": 3
    },
    {
      "id": "GDPR",
      "label": "GDPR",
      "description": "GDPR is a data privacy law that organizations must comply with when deploying AI systems.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "正向传播",
      "label": "正向传播",
      "description": "正向传播是神经网络中从输入层到输出层计算并存储各层变量当前值的过程。<SEP>正向传播是神经网络中计算输出y=f(x)的过程，其导数用于后续的反向传播。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-29234d7a518b3ee30e3ee9cbc39d7e68",
        "chunk-7844fb38c827827af06d614fe4afb4df"
      ],
      "size": 3
    },
    {
      "id": "输入层",
      "label": "输入层",
      "description": "输入层是神经网络中反向传播计算误差的终点。<SEP>输入层是神经网络接收原始数据输入的层。<SEP>输入层是卷积神经网络的一部分，负责接收原始图像数据，通常由三个颜色通道组成一个二维矩阵。<SEP>输入层是卷积神经网络结构的一部分，用于接收文字、语音、图像、视频等各种数字化信号。<SEP>输入层是多层感知机网络结构中的一层。",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-9fcf6610f361d14578f6d58fe5b5ea26",
        "chunk-29234d7a518b3ee30e3ee9cbc39d7e68",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922",
        "chunk-93860b80c6ea559ea9b38a8562c8df8c"
      ],
      "size": 4
    },
    {
      "id": "NLP预处理",
      "label": "NLP预处理",
      "description": "NLP预处理是将原始文本准备好以供程序或机器学习模型分析的过程，旨在将文本转换成深度学习模型更容易分析的格式。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-38b1076024c94a070f64f72dcaea1102"
      ],
      "size": 4
    },
    {
      "id": "Encoder-Decoder Architecture",
      "label": "Encoder-Decoder Architecture",
      "description": "An architecture used in AI models, particularly for sequence-to-sequence tasks like machine translation.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-261214465e9e66011cd2c39022b3dc6b"
      ],
      "size": 3
    },
    {
      "id": "Sigmoid Function",
      "label": "Sigmoid Function",
      "description": "The sigmoid function, σ(z) = 1 / (1 + e^(-z)), transforms the perceptron's output into a continuous function between 0 and 1.<SEP>A specific activation function that maps any input value to a value between 0 and 1.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070"
      ],
      "size": 4
    },
    {
      "id": "深度学习技术",
      "label": "深度学习技术",
      "description": "深度学习技术是一种用于增强基因组数据分析准确性和处理能力的人工智能方法。<SEP>Deep learning technology employed by traders for data exploration, model development, scoring, and consumption.<SEP>Deep learning technology is a method that has achieved breakthroughs in the field of image processing.",
      "domains": [
        "地球科学",
        "生物信息学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-8ac6b800c024bfc59d45d5769abdcb86",
        "chunk-858e73004375c211a45ff338fb81b219",
        "chunk-70cc6b4326bedb7c4b61745cce643075"
      ],
      "size": 3
    },
    {
      "id": "转换器",
      "label": "转换器",
      "description": "转换器是一种用于处理序列问题(如文本或时序数据)的模型架构，包含编码器层和解码器层。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4"
      ],
      "size": 4
    },
    {
      "id": "深度学习欺诈侦测模型",
      "label": "深度学习欺诈侦测模型",
      "description": "一种用于检测欺诈行为的深度学习模型，针对银行和保险业务中的伪卡欺诈和骗保检测等场景。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-98217948cb9ad0bfdb25f3db0b7cd900"
      ],
      "size": 5
    },
    {
      "id": "遥感图像分类",
      "label": "遥感图像分类",
      "description": "遥感图像分类是利用算法对遥感图像中的地物进行识别和归类的关键任务。",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-81494149ccc19d39342ca4e7f5dc4668"
      ],
      "size": 2
    },
    {
      "id": "BP算法",
      "label": "BP算法",
      "description": "BP算法是一种用于训练神经网络的算法，主要用于通过链式求导法则计算网络中每个参数对于损失函数的梯度，从而通过梯度下降法更新网络参数。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a"
      ],
      "size": 3
    },
    {
      "id": "Natural Language Toolkit",
      "label": "Natural Language Toolkit",
      "description": "Natural Language Toolkit (NLTK) is a suite of libraries and programs written in Python for English, supporting tasks like text classification, tokenization, stemming, tagging, parsing, and semantic reasoning.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-59b5b5bb9f78f0060c833f3b8b091e05"
      ],
      "size": 3
    },
    {
      "id": "Token",
      "label": "Token",
      "description": "The smallest linguistic unit used by AI models, assigned an ID number, which facilitates efficient text processing by reducing computational requirements.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 4
    },
    {
      "id": "Narrator",
      "label": "Narrator",
      "description": "The narrator is the individual recounting their learning journey, who relearned the concepts of weight and threshold and encountered various resources like Neural Networks and Deep Learning.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-90d06b6fbc58cfba3d096615baf2b706"
      ],
      "size": 3
    },
    {
      "id": "客户支持",
      "label": "客户支持",
      "description": "客户支持是企业为客户提供的帮助服务，自然语言处理可以自动化部分任务。<SEP>Customer support is a language-related task that LLMs can help supplement or fully undertake, potentially automating it.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "Image",
      "label": "Image",
      "description": "Represented in a computer as a sequence of numbers from 0 to 255, with 0 being darkest and 255 brightest.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794"
      ],
      "size": 3
    },
    {
      "id": "Nature Communications",
      "label": "Nature Communications",
      "description": "Nature Communications is a high-level SCI journal where over 50 articles have been published.<SEP>Nature Communications是郑伟教授发表过文章的高水平SCI期刊之一。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8",
        "chunk-95ce0b0b365782f95d313a054721a437"
      ],
      "size": 3
    },
    {
      "id": "学习范式",
      "label": "学习范式",
      "description": "学习范式是深度学习的一个方面，本文从哲学角度对其进行了深入讨论。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 2
    },
    {
      "id": "高频量化",
      "label": "高频量化",
      "description": "高频量化是作者近两年转向的量化交易策略，特指日内的T0交易，文中指出机器学习在此场景下展现了较大优势。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-0ff265f7709913907a277247870f20cc"
      ],
      "size": 5
    },
    {
      "id": "Christian Ideology",
      "label": "Christian Ideology",
      "description": "Christian ideology is a belief system that Hinton considered to be \"complete rubbish\" during childhood.<SEP>The system of beliefs associated with Christianity, which Geoffrey Hinton considered to be complete rubbish during his childhood and schooling.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837"
      ],
      "size": 3
    },
    {
      "id": "Appier",
      "label": "Appier",
      "description": "Appier is a company that provides AI solutions and maintains a blog covering marketing technology trends, automation, industry insights, best practices, and its own perspectives.<SEP>Appier是一家公司，其首席人工智能科学家孙民在文中被引用。<SEP>Appier is a company that publishes whitepapers and blogs about marketing technology trends and AI applications.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-5ec46d561fc83169cc4cb16171e4b90d",
        "chunk-93d921ef5f299976a4f4ffe79dfe7521",
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1"
      ],
      "size": 4
    },
    {
      "id": "Historical Data",
      "label": "Historical Data",
      "description": "Past weather data collected from various provinces across the country.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-333ff749c2940b520a06027eb3c17eac"
      ],
      "size": 2
    },
    {
      "id": "时间序列数据",
      "label": "时间序列数据",
      "description": "Time series data, such as historical price data, contains complex nonlinear relationships that models like RNN and LSTM are designed to capture.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 3
    },
    {
      "id": "lDDT-Cα",
      "label": "lDDT-Cα",
      "description": "lDDT-Cα is a metric used to evaluate the modeling accuracy of the predicted protein structure.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "Max-Pooling",
      "label": "Max-Pooling",
      "description": "Max-pooling is an operation used in convolutional neural networks to select the maximum feature from each feature map as the final output.<SEP>A technique used in the CNN model to extract the largest feature from each feature map as the final output.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-330f64bec90f2f131895d2de62adeb6f",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 3
    },
    {
      "id": "魏犇群",
      "label": "魏犇群",
      "description": "魏犇群阐述了哲学思考不可替代性的三个方面：提出深刻问题、关注意义与价值、保持对复杂性和不可通约性的敏感。<SEP>魏犇群提出生成式人工智能的发展是一个“哲学事件”，它改变了传统哲学观念，迫使哲学重新理解一系列基础概念并重组内部研究版图。<SEP>Wei Benqun explains that \"AI's philosophy\" has two meanings: philosophy about AI and philosophy created by AI itself. Under the first meaning, its core task is to re-understand human uniqueness in the era where AI imitates or even surpasses human intelligence.<SEP>A participant who discusses algorithmic value and philosophical value, explaining that current algorithmic value is a product of human mental labor but differs from philosophical value in manifestation.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-1583b867ca44e12600f0775616185d52",
        "chunk-47b980b33218327b53ee86797118fbb8",
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 7
    },
    {
      "id": "池化层",
      "label": "池化层",
      "description": "The pooling layer downsamples the feature maps from the convolutional layer, reducing dimensionality and computational load.<SEP>池化层是卷积神经网络中的一层，用于对数据进行下采样。<SEP>Pooling layers are components of a CNN that reduce the spatial dimensions of the features extracted by convolutional layers.<SEP>池化层是卷积神经网络中的一种网络层，用于汇聚局部神经元的输出，减少数据维度，抓取主要特征。<SEP>池化层是卷积神经网络中的一种层，用于通过组合局部神经元的输出并减少数据维度来抓取主要特征，忽略次要因素。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 4
    },
    {
      "id": "Coursera",
      "label": "Coursera",
      "description": "Coursera是一个在线学习平台，上面有推荐的课程。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-9ed0526c7eff8b1a424224e53050b149"
      ],
      "size": 3
    },
    {
      "id": "High-Frequency Trading Strategy",
      "label": "High-Frequency Trading Strategy",
      "description": "A high-frequency trading strategy is a method that executes a large number of trades at very high speeds, based on algorithmic models.<SEP>A trading strategy where ultra-low latency is crucial, presenting high technical and cost barriers for deploying deep learning models.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3",
        "chunk-2dc1c848682669d15114cbb84e3cd6b4"
      ],
      "size": 4
    },
    {
      "id": "结构数据",
      "label": "结构数据",
      "description": "Structural data extracted from the mobile advertising data for further processing.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-a6a52780a97b8eca9204ad8ed2f86840"
      ],
      "size": 3
    },
    {
      "id": "推荐系统",
      "label": "推荐系统",
      "description": "通过巧妙的调整，卷积神经网络也能在推荐系统中发挥作用。<SEP>推荐系统是互联网行业中使用机器学习/深度学习技术的典型应用，用于实现千人千面的个性化推荐。<SEP>推荐系统是机器学习的一个应用领域，例如使用协同过滤算法。",
      "domains": [
        "计算机科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-37f0a7ef7d63be3d8878c173058865c3",
        "chunk-0ff265f7709913907a277247870f20cc",
        "chunk-6003c974467b7a903cb83abef6cc2e24"
      ],
      "size": 4
    },
    {
      "id": "Generative AI",
      "label": "Generative AI",
      "description": "A type of artificial intelligence focused on creating new content, such as text or code.<SEP>A field of artificial intelligence catalyzed by the development of large language models like GPT-3, focused on creating new content.<SEP>Generative AI refers to AI models capable of generating content, such as text or images, and is a core service offered on Google Cloud's Vertex AI platform.",
      "domains": [
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-670e03b55717cd9c769f3cf5e85b2686",
        "chunk-f394bd66e077e288f0b983860f06c440"
      ],
      "size": 4
    },
    {
      "id": "BERT",
      "label": "BERT",
      "description": "Bidirectional Encoder Representations from Transformers, a pre-trained transformer model for language understanding.<SEP>BERT is a pre-trained model based on the Transformer encoder that adapts the representation of the same token to different contexts.<SEP>BERT is a large-scale language model whose rise has increased adoption of the Transformers library.<SEP>BERT is a specific pre-trained language model designed to understand the context of words in search queries and text.<SEP>A transformer-based machine learning technique for natural language processing.",
      "domains": [
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-747e06575d3f3c246eac89670d12c86e",
        "chunk-07c6d2ca0b23fef78261afa6105b1fe0",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 5
    },
    {
      "id": "AlphaDev",
      "label": "AlphaDev",
      "description": "AlphaDev is a reinforcement learning agent trained by Google DeepMind to find better sorting programs.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-82b403277dd4d1f793acce70ac7e2f82"
      ],
      "size": 3
    },
    {
      "id": "市场环境",
      "label": "市场环境",
      "description": "The market environment is dynamic and constantly changing, requiring models to have adaptability, which deep learning models can achieve through continuous training.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 2
    },
    {
      "id": "中低频量化",
      "label": "中低频量化",
      "description": "中低频量化是作者早期从事的量化交易策略，其特点是交易频率较低，文中指出机器学习在此场景下效果不佳。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-0ff265f7709913907a277247870f20cc"
      ],
      "size": 5
    },
    {
      "id": "Image Recognition",
      "label": "Image Recognition",
      "description": "A primary task that Convolutional Neural Networks (CNNs) are designed for, involving the identification of objects or features within images.<SEP>Image recognition is one of the many practical applications of deep learning technology.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c"
      ],
      "size": 3
    },
    {
      "id": "Convolutional Neural Network",
      "label": "Convolutional Neural Network",
      "description": "A deep learning model inspired by biological visual systems, designed to simulate human visual processing, widely used in computer vision.<SEP>A feedforward neural network whose artificial neurons can respond to surrounding units within a partial coverage area, demonstrating excellent performance in large-scale image processing.<SEP>A class of deep neural networks, commonly applied to analyzing visual imagery, abbreviated as CNN.<SEP>A type of deep learning model used for extracting global features from images.",
      "domains": [
        "地球科学",
        "计算机科学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-df57bc33c49fe522c66616c1a4be5336",
        "chunk-fe2c7c19ec682c0e709a26a55e0b8005",
        "chunk-fb89c8462c112775ff8e6c43e7d050e8"
      ],
      "size": 6
    },
    {
      "id": "数据挖掘",
      "label": "数据挖掘",
      "description": "Data mining is a field of focus for the Tianshan Intelligence community, involving discovering patterns in large data sets.<SEP>数据挖掘is the process of discovering patterns and knowledge from large datasets, related to the field of data analysis.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 3
    },
    {
      "id": "Bioinformatics",
      "label": "Bioinformatics",
      "description": "A research direction covered by Nankai Statistics.<SEP>Bioinformatics is a field combined with deep learning in AlphaFold's core technology.<SEP>Bioinformatics is the field or domain of study mentioned in the document metadata.<SEP>Bioinformatics is the domain or field of study mentioned in the document metadata.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-95ce0b0b365782f95d313a054721a437",
        "chunk-5899806c994fc2f391826abc901a8669",
        "chunk-82b403277dd4d1f793acce70ac7e2f82",
        "chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df"
      ],
      "size": 4
    },
    {
      "id": "Encoder",
      "label": "Encoder",
      "description": "A layer within a transformer that accepts input and maps it to a numerical representation containing contextual information.<SEP>A component of the encoder-decoder model that processes input data and converts it into a context representation.<SEP>The Encoder is a stack of multiple Encoder blocks that processes the entire input sequence to produce a contextualized representation.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-eb903a35c2a682651dd2704f765bb4c6",
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 5
    },
    {
      "id": "Deep Neural Network (DNN)",
      "label": "Deep Neural Network (DNN)",
      "description": "An advanced machine learning technique used to identify loans that may be downgraded, often applied to complex real-world problems like fraud detection, image recognition, and natural language processing.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3"
      ],
      "size": 3
    },
    {
      "id": "Large Language Model",
      "label": "Large Language Model",
      "description": "A type of deep learning model based on the Transformer architecture, primarily used for processing various natural language-related tasks such as text continuation, classification, summarization, rewriting, and translation.<SEP>A type of artificial intelligence model used for processing and generating human language.<SEP>A type of artificial intelligence model, central to the learning path and resources mentioned.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4f9864ecff092ef091c227f6ebb2d69f",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81",
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 11
    },
    {
      "id": "权重",
      "label": "权重",
      "description": "权重是神经网络中连接两个神经元的参数，决定了输入信号对下游神经元激活的贡献强度。<SEP>权重是神经网络中连接不同神经元之间的参数，其梯度在反向传播算法中通过公式3计算。<SEP>权重是神经网络中可调整的参数，在反向传播过程中根据误差信号进行修正。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a",
        "chunk-95faa80d73b4394851b10e9cc65232d2"
      ],
      "size": 4
    },
    {
      "id": "Structural Prediction Algorithm",
      "label": "Structural Prediction Algorithm",
      "description": "A developed algorithm that has served nearly 100,000 users from over 100 countries.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-95ce0b0b365782f95d313a054721a437"
      ],
      "size": 2
    },
    {
      "id": "Credit Card Fraud Detection: A Deep Learning Approach",
      "label": "Credit Card Fraud Detection: A Deep Learning Approach",
      "description": "This is an academic paper that proposes using deep learning methods to detect credit card fraud, addressing challenges like concept drift, class imbalance, and verification latency in financial transactions.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 7
    },
    {
      "id": "Deep Auto-Encoders",
      "label": "Deep Auto-Encoders",
      "description": "An unsupervised learning method introduced for fraud detection that learns normal user transaction patterns without labels to identify anomalous patterns, particularly useful for severely imbalanced data.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 4
    },
    {
      "id": "词元",
      "label": "词元",
      "description": "A token is a unit of text, such as a word or subword, that can be pre-trained using models like word2vec, GloVe, or subword embedding models.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-747e06575d3f3c246eac89670d12c86e"
      ],
      "size": 2
    },
    {
      "id": "深度学习",
      "label": "深度学习",
      "description": "深度学习是机器学习的一个子集，也是人工智能（AI）的核心领域与关键技术引擎。它是一种基于人工神经网络，特别是包含多个层级（即“深度”）的深层神经网络的人工智能方法。深度学习专注于通过表示学习或深度表征学习，从数据中自动学习复杂的特征和模式，其核心优势在于能够实现端到端的自动化学习，无需大量手动特征工程，从而颠覆了传统的研发模式并实现了框架的标准化。\n\n该方法框架通用性好，能够学习较远的上下文特征，并可以利用无监督语料进行训练以提升效果。深度学习涵盖了一系列算法和神经网络架构，其中卷积神经网络和循环神经网络是两种重要且典型的架构，分别擅长处理图像和序列数据。它尤其擅长处理图像、语音、文本等非结构化数据，在自然语言处理、图像识别、语音识别、语言翻译等领域扮演关键角色。\n\n深度学习在众多实际应用中表现出色，例如网络搜索、广告推送、金融量化交易等，其性能在某些任务上甚至超越了人类。基于深度学习的大模型技术被视为人工智能技术演进的关键，是一项正在快速变革多个行业的颠覆性技术。此外，它也是掌握计算认知和计算神经科学的基础，为脑科学研究、蛋白质结构预测等科学计算领域提供了重要工具。总体而言，深度学习在大数据背景下蓬勃发展，极大地推动了多个领域的技术进步。<SEP>用于实现遥感图像目标检测的核心技术方法。<SEP>一种机器学习方法，用于从数据中学习特征和模式。<SEP>深度学习是人工智能领域的核心技术之一，近年来在研究和应用层面取得了显著进展，是一种强大的机器学习方法。",
      "domains": [
        "哲学",
        "地球科学",
        "生物信息学",
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-d22adf07bd762e4e32d9bceea2fa6218",
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-c79b805e7da972f5a80b0f9eb1144d75",
        "chunk-225c135f952fba89e32fc67dcf80d0f5",
        "chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8",
        "chunk-88c27f8b7b31c4aea51cfc3d8f79a013",
        "chunk-92f537cdcce6583c2c63c400d634feaf",
        "chunk-9ed0526c7eff8b1a424224e53050b149",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-03a5749c6bb89c89b202fa903dbb847f",
        "chunk-c5eafae240ac5d07dadf7c4eb744e8eb",
        "chunk-62c73611ffdf6388dc832abdf23ad216",
        "chunk-dcad4a5abb7347f0e6403bab97eb576b",
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-0ff265f7709913907a277247870f20cc",
        "chunk-6bc1d4e50f0179dd98e01918a3be7977",
        "chunk-ead8239d6c7d35f7d27952face0dd715",
        "chunk-a6a52780a97b8eca9204ad8ed2f86840",
        "chunk-c00652dd3948d32546676fffc8064300",
        "chunk-5e9c7c6b034fa0090c148c9fb494cca9",
        "chunk-5ec46d561fc83169cc4cb16171e4b90d",
        "chunk-432af570193bd3df6d564434ee8bfbbb",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc",
        "chunk-326a81b79c40b3a07062403d80063e34",
        "chunk-506b50fbb39065edcc65dbbbc31a2bd7",
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 77
    },
    {
      "id": "过拟合",
      "label": "过拟合",
      "description": "过拟合是机器学习模型在训练数据上表现过好，在未见数据上表现差的现象，在全连接层数多时容易发生。<SEP>过拟合是机器学习中的一个问题，指模型在训练数据上表现过好，但在新数据上泛化能力差。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 3
    },
    {
      "id": "神经元",
      "label": "神经元",
      "description": "神经元是神经网络中节点的别称，是构成网络的基本单元。<SEP>神经元是神经网络的基本计算单元，接收输入并应用激活函数产生输出。<SEP>神经元是神经网络的基本单元，由输入值与权重系数乘积的和以及一个激活函数组成，其输出为y=f(e)。<SEP>神经元是神经网络中的基本单元，类似于生物神经细胞。<SEP>A basic computational unit in a neural network, organized in layers.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-cb5e07f0bad1ec285e66b4df8be69531",
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-2bd963b40a794cdd2a7befd072b521f8"
      ],
      "size": 7
    },
    {
      "id": "Abstract",
      "label": "Abstract",
      "description": "论文的英文摘要部分。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 2
    },
    {
      "id": "Watson Studio",
      "label": "Watson Studio",
      "description": "An IBM platform for data scientists and AI developers to build, train, and manage models.<SEP>An IBM platform that provides tools for building, training, tuning, and deploying CNN models as part of end-to-end solutions for image recognition and intelligent vision.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "输出层",
      "label": "输出层",
      "description": "输出层是神经网络中反向传播计算误差的起始点。<SEP>输出层是神经网络产生最终预测结果的层。<SEP>输出层是神经网络的最后一层，负责产生模型的最终预测结果，例如通过softmax函数输出分类概率。<SEP>输出层是卷积神经网络的一部分，产生最终的输出结果。<SEP>输出层是卷积神经网络结构的一部分，通常输出分类的类别及其概率，例如手写数字识别中的0-9数字或车型识别中的品牌概率。<SEP>输出层是神经网络的最后一层，负责给出最终的预测结果。<SEP>输出层是多层感知机网络结构中的一层。",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-9fcf6610f361d14578f6d58fe5b5ea26",
        "chunk-29234d7a518b3ee30e3ee9cbc39d7e68",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922",
        "chunk-93860b80c6ea559ea9b38a8562c8df8c"
      ],
      "size": 5
    },
    {
      "id": "遥感图像目标检测",
      "label": "遥感图像目标检测",
      "description": "基于深度学习的遥感图像目标检测方法，从尺度不变性、旋转不变性、复杂背景干扰、样本量少和多波段数据检测5个角度进行总结。",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-326a81b79c40b3a07062403d80063e34"
      ],
      "size": 2
    },
    {
      "id": "维度灾难",
      "label": "维度灾难",
      "description": "The \"curse of dimensionality\" is a problem often encountered by traditional statistical methods in high-dimensional spaces, which deep learning helps to avoid.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 2
    },
    {
      "id": "大语言模型",
      "label": "大语言模型",
      "description": "大语言模型是基于Transformer架构、参数规模极大的神经网络语言模型，通过在海量文本数据上进行预训练来理解和生成自然语言，是人工智能领域的一个重要分支。<SEP>基于Transformer架构、参数规模极大的神经网络语言模型，通过在海量文本数据上进行预训练来理解和生成自然语言，是驱动智能化从“辅助工具”向“自主系统”演进的核心支柱之一。<SEP>大语言模型是深度学习技术的杰出应用之一，专为处理和生成自然语言文本而设计，通常包含庞大的参数规模，能够深刻理解和生成复杂语言结构。<SEP>一种由包含数百亿以上权重的深度神经网络构建的语言模型。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771",
        "chunk-3678971988880bb3960a90e15878444d"
      ],
      "size": 10
    },
    {
      "id": "SGD",
      "label": "SGD",
      "description": "SGD是一种优化器，用于训练神经网络，学习率可设置为0.1。<SEP>SGD是随机梯度下降的缩写，是一种优化算法。",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-88c27f8b7b31c4aea51cfc3d8f79a013"
      ],
      "size": 3
    },
    {
      "id": "图像分类",
      "label": "图像分类",
      "description": "图像分类是深度卷积网络的一个应用示例，通过逐层卷积学习边缘、花纹、物体部位等特征。<SEP>图像分类是一种深度学习应用，将输入的二维像素矩阵处理后输出类别标签，属于一对一问题。",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0424a179537a1b36c1d9bf13f9a5a922",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 3
    },
    {
      "id": "Self-Attention",
      "label": "Self-Attention",
      "description": "Self-Attention is a core attention mechanism where elements of a sequence attend to all other elements in the same sequence to compute a weighted representation.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 3
    },
    {
      "id": "Decoder Block",
      "label": "Decoder Block",
      "description": "Decoder Block is a component of the Transformer model, containing two Multi-Head Attention layers (one with Masked attention) and processes sequences autoregressively.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 5
    },
    {
      "id": "Decoder",
      "label": "Decoder",
      "description": "A layer within a transformer that uses information from the encoder to generate output, such as translated text.<SEP>A component of the encoder-decoder model that generates output data based on the context representation from the encoder.<SEP>The Decoder is a stack of multiple Decoder blocks that generates the output sequence autoregressively, using the Encoder's output and its own previous outputs.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-eb903a35c2a682651dd2704f765bb4c6",
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 5
    },
    {
      "id": "ReLU",
      "label": "ReLU",
      "description": "ReLU是一种激活函数，用于在卷积神经网络中引入非线性。<SEP>Rectified Linear Unit, a common activation function used in neural networks.<SEP>ReLU is an activation function in neural networks, with its gradient being a key property for backpropagation.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-8bed972d3227719ebad6c051fae785c9"
      ],
      "size": 4
    },
    {
      "id": "反向传播",
      "label": "反向传播",
      "description": "反向传播（Back Propagation）是一种用于训练神经网络的核心算法，也是深度学习的基础。作为一种通用的思想或算法，它利用动态规划思想，通过链式法则从输出层向输入层逐层计算误差（或梯度），以实现高效计算。该过程依赖于正向传播得到的变量当前值，其计算顺序涉及将误差信号乘以节点的局部导数，并将结果向后传递。\n\n反向传播的核心目的是计算神经网络中损失函数对每个参数（如权重）的梯度。这些梯度随后被用于梯度下降等优化算法中，以更新网络权重，从而最小化损失函数。因此，它是几乎所有神经网络训练不可或缺的基础方法。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9fcf6610f361d14578f6d58fe5b5ea26",
        "chunk-29234d7a518b3ee30e3ee9cbc39d7e68",
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-ecf37963c494ecfacb6a6432c237dd3b",
        "chunk-7844fb38c827827af06d614fe4afb4df",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-3a728b359622810cd77efd2985a7fcfd",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a"
      ],
      "size": 25
    },
    {
      "id": "Synapse",
      "label": "Synapse",
      "description": "A synapse is a neural connection whose strength can be modified by neuronal activity, potentially forming the basis of learning.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c"
      ],
      "size": 3
    },
    {
      "id": "梯度下降算法",
      "label": "梯度下降算法",
      "description": "梯度下降算法是一种优化算法，用于在反向传播过程中根据计算出的梯度调整神经网络的权重和偏差。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-072c6009a64360fcdc975b14582a2c8c"
      ],
      "size": 3
    },
    {
      "id": "SSD",
      "label": "SSD",
      "description": "SSD (Single Shot MultiBox Detector) is a single-stage object detection model known for its speed, suitable for real-time applications like video surveillance.<SEP>SSD is mentioned as a possible one-stage object detection model for remote sensing applications.",
      "domains": [
        "地球科学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 3
    },
    {
      "id": "霍克海默",
      "label": "霍克海默",
      "description": "Horkheimer, a German philosopher cited by Wang Tian, pointed out that understanding the crisis of science depends on a correct theory of the current social situation.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 3
    },
    {
      "id": "Deep Dive Into Llms Like Chatgpt",
      "label": "Deep Dive Into Llms Like Chatgpt",
      "description": "A long introductory video by Andrej Karpathy, lasting three hours, highly recommended.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 3
    },
    {
      "id": "生成对抗网络",
      "label": "生成对抗网络",
      "description": "生成对抗网络是一种用于创建真实内容(如图像)的生成模型，由生成器和判别器两个网络组成，通过竞争进行训练。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4"
      ],
      "size": 2
    },
    {
      "id": "Google Cloud",
      "label": "Google Cloud",
      "description": "Google Cloud is a cloud computing platform offering various AI, machine learning, and other cloud services and products.<SEP>Google Cloud is an enterprise AI platform that integrates Google DeepMind's technologies to provide generative AI services.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-cb25bd59eb20459d90d689a472568aea",
        "chunk-f394bd66e077e288f0b983860f06c440"
      ],
      "size": 5
    },
    {
      "id": "三位青年学者",
      "label": "三位青年学者",
      "description": "\"Three young scholars\" are the participants organized by the journal to discuss philosophical research in the age of artificial intelligence.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63"
      ],
      "size": 2
    },
    {
      "id": "聊天机器人",
      "label": "聊天机器人",
      "description": "聊天机器人是能够与用户进行对话的软件程序，例如Amazon的Alexa、Apple的Siri和Microsoft的Cortana。<SEP>A chatbot is an example of an application that can be implemented using LLMs to provide 24/7 customer support.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 6
    },
    {
      "id": "孫民",
      "label": "孫民",
      "description": "孫民是一位專家，他提到深度學習和人工智慧在行銷中的應用，包括關鍵字擴展、情感分析的優勢以及當前技術的不足之處。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1"
      ],
      "size": 3
    },
    {
      "id": "ESMFold",
      "label": "ESMFold",
      "description": "一种基于深度学习的高精度方法，用于根据氨基酸序列预测蛋白质结构。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-62c73611ffdf6388dc832abdf23ad216"
      ],
      "size": 3
    },
    {
      "id": "Autoregressive Decoder-Only LLM",
      "label": "Autoregressive Decoder-Only LLM",
      "description": "A specific type of large language model architecture, exemplified by models like GPT-3 and Claude.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 4
    },
    {
      "id": "Feed Forward",
      "label": "Feed Forward",
      "description": "A process in a neural network where inputs are passed through layers to produce an output.<SEP>Feed Forward is a fully connected neural network layer applied position-wise within each Transformer block after the attention mechanism.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070",
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 3
    },
    {
      "id": "Attention Sublayer",
      "label": "Attention Sublayer",
      "description": "A component that makes transformers distinct from other encoder-decoder architectures.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-eb903a35c2a682651dd2704f765bb4c6"
      ],
      "size": 3
    },
    {
      "id": "Concept Drift",
      "label": "Concept Drift",
      "description": "A challenge in fraud detection where the statistical properties of the target variable change over time, which traditional systems struggle with.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 3
    },
    {
      "id": "NLP",
      "label": "NLP",
      "description": "NLP (Natural Language Processing) is the field of study that the Transformers package supports.<SEP>Natural Language Processing, a field with which transformer models are commonly associated.<SEP>自然语言处理的缩写，是人工智能领域处理人类语言技术的统称。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-07c6d2ca0b23fef78261afa6105b1fe0",
        "chunk-670e03b55717cd9c769f3cf5e85b2686",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3"
      ],
      "size": 3
    },
    {
      "id": "文本分类",
      "label": "文本分类",
      "description": "文本分类是一种深度学习应用，输入一个文本序列后输出其类别，属于多对一问题。<SEP>深度学习的一个应用方向。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 4
    },
    {
      "id": "哲学研究",
      "label": "哲学研究",
      "description": "Philosophical research is the activity of inquiry facing challenges from AI, particularly concerning human cognitive boundaries and the relationship between technology and the human future.<SEP>Philosophical research, which in the AI era must be \"based on humans, centered on humans, and for humans,\" according to Zhao Li.<SEP>An activity that means human mental labor production.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 3
    },
    {
      "id": "数据量",
      "label": "数据量",
      "description": "数据量指可用于模型训练的数据规模，文中指出中低频数据量少是机器学习效果差的另一个原因，而高频数据量巨大。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-0ff265f7709913907a277247870f20cc"
      ],
      "size": 3
    },
    {
      "id": "高频交易",
      "label": "高频交易",
      "description": "High-frequency trading (HFT) is a field involving extremely large and rapidly changing data volumes, where deep learning models like CNN and RNN can process micro-market structure data.<SEP>High-frequency trading, involving rapid execution of a large number of orders using complex algorithms.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 4
    },
    {
      "id": "意图理解",
      "label": "意图理解",
      "description": "意图理解是系统理解用户查询背后意图的能力，由自然语言处理提供支持。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "卷积神经网络",
      "label": "卷积神经网络",
      "description": "卷积神经网络（Convolutional Neural Network，CNN）是一种深度学习模型，属于前馈神经网络的一种代表性架构。其设计灵感源于生物视觉系统，旨在模仿生物神经网络的行为特征，特别是受到视觉皮层结构的启发。该网络专门用于处理具有网格结构的数据，如图像，通过利用数据（如图像像素、音频信号、时间序列）间的空间或局部关联性进行高效学习和模式识别。\n\n卷积神经网络的核心架构包含卷积层、池化层和全连接层。卷积层通过卷积运算从输入数据中自动提取局部特征，这是其命名的由来，并赋予了网络强大的特征提取能力，能够直接从原始数据中学习高级、抽象的特征。池化层则用于降低数据的空间维度，增强模型的鲁棒性。最后，全连接层通常负责执行分类或回归等任务。整个网络的训练过程涉及基于反向传播算法的梯度计算。\n\n除了在图像识别、对象检测和计算机视觉领域表现出色外，卷积神经网络也被广泛应用于自然语言处理、音频处理、信号处理以及序列数据编码等其他任务。它因其能够有效捕捉数据中的空间或局部依赖关系，而成为深度学习中的核心模型之一。该模型由Yann LeCun等人发明，并曾成功应用于高效的手写数字识别等任务。<SEP>卷积神经网络是一种深度学习模型，应用于医学影像识别等领域。",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-95faa80d73b4394851b10e9cc65232d2",
        "chunk-d22adf07bd762e4e32d9bceea2fa6218",
        "chunk-37f0a7ef7d63be3d8878c173058865c3",
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-c79065b95e8586e85c1d4a6dfcdb5d37",
        "chunk-c79b805e7da972f5a80b0f9eb1144d75",
        "chunk-225c135f952fba89e32fc67dcf80d0f5",
        "chunk-df57bc33c49fe522c66616c1a4be5336",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922",
        "chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-6003c974467b7a903cb83abef6cc2e24"
      ],
      "size": 37
    },
    {
      "id": "AI投资",
      "label": "AI投资",
      "description": "AI investment refers to financial commitments made into artificial intelligence technologies.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 2
    },
    {
      "id": "Google",
      "label": "Google",
      "description": "Google的搜索算法是神经网络的一个著名应用示例。<SEP>Google是一家科技公司，投入巨资研究卷积神经网络的变体。<SEP>A technology company where Geoffrey Hinton worked part-time. It also acquired DeepMind.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c"
      ],
      "size": 5
    },
    {
      "id": "时间序列",
      "label": "时间序列",
      "description": "一种数据类型，卷积神经网络能很好地对它进行处理。<SEP>Refers to time series models or AI capabilities for analyzing sequential data over time.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-225c135f952fba89e32fc67dcf80d0f5",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "反欺诈",
      "label": "反欺诈",
      "description": "反欺诈是互联网行业中机器学习/深度学习的另一个应用领域。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-0ff265f7709913907a277247870f20cc"
      ],
      "size": 3
    },
    {
      "id": "David Baker",
      "label": "David Baker",
      "description": "David Baker is a professor at the University of Washington and a world-renowned expert in protein design, having published over 700 research papers in the field of proteins.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-b1d2ad62c7c26e8ff618cb6a7b89c7df"
      ],
      "size": 2
    },
    {
      "id": "浙江大学人工智能教育教学研究中心",
      "label": "浙江大学人工智能教育教学研究中心",
      "description": "浙江大学人工智能教育教学研究中心是进行人工智能教育研究并展示相关研究成果的机构。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-d59c5769fc2d8973bb797259108a6319"
      ],
      "size": 4
    },
    {
      "id": "人与机器身份悖论",
      "label": "人与机器身份悖论",
      "description": "该悖论探讨了人工智能作为工具延伸弱化人类自主性，甚至当AI获得法律身份时，迫使哲学重新反思“人是什么”的本质问题。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 2
    },
    {
      "id": "链式规则",
      "label": "链式规则",
      "description": "链式规则是微积分中用于计算复合函数导数的法则，是反向传播的基础。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-3a728b359622810cd77efd2985a7fcfd"
      ],
      "size": 3
    },
    {
      "id": "CASP14",
      "label": "CASP14",
      "description": "CASP14 is the 14th Critical Assessment of protein Structure Prediction competition where AlphaFold2 was presented.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 2
    },
    {
      "id": "神经科学",
      "label": "神经科学",
      "description": "The study of the nervous system. It has provided inspirational principles for artificial intelligence, such as the visual system inspiring CNNs and the layered organization of the cerebral cortex inspiring deep learning architectures. It is seen as a source for future key principles to expand AI capabilities.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c"
      ],
      "size": 3
    },
    {
      "id": "江珀",
      "label": "江珀",
      "description": "Jiang Po led a young team to re-examine and comprehensively adjust the initial version of AlphaFold, introducing new ideas for improvement.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f"
      ],
      "size": 2
    },
    {
      "id": "Life Sciences",
      "label": "Life Sciences",
      "description": "Life sciences is a field expected to benefit widely from accurate protein structure prediction, including drug discovery and disease understanding.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-d23247c8edaf8929e7855d9186007c46"
      ],
      "size": 2
    },
    {
      "id": "ResNet-18",
      "label": "ResNet-18",
      "description": "A deep learning model whose performance on test datasets is relatively better.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-fb89c8462c112775ff8e6c43e7d050e8"
      ],
      "size": 3
    },
    {
      "id": "Hung-yi Lee",
      "label": "Hung-yi Lee",
      "description": "Hung-yi Lee is a professor who created and presented the lecture \"【機器學習2021】Transformer (上)\".",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-a6f32e4615a0137e965400eba7166c47"
      ],
      "size": 3
    },
    {
      "id": "LeNet-5",
      "label": "LeNet-5",
      "description": "An early and influential CNN architecture.<SEP>A classic and widely recognized convolutional neural network architecture.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "华南师范大学马克思主义学院",
      "label": "华南师范大学马克思主义学院",
      "description": "华南师范大学马克思主义学院是杨媛所属的学术机构。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 2
    },
    {
      "id": "N元语法模型",
      "label": "N元语法模型",
      "description": "一种用于提取局部文本特征的模型。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-012b11b19422c013994d2348ab5422de"
      ],
      "size": 2
    },
    {
      "id": "垂直模型",
      "label": "垂直模型",
      "description": "垂直模型是传统的AI模型，只会做特定领域的事情，例如翻译、下围棋或对话，无法像人类一样通用。<SEP>垂直模型是传统的AI模型，指只会做特定领域事情的模型，例如翻译、下围棋或对话。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 2
    },
    {
      "id": "Transformer Encoder",
      "label": "Transformer Encoder",
      "description": "The encoder component of a Transformer model, initialized with vocabulary size and architectural parameters, and composed of multiple EncoderBlock layers. It processes input X and valid lengths using positional encoding.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ad8f11550a8a8807684e7ecc93a2a801"
      ],
      "size": 3
    },
    {
      "id": "郑伟",
      "label": "郑伟",
      "description": "郑伟是南开大学统计与数据科学学院的教授，是论文的第一作者，长期从事生物分子结构预测研究，开发了D-I-TASSER等算法。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8"
      ],
      "size": 6
    },
    {
      "id": "News Headline Generation",
      "label": "News Headline Generation",
      "description": "A specific application of generative text models, using the first paragraph of a news article as input to generate a title, sharing the core idea of generative summarization.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 2
    },
    {
      "id": "利益相关者要求",
      "label": "利益相关者要求",
      "description": "Stakeholder requirements refer to the needs and expectations of all parties affected by the AI model's development and use.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "Recurrent Neural Network",
      "label": "Recurrent Neural Network",
      "description": "A class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence, abbreviated as RNN.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-fe2c7c19ec682c0e709a26a55e0b8005"
      ],
      "size": 3
    },
    {
      "id": "RAG",
      "label": "RAG",
      "description": "RAG (Retrieval-Augmented Generation) is a technique that combines Large Language Models (LLMs) with external knowledge bases to generate precise answers by first retrieving relevant information.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0222ac86b3d60100ac5d03d88a69654e"
      ],
      "size": 4
    },
    {
      "id": "大数据",
      "label": "大数据",
      "description": "Big data is described as an important characteristic of current scientific development, exemplified by genome sequencing results and massive papers.<SEP>Big data, a key context for the rapid development of deep learning.<SEP>大数据refers to large volumes of data that support the development and learning of AI models.",
      "domains": [
        "生物信息学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f",
        "chunk-5e9c7c6b034fa0090c148c9fb494cca9",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 4
    },
    {
      "id": "计算认知",
      "label": "计算认知",
      "description": "计算认知是一个研究领域，旨在加深对其的理解。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-9ed0526c7eff8b1a424224e53050b149"
      ],
      "size": 3
    },
    {
      "id": "MIT 6.874",
      "label": "MIT 6.874",
      "description": "麻省理工学院开设的一门交叉专业课程，内容涵盖生命科学与计算机科学。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-dcad4a5abb7347f0e6403bab97eb576b"
      ],
      "size": 4
    },
    {
      "id": "文本预处理",
      "label": "文本预处理",
      "description": "文本预处理是将原始文本转换为机器更容易理解的格式的过程，包括标记化、小写转换等步骤。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 4
    },
    {
      "id": "Black Box Problem",
      "label": "Black Box Problem",
      "description": "The challenge of interpreting the internal decision-making process of complex deep learning models, a significant issue in regulated industries like finance.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-2dc1c848682669d15114cbb84e3cd6b4"
      ],
      "size": 2
    },
    {
      "id": "技术演进",
      "label": "技术演进",
      "description": "技术演进是深度学习的发展脉络，本文对其进行了梳理。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 2
    },
    {
      "id": "深度学习框架",
      "label": "深度学习框架",
      "description": "Deep Learning Frameworks are standardized software tools and libraries that facilitate the development and deployment of deep learning models.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c0eefe5184862c24ce2da501217562b3"
      ],
      "size": 2
    },
    {
      "id": "技术哲学",
      "label": "技术哲学",
      "description": "技术哲学是从哲学角度审视技术(如深度学习)的学科领域。<SEP>技术哲学是哲学中因人工智能普遍应用而可能兴起的新领域，专门研究技术如何塑造生活世界等基础议题，并与传统哲学领域并驾齐驱。<SEP>A broad field of philosophy that studies fundamental issues related to technology, such as how technology shapes the lifeworld and the relationship between humans and technology.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd",
        "chunk-47b980b33218327b53ee86797118fbb8",
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 5
    },
    {
      "id": "人工智能的哲学",
      "label": "人工智能的哲学",
      "description": "AI's philosophy has two meanings according to Wei Benqun: philosophy about AI and philosophy created by AI itself. Under the first meaning, it belongs to human philosophy and aims to guide technological development with humanistic reflection.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 2
    },
    {
      "id": "三维空间结构",
      "label": "三维空间结构",
      "description": "三维空间结构是蛋白质的立体构象，决定了其生理功能。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-99be6d80a8d1a4129da56c2930cc8b6d"
      ],
      "size": 2
    },
    {
      "id": "激活函数",
      "label": "激活函数",
      "description": "The activation function, denoted as f, implements nonlinear transformations within neurons in a neural network.<SEP>激活函数是应用于神经元输入的数学函数，用于引入非线性，使神经网络能够学习复杂模式。<SEP>激活函数是神经网络中的非线性函数，用于决定神经元是否被激活，常见的例子包括tanh和softmax函数。<SEP>激活函数用于为神经网络引入非线性，文中提到sigmoid函数可能不适合多层网络。<SEP>激活函数是神经元中的非线性函数f(e)，用于引入非线性特性，将输入e转换为输出y。<SEP>激活函数如ReLU在卷积操作后应用，为网络引入非线性，使其能够学习复杂特征。<SEP>激活函数是神经网络中引入的非线性因素，卷积神经网络在卷积操作后也会加入激活函数以解决非线性问题。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-ecf37963c494ecfacb6a6432c237dd3b",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a",
        "chunk-95faa80d73b4394851b10e9cc65232d2",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 7
    },
    {
      "id": "Threshold",
      "label": "Threshold",
      "description": "The threshold is a value used in a perceptron to determine the output; it is often represented as a bias `b`.<SEP>Threshold is a parameter in neural networks whose significance was relearned clearly and profoundly by the narrator.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-90d06b6fbc58cfba3d096615baf2b706"
      ],
      "size": 5
    },
    {
      "id": "局部导数",
      "label": "局部导数",
      "description": "局部导数是指在正向传播中函数y=f(x)的导数，即∂y/∂x，用于反向传播的计算。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-7844fb38c827827af06d614fe4afb4df"
      ],
      "size": 3
    },
    {
      "id": "认知神经科学",
      "label": "认知神经科学",
      "description": "认知神经科学是输入文本中提到的研究领域。<SEP>认知神经科学是研究认知过程与神经机制之间关系的交叉学科领域。<SEP>The domain or field of study mentioned in the document metadata, which is cognitive neuroscience.<SEP>A field of study that combines cognitive psychology and neuroscience to understand the neural mechanisms underlying mental processes.<SEP>认知神经科学is the domain or field of study mentioned in the document metadata.<SEP>A field of study mentioned as the domain of the document.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-93860b80c6ea559ea9b38a8562c8df8c",
        "chunk-88c27f8b7b31c4aea51cfc3d8f79a013",
        "chunk-92f537cdcce6583c2c63c400d634feaf",
        "chunk-03a5749c6bb89c89b202fa903dbb847f",
        "chunk-3954d1f048ce5cd91b5693da96becc81",
        "chunk-a0a9ca6f9242eabc77977a8fe45c5022"
      ],
      "size": 2
    },
    {
      "id": "Seed Data",
      "label": "Seed Data",
      "description": "Seed data are initial inputs provided to an AI system in deep learning, which then finds similar keywords in the vector space for applications like keyword marketing.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-5ec46d561fc83169cc4cb16171e4b90d"
      ],
      "size": 2
    },
    {
      "id": "监督学习",
      "label": "监督学习",
      "description": "监督学习是一种机器学习方法，使用标记数据集来训练算法。<SEP>监督学习是一种机器学习范式，模型在带有标签的数据集上进行训练，反向传播是其训练神经网络做出更优质预测的关键技术。<SEP>Supervised learning is a machine learning paradigm where models are trained using labeled data.<SEP>A learning paradigm where an artificial neural network is trained using data where the final answers are known in advance. This is contrasted with creative thinking which may not have a predefined answer.<SEP>机器学习的一种范式。<SEP>Supervised Learning is a type of machine learning where models are trained on labeled data (input-output pairs) to learn a mapping function.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-80c468f42f64d269b4538a150a4f94cd",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-c0eefe5184862c24ce2da501217562b3"
      ],
      "size": 5
    },
    {
      "id": "重要架构",
      "label": "重要架构",
      "description": "Important architecture refers to key components like IPA and Residue Gas.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "LSTM",
      "label": "LSTM",
      "description": "LSTM (Long Short-Term Memory) is a type of recurrent neural network architecture used for time series forecasting.<SEP>Long Short-Term Memory networks, capable of learning long-range context, which is very helpful for recognition tasks.<SEP>一种用于处理序列依赖或长时间依赖特征的神经网络模型。<SEP>LSTM是一种深度学习模型，能够捕捉长距离的上下文特征，帮助解决语义理解问题。",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-201fcd200de194e722ae83a479174b8b",
        "chunk-432af570193bd3df6d564434ee8bfbbb",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 6
    },
    {
      "id": "Generative Ai",
      "label": "Generative Ai",
      "description": "Generative AI is a type of artificial intelligence capable of creating new content, solutions, and value, requiring investment and carrying associated risks.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-833d835632b095e419f4a96b3c5dac04"
      ],
      "size": 2
    },
    {
      "id": "Vertex AI",
      "label": "Vertex AI",
      "description": "Vertex AI is a managed machine learning platform offered by Google Cloud, available for trial with promotional credits.<SEP>Vertex AI is a service on Google Cloud that provides access to Gemini and other generative AI models for building and testing AI applications.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-cb25bd59eb20459d90d689a472568aea",
        "chunk-f394bd66e077e288f0b983860f06c440"
      ],
      "size": 4
    },
    {
      "id": "语言",
      "label": "语言",
      "description": "Refers to language models or AI capabilities related to natural language processing.<SEP>语言是人类感官之一，在人工智能中对应自然语言处理技术。<SEP>语言在大语言模型中是核心，它不仅是模型的学习对象，也是推理过程中用于生成和理解的基础，模型通过训练掌握语言的使用规则和模式。<SEP>语言帮助人类表达思想和情感，并使得人类能够以创造性的方式运用。",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 4
    },
    {
      "id": "自监督学习",
      "label": "自监督学习",
      "description": "Self-supervised learning is a machine learning paradigm where models generate their own supervisory signal from the data.<SEP>Self-supervised learning is a method widely used for pre-training text representations by predicting hidden parts of text using surrounding text.",
      "domains": [
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-80c468f42f64d269b4538a150a4f94cd",
        "chunk-747e06575d3f3c246eac89670d12c86e"
      ],
      "size": 2
    },
    {
      "id": "哲学思考",
      "label": "哲学思考",
      "description": "Philosophical thinking is described as a solitary journey into uncharted territory, whose core involves proposing new questions, redefining old ones, and challenging presuppositions, abilities unique to the human mind.<SEP>Philosophical thinking is described as having the purpose of \"knowing thyself\" through reflective self-examination, which cannot be replaced by examining others or being examined by others. It can also provide possible conditions for transforming the world through speculative power.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 6
    },
    {
      "id": "Microsoft Cortana",
      "label": "Microsoft Cortana",
      "description": "Microsoft Cortana是微软开发的语音助手，是一个聊天机器人的例子。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "Weight Matrix WV",
      "label": "Weight Matrix WV",
      "description": "A unique weight matrix used to generate the value vector (V) from a token embedding.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 2
    },
    {
      "id": "quant-computer",
      "label": "quant-computer",
      "description": "A user who graduated in 2017, worked in quantitative finance until 2018, then left to consider transitioning to machine learning, and later switched to deep learning (image processing).<SEP>\"quant-computer\" is a user who posted a comment on the article discussing their career shift from quantitative finance to deep learning (image processing).",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-0ff265f7709913907a277247870f20cc",
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 3
    },
    {
      "id": "AI Expert",
      "label": "AI Expert",
      "description": "AI experts are individuals in the field of artificial intelligence who are criticized by Douglas Hofstadter for lacking genuine interest in how the brain and mind function.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-90d06b6fbc58cfba3d096615baf2b706"
      ],
      "size": 2
    },
    {
      "id": "Area Under the Curve of Receiver Operating Characteristic (AUC)",
      "label": "Area Under the Curve of Receiver Operating Characteristic (AUC)",
      "description": "A metric used to evaluate the performance of a model, particularly for binary classification problems.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3"
      ],
      "size": 3
    },
    {
      "id": "Training",
      "label": "Training",
      "description": "Training is the process of iteratively adjusting weights and bias through trial and error to find the values that produce the most accurate output.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917"
      ],
      "size": 5
    },
    {
      "id": "马克思主义",
      "label": "马克思主义",
      "description": "Marxism revealed the laws of development and future direction of human society, providing a scientific guide for \"where humanity is headed.\"",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 2
    },
    {
      "id": "古希腊哲人",
      "label": "古希腊哲人",
      "description": "Ancient Greek philosophers discussed the origin of the world, which gave rise to early science and mathematics.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 2
    },
    {
      "id": "神经网络",
      "label": "神经网络",
      "description": "神经网络是一种受人脑或生物神经系统结构及功能启发的计算模型，它是深度学习算法的底层技术基础。神经网络由多层互连的节点（或称神经元）组成，这些节点分层排列，形成一种分层结构。它能够通过前向传播处理输入数据，并利用反向传播等算法进行训练和学习，从而完成快速的数据分类、聚类以及预测任务，广泛应用于语音识别、图像识别等机器学习与人工智能领域。自编码器是神经网络中的一类特定类型，属于一种深度前馈结构。<SEP>Neural networks are computational models where communication between layers and between different networks occurs through vectors.<SEP>神经网络是模拟人脑神经元连接的计算模型，是深度学习和语言模型的基础。<SEP>构成大语言模型等人工智能模型的基础计算模型。<SEP>神经网络是一种计算模型，是深度学习的基础，通过模拟生物神经网络的结构和功能来进行信息处理。<SEP>神经网络是深度学习的基本概念。",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-cb5e07f0bad1ec285e66b4df8be69531",
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-ecf37963c494ecfacb6a6432c237dd3b",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-e101b215c048456f8049a66e9ebd2c54",
        "chunk-0a82bdcf222bdb547252e178dfe4d622",
        "chunk-03a5749c6bb89c89b202fa903dbb847f",
        "chunk-1eb9c8a9254475c3a6672347d5ac549f",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-d59c5769fc2d8973bb797259108a6319",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 17
    },
    {
      "id": "AI监管",
      "label": "AI监管",
      "description": "AI regulation is crucial for the responsible development and oversight of LLMs, ensuring they align with organizational values and legal requirements.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 4
    },
    {
      "id": "深度學習模型",
      "label": "深度學習模型",
      "description": "Deep learning models, such as CNN and RNN, are capable of processing massive amounts of micro-market structure data.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-82bdb1406dfe17a400fa95a5a4727859"
      ],
      "size": 3
    },
    {
      "id": "命名实体识别",
      "label": "命名实体识别",
      "description": "深度学习的一个应用方向。<SEP>命名实体识别是识别文本中具有特定意义的实体(如人名、地名、组织名)并分类的技术。<SEP>命名实体识别是识别文本中特定类型实体(如人名、地名)的任务。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 3
    },
    {
      "id": "Machine Learning",
      "label": "Machine Learning",
      "description": "{\"entities\": [\"熵\", \"热力学第二定律\", \"耗散结构\", \"香农\", \"薛定谔\", \"玻尔兹曼\", \"最大熵原理\", \"公式 S=k*lnW\", \"生命是什么\"]}",
      "domains": [
        "地球科学",
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-cb25bd59eb20459d90d689a472568aea",
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-ac1ed9e88e425ab885199259d92315e5",
        "chunk-9f34e4a3e164d008eba0c74c96804047",
        "chunk-0724c887b70d220c530dcfaee28003c1",
        "chunk-833d835632b095e419f4a96b3c5dac04",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81",
        "chunk-333ff749c2940b520a06027eb3c17eac"
      ],
      "size": 9
    },
    {
      "id": "Deep Learning Models",
      "label": "Deep Learning Models",
      "description": "Deep learning models are highly scalable and improve the accuracy of detecting fraudulent activities.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-ac1ed9e88e425ab885199259d92315e5"
      ],
      "size": 3
    },
    {
      "id": "Object Detection",
      "label": "Object Detection",
      "description": "A computer vision task where Convolutional Neural Networks have shown significant progress.<SEP>A primary task that Convolutional Neural Networks (CNNs) are designed for, involving locating and classifying objects within images.<SEP>Object Detection is a computer vision task for identifying and locating objects in images, with specific applications and model evaluations (e.g., mAP) discussed for remote sensing.",
      "domains": [
        "地球科学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794",
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 6
    },
    {
      "id": "价格预测",
      "label": "价格预测",
      "description": "Price prediction is a direct application of deep learning in quantitative trading, using models like LSTM and Transformer to forecast future price movements.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 3
    },
    {
      "id": "语言翻译",
      "label": "语言翻译",
      "description": "语言翻译是将文本从一种语言转换为另一种语言的过程，自然语言处理有助于此过程。<SEP>Language translation is a capability of LLMs that can facilitate cross-cultural communication.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "Retrieval-Augmented Generation",
      "label": "Retrieval-Augmented Generation",
      "description": "A technique that combines LLMs with external knowledge bases, where the LLM retrieves relevant information first before generating an answer.<SEP>A method that combines retrieval of information with generative models.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4f9864ecff092ef091c227f6ebb2d69f",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 3
    },
    {
      "id": "Continuous Function",
      "label": "Continuous Function",
      "description": "A continuous function, like the sigmoid output, is necessary for training sensitivity as opposed to a binary output.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917"
      ],
      "size": 2
    },
    {
      "id": "Attention Mechanism",
      "label": "Attention Mechanism",
      "description": "Attention Mechanism is the core concept in Transformer models, allowing the model to focus on different parts of the input sequence when producing an output.<SEP>Attention mechanism is a technique that can be referenced for understanding Transformer models.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5",
        "chunk-778f83860f7db1907e0da6e0cb412723"
      ],
      "size": 4
    },
    {
      "id": "Back-Testing Results",
      "label": "Back-Testing Results",
      "description": "Back-testing results are performance metrics for trading strategies, including number of trades, win rate, average profit, average loss, profit-loss ratio, and expected return.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3"
      ],
      "size": 2
    },
    {
      "id": "医学影像识别",
      "label": "医学影像识别",
      "description": "医学影像识别是深度学习的一个应用领域，例如使用卷积神经网络。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-6003c974467b7a903cb83abef6cc2e24"
      ],
      "size": 2
    },
    {
      "id": "计算机学者",
      "label": "计算机学者",
      "description": "计算机学者是受生理学家和数学家启发而创造卷积神经网络等模型的研究人员。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 2
    },
    {
      "id": "Artificial General Intelligence (AGI)",
      "label": "Artificial General Intelligence (AGI)",
      "description": "Artificial General Intelligence (AGI) is the stated goal of achieving human-level or general intelligence in machines, which critics like Douglas Hofstadter deem a vain dream due to the field's disconnect from brain and mind research.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-90d06b6fbc58cfba3d096615baf2b706"
      ],
      "size": 3
    },
    {
      "id": "ChatGPT",
      "label": "ChatGPT",
      "description": "An AI chatbot released by OpenAI, powered by models like GPT-3.<SEP>ChatGPT是一个大语言模型的应用实例，用于智能客服和对话生成。<SEP>ChatGPT is an AI chatbot application based on a large language model, capable of conversational interactions.<SEP>ChatGPT is a popular AI application whose success brought widespread attention to large language models.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 3
    },
    {
      "id": "Multi-layer Feed-forward Neural Network",
      "label": "Multi-layer Feed-forward Neural Network",
      "description": "A deep learning model used for credit card fraud detection that feeds input data through layers, using non-linear transformations to learn hierarchical features from the data.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 2
    },
    {
      "id": "Jim Anderson",
      "label": "Jim Anderson",
      "description": "Jim Anderson is an author or interviewee featured in the book \"Talking Nets\".<SEP>Co-author of the interview collection \"Talking nets\" which contains interviews with Lettvin and Hinton.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837"
      ],
      "size": 3
    },
    {
      "id": "Claude",
      "label": "Claude",
      "description": "A closed-source large language model developed by Anthropic.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 3
    },
    {
      "id": "Yann LeCun",
      "label": "Yann LeCun",
      "description": "Yann LeCun是法国学者，在1998年提出了基于梯度学习的卷积神经网络算法LeNet，广泛应用于手写数字和字符识别。<SEP>Yann LeCun is a co-author of the 2015 Nature review article on deep learning.<SEP>Another foundational figure in deep learning. Inspired by the principles of the nervous system, he extended the organizational structure of the brain's visual system to artificial neural networks, inventing Convolutional Neural Networks (CNNs) for efficient handwritten digit recognition.",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837"
      ],
      "size": 5
    },
    {
      "id": "GRU",
      "label": "GRU",
      "description": "Gated Recurrent Unit, a component of the GBDT→GRU→RF sandwich structure used in the fraud detection model.<SEP>一种比LSTM稍简单的循环神经网络单元，在层次深或复杂时运算效率更高，但精度可能稍差。",
      "domains": [
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-98217948cb9ad0bfdb25f3db0b7cd900",
        "chunk-012b11b19422c013994d2348ab5422de"
      ],
      "size": 3
    },
    {
      "id": "GoogleNet",
      "label": "GoogleNet",
      "description": "GoogleNet是一种卷积神经网络，增加了网络的宽度，使用1x1卷积降维减少参数量，并在多个不同尺寸的卷积核上进行卷积后再聚合。<SEP>GoogleNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.",
      "domains": [
        "地球科学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 3
    },
    {
      "id": "隐藏层",
      "label": "隐藏层",
      "description": "隐藏层是神经网络中位于输入层和输出层之间的中间层，负责逐步提取和转换输入数据的关键特征。<SEP>隐藏层是多层感知机网络结构中的一层。",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-93860b80c6ea559ea9b38a8562c8df8c"
      ],
      "size": 3
    },
    {
      "id": "watsonx.ai",
      "label": "watsonx.ai",
      "description": "An IBM enterprise AI and data platform for building and scaling AI.<SEP>An IBM platform that provides tools for building, training, tuning, and deploying CNN models as part of end-to-end solutions for image recognition and intelligent vision.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 7
    },
    {
      "id": "Artificial Neuron",
      "label": "Artificial Neuron",
      "description": "An artificial neuron is a model designed to simulate biological neurons and serves as the basic building block of artificial neural networks.<SEP>An artificial neuron is a computational model inspired by biological neurons, used as a building block for artificial neural networks to simulate thinking.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-90d06b6fbc58cfba3d096615baf2b706"
      ],
      "size": 3
    },
    {
      "id": "IBM Granite",
      "label": "IBM Granite",
      "description": "IBM Granite是一个AI模型，由IBM提供深入了解的课程。<SEP>IBM Granite是IBM推出的一个开放式、高性能、可信赖的AI模型系列，专为企业定制并经过优化，用于扩展AI应用程序。<SEP>IBM's series of open, performant, and trustworthy AI models tailored for enterprise use.<SEP>A series of open, high-performance, and trusted AI models from IBM, tailored and optimized for enterprise use.<SEP>An open-source, high-performance, and trustworthy series of AI models tailored for enterprises, optimized for scaling AI applications across language, code, time series, and guardrail options.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 7
    },
    {
      "id": "非线性动力学系统",
      "label": "非线性动力学系统",
      "description": "Nonlinear Dynamical Systems are systems described by differential or difference equations, where complexity arises from nonlinearity and sensitivity to initial conditions.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-ecf37963c494ecfacb6a6432c237dd3b"
      ],
      "size": 3
    },
    {
      "id": "Filter",
      "label": "Filter",
      "description": "A set of fixed weights, also known as a convolution kernel, used in the convolution operation to extract features.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794"
      ],
      "size": 3
    },
    {
      "id": "Convolutional Neural Networks",
      "label": "Convolutional Neural Networks",
      "description": "A class of feedforward neural networks that includes convolutional computation and has a deep structure, and is a representative of deep learning.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c79b805e7da972f5a80b0f9eb1144d75"
      ],
      "size": 2
    },
    {
      "id": "统计机器学习",
      "label": "统计机器学习",
      "description": "统计机器学习是一种基于统计模型的机器学习方法，在上世纪九十年代推动了自然语言处理技术的革新。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade"
      ],
      "size": 3
    },
    {
      "id": "科学",
      "label": "科学",
      "description": "博士学位被称为Doctor of Philosophy，体现了科学和艺术领域之间的深层逻辑联系。<SEP>Science, whose crisis understanding depends on a correct theory of the current social situation, as cited by Wang Tian from Horkheimer.",
      "domains": [
        "哲学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 3
    },
    {
      "id": "Deep-Algotrading",
      "label": "Deep-Algotrading",
      "description": "Deep-Algotrading is a resource repository for learners covering topics from simple regression analysis to complex time series forecasting techniques.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-201fcd200de194e722ae83a479174b8b"
      ],
      "size": 2
    },
    {
      "id": "Transformer Architecture",
      "label": "Transformer Architecture",
      "description": "A deep learning model architecture that forms the basis for Large Language Models.<SEP>A deep learning model architecture based on self-attention mechanisms.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4f9864ecff092ef091c227f6ebb2d69f",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 2
    },
    {
      "id": "人工智能技术",
      "label": "人工智能技术",
      "description": "Technology that mass-produces information difficult to distinguish as true or false and shapes inequality gaps through algorithms.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 3
    },
    {
      "id": "DOI: 10.12677/acpp.2025.145279",
      "label": "DOI: 10.12677/acpp.2025.145279",
      "description": "论文《深度学习的技术路径与哲学审视》的数字对象标识符。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 3
    },
    {
      "id": "仿真验证",
      "label": "仿真验证",
      "description": "使用真实数据对模型进行模拟测试和验证的过程。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-98217948cb9ad0bfdb25f3db0b7cd900"
      ],
      "size": 3
    },
    {
      "id": "文本表示",
      "label": "文本表示",
      "description": "Text representation is the vector form of tokens learned through pre-training, which can be used in various deep learning architectures.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-747e06575d3f3c246eac89670d12c86e"
      ],
      "size": 6
    },
    {
      "id": "卷积",
      "label": "卷积",
      "description": "卷积是一种在图像和文本处理中用于特征提取的数学运算，通过层层过滤选出最佳特征结果。<SEP>CNN中的核心操作，使用过滤器(如九宫格)在输入(如图像或文本)上滑动并进行矩阵相乘以提取特征。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 4
    },
    {
      "id": "Meteorological Elements Forecasting Method",
      "label": "Meteorological Elements Forecasting Method",
      "description": "A forecasting method for meteorological elements that is based on deep learning techniques.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-ed300ee31268ac8e853d58a7e20740f0"
      ],
      "size": 3
    },
    {
      "id": "深度學習",
      "label": "深度學習",
      "description": "深度學習是一種人工智慧方法，可以幫助企業從種子資料中尋找相似關鍵字，並進行更精準的情感分析。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-23a71ac8e1e391c0d5c2b9361cf23dc1"
      ],
      "size": 4
    },
    {
      "id": "Multi-Modal Learning",
      "label": "Multi-Modal Learning",
      "description": "Multi-Modal Learning is a method that combines various types of data such as numerical, text, and images to build a more comprehensive market view.<SEP>A future development direction in deep learning for quantitative trading that combines numerical, text, image, and other data types to build a comprehensive market view.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-2dc1c848682669d15114cbb84e3cd6b4",
        "chunk-d9ecda3ea425b03f3129938c0ba44219"
      ],
      "size": 3
    },
    {
      "id": "RGB Color Model",
      "label": "RGB Color Model",
      "description": "A color model using red, green, and blue primary colors combined in different proportions to produce various colors.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794"
      ],
      "size": 2
    },
    {
      "id": "Feature Extraction",
      "label": "Feature Extraction",
      "description": "Feature extraction is the process of converting raw text into numerical representations that machines can analyze, using techniques like Bag of Words and TF-IDF.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-59b5b5bb9f78f0060c833f3b8b091e05"
      ],
      "size": 3
    },
    {
      "id": "Gemini",
      "label": "Gemini",
      "description": "Gemini is a multimodal model developed by Google DeepMind, capable of understanding various inputs and generating outputs, accessible via Vertex AI.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-f394bd66e077e288f0b983860f06c440"
      ],
      "size": 3
    },
    {
      "id": "链式法则",
      "label": "链式法则",
      "description": "链式法则是微积分中的求导法则，在反向传播中用于计算复合函数(如损失函数)对中间变量的梯度。<SEP>链式法则是微积分中的求导法则，是反向传播算法梯度计算的核心数学基础。<SEP>链式法则是链式求导法则的另一种表述，在BP算法中用于分解和计算复合函数的导数。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a815fcba7c08869c15a406f42f940fb2",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a",
        "chunk-95faa80d73b4394851b10e9cc65232d2"
      ],
      "size": 4
    },
    {
      "id": "A Survey Of Prompt Engineering Methods In Large Language Models For Different Nlp Tasks",
      "label": "A Survey Of Prompt Engineering Methods In Large Language Models For Different Nlp Tasks",
      "description": "A survey paper on prompt engineering methods for various NLP tasks.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c73155a0054fe7510b458e0f7fe666b7"
      ],
      "size": 2
    },
    {
      "id": "AlphaGo",
      "label": "AlphaGo",
      "description": "An artificial intelligence program created by a team led by DeepMind. It combines deep learning with reinforcement learning and defeated top professional Go players like Lee Sedol.<SEP>AlphaGo is an artificial intelligence algorithm that defeated top human Go players, including Ke Jie.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c",
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c"
      ],
      "size": 4
    },
    {
      "id": "Hinton",
      "label": "Hinton",
      "description": "Hinton是研究人员，在2012年ImageNet竞赛中凭借AlexNet一举夺魁。<SEP>Hinton is a person whose interview is included in the book \"Talking Nets\".",
      "domains": [
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837"
      ],
      "size": 3
    },
    {
      "id": "D-I-TASSER",
      "label": "D-I-TASSER",
      "description": "D-I-TASSER是一种融合深度学习空间约束与统计能量函数的蛋白质结构预测算法，旨在解决孤儿蛋白和多结构域蛋白的预测难题。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8"
      ],
      "size": 4
    },
    {
      "id": "对抗网络",
      "label": "对抗网络",
      "description": "对抗网络是一种前沿技术，属于机器学习领域。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-432af570193bd3df6d564434ee8bfbbb"
      ],
      "size": 2
    },
    {
      "id": "运营",
      "label": "运营",
      "description": "Operations are business functions that can be transformed through AI to enhance decision-making and value.<SEP>Operations refer to the day-to-day activities and processes within an organization that can be optimized using AI.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0e8d4ef62e491849bee6335c81b740ee",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "Perceptron",
      "label": "Perceptron",
      "description": "The perceptron is an early model of an artificial neuron proposed in the 1960s and is still in use today.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917"
      ],
      "size": 5
    },
    {
      "id": "Deep Pyramid CNN",
      "label": "Deep Pyramid CNN",
      "description": "A deep CNN characterized by a simple structure. It consists of multiple identical blocks (except the first layer), each performing a pooling operation to halve dimensions, followed by two convolutions of equal width, outputting 250 dimensions. Stacking multiple layers allows it to learn accurate semantics.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 3
    },
    {
      "id": "Electronic Health Records",
      "label": "Electronic Health Records",
      "description": "Digital versions of patient paper charts, used as data sources for building disease risk prediction models.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-fe2c7c19ec682c0e709a26a55e0b8005"
      ],
      "size": 3
    },
    {
      "id": "Transformer架构",
      "label": "Transformer架构",
      "description": "Transformer架构是大语言模型所基于的神经网络架构，用于处理序列数据，特别是在理解和生成自然语言方面表现出色。<SEP>大语言模型所基于的神经网络架构。<SEP>Transformer architecture involves millions or billions of parameters, enabling it to capture complex language patterns and nuances.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 5
    },
    {
      "id": "氨基酸序列",
      "label": "氨基酸序列",
      "description": "氨基酸序列是构成蛋白质的一级结构，是蛋白质结构预测的输入信息。<SEP>构成蛋白质的氨基酸排列顺序，是蛋白质结构预测的输入数据。",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-99be6d80a8d1a4129da56c2930cc8b6d",
        "chunk-62c73611ffdf6388dc832abdf23ad216"
      ],
      "size": 3
    },
    {
      "id": "Microsoft Azure Global Edition",
      "label": "Microsoft Azure Global Edition",
      "description": "Microsoft Azure Global Edition is the global version of Microsoft's cloud platform, hosting technical documentation.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4"
      ],
      "size": 2
    },
    {
      "id": "Large Language Model (LLM)",
      "label": "Large Language Model (LLM)",
      "description": "A type of AI model, often based on the transformer architecture, that is pre-trained on vast amounts of text data and can generate human-like text.<SEP>A Large Language Model (LLM) is trained on extensive text data using neural networks to generate text, translate, or perform other tasks, with performance improving with more data.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686",
        "chunk-f394bd66e077e288f0b983860f06c440"
      ],
      "size": 9
    },
    {
      "id": "Encoder Block",
      "label": "Encoder Block",
      "description": "Encoder Block is a component of the Transformer model, composed of Multi-Head Attention, Add & Norm, and Feed Forward layers, processing input matrices.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5"
      ],
      "size": 6
    },
    {
      "id": "计算机视觉",
      "label": "计算机视觉",
      "description": "一个领域，其中基于卷积神经网络的模型占主导地位，应用于图像识别、目标检测和语义分割等任务。<SEP>计算机视觉是一个领域，卷积神经网络是其成功的关键构建模块，应用于自动驾驶、智能医疗保健等。<SEP>Computer vision is a field of artificial intelligence where Convolutional Neural Networks (CNNs) are extensively applied for tasks like image and video processing.<SEP>计算机视觉是卷积神经网络最初相遇和应用的领域。<SEP>计算机视觉是人工智能的一个方面，涉及让机器识别和理解图像和视觉信息。<SEP>计算机视觉是人工智能的一个子领域，专注于使计算机能够从图像或视频中获取信息。<SEP>Computer Vision is a subfield of artificial intelligence that enables computers to derive meaningful information from digital images, videos, and other visual inputs.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-37f0a7ef7d63be3d8878c173058865c3",
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 3
    },
    {
      "id": "情感",
      "label": "情感",
      "description": "情感是个人体验的感觉或情绪，情感分析可以提取文本中的情感信息。<SEP>Emotion is mentioned by Wei Benqun as an aspect of human uniqueness that needs to be re-understood in the era of AI.",
      "domains": [
        "哲学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 3
    },
    {
      "id": "误差损失函数",
      "label": "误差损失函数",
      "description": "The error loss function quantifies the dissatisfaction with the network's output, such as the mean squared error between predicted and target values.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-ecf37963c494ecfacb6a6432c237dd3b"
      ],
      "size": 3
    },
    {
      "id": "Bi-LSTM",
      "label": "Bi-LSTM",
      "description": "Bidirectional LSTM, considered a very good and relatively mature approach for practical or industrial applications, balancing overall effectiveness and complexity.<SEP>一种双向的LSTM，可以学习前后上下文的特征和语义。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 4
    },
    {
      "id": "谭铁牛",
      "label": "谭铁牛",
      "description": "谭铁牛is an academician of the Chinese Academy of Sciences who provided a definition of artificial intelligence in an article published in \"求实\".",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 2
    },
    {
      "id": "赵立",
      "label": "赵立",
      "description": "赵立认为哲学思考的核心是批判性反思，必须基于实践真知和理论思维来锚定普遍性问题，以校准人工智能技术与哲学思考的发展方向。<SEP>赵立is a discussant who comments on the relationship between philosophy as a product of human creative thinking and AI as an efficient technical integration of past human thought.<SEP>Zhao Li states that philosophical thinking in the AI era must be \"based on humans, centered on humans, and for humans.\" He argues that philosophy should \"legislate\" for the use of science and technology, providing guidance and control.<SEP>A participant who discusses how AI technology shapes the era and necessitates philosophical responses, including rethinking the human-technology relationship and new social problems.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-1583b867ca44e12600f0775616185d52",
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 5
    },
    {
      "id": "Small Sorting Algorithm",
      "label": "Small Sorting Algorithm",
      "description": "Small sorting algorithms are compact computer programs for arranging data, discovered from scratch by AlphaDev.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-82b403277dd4d1f793acce70ac7e2f82"
      ],
      "size": 2
    },
    {
      "id": "Training Set",
      "label": "Training Set",
      "description": "A collection of input-output pairs used to train a neural network.<SEP>A subset of the dataset, constituting 80% (2,330,617 observations) of the total data, used to train the machine learning model.<SEP>A training set comprising 75% of the data was used to train the Deep Auto-Encoder model in Experiment Two.",
      "domains": [
        "计算机科学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070",
        "chunk-dd790e22e66ff566c3fcba5e9ed475b3",
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 5
    },
    {
      "id": "蛋白质骨架初始Residue Gas",
      "label": "蛋白质骨架初始Residue Gas",
      "description": "The initial Residue Gas for the protein backbone is the starting 3D representation input to the Structure Module.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "Amazon",
      "label": "Amazon",
      "description": "Amazon是一家使用机器学习根据客户浏览和购买历史进行产品推荐的公司。<SEP>Amazon is a technology company that developed the Alexa voice assistant.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 3
    },
    {
      "id": "全连接层",
      "label": "全连接层",
      "description": "全连接层是卷积神经网络中的一层，通常位于网络末端用于输出。<SEP>Fully connected layers are components of a CNN that perform final classification or regression tasks based on the processed features.<SEP>全连接层是神经网络中的一种层结构，其中每层节点都与上一层的所有节点相连，参数众多，容易产生过拟合。<SEP>全连接层是卷积神经网络的最后层，用于从全局出发做出最终结论，并将数据维度降低到与类别数相等。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 3
    },
    {
      "id": "Weight",
      "label": "Weight",
      "description": "Weights are parameters in a neural network model that are multiplied by input factors to calculate a weighted sum.<SEP>Weight is a parameter in neural networks whose significance was relearned clearly and profoundly by the narrator.<SEP>The fixed values within a convolution kernel (filter) used during the convolution operation.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c8c18ca634546204b03cd44a9bdee917",
        "chunk-90d06b6fbc58cfba3d096615baf2b706",
        "chunk-9654c79f59367cfc9f7483a23aec5794"
      ],
      "size": 5
    },
    {
      "id": "Transformer Model",
      "label": "Transformer Model",
      "description": "A neural network architecture adept at processing sequential data, known for its association with large language models (LLMs) and its application in fields like computer vision, speech recognition, and time series prediction.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 7
    },
    {
      "id": "Think Newsletter",
      "label": "Think Newsletter",
      "description": "The Think Newsletter is a weekly publication by IBM that provides curated insights on important and interesting AI news.<SEP>A weekly newsletter offering curated insights and analysis on the most important and interesting AI news.<SEP>Think Newsletter provides insights on important and interesting industry trends in AI, automation, data, and other areas.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-2103a1c2471cc6226897b2080204b309"
      ],
      "size": 2
    },
    {
      "id": "Residue Gas",
      "label": "Residue Gas",
      "description": "Residue Gas is a representation used for the protein structure, modeling it as a gas of 3D rigid bodies.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 3
    },
    {
      "id": "自然语言处理",
      "label": "自然语言处理",
      "description": "自然语言处理（Natural Language Processing，NLP）是人工智能和计算机科学的一个关键子领域。它专注于研究计算机与人类之间使用自然语言进行的交互，旨在让机器能够理解、解释、生成并处理人类语言。该领域结合了计算语言学、预测性人工智能以及深度学习模型等多种技术，以辨别和应对人类语言中的细微差异，从而改变人工智能理解人类思想与行为的方式。\n\n从技术构成上看，自然语言处理通常包含两个核心组成部分：自然语言理解（NLU）和自然语言生成（NLG）。其应用范围广泛，涵盖了智能问答、机器翻译、文本分析等多个重要方向。本质上，它是通过机器学习等方法，使计算机具备与人类进行有效语言交流的能力。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-747e06575d3f3c246eac89670d12c86e",
        "chunk-5ec46d561fc83169cc4cb16171e4b90d",
        "chunk-b572e7e95c9e5e07043de0b3cb587187",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-48a8f8eb7c58289118bd89b3aa9c47b3",
        "chunk-6003c974467b7a903cb83abef6cc2e24",
        "chunk-c0eefe5184862c24ce2da501217562b3",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 27
    },
    {
      "id": "生成式人工智能",
      "label": "生成式人工智能",
      "description": "生成式人工智能是一种AI技术，用于创建新内容或解决方案，可以提高投资回报率。<SEP>Generative AI is the latest technology but may not be suitable for financial forecasting as other mature models can achieve similar results with less effort and lower cost.<SEP>生成式人工智能是能够生成新内容的人工智能，自然语言处理的研究有助于推动其发展。<SEP>生成式人工智能的迅猛发展激发出新的哲学问题(如道德地位、事故归责)，并可能颠覆传统的哲学观念和视野。",
      "domains": [
        "哲学",
        "计算机科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-2103a1c2471cc6226897b2080204b309",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792",
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 5
    },
    {
      "id": "IBM",
      "label": "IBM",
      "description": "IBM（国际商业机器公司）是一家跨国科技公司。该公司在人工智能（AI）领域提供广泛的专业知识、解决方案和咨询服务，具体包括数据与AI解决方案、网络研讨会、报告和课程，以帮助企业实施AI。\n\nIBM开发了多个AI模型和平台，其中包括IBM Granite系列AI模型以及名为watsonx.ai的开发平台。在其Watson Studio和watsonx.ai平台中，IBM提供对卷积神经网络（CNN）架构的支持，以实现高性能部署，应用领域涵盖医疗影像诊断、自动驾驶感知和智能安防等。\n\n此外，IBM还提供如IBM Cloud Pak for Business Automation等解决方案，用于运营管理和自动化。公司也发布相关通讯，如Think Newsletter，并设有隐私声明。",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-1e18404a1598e3f3a1e3304e3abfc2c0",
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-2103a1c2471cc6226897b2080204b309",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 10
    },
    {
      "id": "中文分词",
      "label": "中文分词",
      "description": "深度学习的一个应用方向。<SEP>中文分词是将连续的中文文本序列切分成单独词语的过程，是中文自然语言处理的基础任务。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de"
      ],
      "size": 2
    },
    {
      "id": "Word2Vec",
      "label": "Word2Vec",
      "description": "深度学习在NLP领域火起来之前最有代表性的工作，将字或词表示为向量。<SEP>Word2Vec is an advanced word embedding method that represents words as dense vectors in a continuous space to capture semantic relationships.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-59b5b5bb9f78f0060c833f3b8b091e05"
      ],
      "size": 2
    },
    {
      "id": "Real-Time Data",
      "label": "Real-Time Data",
      "description": "Current and continuously updated weather data.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-333ff749c2940b520a06027eb3c17eac"
      ],
      "size": 2
    },
    {
      "id": "节点",
      "label": "节点",
      "description": "节点是神经网络中的基本计算单元，在分层结构中相互连接。<SEP>节点是计算图中的基本单元，在正向传播中计算输出，在反向传播中计算并传递梯度。<SEP>节点是神经网络中与神经元相连的基本单元。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-cb5e07f0bad1ec285e66b4df8be69531",
        "chunk-7844fb38c827827af06d614fe4afb4df",
        "chunk-61775650edeed94f49f7144412443478"
      ],
      "size": 4
    },
    {
      "id": "信噪比",
      "label": "信噪比",
      "description": "信噪比是衡量信号中有效信息与噪声比例的指标，文中指出中低频量化信噪比低是机器学习效果差的原因之一，而高频量化信噪比较高。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-0ff265f7709913907a277247870f20cc"
      ],
      "size": 3
    },
    {
      "id": "Bat Algorithm",
      "label": "Bat Algorithm",
      "description": "A nature-inspired optimization algorithm that simulates bat echolocation behavior, used for feature selection and reducing training costs in the deep learning fraud detection model.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-9f34e4a3e164d008eba0c74c96804047"
      ],
      "size": 2
    },
    {
      "id": "VGGNet",
      "label": "VGGNet",
      "description": "A CNN architecture known for its simplicity and depth, using very small convolutional filters.<SEP>A common CNN architecture suitable for image tasks with varying complexity and performance requirements.<SEP>VGGNet是牛津大学提出的卷积神经网络模型，采用堆积的小卷积核替代大的卷积核，以增加判别性并减少参数量。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878"
      ],
      "size": 3
    },
    {
      "id": "图像处理",
      "label": "图像处理",
      "description": "Image processing is a field where deep learning algorithms, specifically CNNs, are applied to analyze and manipulate images.<SEP>图像处理是卷积神经网络应用的一个技术领域。<SEP>Image processing is a field where deep learning technology has made breakthroughs.",
      "domains": [
        "地球科学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-70cc6b4326bedb7c4b61745cce643075"
      ],
      "size": 3
    },
    {
      "id": "Appier Blog",
      "label": "Appier Blog",
      "description": "The Appier Blog is a subscription-based content source that delivers the latest trends in marketing technology, automated marketing, industry trends, best practice cases, and Appier's viewpoints.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-93d921ef5f299976a4f4ffe79dfe7521"
      ],
      "size": 2
    },
    {
      "id": "Evaluation System",
      "label": "Evaluation System",
      "description": "A system established to evaluate the feasibility of deep learning global features, quantifying Precision@K, average ranking, feature extraction time, similarity calculation time, and hardware consumption.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-fb89c8462c112775ff8e6c43e7d050e8"
      ],
      "size": 2
    },
    {
      "id": "NNLM模型",
      "label": "NNLM模型",
      "description": "NNLM模型是一种使用神经网络建模语言的经典范例，其思路与统计语言模型保持一致。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-fd544a0511ae2b1911f2ec7bdc2235ae"
      ],
      "size": 2
    },
    {
      "id": "RNN",
      "label": "RNN",
      "description": "RNN(循环神经网络)是一种神经网络结构，文中提到了其反向传播公式的推导。<SEP>RNN is an abbreviation for Recurrent Neural Network, a type of neural network used in deep learning for encoding sequences.<SEP>Recurrent Neural Network (RNN) is a type of deep learning model used for processing sequential data.<SEP>RNN is a type of neural network that is good at remembering recent information, as mentioned in contrast to LSTM.<SEP>一种用于处理序列依赖或长时间依赖特征的神经网络模型。<SEP>循环神经网络是一种用于处理序列数据的神经网络，能够捕捉时间序列中的动态temporal behavior。<SEP>Recurrent Neural Network, a previous neural network architecture for sequential data, outperformed by transformer models.",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-95faa80d73b4394851b10e9cc65232d2",
        "chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8",
        "chunk-82bdb1406dfe17a400fa95a5a4727859",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 6
    },
    {
      "id": "原始文本",
      "label": "原始文本",
      "description": "原始文本是未经处理的文本数据，是NLP预处理的输入对象。<SEP>原始文本是未经处理的文本数据，是文本预处理的输入。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-38b1076024c94a070f64f72dcaea1102",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 3
    },
    {
      "id": "细胞状态",
      "label": "细胞状态",
      "description": "细胞状态是长短期记忆网络中用于存储长期信息的一种状态，通常称为“cell”。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 2
    },
    {
      "id": "自动微分",
      "label": "自动微分",
      "description": "自动微分是一种自动计算梯度的技术，简化了深度学习算法的实现。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-3a728b359622810cd77efd2985a7fcfd"
      ],
      "size": 2
    },
    {
      "id": "量化交易",
      "label": "量化交易",
      "description": "Quantitative trading is a field in finance that traditionally relies on technical indicators, fundamental analysis, or statistical models to make trading decisions.<SEP>量化交易是一种使用数学模型和计算机程序进行金融交易的方法，文中讨论了机器学习在其中不同频率的应用。<SEP>Quantitative trading, using mathematical models and algorithms for trading decisions.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411",
        "chunk-0ff265f7709913907a277247870f20cc",
        "chunk-6bc1d4e50f0179dd98e01918a3be7977"
      ],
      "size": 4
    },
    {
      "id": "蝴蝶效应",
      "label": "蝴蝶效应",
      "description": "The Butterfly Effect is a concept from chaos theory describing how small initial changes can lead to large, long-term chain reactions in a dynamic system.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-ecf37963c494ecfacb6a6432c237dd3b"
      ],
      "size": 2
    },
    {
      "id": "GPU",
      "label": "GPU",
      "description": "GPU(图形处理单元)是高端计算机硬件，能够有效优化深度学习所需的大量矩阵乘法运算。<SEP>GPU (Graphics Processing Unit) is a type of high-performance computing resource used for parallel computations in AI and machine learning.<SEP>图形处理器，用于高效并行计算卷积操作，使得卷积神经网络的计算更加高效。<SEP>Computational hardware required for the training and inference of deep learning models, contributing to high technical and cost thresholds.<SEP>图形处理器是一种专为并行计算设计的硬件，其加速能力对深度学习等计算密集型算法的训练速度影响巨大。",
      "domains": [
        "计算机科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-cb25bd59eb20459d90d689a472568aea",
        "chunk-37f0a7ef7d63be3d8878c173058865c3",
        "chunk-2dc1c848682669d15114cbb84e3cd6b4",
        "chunk-ba24370cf2cd1eb19282998e57cddade"
      ],
      "size": 5
    },
    {
      "id": "Lettvin",
      "label": "Lettvin",
      "description": "Lettvin is a person referenced in an interview with Jim Anderson.<SEP>A person interviewed in \"Talking nets\", a source of information about Pitts.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-c9ebca01c6cfa5bfc38e623dde85f68c",
        "chunk-e7712ad4739a66b6cf3b8376df6a6837"
      ],
      "size": 3
    },
    {
      "id": "高维数据",
      "label": "高维数据",
      "description": "High-dimensional data in quantitative trading involves massive information from different asset classes and time scales, which deep learning models can process effectively.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-279be5ddf8d39d85d83b28cea5971411"
      ],
      "size": 2
    },
    {
      "id": "机器翻译",
      "label": "机器翻译",
      "description": "机器翻译是一种深度学习应用，属于异步的多对多序列到序列问题，需要根据上下文进行翻译。<SEP>深度学习的一个应用方向。<SEP>机器翻译是使用计算机将文本或语音从一种语言自动翻译成另一种语言的技术，是自然语言处理的早期应用之一。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-c19e0a082e14fb0e3e54b47fab68066a"
      ],
      "size": 2
    },
    {
      "id": "PyTorch",
      "label": "PyTorch",
      "description": "PyTorch is an open-source machine learning framework mentioned in the context of training deep learning models using transfer learning in Azure Machine Learning.<SEP>PyTorch是一个深度学习框架，用于实现卷积神经网络模型。<SEP>PyTorch is an open-source machine learning library based on the Torch library.<SEP>PyTorch is a deep learning framework used for building and implementing models for tasks like remote sensing image object detection and segmentation.",
      "domains": [
        "地球科学",
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-80c468f42f64d269b4538a150a4f94cd",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 3
    },
    {
      "id": "DenseNet",
      "label": "DenseNet",
      "description": "A deep learning model whose performance on test datasets is relatively better, with the highest Precision@K, indicating the highest success rate.<SEP>DenseNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-fb89c8462c112775ff8e6c43e7d050e8",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 3
    },
    {
      "id": "Test Datasets",
      "label": "Test Datasets",
      "description": "The datasets used to evaluate and compare the performance of deep learning models like DenseNet, ResNet-18, and VggNet.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-fb89c8462c112775ff8e6c43e7d050e8"
      ],
      "size": 4
    },
    {
      "id": "哲学学者",
      "label": "哲学学者",
      "description": "Philosophical scholars are researchers whose personal practice is challenged by AI's capabilities in information search, integration, and analysis, potentially leading to over-reliance and loss of originality.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63"
      ],
      "size": 2
    },
    {
      "id": "AlexNet",
      "label": "AlexNet",
      "description": "A groundbreaking CNN architecture that significantly advanced the field of deep learning for computer vision.<SEP>A common CNN architecture suitable for image tasks with varying complexity and performance requirements.<SEP>AlexNet是由Hinton等人提出的卷积神经网络，在2012年ImageNet竞赛中取得超高的识别率，展示了卷积神经网络的巨大潜力。<SEP>AlexNet is a convolutional neural network model mentioned in the evolution of model structures for deep learning optimization.",
      "domains": [
        "地球科学",
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878",
        "chunk-b80301dc089946e283419441a33451d1"
      ],
      "size": 4
    },
    {
      "id": "孙民",
      "label": "孙民",
      "description": "孙民是Appier的首席人工智能科学家，对传统NLP方法的局限性和深度学习的优势发表了见解。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-5ec46d561fc83169cc4cb16171e4b90d"
      ],
      "size": 3
    },
    {
      "id": "Clear Plaster",
      "label": "Clear Plaster",
      "description": "Clear Plaster is a search query example (\"clear plaster\") used to demonstrate that AI trained with deep learning can correctly interpret it as a first-aid item rather than a decoration material.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-5ec46d561fc83169cc4cb16171e4b90d"
      ],
      "size": 2
    },
    {
      "id": "Neural Network",
      "label": "Neural Network",
      "description": "A computational model inspired by biological neural networks, consisting of interconnected layers of neurons.<SEP>A computing system inspired by biological neural networks.<SEP>A Neural Network is a computational model used in LLMs, trained on large datasets to perform tasks like text generation and translation.<SEP>A computational model inspired by biological neural networks, used as a core component in the forecasting method.",
      "domains": [
        "地球科学",
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-b0c9962abc15c97c8cc9a40c8f13e070",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81",
        "chunk-f394bd66e077e288f0b983860f06c440",
        "chunk-ed300ee31268ac8e853d58a7e20740f0"
      ],
      "size": 5
    },
    {
      "id": "AlphaFold2",
      "label": "AlphaFold2",
      "description": "AlphaFold2 is the improved version of AlphaFold that achieved a breakthrough in protein structure prediction, notably performing excellently in the CASP14 competition.<SEP>AlphaFold2是一种深度学习方法，在蛋白质结构预测领域取得了突破性进展，但其对孤儿蛋白和多结构域蛋白的预测存在短板。<SEP>AlphaFold2 is an improved version of AlphaFold that achieved a breakthrough in protein structure prediction, notably performing exceptionally well in the 14th CASP competition.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f",
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8",
        "chunk-3692370e0fbe26ddf6ddebef5657ecc2"
      ],
      "size": 6
    },
    {
      "id": "Amazon Alexa",
      "label": "Amazon Alexa",
      "description": "Amazon Alexa是亚马逊开发的语音助手，是一个聊天机器人的例子。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 3
    },
    {
      "id": "Query, Key, Value Vectors",
      "label": "Query, Key, Value Vectors",
      "description": "Three new vectors (Q, K, V) generated from the original token embedding by passing it through three parallel feedforward neural network layers, each with a unique weight matrix.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 3
    },
    {
      "id": "Convolution Operation",
      "label": "Convolution Operation",
      "description": "An operation in CNNs involving a movable small window (data window) performing element-wise multiplication and summation with an image.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-9654c79f59367cfc9f7483a23aec5794"
      ],
      "size": 5
    },
    {
      "id": "深度学习模型",
      "label": "深度学习模型",
      "description": "深度学习模型是一种能够识别复杂数据模式(如图片、文本和声音)并生成准确见解和预测的人工智能模型。<SEP>深度学习模型是基于深度神经网络架构的模型，从多层感知器到复杂的生成式AI网络，依赖反向传播进行训练。<SEP>深度学习模型是一种用于处理自然语言的神经网络方法，在2013年左右被研究者广泛使用。<SEP>深度学习模型是一种特定的机器学习模型，其分析过程需要文本经过NLP预处理转换成特定格式。<SEP>Deep learning models are used within natural language processing to handle human language.",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-cb5e07f0bad1ec285e66b4df8be69531",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-fd544a0511ae2b1911f2ec7bdc2235ae",
        "chunk-38b1076024c94a070f64f72dcaea1102",
        "chunk-b572e7e95c9e5e07043de0b3cb587187"
      ],
      "size": 6
    },
    {
      "id": "参数梯度",
      "label": "参数梯度",
      "description": "参数梯度是损失函数相对于神经网络参数的偏导数，用于在优化过程中更新参数。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-29234d7a518b3ee30e3ee9cbc39d7e68"
      ],
      "size": 2
    },
    {
      "id": "知网",
      "label": "知网",
      "description": "CNKI (China National Knowledge Infrastructure) is a platform where research papers, including master's theses on CNN training, can be downloaded.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-cb9ff55215bc8081de2f351af1fd25fe"
      ],
      "size": 3
    },
    {
      "id": "AI",
      "label": "AI",
      "description": "AI, or Artificial Intelligence, is the field of study focused on creating intelligent machines, described in the text as remaining a vain dream because its practitioners allegedly ignore brain and cognitive science.<SEP>AI (Artificial Intelligence) is a technology that can run on basic hardware for simple tasks but requires more computational power for complex models.<SEP>Artificial Intelligence, a broad field of computer science focused on creating intelligent machines.<SEP>AI is described as being trained on massive data and capable of judgment beyond human intuition, but it follows mathematical logic, emphasizes computation, causality, and recursion, and aims to execute commands and complete tasks. It lacks intuitive ability towards the external world and the reflective and negative nature of dialectical thinking.",
      "domains": [
        "哲学",
        "计算机科学",
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-90d06b6fbc58cfba3d096615baf2b706",
        "chunk-cb25bd59eb20459d90d689a472568aea",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-261214465e9e66011cd2c39022b3dc6b",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 4
    },
    {
      "id": "数据准备",
      "label": "数据准备",
      "description": "Data preparation involves collecting, cleaning, and organizing raw data for training LLMs, including steps like data cleaning, filtering, and tokenization.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 2
    },
    {
      "id": "Kernel (Filter)",
      "label": "Kernel (Filter)",
      "description": "A feature detector that moves across the receptive fields of an image in a convolutional layer to check for the presence of features.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0"
      ],
      "size": 2
    },
    {
      "id": "Fine-Tuning",
      "label": "Fine-Tuning",
      "description": "Fine-Tuning is a model adaptation process that can be made more efficient by using techniques like torch.compile and padding-free data collation.<SEP>The process of adapting a pre-trained model to a specific task.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0222ac86b3d60100ac5d03d88a69654e",
        "chunk-1bb6bf3f22f6625482a3700d160f6e81"
      ],
      "size": 4
    },
    {
      "id": "蛋白质结构预测",
      "label": "蛋白质结构预测",
      "description": "蛋白质结构预测是指借助计算机计算模拟方法从氨基酸序列推断其三维空间结构的过程。<SEP>蛋白质结构预测是生物信息学领域的研究方向，涉及预测蛋白质的三维空间结构。<SEP>Protein structure prediction is a major problem in life sciences that was significantly advanced by AlphaFold2.<SEP>Protein structure prediction is the computational task of predicting a protein's 3D structure from its amino acid sequence.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-99be6d80a8d1a4129da56c2930cc8b6d",
        "chunk-c5eafae240ac5d07dadf7c4eb744e8eb",
        "chunk-94655c02fc2c25c9a0fd0b9bf8d8dc6f",
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 7
    },
    {
      "id": "CNN",
      "label": "CNN",
      "description": "CNN（卷积神经网络，Convolutional Neural Network）是一种深度学习模型，属于深度神经网络的一个类别。它主要设计用于处理具有网格状拓扑结构的数据，如图像。其核心结构包含卷积层、池化层等，能够自动从数据中学习并提取局部特征。在计算机视觉领域，CNN是图像识别和处理的基础模型。此外，它也被应用于自然语言处理等任务中，用于提取文本的局部特征，或处理类似图像的序列数据（如金融交易中的K线图），以捕捉技术模式。\n\n值得注意的是，存在一个与上述技术实体同名的媒体实体“CNN”。该实体是一家新闻机构，曾于2021年11月9日发表一篇题为“Zillow’s home-buying debacle shows how hard it is to use AI to value real estate”的文章。此外，在金融领域，“CNN”也可能作为一种高频交易策略的计算模型基础被提及。这些描述指向了与“卷积神经网络”完全不同的实体。",
      "domains": [
        "计算机科学",
        "认知神经科学",
        "语言学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-95faa80d73b4394851b10e9cc65232d2",
        "chunk-d22adf07bd762e4e32d9bceea2fa6218",
        "chunk-61775650edeed94f49f7144412443478",
        "chunk-225c135f952fba89e32fc67dcf80d0f5",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-df57bc33c49fe522c66616c1a4be5336",
        "chunk-0424a179537a1b36c1d9bf13f9a5a922",
        "chunk-cc43c5c5bb53711c8b6a6ae6cdc8e9c8",
        "chunk-a21e1bb9888d36e0f2daf5ed5c43c4f3",
        "chunk-82bdb1406dfe17a400fa95a5a4727859",
        "chunk-2103a1c2471cc6226897b2080204b309",
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-012b11b19422c013994d2348ab5422de",
        "chunk-330f64bec90f2f131895d2de62adeb6f",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 17
    },
    {
      "id": "AI模型",
      "label": "AI模型",
      "description": "Artificial Intelligence model, a mathematical framework for making predictions or decisions based on data.<SEP>AI模型是人工智能领域的核心，通过模拟人类智能的方式使机器能够执行复杂任务，涵盖了机器学习、自然语言处理、计算机视觉等多个方面。",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-bae01b8f0bc3c1509b035bf0d8ee1771"
      ],
      "size": 7
    },
    {
      "id": "王田",
      "label": "王田",
      "description": "王田引用恩格斯的观点，认为哲学思考的不可替代性在于辩证思维方法，它既是科学思维方法的方法论前提，又能吸收和提升现代科学思维方法。<SEP>王田分析了人工智能发展对传统哲学主体概念带来的三大悖论挑战，以及人工智能引发的社会安全性、可靠性和公平性等哲学研究新视域。<SEP>王田is a lecturer in the Department of Philosophy and Culture at the Party School of the Beijing Municipal Committee of the CPC (Beijing Administrative College) and a participant in the discussion.<SEP>Wang Tian states that developing AI's \"philosophy\" first requires ensuring technological innovation is led by humans, not dominated by capital or technological logic. He cites Horkheimer and emphasizes considering social conditions and human scale.<SEP>A participant who discusses the tension between algorithmic value and philosophical value, arguing for a re-examination of labor theory of value in the AI era and the irreplaceable role of laborers.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-dd306af31a739643f5fdb50f2073ec63",
        "chunk-9443f3ff3d63c86fe69beb12e077ee15",
        "chunk-1583b867ca44e12600f0775616185d52",
        "chunk-47b980b33218327b53ee86797118fbb8",
        "chunk-c9369fc176f49069a39d1f5e88729d68"
      ],
      "size": 5
    },
    {
      "id": "计算机科学",
      "label": "计算机科学",
      "description": "计算机科学是反向传播和动态规划等技术所应用的领域。<SEP>The domain or field of study mentioned in the document metadata.<SEP>一个科学领域，与生命科学交叉，是MIT 6.874课程的核心内容之一。<SEP>计算机科学是研究计算机及其应用的学科，自然语言处理是其一个子领域。",
      "domains": [
        "生物信息学",
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-9fcf6610f361d14578f6d58fe5b5ea26",
        "chunk-225c135f952fba89e32fc67dcf80d0f5",
        "chunk-dcad4a5abb7347f0e6403bab97eb576b",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 3
    },
    {
      "id": "部署需求",
      "label": "部署需求",
      "description": "Deployment requirements refer to the technical and operational needs for integrating an AI model into a production environment.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 3
    },
    {
      "id": "Weather Forecasting",
      "label": "Weather Forecasting",
      "description": "The application of science and technology to predict atmospheric conditions, addressed by the ensemble neural network method.<SEP>The process of predicting future weather conditions.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-ed300ee31268ac8e853d58a7e20740f0",
        "chunk-333ff749c2940b520a06027eb3c17eac"
      ],
      "size": 5
    },
    {
      "id": "Linear Layer",
      "label": "Linear Layer",
      "description": "Linear Layer is a fully connected layer used in the Transformer to project the concatenated outputs from multiple attention heads into the final output dimension.<SEP>A neural network layer where each parallel subset has a unique weight matrix learned during pre-training.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 5
    },
    {
      "id": "链式求导法则",
      "label": "链式求导法则",
      "description": "链式求导法则是微积分中的一种求导方法，在BP算法的推导中被用于计算误差对网络权重的导数。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a"
      ],
      "size": 3
    },
    {
      "id": "Evoformer",
      "label": "Evoformer",
      "description": "Evoformer is an attention-based architecture within AlphaFold2 used for processing MSA and template information.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-224a7273b9442fd233a7ec61f799fa44"
      ],
      "size": 2
    },
    {
      "id": "CRF",
      "label": "CRF",
      "description": "Conditional Random Fields, a traditional model that performs well for sequence labeling tasks.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-330f64bec90f2f131895d2de62adeb6f"
      ],
      "size": 4
    },
    {
      "id": "David Silver",
      "label": "David Silver",
      "description": "David Silver是AlphaGo项目的主要负责人，他发表了关于深度学习与强化学习结合构成人工智能的言论。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade"
      ],
      "size": 2
    },
    {
      "id": "Convolutional Neural Network (CNN)",
      "label": "Convolutional Neural Network (CNN)",
      "description": "A class of deep learning models specifically designed for image recognition and object detection, capable of automatically extracting image features and performing classification tasks through the combination of convolutional layers, pooling layers, and fully connected layers.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0"
      ],
      "size": 8
    },
    {
      "id": "IBM Watsonx.Ai",
      "label": "IBM Watsonx.Ai",
      "description": "IBM Watsonx.Ai is an enterprise-grade development platform for AI builders, enabling the training, validation, tuning, and deployment of generative AI, foundation models, and machine learning capabilities.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-833d835632b095e419f4a96b3c5dac04"
      ],
      "size": 3
    },
    {
      "id": "Protein Structure Prediction",
      "label": "Protein Structure Prediction",
      "description": "Protein structure prediction is the ability to accurately predict protein structures based on amino acid sequences, expected to benefit life sciences.<SEP>Protein structure prediction is a scientific problem that AlphaFold2 solved, representing a significant breakthrough for life sciences research.<SEP>Protein structure prediction is a field of research focused on determining the three-dimensional structure of proteins from their amino acid sequences.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-d23247c8edaf8929e7855d9186007c46",
        "chunk-3692370e0fbe26ddf6ddebef5657ecc2",
        "chunk-cfa0a8834ed9c35960b3f0264cbc2d1d"
      ],
      "size": 4
    },
    {
      "id": "代理式AI",
      "label": "代理式AI",
      "description": "代理式AI是人工智能的一种类型，常与生成式AI进行对比。<SEP>Agent AI combines automation technology with the creativity of LLMs; its communication with tools involves orchestration, allowing LLMs to \"reason\" and determine the best way to answer questions.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-4d514ef014c3cb4cb7fc652928e9a4a4",
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "深度卷积网络",
      "label": "深度卷积网络",
      "description": "深度卷积网络是通过层层堆叠卷积层构成的网络，层数越多，对复杂特征的表达能力越强。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-0424a179537a1b36c1d9bf13f9a5a922"
      ],
      "size": 3
    },
    {
      "id": "风控建模方法",
      "label": "风控建模方法",
      "description": "一种基于深度学习的金融风险控制建模方法，包含从云端数据库获取并处理用户数据的步骤。",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-ead8239d6c7d35f7d27952face0dd715"
      ],
      "size": 3
    },
    {
      "id": "Technical Path and Philosophical Review of Deep Learning",
      "label": "Technical Path and Philosophical Review of Deep Learning",
      "description": "论文的英文标题。",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-ea37ab1462f7ff56b1e76b106d6df9dd"
      ],
      "size": 2
    },
    {
      "id": "GPT-3",
      "label": "GPT-3",
      "description": "A generative pre-trained transformer model developed by OpenAI, which catalyzed the modern era of generative AI and powered the release of ChatGPT.<SEP>GPT-3 is a specific large language model developed by OpenAI, known for its powerful text generation capabilities.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-670e03b55717cd9c769f3cf5e85b2686",
        "chunk-c0eefe5184862c24ce2da501217562b3"
      ],
      "size": 5
    },
    {
      "id": "移动广告数据",
      "label": "移动广告数据",
      "description": "Data obtained from mobile advertising, which undergoes preprocessing as part of the detection method.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-a6a52780a97b8eca9204ad8ed2f86840"
      ],
      "size": 2
    },
    {
      "id": "HIPAA",
      "label": "HIPAA",
      "description": "HIPAA is a data privacy law that organizations must comply with when deploying AI systems.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-1b739ad6a105eb84f8c6e5dd40826bdc"
      ],
      "size": 3
    },
    {
      "id": "Multi-Head Attention",
      "label": "Multi-Head Attention",
      "description": "Multi-Head Attention is a mechanism within the Transformer, consisting of multiple Self-Attention heads, used to compute attention across different representation subspaces.<SEP>A technique used in transformer models where the attention mechanism is applied multiple times in parallel, allowing the model to jointly attend to information from different representation subspaces.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-3ac3b580cca11b5e1d0122810a6ec5f5",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 6
    },
    {
      "id": "Google DeepMind",
      "label": "Google DeepMind",
      "description": "Google DeepMind is an organization that trained a reinforcement learning agent called AlphaDev.<SEP>Google DeepMind is an organization that develops and tests innovative technologies, including the Gemini model, which are integrated into Google Cloud.",
      "domains": [
        "生物信息学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-82b403277dd4d1f793acce70ac7e2f82",
        "chunk-f394bd66e077e288f0b983860f06c440"
      ],
      "size": 4
    },
    {
      "id": "生物视觉系统",
      "label": "生物视觉系统",
      "description": "The biological visual system, particularly the research by Hubel and Wiesel, served as the inspiration for the architectural design of Convolutional Neural Networks.<SEP>生物视觉系统的研究启发了福岛邦彦提出层级化的人工神经网络。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-cb9ff55215bc8081de2f351af1fd25fe",
        "chunk-0a618e37c4fa120a22ba1b02c9ff4878"
      ],
      "size": 3
    },
    {
      "id": "哲学价值",
      "label": "哲学价值",
      "description": "The value manifested in critical insight and meaning creation, which cannot be replaced or commensurated by algorithmic value.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 3
    },
    {
      "id": "Overfitting",
      "label": "Overfitting",
      "description": "A risk in machine learning where a model performs well on training data but poorly on unseen data; pooling layers in CNNs help limit this risk.<SEP>A risk where deep learning models perform well on training data but poorly on unseen data due to memorizing historical noise instead of genuine market patterns.",
      "domains": [
        "计算机科学",
        "金融学"
      ],
      "source_chunks": [
        "chunk-2d11b22a41860af6077284a29530e1e0",
        "chunk-2dc1c848682669d15114cbb84e3cd6b4"
      ],
      "size": 3
    },
    {
      "id": "近代启蒙思想家",
      "label": "近代启蒙思想家",
      "description": "Modern Enlightenment thinkers inspired people's pursuit of freedom, equality, and democratic ideals.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-9443f3ff3d63c86fe69beb12e077ee15"
      ],
      "size": 2
    },
    {
      "id": "马克思劳动价值论",
      "label": "马克思劳动价值论",
      "description": "A theory stating that the value of data elements still condenses in human labor.",
      "domains": [
        "哲学"
      ],
      "source_chunks": [
        "chunk-47b980b33218327b53ee86797118fbb8"
      ],
      "size": 2
    },
    {
      "id": "Text Analysis",
      "label": "Text Analysis",
      "description": "Text analysis involves interpreting and extracting meaningful information from text data using various computational techniques.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-59b5b5bb9f78f0060c833f3b8b091e05"
      ],
      "size": 2
    },
    {
      "id": "文本挖掘",
      "label": "文本挖掘",
      "description": "文本挖掘是从非结构化文本数据中提取有价值信息和模式的过程，是自然语言处理的一个应用方向。<SEP>文本挖掘是从非结构化文本数据中提取信息和发现模式的技术。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 4
    },
    {
      "id": "Nature Biotechnology",
      "label": "Nature Biotechnology",
      "description": "Nature Biotechnology是国际生物技术领域的顶尖期刊，是Nature系列期刊之一，发表了关于D-I-TASSER算法的研究论文。<SEP>An authoritative biomedical journal where dozens of papers have been published.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8",
        "chunk-95ce0b0b365782f95d313a054721a437"
      ],
      "size": 3
    },
    {
      "id": "深度学习系统",
      "label": "深度学习系统",
      "description": "深度学习系统是计算机科学领域中的一种系统类型，主要包含卷积神经网络和循环神经网络两种不同架构。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-c79065b95e8586e85c1d4a6dfcdb5d37"
      ],
      "size": 3
    },
    {
      "id": "自编码器",
      "label": "自编码器",
      "description": "自编码器是一种执行无监督学习任务的神经网络结构，旨在学习数据的重新表达或编码。<SEP>自编码器是一种前馈神经网络，最初用于数据降维和特征提取，现在也用于生成模型，例如生成图片。",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-e101b215c048456f8049a66e9ebd2c54",
        "chunk-0c8c61555719c99f2248173e3fd5ae4f"
      ],
      "size": 4
    },
    {
      "id": "Hidden Layer Variable",
      "label": "Hidden Layer Variable",
      "description": "An intermediate variable h in ℝ^h, which is the result of applying an activation function to the intermediate variable z.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-75a5bc7ce82bf1f70e397344566d62eb"
      ],
      "size": 3
    },
    {
      "id": "分层结构",
      "label": "分层结构",
      "description": "分层结构是神经网络的组织形式，节点或神经元在其中互连。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-cb5e07f0bad1ec285e66b4df8be69531"
      ],
      "size": 3
    },
    {
      "id": "生成式AI",
      "label": "生成式AI",
      "description": "生成式AI是AI的一个子集，使用深度学习等技术生成新的内容，如图像、文本或音频。<SEP>Generative AI is a technology that can improve return on investment and is used to build innovative solutions.<SEP>Generative AI is a technology that can be used to build innovative solutions and improve investment returns.<SEP>生成式AI是指能够生成新内容(如文本、图像)的人工智能，其复杂深度神经网络架构的训练依赖于反向传播。<SEP>Generative AI, a type of artificial intelligence that can create new content, such as text or images.<SEP>生成式AI是人工智能的一种类型，可以创建新的内容，常与代理式AI进行对比。",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-0e8d4ef62e491849bee6335c81b740ee",
        "chunk-072c6009a64360fcdc975b14582a2c8c",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42",
        "chunk-4d514ef014c3cb4cb7fc652928e9a4a4"
      ],
      "size": 12
    },
    {
      "id": "Quantitative Trading",
      "label": "Quantitative Trading",
      "description": "Quantitative Trading is a field being reshaped by deep learning, offering advanced tools for market analysis and investment decisions.",
      "domains": [
        "金融学"
      ],
      "source_chunks": [
        "chunk-d9ecda3ea425b03f3129938c0ba44219"
      ],
      "size": 4
    },
    {
      "id": "Nature Methods",
      "label": "Nature Methods",
      "description": "Nature Methods is a high-level SCI journal where over 50 articles have been published.<SEP>Nature Methods是郑伟教授发表过文章的高水平SCI期刊之一。<SEP>Nature Methods is a journal that named protein structure prediction as its 2021 Method of the Year.",
      "domains": [
        "生物信息学"
      ],
      "source_chunks": [
        "chunk-a4bf6e4cf6f9e616e1d6f994a99479a8",
        "chunk-95ce0b0b365782f95d313a054721a437",
        "chunk-3692370e0fbe26ddf6ddebef5657ecc2"
      ],
      "size": 3
    },
    {
      "id": "混沌理论",
      "label": "混沌理论",
      "description": "Chaos theory studies nonlinear dynamical systems that are sensitive to initial conditions, with phenomena like the butterfly effect.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-ecf37963c494ecfacb6a6432c237dd3b"
      ],
      "size": 3
    },
    {
      "id": "特征提取",
      "label": "特征提取",
      "description": "特征提取是机器学习中的一种技术，通过从数据中识别和选择关键信息来告知算法如何进行准确的预测。<SEP>特征提取是将原始文本转换为数字表示的过程，以便机器分析。",
      "domains": [
        "计算机科学",
        "语言学"
      ],
      "source_chunks": [
        "chunk-0a7f0ecd8f00998a373494f4a3fd9ab4",
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 4
    },
    {
      "id": "Positional Encoding",
      "label": "Positional Encoding",
      "description": "A technique used in Transformer models where embedding values are scaled by the square root of the embedding dimension and then added to positional encodings that range between -1 and 1.<SEP>A technique where a value vector is added to a token's embedding based on its relative position before it enters the attention mechanism, helping the model learn to pay more attention to nearby tokens.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ad8f11550a8a8807684e7ecc93a2a801",
        "chunk-670e03b55717cd9c769f3cf5e85b2686"
      ],
      "size": 3
    },
    {
      "id": "Knowledge Base",
      "label": "Knowledge Base",
      "description": "知识数据库是一种人工智能形式，它可能不那么智能，但属于AI的范畴。<SEP>A Knowledge Base is an external repository of information from which RAG retrieves relevant data to inform its answer generation.<SEP>An external repository of information used in the Retrieval-Augmented Generation technique to retrieve relevant data.",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-ba24370cf2cd1eb19282998e57cddade",
        "chunk-0222ac86b3d60100ac5d03d88a69654e",
        "chunk-4f9864ecff092ef091c227f6ebb2d69f"
      ],
      "size": 4
    },
    {
      "id": "统计NLP",
      "label": "统计NLP",
      "description": "统计NLP是使用机器学习自动提取、分类和标记文本元素并分配统计可能性的方法。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-0e7e40a218a89d1fc6c27eae7e866792"
      ],
      "size": 2
    },
    {
      "id": "AI应用程序",
      "label": "AI应用程序",
      "description": "AI applications are software programs that can be built quickly with minimal data using platforms like IBM watsonx.ai.<SEP>AI applications can be built quickly using a small subset of data on platforms like IBM watsonx.ai.<SEP>AI applications are software programs that utilize artificial intelligence to perform specific tasks or provide services.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-d7b8dfbe2e2307428f725f64c9ea6c19",
        "chunk-0e8d4ef62e491849bee6335c81b740ee",
        "chunk-6ea76c6cb7ba7180cc09124704c29e42"
      ],
      "size": 5
    },
    {
      "id": "语料库",
      "label": "语料库",
      "description": "语料库是用于语言学习的大量文本集合，通常来自新闻网站、维基百科和Reddit等来源。<SEP>语料库是大量文本数据的集合，用于训练和评估自然语言处理模型，其质量对统计模型的效果至关重要。",
      "domains": [
        "语言学"
      ],
      "source_chunks": [
        "chunk-5ec46d561fc83169cc4cb16171e4b90d",
        "chunk-ba24370cf2cd1eb19282998e57cddade"
      ],
      "size": 3
    },
    {
      "id": "计算图",
      "label": "计算图",
      "description": "计算图是一种用于可视化计算中操作符和变量依赖关系的图形表示。<SEP>计算图是深度学习中的一种数据结构，用于表示计算过程，是执行前向传播和反向传播算法的框架。",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-3a728b359622810cd77efd2985a7fcfd",
        "chunk-a5ecc39f0afdf3e1ae562d6befd49d9a"
      ],
      "size": 2
    },
    {
      "id": "McCulloch-Pitts Network",
      "label": "McCulloch-Pitts Network",
      "description": "The McCulloch-Pitts network is a simplified binary model of neural activity and an early form of a finite automaton.",
      "domains": [
        "认知神经科学"
      ],
      "source_chunks": [
        "chunk-6de93055a89fdb2a0b2d1eab2a75410c"
      ],
      "size": 2
    },
    {
      "id": "卷积平摊",
      "label": "卷积平摊",
      "description": "Convolution flattening is a concept mentioned in the context of explaining the principles of Convolutional Neural Networks in deep learning.",
      "domains": [
        "计算机科学"
      ],
      "source_chunks": [
        "chunk-8fdf6fb33dcdd2dacd4cd9bce21714bc"
      ],
      "size": 2
    },
    {
      "id": "深度学习地球系统模型",
      "label": "深度学习地球系统模型",
      "description": "A deep learning-based Earth system model (DLESyM) that uses two parallel neural networks to simulate the ocean and atmosphere, capable of accurate short-term predictions and simulating climate over a 1000-year period.",
      "domains": [
        "地球科学"
      ],
      "source_chunks": [
        "chunk-b7e84880c36323dbbf1d92748718a1d1"
      ],
      "size": 4
    }
  ],
  "edges": [
    {
      "source": "基于规则的NLP",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理结合基于规则的NLP方法。"
    },
    {
      "source": "二维卷积层",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "二维卷积层是卷积神经网络中最常见的一种卷积层类型。"
    },
    {
      "source": "LLM",
      "target": "深度学习",
      "relation": "related",
      "description": "LLMs, including their Transformer architecture and parameters, are components of the broader deep learning structure used for training."
    },
    {
      "source": "LLM",
      "target": "人工智能",
      "relation": "related",
      "description": "LLM is the abbreviation for Large Language Model, which is a subset and important branch of the AI field.<SEP>LLM(大语言模型)是人工智能领域的一个应用概念。"
    },
    {
      "source": "LLM",
      "target": "机器学习模型",
      "relation": "related",
      "description": "LLM is a specific type of machine learning model with advanced language understanding and generation capabilities."
    },
    {
      "source": "LLM",
      "target": "聊天机器人",
      "relation": "related",
      "description": "LLMs can be implemented in chatbots to provide applications like 24/7 customer support."
    },
    {
      "source": "LLM",
      "target": "客户支持",
      "relation": "related",
      "description": "LLMs can help supplement or fully undertake customer support tasks, automating this function."
    },
    {
      "source": "LLM",
      "target": "语言翻译",
      "relation": "related",
      "description": "Language translation is one of the capabilities of LLMs."
    },
    {
      "source": "LLM",
      "target": "GPT-3",
      "relation": "related",
      "description": "GPT-3 is a specific, well-known instance of a Large Language Model."
    },
    {
      "source": "LLM",
      "target": "Transformer架构",
      "relation": "related",
      "description": "The Transformer architecture, with its millions/billions of parameters, is the core technology that enables LLMs to capture complex language patterns."
    },
    {
      "source": "LLM",
      "target": "AI黑话揭秘",
      "relation": "related",
      "description": "文章《AI黑话揭秘》旨在解释LLM(大语言模型)及其相关概念。"
    },
    {
      "source": "LLM",
      "target": "大模型",
      "relation": "related",
      "description": "Large Language Models (LLMs) are a specific and prominent type of Large Model focused on language tasks."
    },
    {
      "source": "LLM",
      "target": "RAG",
      "relation": "related",
      "description": "RAG enhances LLMs by integrating them with external knowledge retrieval to improve answer accuracy."
    },
    {
      "source": "LLM",
      "target": "红帽AI",
      "relation": "related",
      "description": "红帽AI提供对LLM等第三方模型库的访问权限。"
    },
    {
      "source": "LLM",
      "target": "SLM",
      "relation": "related",
      "description": "LLM和SLM是两种不同类型的语言模型，常被放在一起进行对比。"
    },
    {
      "source": "LLM",
      "target": "数据准备",
      "relation": "related",
      "description": "Data preparation is the foundational step for collecting, cleaning, and organizing the raw data used to train LLMs."
    },
    {
      "source": "LLM",
      "target": "检索增强生成(RAG)",
      "relation": "related",
      "description": "RAG is an architecture designed to augment the knowledge of LLMs by connecting them to external data sources."
    },
    {
      "source": "LLM",
      "target": "代理式AI",
      "relation": "related",
      "description": "Agent AI combines with LLMs to enhance their capabilities, allowing for automated reasoning and interaction with tools."
    },
    {
      "source": "LLM",
      "target": "GDPR",
      "relation": "related",
      "description": "Organizations deploying LLMs must ensure compliance with data privacy laws like GDPR."
    },
    {
      "source": "LLM",
      "target": "HIPAA",
      "relation": "related",
      "description": "Organizations deploying LLMs must ensure compliance with data privacy laws like HIPAA."
    },
    {
      "source": "LLM",
      "target": "人机回圈",
      "relation": "related",
      "description": "Human-in-the-loop strategies are crucial for establishing accountability and oversight in the development and deployment of LLMs."
    },
    {
      "source": "LLM",
      "target": "数据分析",
      "relation": "related",
      "description": "LLMs can help supplement or fully undertake data analysis tasks, automating this function."
    },
    {
      "source": "研究",
      "target": "深度学习",
      "relation": "related",
      "description": "这项研究深入探讨了深度学习中通过优化实现有效学习的机制。"
    },
    {
      "source": "研究",
      "target": "认知神经科学",
      "relation": "related",
      "description": "这项研究属于认知神经科学领域。"
    },
    {
      "source": "卷积核",
      "target": "卷积层",
      "relation": "related",
      "description": "卷积层使用卷积核与输入图像进行卷积操作。<SEP>卷积层使用卷积核进行运算，卷积核具有共享权重的特性，能大幅减少参数数量。"
    },
    {
      "source": "卷积核",
      "target": "卷积操作",
      "relation": "related",
      "description": "卷积操作是使用卷积核对输入图像执行的运算。"
    },
    {
      "source": "高强度计算平台",
      "target": "交易员",
      "relation": "related",
      "description": "Traders operate on a high-intensity computing platform to perform data exploration, model development, and model consumption."
    },
    {
      "source": "Attention",
      "target": "Attention Sublayer",
      "relation": "related",
      "description": "The attention sublayer implements the attention mechanism, which weights input parts based on context."
    },
    {
      "source": "Attention",
      "target": "Alphafold2",
      "relation": "related",
      "description": "AlphaFold2 uses the Attention mechanism to integrate 1D and 2D information."
    },
    {
      "source": "Attention",
      "target": "Deep Pyramid CNN",
      "relation": "related",
      "description": "Deep Pyramid CNN incorporates Attention mechanisms at different levels (word and sentence) to filter important information, making the model partially interpretable by highlighting important words and sentences."
    },
    {
      "source": "Attention",
      "target": "Generative Summarization",
      "relation": "related",
      "description": "Generative summarization models incorporate an attention mechanism to focus on useful information during decoding, enabling the generation of sequences like news headlines."
    },
    {
      "source": "主持人",
      "target": "人工智能",
      "relation": "related",
      "description": "The host raises questions about the challenges that the development of Artificial Intelligence poses to philosophical research."
    },
    {
      "source": "主持人",
      "target": "哲学",
      "relation": "related",
      "description": "主持人提出问题，引导讨论聚焦于哲学思考的不可替代性这一真问题。"
    },
    {
      "source": "主持人",
      "target": "马克思劳动价值论",
      "relation": "related",
      "description": "The moderator raises a question based on Marx's labor theory of value."
    },
    {
      "source": "Artificial Intelligence",
      "target": "Deep Learning",
      "relation": "related",
      "description": "Deep learning is a subfield within the broader domain of artificial intelligence."
    },
    {
      "source": "Artificial Intelligence",
      "target": "McCulloch-Pitts Network",
      "relation": "related",
      "description": "The abstract model of the McCulloch-Pitts network provided a foundational concept for the field of Artificial Intelligence."
    },
    {
      "source": "Artificial Intelligence",
      "target": "Traditional Fraud Detection Systems",
      "relation": "related",
      "description": "Current traditional fraud detection systems rely on Artificial Intelligence as a foundational technology."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "深度学习",
      "relation": "related",
      "description": "Geoffrey Hinton is a foundational figure who made outstanding contributions to deep learning, including inventing key training methods in 2006."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "人工神经网络",
      "relation": "related",
      "description": "Geoffrey Hinton has long been dedicated to optimizing the learning process of artificial neural networks."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "Google",
      "relation": "related",
      "description": "Geoffrey Hinton worked part-time for Google."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "反向传播算法",
      "relation": "related",
      "description": "Geoffrey Hinton, along with peers, promoted the widespread application of the Back-propagation algorithm."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "Deep Learning",
      "relation": "related",
      "description": "Geoffrey Hinton co-authored the introductory review article on deep learning.<SEP>Geoffrey Hinton made prominent contributions that helped drive the deep learning revolution."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "Yann LeCun",
      "relation": "related",
      "description": "Both Geoffrey Hinton and Yann LeCun are foundational figures in deep learning, and their perseverance is seen as a testament to the rewards of坚守(perseverance)."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "神经科学",
      "relation": "related",
      "description": "Geoffrey Hinton transplanted the layered organizational principle of the cerebral cortex into artificial neural networks, inspiring his 2006 deep learning training method."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "Talking Nets",
      "relation": "related",
      "description": "The book \"Talking nets\" contains an interview with Geoffrey Hinton."
    },
    {
      "source": "Geoffrey Hinton",
      "target": "Christian Ideology",
      "relation": "related",
      "description": "Geoffrey Hinton was convinced that Christian ideology was complete rubbish during his childhood and schooling."
    },
    {
      "source": "情感分析",
      "target": "自然語言處理",
      "relation": "related",
      "description": "建立在深度學習上的自然語言處理機制可以更精準地進行情感分析，判斷使用者的搜尋意圖和感受。"
    },
    {
      "source": "情感分析",
      "target": "人工智慧",
      "relation": "related",
      "description": "人工智慧透過情感分析，根據使用者搜尋的關鍵字組合(如「宿霧」和「地震」)來判定其是否為合適的行銷對象。"
    },
    {
      "source": "情感分析",
      "target": "文本分类",
      "relation": "related",
      "description": "文本分类和情感分析都属于深度学习中“多对一”类型的应用，即输入序列输出单一结果。"
    },
    {
      "source": "情感分析",
      "target": "文本挖掘",
      "relation": "related",
      "description": "情感分析是文本挖掘中使用的一种技术，用于提取文本中的主观特质。"
    },
    {
      "source": "情感分析",
      "target": "情感",
      "relation": "related",
      "description": "情感分析可以从文本中提取情感等主观特质。"
    },
    {
      "source": "非线性激活函数",
      "target": "多层感知机",
      "relation": "related",
      "description": "多层感知机表达能力的提升依赖于非线性激活函数的复合作用。"
    },
    {
      "source": "VggNet",
      "target": "Deep Learning",
      "relation": "related",
      "description": "VggNet is a specific deep learning model evaluated within the study."
    },
    {
      "source": "VggNet",
      "target": "Test Datasets",
      "relation": "related",
      "description": "VggNet's relatively better performance is evaluated based on the test datasets."
    },
    {
      "source": "并行计算",
      "target": "深度学习",
      "relation": "related",
      "description": "深度学习的算法训练速度极大地依赖于GPU等并行计算技术的加速。"
    },
    {
      "source": "Recycling多轮迭代",
      "target": "Alphafold2",
      "relation": "related",
      "description": "AlphaFold2 employs a recycling process of multiple iterations to refine its structure predictions."
    },
    {
      "source": "关键词",
      "target": "深度学习",
      "relation": "related",
      "description": "“深度学习”是论文关键词列表中的一个核心术语。"
    },
    {
      "source": "关键词",
      "target": "人工智能",
      "relation": "related",
      "description": "“人工智能”是论文关键词列表中的一个核心术语。"
    },
    {
      "source": "关键词",
      "target": "技术哲学",
      "relation": "related",
      "description": "“技术哲学”是论文关键词列表中的一个核心术语。"
    },
    {
      "source": "Cross-Attention",
      "target": "Attention Mechanism",
      "relation": "related",
      "description": "Cross-Attention is a specific type of Attention Mechanism used in the decoder to attend to encoder outputs."
    },
    {
      "source": "参数",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播遍历网络以计算关于模型参数(如权重矩阵)的梯度。"
    },
    {
      "source": "参数",
      "target": "Transformer架构",
      "relation": "related",
      "description": "Parameters are the fundamental, numerous components of the Transformer architecture that enable its learning capacity."
    },
    {
      "source": "Sigmoid",
      "target": "Activation Function",
      "relation": "related",
      "description": "Sigmoid is a specific type of activation function used in neural networks."
    },
    {
      "source": "Sigmoid",
      "target": "Gradient",
      "relation": "related",
      "description": "The gradient of the Sigmoid function is calculated and plotted, which is essential for training neural networks."
    },
    {
      "source": "Sigmoid",
      "target": "Tanh",
      "relation": "related",
      "description": "The text presents a mathematical proof showing the identity tanh(x) + 1 = 2 * sigmoid(2x), establishing a formal relationship between the two functions."
    },
    {
      "source": "机器学习模型",
      "target": "NLP预处理",
      "relation": "related",
      "description": "NLP预处理将文本准备好，以便机器学习模型能够对其进行分析。"
    },
    {
      "source": "长短期记忆网络",
      "target": "RNN",
      "relation": "related",
      "description": "RNN is good at remembering recent information, while LSTM extends this capability to remember both long-term and short-term information."
    },
    {
      "source": "长短期记忆网络",
      "target": "时间序列数据",
      "relation": "related",
      "description": "Long Short-Term Memory networks (LSTM) are applied to capture complex relationships and long-term dependencies within time series data."
    },
    {
      "source": "长短期记忆网络",
      "target": "价格预测",
      "relation": "related",
      "description": "Long Short-Term Memory networks (LSTM) are used for the application of price prediction in quantitative trading."
    },
    {
      "source": "长短期记忆网络",
      "target": "细胞状态",
      "relation": "related",
      "description": "长短期记忆网络通过细胞状态来存储长期信息，这是其区别于传统循环神经网络的关键。"
    },
    {
      "source": "长短期记忆网络",
      "target": "文本分类",
      "relation": "related",
      "description": "长短期记忆网络能够记忆长短期语义信息，对文本分类等序列建模任务中的特征选择有很大帮助。"
    },
    {
      "source": "Panel_Trader",
      "target": "深度学习",
      "relation": "related",
      "description": "The user 'Panel_Trader' recommended deep learning as suitable for large-sample, high-frequency data."
    },
    {
      "source": "Panel_Trader",
      "target": "线性模型",
      "relation": "related",
      "description": "The user 'Panel_Trader' recommended linear models as suitable for small-sample, low-frequency data."
    },
    {
      "source": "象牙山李宝库",
      "target": "Python",
      "relation": "related",
      "description": "The user distinguished using Python for basic data scraping and analysis from more advanced machine learning tasks."
    },
    {
      "source": "象牙山李宝库",
      "target": "量化交易",
      "relation": "related",
      "description": "The user '象牙山李宝库' discussed the field of quantitative trading."
    },
    {
      "source": "象牙山李宝库",
      "target": "高频交易",
      "relation": "related",
      "description": "The user mentioned high-frequency trading as a specific type within quantitative trading, requiring a large team and high mathematical modeling skills."
    },
    {
      "source": "象牙山李宝库",
      "target": "财务分析",
      "relation": "related",
      "description": "The user gave financial analysis as an example where quantitative data analysis significantly speeds up the process compared to traditional methods."
    },
    {
      "source": "反向传播算法",
      "target": "人工神经网络",
      "relation": "related",
      "description": "反向传播算法是训练人工神经网络最常用且最有效的算法。"
    },
    {
      "source": "反向传播算法",
      "target": "梯度",
      "relation": "related",
      "description": "反向传播算法的核心是通过计算损失函数对网络参数的梯度来优化网络。"
    },
    {
      "source": "反向传播算法",
      "target": "链式法则",
      "relation": "related",
      "description": "反向传播算法的本质是微积分中链式法则的应用。"
    },
    {
      "source": "反向传播算法",
      "target": "激活函数",
      "relation": "related",
      "description": "文中分析激活函数(如Sigmoid)的特性会影响反向传播算法中的梯度扩散问题。"
    },
    {
      "source": "反向传播算法",
      "target": "权重",
      "relation": "related",
      "description": "反向传播算法通过公式3计算权重的梯度，用于后续的参数更新。"
    },
    {
      "source": "反向传播算法",
      "target": "梯度下降",
      "relation": "related",
      "description": "梯度下降优化算法利用反向传播算法计算出的梯度来更新网络权重。"
    },
    {
      "source": "反向传播算法",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "卷积神经网络的训练也使用反向传播算法，其卷积层的梯度推导是重点。<SEP>Convolutional Neural Networks can be trained using the backpropagation algorithm."
    },
    {
      "source": "反向传播算法",
      "target": "RNN",
      "relation": "related",
      "description": "反向传播算法也应用于训练RNN，文中提到了RNN反向传播公式的推导。"
    },
    {
      "source": "反向传播算法",
      "target": "CNN",
      "relation": "related",
      "description": "反向传播算法是训练CNN的核心，文中重点探讨了CNN中卷积层的反向传播梯度推导。"
    },
    {
      "source": "反向传播算法",
      "target": "多层感知机",
      "relation": "related",
      "description": "多层感知机在1980年代通过反向传播算法取得了重大进展。"
    },
    {
      "source": "LLaMA",
      "target": "Large Language Model",
      "relation": "related",
      "description": "LLaMA is a common example of a Large Language Model."
    },
    {
      "source": "Feature Map",
      "target": "CNN",
      "relation": "related",
      "description": "The convolutional layers in the CNN generate feature maps, which are then processed by max-pooling."
    },
    {
      "source": "Feature Map",
      "target": "Convolution Operation",
      "relation": "related",
      "description": "Applying a convolution operation to an input image produces an output called a feature map."
    },
    {
      "source": "Feature Map",
      "target": "Convolutional Layer",
      "relation": "related",
      "description": "The application of a filter to input data during convolution produces a feature map, which represents the extracted features."
    },
    {
      "source": "Feature Map",
      "target": "单层CNN",
      "relation": "related",
      "description": "The single-layer CNN generates feature maps by applying several types of convolution operations."
    },
    {
      "source": "TF-IDF",
      "target": "特征提取",
      "relation": "related",
      "description": "TF-IDF是特征提取过程中使用的一种技术。"
    },
    {
      "source": "TF-IDF",
      "target": "特征工程",
      "relation": "related",
      "description": "特征工程中会根据TF-IDF等方式去算特征值或对特征进行过滤排序。<SEP>在传统机器学习的特征工程中，会使用TF-IDF等方法来计算特征值。"
    },
    {
      "source": "性能",
      "target": "AI模型",
      "relation": "related",
      "description": "Performance is a key factor to consider when choosing an AI model."
    },
    {
      "source": "性能",
      "target": "最佳模型",
      "relation": "related",
      "description": "Balancing performance with other factors helps determine the best model."
    },
    {
      "source": "数学方程",
      "target": "文章",
      "relation": "related",
      "description": "文章中包含了复杂的数学方程来解释卷积神经网络的原理。"
    },
    {
      "source": "L2正则化",
      "target": "目标函数",
      "relation": "related",
      "description": "L2正则化项被添加到损失函数中以构成最终需要优化的目标函数。"
    },
    {
      "source": "Global Features",
      "target": "Deep Learning",
      "relation": "related",
      "description": "Deep learning is the method used to extract global features for satellite image tasks."
    },
    {
      "source": "自动编码器",
      "target": "神经网络",
      "relation": "related",
      "description": "自动编码器是神经网络的一种类型。"
    },
    {
      "source": "自动编码器",
      "target": "编码器",
      "relation": "related",
      "description": "自动编码器包含编码器作为其组成部分，两者串联合作。"
    },
    {
      "source": "自动编码器",
      "target": "解码器",
      "relation": "related",
      "description": "自动编码器包含解码器作为其组成部分，两者串联合作。"
    },
    {
      "source": "廣告創意素材",
      "target": "人工智慧",
      "relation": "related",
      "description": "人工智慧可以用於打造廣告創意素材，從而實現「千人千面」的個性化顧客旅程。"
    },
    {
      "source": "AlphaFold 2",
      "target": "DeepMind",
      "relation": "related",
      "description": "DeepMind issued press releases that propelled media attention for AlphaFold 2's success."
    },
    {
      "source": "AlphaFold 2",
      "target": "CASP",
      "relation": "related",
      "description": "CASP issued press releases that propelled media attention for AlphaFold 2's success."
    },
    {
      "source": "AlphaFold 2",
      "target": "Protein Structure Prediction",
      "relation": "related",
      "description": "AlphaFold 2 is an AI algorithm that provides the ability to predict protein structures accurately."
    },
    {
      "source": "哲学",
      "target": "算法",
      "relation": "related",
      "description": "算法价值与哲学价值之间存在张力，这种张力可以转化为人工智能时代发展的创造性势能。"
    },
    {
      "source": "哲学",
      "target": "技术哲学",
      "relation": "related",
      "description": "The philosophy of technology becomes a new field restructuring the internal landscape of philosophy, comparable to traditional fields."
    },
    {
      "source": "哲学",
      "target": "人工智能时代",
      "relation": "related",
      "description": "哲学总会以批判性反思的姿态在场并介入时代，并在与技术和时代的动态关系中演化出新形态，迈向新阶段。<SEP>The Age of Artificial Intelligence serves as the contemporary context that prompts and shapes philosophical reflection on technology and the human future."
    },
    {
      "source": "哲学",
      "target": "辩证法",
      "relation": "related",
      "description": "Philosophy includes dialectics as part of the doctrine of the laws of the thinking process itself. Dialectical thinking is the methodological premise of scientific thinking."
    },
    {
      "source": "哲学",
      "target": "魏犇群",
      "relation": "related",
      "description": "魏犇群从提出深刻问题、关注意义与价值、保持对复杂性敏感三个方面阐述了哲学思考的不可替代性。"
    },
    {
      "source": "哲学",
      "target": "哲学史",
      "relation": "related",
      "description": "哲学研究尤其依赖对于哲学史的长期积累过程。"
    },
    {
      "source": "Jumper, J",
      "target": "Nature",
      "relation": "related",
      "description": "Jumper, J is an author of the AlphaFold2 paper published in Nature."
    },
    {
      "source": "Jumper, J",
      "target": "Alphafold模型架构",
      "relation": "related",
      "description": "Jumper, J is an author who documented the AlphaFold model architecture in the Nature paper."
    },
    {
      "source": "损失函数",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播通过损失函数计算模型的预测误差，并将该误差反向传播以了解网络各部分对误差的贡献。<SEP>反向传播的目标是最小化损失函数，该函数的值是计算误差和梯度的起点。"
    },
    {
      "source": "损失函数",
      "target": "参数梯度",
      "relation": "related",
      "description": "参数梯度是损失函数相对于模型参数的偏导数，是优化模型的基础。"
    },
    {
      "source": "损失函数",
      "target": "梯度下降法",
      "relation": "related",
      "description": "梯度下降法被用于最小化损失函数，通过迭代调整权重来减少预测误差。"
    },
    {
      "source": "损失函数",
      "target": "梯度下降算法",
      "relation": "related",
      "description": "梯度下降算法利用损失函数计算出的梯度来调整模型参数，目的是最小化由损失函数衡量的误差。"
    },
    {
      "source": "损失函数",
      "target": "目标函数",
      "relation": "related",
      "description": "损失函数是构成目标函数的核心部分，用于衡量模型误差。"
    },
    {
      "source": "Alphafold2",
      "target": "Nature",
      "relation": "related",
      "description": "The journal Nature published papers in 2020 and 2021 that describe the AlphaFold2 model and its architecture."
    },
    {
      "source": "Alphafold2",
      "target": "蛋白质结构预测",
      "relation": "related",
      "description": "AlphaFold2 is a method designed to solve the problem of protein structure prediction."
    },
    {
      "source": "Alphafold2",
      "target": "DeepMind",
      "relation": "related",
      "description": "DeepMind is the organization that developed the AlphaFold2 model."
    },
    {
      "source": "Alphafold2",
      "target": "3D Equivariant Structure Module",
      "relation": "related",
      "description": "The 3D Equivariant Structure Module is a key component of AlphaFold2 responsible for generating the 3D structure."
    },
    {
      "source": "Alphafold2",
      "target": "Evoformer",
      "relation": "related",
      "description": "AlphaFold2 contains an Evoformer module for processing multiple sequence alignments and template information."
    },
    {
      "source": "敬畏常识",
      "target": "机器学习",
      "relation": "related",
      "description": "The user '敬畏常识' stated that machine learning is merely a modifier of knowledge and does not generate knowledge itself."
    },
    {
      "source": "敬畏常识",
      "target": "模型",
      "relation": "related",
      "description": "The user '敬畏常识' argued that unquantifiable stock information leads to distorted inputs for models."
    },
    {
      "source": "输入",
      "target": "序列信息",
      "relation": "related",
      "description": "Sequence information is specified as one of the inputs to the Structure Module."
    },
    {
      "source": "输入",
      "target": "Distance Map信息",
      "relation": "related",
      "description": "Distance map information is specified as one of the inputs to the Structure Module."
    },
    {
      "source": "输入",
      "target": "蛋白质骨架初始Residue Gas",
      "relation": "related",
      "description": "The initial Residue Gas for the protein backbone is specified as an input to the Structure Module."
    },
    {
      "source": "Prompt Engineering",
      "target": "RAG",
      "relation": "related",
      "description": "Prompt Engineering is contrasted with RAG as an alternative approach for generating model answers."
    },
    {
      "source": "Prompt Engineering",
      "target": "Fine-Tuning",
      "relation": "related",
      "description": "Prompt Engineering is compared with Fine-Tuning as different techniques for adapting or guiding model behavior."
    },
    {
      "source": "Prompt Engineering",
      "target": "Large Language Model",
      "relation": "related",
      "description": "Prompt Engineering is a method used to integrate data when building applications with Large Language Models."
    },
    {
      "source": "Prompt Engineering",
      "target": "Brex's Prompt Engineering Guide",
      "relation": "related",
      "description": "Brex's Prompt Engineering Guide is an introductory guide to the concept of Prompt Engineering."
    },
    {
      "source": "Prompt Engineering",
      "target": "A Survey Of Prompt Engineering Methods In Large Language Models For Different Nlp Tasks",
      "relation": "related",
      "description": "The survey paper provides an overview of methods related to Prompt Engineering."
    },
    {
      "source": "Natural Language Processing",
      "target": "Nankai Statistics",
      "relation": "related",
      "description": "The research directions of Nankai Statistics cover the application of Natural Language Processing in biomedicine."
    },
    {
      "source": "Natural Language Processing",
      "target": "Feature Extraction",
      "relation": "related",
      "description": "Feature extraction is a core process in Natural Language Processing that converts text into a format suitable for machine analysis."
    },
    {
      "source": "Natural Language Processing",
      "target": "Text Analysis",
      "relation": "related",
      "description": "Text analysis is a key application area of Natural Language Processing, involving various techniques to derive meaning from text."
    },
    {
      "source": "Natural Language Processing",
      "target": "Natural Language Toolkit",
      "relation": "related",
      "description": "The Natural Language Toolkit is a software environment used for implementing various Natural Language Processing tasks."
    },
    {
      "source": "语音助手",
      "target": "深度学习",
      "relation": "related",
      "description": "深度学习应用于语音助手领域，例如使用循环神经网络。"
    },
    {
      "source": "多层感知机",
      "target": "神经元",
      "relation": "related",
      "description": "A multilayer perceptron is composed of multiple layers of neurons."
    },
    {
      "source": "多层感知机",
      "target": "输出层",
      "relation": "related",
      "description": "多层感知机由输出层构成。"
    },
    {
      "source": "多层感知机",
      "target": "输入层",
      "relation": "related",
      "description": "多层感知机由输入层构成。"
    },
    {
      "source": "多层感知机",
      "target": "隐藏层",
      "relation": "related",
      "description": "多层感知机由隐藏层构成。"
    },
    {
      "source": "多层感知机",
      "target": "前馈神经网络",
      "relation": "related",
      "description": "多层感知机是一种前馈神经网络。"
    },
    {
      "source": "风险",
      "target": "AI模型",
      "relation": "related",
      "description": "Risk is a key factor to consider when choosing an AI model."
    },
    {
      "source": "风险",
      "target": "指南面向CEO的生成式AI指南",
      "relation": "related",
      "description": "The guide addresses the risks associated with generative AI."
    },
    {
      "source": "风险",
      "target": "最佳模型",
      "relation": "related",
      "description": "Balancing risk with other factors helps determine the best model."
    },
    {
      "source": "Encoder-Decoder Model",
      "target": "Large Language Model",
      "relation": "related",
      "description": "Encoder-Decoder Model is a type of model architecture suitable for sequence-to-sequence tasks within Large Language Models."
    },
    {
      "source": "Lecture Video",
      "target": "Hung-yi Lee",
      "relation": "related",
      "description": "Hung-yi Lee is the creator and presenter of the lecture video published on his YouTube channel."
    },
    {
      "source": "Lecture Video",
      "target": "DOC_ID: chunk-6db04701",
      "relation": "related",
      "description": "The document chunk with ID chunk-6db04701 contains the metadata and description of the lecture video."
    },
    {
      "source": "NeOn-GPT",
      "target": "Large Language Model",
      "relation": "related",
      "description": "NeOn-GPT is a pipeline powered by large language models for the task of ontology learning."
    },
    {
      "source": "CASP",
      "target": "D-I-TASSER",
      "relation": "related",
      "description": "D-I-TASSER参加了第15届CASP比赛，在单结构域蛋白和多结构域蛋白两个单项比赛中均排名世界第一。"
    },
    {
      "source": "Nankai Statistics",
      "target": "Computer Vision",
      "relation": "related",
      "description": "The research directions of Nankai Statistics cover the application of Computer Vision in biomedicine."
    },
    {
      "source": "Nankai Statistics",
      "target": "Nature Biotechnology",
      "relation": "related",
      "description": "Nankai Statistics has published dozens of papers in authoritative biomedical journals including Nature Biotechnology."
    },
    {
      "source": "Nankai Statistics",
      "target": "Nature Methods",
      "relation": "related",
      "description": "Nankai Statistics has published over 50 articles in high-level SCI journals including Nature Methods."
    },
    {
      "source": "Nankai Statistics",
      "target": "Nature Communications",
      "relation": "related",
      "description": "Nankai Statistics has published over 50 articles in high-level SCI journals including Nature Communications."
    },
    {
      "source": "Nankai Statistics",
      "target": "PNAS",
      "relation": "related",
      "description": "Nankai Statistics has published over 50 articles in high-level SCI journals including PNAS."
    },
    {
      "source": "Nankai Statistics",
      "target": "Structural Prediction Algorithm",
      "relation": "related",
      "description": "Nankai Statistics developed the structural prediction algorithm that serves nearly 100,000 users globally."
    },
    {
      "source": "Nankai Statistics",
      "target": "Bioinformatics",
      "relation": "related",
      "description": "The research directions of Nankai Statistics cover Bioinformatics."
    },
    {
      "source": "Nankai Statistics",
      "target": "Nankai University",
      "relation": "related",
      "description": "Nankai Statistics is an academic unit affiliated with Nankai University."
    },
    {
      "source": "指南面向CEO的生成式AI指南",
      "target": "生成式AI",
      "relation": "related",
      "description": "The guide helps CEOs understand generative AI."
    },
    {
      "source": "人工智能时代",
      "target": "算法",
      "relation": "related",
      "description": "算法在人工智能时代狂飙突进，实现了对社会的整体建构，但也引发了诸多争议。"
    },
    {
      "source": "人工智能时代",
      "target": "三位青年学者",
      "relation": "related",
      "description": "The three young scholars participate in a discussion organized around the theme of philosophical research in the Age of Artificial Intelligence."
    },
    {
      "source": "人工智能时代",
      "target": "赵立",
      "relation": "related",
      "description": "赵立认为基于哲学的批判性反思可以全面观照人工智能技术，从而校准其与哲学思考的发展方向。"
    },
    {
      "source": "Add & Norm Layer",
      "target": "Encoder Block",
      "relation": "related",
      "description": "An Encoder block contains an Add & Norm layer following the Multi-Head Attention and Feed Forward layers."
    },
    {
      "source": "Add & Norm Layer",
      "target": "Decoder Block",
      "relation": "related",
      "description": "A Decoder block contains Add & Norm layers following its attention mechanisms."
    },
    {
      "source": "Protein Design",
      "target": "Bioinformatics",
      "relation": "related",
      "description": "Protein design is a research area within the broader domain of bioinformatics."
    },
    {
      "source": "Protein Design",
      "target": "David Baker",
      "relation": "related",
      "description": "David Baker is a leading expert and conducts extensive research in the field of protein design."
    },
    {
      "source": "红帽AI",
      "target": "SLM",
      "relation": "related",
      "description": "红帽AI提供对SLM等第三方模型库的访问权限。<SEP>Red Hat AI provides access to model libraries, facilitating comparisons and decisions between different model types like LLMs and SLMs."
    },
    {
      "source": "Rectified Linear Unit (ReLU)",
      "target": "Convolutional Layer",
      "relation": "related",
      "description": "After each convolution operation, a ReLU transformation is applied to the feature map to introduce non-linearity into the CNN model."
    },
    {
      "source": "白皮書",
      "target": "Appier",
      "relation": "related",
      "description": "Appier發布了名為「鎖定高價值應用程式使用者: 運用深度學習提高獲取新客的行銷成效」的白皮書，提供深度學習在行銷應用的洞察。"
    },
    {
      "source": "白皮書",
      "target": "深度學習",
      "relation": "related",
      "description": "Appier的白皮書主題是探討如何運用深度學習來提高獲取新客的行銷成效。"
    },
    {
      "source": "本研究",
      "target": "深度神经网络",
      "relation": "related",
      "description": "本研究对深度神经网络在遥感领域的应用进行了系统的综述和分析。"
    },
    {
      "source": "GPT-4",
      "target": "文章",
      "relation": "related",
      "description": "GPT-4可以根据提示生成文章。"
    },
    {
      "source": "GPT-4",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理为GPT-4等高级语言模型提供支持，以生成类人文本。"
    },
    {
      "source": "GPT-4",
      "target": "Large Language Model",
      "relation": "related",
      "description": "GPT-4 is a closed-source Large Language Model noted for its outstanding performance."
    },
    {
      "source": "数据管理",
      "target": "IBM",
      "relation": "related",
      "description": "IBM提供数据管理等方面的解决方案，帮助企业构建AI系统。"
    },
    {
      "source": "Class Imbalance",
      "target": "Credit Card Fraud Detection: A Deep Learning Approach",
      "relation": "related",
      "description": "A core focus of the paper is to address the challenge of class imbalance in credit card fraud detection data using its proposed methods."
    },
    {
      "source": "Class Imbalance",
      "target": "Traditional Fraud Detection Systems",
      "relation": "related",
      "description": "Traditional fraud detection systems struggle with the challenge of class imbalance in fraud data."
    },
    {
      "source": "Andrej Karpathy",
      "target": "State Of Gpt",
      "relation": "related",
      "description": "Andrej Karpathy is the creator of the presentation \"State of GPT\"."
    },
    {
      "source": "Andrej Karpathy",
      "target": "Deep Dive Into Llms Like Chatgpt",
      "relation": "related",
      "description": "Andrej Karpathy is the creator of the video \"Deep Dive into LLMs like ChatGPT\"."
    },
    {
      "source": "计算语言学",
      "target": "自然语言处理",
      "relation": "related",
      "description": "Natural language processing incorporates computational linguistics as one of its foundational components.<SEP>自然语言处理通过结合计算语言学(基于规则的语言建模)来处理语言。"
    },
    {
      "source": "序列信息",
      "target": "3D Equivariant Structure Module",
      "relation": "related",
      "description": "The Structure Module takes sequence information of the target protein as one of its inputs."
    },
    {
      "source": "Federated Learning",
      "target": "Quantitative Trading",
      "relation": "related",
      "description": "Federated Learning is a technology that can play a significant role in collaborations between financial institutions within the quantitative trading landscape."
    },
    {
      "source": "欺诈应用检测方法",
      "target": "深度学习",
      "relation": "related",
      "description": "Deep learning is the foundational methodology used for the fraud application detection method."
    },
    {
      "source": "欺诈应用检测方法",
      "target": "移动广告数据",
      "relation": "related",
      "description": "The fraud application detection method uses mobile advertising data as its primary input for processing."
    },
    {
      "source": "欺诈应用检测方法",
      "target": "结构数据",
      "relation": "related",
      "description": "The fraud application detection method involves extracting structural data from the input."
    },
    {
      "source": "Gradient",
      "target": "ReLU",
      "relation": "related",
      "description": "The gradient of the ReLU function is calculated and plotted, which is essential for training neural networks."
    },
    {
      "source": "Gradient",
      "target": "Tanh",
      "relation": "related",
      "description": "The gradient of the Tanh function is calculated and plotted, which is essential for training neural networks."
    },
    {
      "source": "卷积操作",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "The convolution operation is the fundamental mathematical process that defines and gives its name to the Convolutional Neural Network."
    },
    {
      "source": "训练数据",
      "target": "深度学习",
      "relation": "related",
      "description": "Training data is the input for deep learning models; biases in this data can lead to flawed outputs in AI systems."
    },
    {
      "source": "训练数据",
      "target": "人类偏见",
      "relation": "related",
      "description": "Existing human biases can be transferred to AI systems through the training data."
    },
    {
      "source": "Tanh",
      "target": "Activation Function",
      "relation": "related",
      "description": "Tanh is a specific type of activation function used in neural networks."
    },
    {
      "source": "全原子的位置坐标",
      "target": "3D Equivariant Structure Module",
      "relation": "related",
      "description": "The primary output of the Structure Module is the full set of atomic position coordinates for the protein."
    },
    {
      "source": "全原子的位置坐标",
      "target": "输出",
      "relation": "related",
      "description": "Full atomic position coordinates are specified as an output of the Structure Module."
    },
    {
      "source": "Internal Data Science Laboratory",
      "target": "Data Processing Procedure",
      "relation": "related",
      "description": "The data processing procedure is completed rapidly by leveraging the computational power of the Internal Data Science Laboratory."
    },
    {
      "source": "非结构化文本数据",
      "target": "文本挖掘",
      "relation": "related",
      "description": "文本挖掘技术用于分析非结构化文本数据。"
    },
    {
      "source": "序列",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "卷积神经网络用于对序列数据进行编码处理。"
    },
    {
      "source": "序列",
      "target": "循环神经网络",
      "relation": "related",
      "description": "循环神经网络用于对序列数据进行编码处理。"
    },
    {
      "source": "IPA (Invariant Point Attention)",
      "target": "3D Equivariant Structure Module",
      "relation": "related",
      "description": "The IPA (Invariant Point Attention) is a crucial part of the 3D Equivariant Structure Module that ensures equivariance."
    },
    {
      "source": "IPA (Invariant Point Attention)",
      "target": "重要架构",
      "relation": "related",
      "description": "IPA is listed as an important architectural component."
    },
    {
      "source": "气候学",
      "target": "人工智能",
      "relation": "related",
      "description": "Artificial intelligence is being combined with the field of climatology."
    },
    {
      "source": "气候学",
      "target": "研究人员",
      "relation": "related",
      "description": "Researchers are working within the field of climatology."
    },
    {
      "source": "AI Agent风控模型",
      "target": "深度学习",
      "relation": "related",
      "description": "AI Agent风控模型是基于深度学习技术实现的。"
    },
    {
      "source": "计算神经科学",
      "target": "深度学习",
      "relation": "related",
      "description": "掌握深度学习的基本知识是加深对计算神经科学理解的基础。"
    },
    {
      "source": "计算神经科学",
      "target": "Coursera",
      "relation": "related",
      "description": "Coursera平台上有推荐的课程，用于加深对计算神经科学的理解。"
    },
    {
      "source": "成本",
      "target": "AI模型",
      "relation": "related",
      "description": "Cost is a key factor to consider when choosing an AI model."
    },
    {
      "source": "成本",
      "target": "最佳模型",
      "relation": "related",
      "description": "Balancing cost with other factors helps determine the best model."
    },
    {
      "source": "无监督学习",
      "target": "深度学习",
      "relation": "related",
      "description": "Unsupervised learning is a method within the broader deep learning framework used to train models like LLMs."
    },
    {
      "source": "无监督学习",
      "target": "机器学习",
      "relation": "related",
      "description": "无监督学习是机器学习的一种主要学习范式和方法类别。<SEP>Unsupervised Learning is one of the primary types and methodologies within Machine Learning."
    },
    {
      "source": "无监督学习",
      "target": "监督学习",
      "relation": "related",
      "description": "监督学习和无监督学习是两种不同的机器学习方法，主要区别在于是否使用标记数据集。"
    },
    {
      "source": "无监督学习",
      "target": "自编码器",
      "relation": "related",
      "description": "自编码器是执行无监督学习任务的一类神经网络结构。"
    },
    {
      "source": "无监督学习",
      "target": "Transformer架构",
      "relation": "related",
      "description": "The Transformer architecture and its parameters guide the unsupervised learning process of LLMs."
    },
    {
      "source": "Time Series Forecasting",
      "target": "Deep-Algotrading",
      "relation": "related",
      "description": "The Deep-Algotrading resource repository covers time series forecasting as a complex topic for learners."
    },
    {
      "source": "Time Series Forecasting",
      "target": "LSTM",
      "relation": "related",
      "description": "LSTM is presented as a specific, complex technique used within the broader domain of time series forecasting."
    },
    {
      "source": "Agent",
      "target": "人工智能",
      "relation": "related",
      "description": "Agent是人工智能领域的一个应用概念。"
    },
    {
      "source": "Agent",
      "target": "AI黑话揭秘",
      "relation": "related",
      "description": "文章《AI黑话揭秘》旨在解释Agent及其相关概念。"
    },
    {
      "source": "ResNet",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "ResNet解决了网络模型的退化问题，允许构建更深的卷积神经网络。"
    },
    {
      "source": "ResNet",
      "target": "CNN",
      "relation": "related",
      "description": "ResNet is listed as a common CNN architecture."
    },
    {
      "source": "ResNet",
      "target": "Deep Learning",
      "relation": "related",
      "description": "ResNet is part of the discussed evolution of deep learning model structures for optimization."
    },
    {
      "source": "深度神经网络",
      "target": "大语言模型",
      "relation": "related",
      "description": "大语言模型是由深度神经网络构建的。"
    },
    {
      "source": "深度神经网络",
      "target": "遥感图像分类",
      "relation": "related",
      "description": "深度神经网络被应用于执行遥感图像分类任务。"
    },
    {
      "source": "Dataset",
      "target": "Training",
      "relation": "related",
      "description": "A dataset with known answers is used during the training process to teach the model."
    },
    {
      "source": "Dataset",
      "target": "Training Set",
      "relation": "related",
      "description": "The Dataset is randomly split, with 80% allocated as the Training Set."
    },
    {
      "source": "Dataset",
      "target": "Test Set",
      "relation": "related",
      "description": "The Dataset is randomly split, with 20% allocated as the Test Set."
    },
    {
      "source": "文本清理",
      "target": "文本预处理",
      "relation": "related",
      "description": "文本清理是文本预处理中删除不需要元素的步骤。"
    },
    {
      "source": "Output Layer Variable",
      "target": "Hidden Layer Variable",
      "relation": "related",
      "description": "The hidden layer variable h is multiplied by the output layer weight parameter W^(2) to produce the output layer variable o."
    },
    {
      "source": "Weight Matrix WQ",
      "target": "Linear Layer",
      "relation": "related",
      "description": "The linear layer contains parallel subsets, one of which includes the unique weight matrix WQ."
    },
    {
      "source": "Faster R-CNN",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "Faster R-CNN is a specific variant of Convolutional Neural Network architecture designed for high-accuracy, two-stage object detection."
    },
    {
      "source": "Faster R-CNN",
      "target": "Object Detection",
      "relation": "related",
      "description": "Faster R-CNN is cited as an example of a two-stage model for object detection in remote sensing."
    },
    {
      "source": "词向量",
      "target": "深度学习",
      "relation": "related",
      "description": "深度学习机制需要让计算机学会每个独立词汇所代表的词向量，这是其理解语义的基础。"
    },
    {
      "source": "PNAS",
      "target": "郑伟",
      "relation": "related",
      "description": "郑伟教授在PNAS期刊上发表过文章。"
    },
    {
      "source": "Supervised Learning",
      "target": "Machine Learning",
      "relation": "related",
      "description": "Supervised Learning is a core paradigm within the broader field of Machine Learning."
    },
    {
      "source": "循环神经网络",
      "target": "深度学习",
      "relation": "related",
      "description": "深度学习经常使用循环神经网络作为对序列进行编码的方法之一。<SEP>深度学习使用循环神经网络等模型在语音助手等领域进行应用。"
    },
    {
      "source": "循环神经网络",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "即使在传统上使用循环神经网络处理的一维序列任务(如音频、文本分析)中，卷积神经网络也变得越来越受欢迎。"
    },
    {
      "source": "循环神经网络",
      "target": "深度学习系统",
      "relation": "related",
      "description": "深度学习系统包含循环神经网络作为其主要类型之一。"
    },
    {
      "source": "循环神经网络",
      "target": "时间序列数据",
      "relation": "related",
      "description": "Recurrent Neural Networks (RNN) are applied to capture complex relationships within time series data."
    },
    {
      "source": "循环神经网络",
      "target": "高频交易",
      "relation": "related",
      "description": "Recurrent Neural Networks (RNN) are applied in the field of high-frequency trading to process large volumes of micro-market data."
    },
    {
      "source": "数字偏见",
      "target": "人工智能",
      "relation": "related",
      "description": "人工智能的应用导致了数字偏见和“数字鸿沟”，这是公平性方面的新哲学视域。"
    },
    {
      "source": "算法价值",
      "target": "魏犇群",
      "relation": "related",
      "description": "Wei Benqun explains that algorithmic value is currently a product of human mental labor."
    },
    {
      "source": "算法价值",
      "target": "哲学价值",
      "relation": "related",
      "description": "There is a tension and distinction between the value created by algorithms and the value of philosophy."
    },
    {
      "source": "交易员",
      "target": "深度学习技术",
      "relation": "related",
      "description": "Traders employ deep learning technology for data analysis and model-related activities."
    },
    {
      "source": "资金分配模型",
      "target": "深度学习",
      "relation": "related",
      "description": "In a hybrid approach, deep learning models generate trading signals while traditional capital allocation models optimize the portfolio."
    },
    {
      "source": "卷积层",
      "target": "激活函数",
      "relation": "related",
      "description": "卷积操作后，卷积层应用激活函数如ReLU来引入非线性。<SEP>卷积层在运算后通常会结合激活函数，为模型引入非线性因素。"
    },
    {
      "source": "卷积层",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "卷积层是构成所有卷积神经网络主干的基本核心元素之一。<SEP>The convolutional layer is a primary and essential structural component within a Convolutional Neural Network.<SEP>卷积层是卷积神经网络的一个核心组成部分，通过卷积操作提取特征。<SEP>Convolutional Neural Networks use convolutional layers as a core component to perform convolution operations and extract local features from data.<SEP>卷积神经网络包含卷积层作为其核心组件之一，该层负责从输入数据中提取特征。<SEP>卷积层是卷积神经网络的核心组成部分之一，负责通过卷积核进行特征提取。"
    },
    {
      "source": "卷积层",
      "target": "池化层",
      "relation": "related",
      "description": "池化层通常跟在卷积层后面，用于进一步放大主要特征并降低数据维度。"
    },
    {
      "source": "卷积层",
      "target": "特征图",
      "relation": "related",
      "description": "卷积层通过卷积运算生成特征图，作为提取到的特征的表示。"
    },
    {
      "source": "卷积层",
      "target": "深度卷积网络",
      "relation": "related",
      "description": "通过层层堆叠卷积层可以构成深度卷积网络，以增强特征表达能力。"
    },
    {
      "source": "指南",
      "target": "生成式AI",
      "relation": "related",
      "description": "The guide provides instructions on how to leverage generative AI to its full potential."
    },
    {
      "source": "Deep Learning Model",
      "target": "GPU",
      "relation": "related",
      "description": "Deep learning models depend on GPUs for training and inference, contributing to high technical and cost thresholds."
    },
    {
      "source": "Deep Learning Model",
      "target": "Overfitting",
      "relation": "related",
      "description": "Deep learning models are vulnerable to overfitting, especially in the non-stationary financial market environment."
    },
    {
      "source": "Deep Learning Model",
      "target": "High-Frequency Trading Strategy",
      "relation": "related",
      "description": "The high-speed demands of high-frequency trading strategies create significant barriers to applying deep learning models."
    },
    {
      "source": "Deep Learning Model",
      "target": "Black Box Problem",
      "relation": "related",
      "description": "Deep learning models suffer from the black box problem, making their decisions difficult to interpret."
    },
    {
      "source": "输出",
      "target": "lDDT-Cα",
      "relation": "related",
      "description": "The lDDT-Cα score is specified as an output of the Structure Module."
    },
    {
      "source": "Distance Map信息",
      "target": "3D Equivariant Structure Module",
      "relation": "related",
      "description": "The Structure Module uses predicted distance map information as an input."
    },
    {
      "source": "连接",
      "target": "神经网络",
      "relation": "related",
      "description": "神经网络中的节点通过连接相互关联。"
    },
    {
      "source": "AIGC",
      "target": "人工智能",
      "relation": "related",
      "description": "人工智能基于深度学习的大模型技术正向AIGC(人工智能生成内容)应用体系演进。"
    },
    {
      "source": "AIGC",
      "target": "自然语言处理",
      "relation": "related",
      "description": "AIGC涉及到的领域很广泛，其中自然语言处理是一项很重要的技术。"
    },
    {
      "source": "Apple Siri",
      "target": "聊天机器人",
      "relation": "related",
      "description": "Apple Siri是聊天机器人的一个实例。"
    },
    {
      "source": "福岛邦彦",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "卷积神经网络的前身“神经认知模型”由日本学者福岛邦彦提出，受生物视觉系统研究启发。"
    },
    {
      "source": "福岛邦彦",
      "target": "生物视觉系统",
      "relation": "related",
      "description": "福岛邦彦受前人关于生物视觉系统研究的启发，提出了“神经认知模型”。"
    },
    {
      "source": "梯度下降法",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播计算得到的梯度被梯度下降法或其变种用于更新神经网络的参数。"
    },
    {
      "source": "梯度下降法",
      "target": "梯度",
      "relation": "related",
      "description": "梯度下降法依据梯度所指示的方向和幅度来调整网络参数。"
    },
    {
      "source": "梯度下降法",
      "target": "学习率",
      "relation": "related",
      "description": "学习率是梯度下降法中的一个关键超参数，它控制着每次权重更新的步长大小。"
    },
    {
      "source": "梯度下降法",
      "target": "误差损失函数",
      "relation": "related",
      "description": "Gradient descent is the method used to minimize the error loss function during neural network training."
    },
    {
      "source": "深度学习架构",
      "target": "文本表示",
      "relation": "related",
      "description": "Pre-trained text representations are components that can be integrated into various deep learning architectures."
    },
    {
      "source": "Transformers Library",
      "target": "BERT",
      "relation": "related",
      "description": "The rise of the BERT model contributed to the increased adoption of the Transformers library."
    },
    {
      "source": "Transformers Library",
      "target": "GPT",
      "relation": "related",
      "description": "The rise of the GPT model contributed to the increased adoption of the Transformers library."
    },
    {
      "source": "气候数据",
      "target": "人工智能",
      "relation": "related",
      "description": "Artificial intelligence is used to analyze massive climate data to discover new models."
    },
    {
      "source": "模型风险管理",
      "target": "机器学习",
      "relation": "related",
      "description": "AI and machine learning can be applied to model risk management processes like validation and monitoring to help manage risk."
    },
    {
      "source": "模型风险管理",
      "target": "模型风险管理监管指南",
      "relation": "related",
      "description": "Model risk management must follow regulatory guidelines, such as the Model Risk Management Supervisory Guide issued by the Federal Reserve and OCC, which serves as a benchmark."
    },
    {
      "source": "Transformer",
      "target": "Encoder",
      "relation": "related",
      "description": "The transformer architecture contains encoder layers for processing input sequences."
    },
    {
      "source": "Transformer",
      "target": "Decoder",
      "relation": "related",
      "description": "The transformer architecture contains decoder layers for generating output sequences."
    },
    {
      "source": "Transformer",
      "target": "Attention Sublayer",
      "relation": "related",
      "description": "The attention sublayer is a key component that distinguishes transformers from other encoder-decoder architectures."
    },
    {
      "source": "Transformer",
      "target": "价格预测",
      "relation": "related",
      "description": "Transformer models are used for the application of price prediction in quantitative trading."
    },
    {
      "source": "Transformer",
      "target": "Encoder Block",
      "relation": "related",
      "description": "The Transformer model architecture is composed of stacked Encoder blocks to process input sequences."
    },
    {
      "source": "Transformer",
      "target": "Decoder Block",
      "relation": "related",
      "description": "The Transformer model architecture is composed of stacked Decoder blocks to generate output sequences."
    },
    {
      "source": "Transformer",
      "target": "Embedding",
      "relation": "related",
      "description": "The Transformer model uses an Embedding layer to convert input tokens into vector representations."
    },
    {
      "source": "Transformer",
      "target": "Deep Learning",
      "relation": "related",
      "description": "The Transformer is a prominent model architecture within the field of Deep Learning."
    },
    {
      "source": "Transformer",
      "target": "Attention Mechanism",
      "relation": "related",
      "description": "Transformer utilizes the attention mechanism to improve its training speed."
    },
    {
      "source": "Transformer",
      "target": "Self-Attention Mechanism",
      "relation": "related",
      "description": "Transformer is completely based on the self-attention mechanism."
    },
    {
      "source": "Transformer",
      "target": "Hung-yi Lee",
      "relation": "related",
      "description": "Hung-yi Lee created and presented a lecture explaining the Transformer model architecture."
    },
    {
      "source": "前向传播",
      "target": "神经网络",
      "relation": "related",
      "description": "在神经网络中，前向传播是输入数据通过网络层产生输出的过程。"
    },
    {
      "source": "前向传播",
      "target": "反向传播",
      "relation": "related",
      "description": "前向传播按从输入到输出的顺序计算，而反向传播按相反顺序计算梯度。"
    },
    {
      "source": "Weight Coefficient",
      "target": "Neuron",
      "relation": "related",
      "description": "Each neuron contains weight coefficients that determine the strength of its connections to inputs."
    },
    {
      "source": "自监督学习方法",
      "target": "大语言模型",
      "relation": "related",
      "description": "大语言模型使用自监督学习方法进行训练。"
    },
    {
      "source": "Artificial Neural Network",
      "target": "Artificial Neuron",
      "relation": "related",
      "description": "Artificial neurons are the components used to build artificial neural networks, which simulate thinking."
    },
    {
      "source": "Artificial Neural Network",
      "target": "Learning",
      "relation": "related",
      "description": "In artificial intelligence, the modification of connection strengths in artificial neural networks enables learning."
    },
    {
      "source": "Artificial Neural Network",
      "target": "AlphaFold",
      "relation": "related",
      "description": "AlphaFold utilizes artificial neural networks as its core computational methodology."
    },
    {
      "source": "Image Segmentation",
      "target": "Deep Learning",
      "relation": "related",
      "description": "Deep learning provides the methodology for performing image segmentation tasks on remote sensing images."
    },
    {
      "source": "Pooling Layer",
      "target": "Convolutional Neural Network (CNN)",
      "relation": "related",
      "description": "Pooling layers are used in CNNs to reduce complexity, improve efficiency, and limit overfitting, despite some information loss."
    },
    {
      "source": "Pooling Layer",
      "target": "Overfitting",
      "relation": "related",
      "description": "Pooling layers in CNNs help limit the risk of overfitting, a common problem in machine learning models."
    },
    {
      "source": "Deep Neural Network",
      "target": "DeepMind",
      "relation": "related",
      "description": "Researchers from DeepMind are involved with the neural networks that predict protein properties."
    },
    {
      "source": "Deep Neural Network",
      "target": "AlphaFold",
      "relation": "related",
      "description": "AlphaFold builds models that rely on deep neural networks."
    },
    {
      "source": "人工神经网络",
      "target": "深度学习",
      "relation": "related",
      "description": "深度学习的技术基础是人工神经网络，其多层结构使得深度学习能够进行复杂的数据处理和学习。<SEP>Deep learning represents a revival and significant advancement of artificial neural networks, overcoming previous limitations like local minima.<SEP>Deep Learning models are built upon and implemented using architectures based on Artificial Neural Networks."
    },
    {
      "source": "人工神经网络",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "卷积神经网络也被称为人工神经网络，两者是同一概念的不同表述。"
    },
    {
      "source": "人工神经网络",
      "target": "监督学习",
      "relation": "related",
      "description": "Supervised learning is a training paradigm for artificial neural networks that requires known final answers in advance."
    },
    {
      "source": "Torch.compile",
      "target": "Fine-Tuning",
      "relation": "related",
      "description": "Fine-Tuning can be made more efficient by using torch.compile to optimize the model's runtime."
    },
    {
      "source": "Reinforcement Learning",
      "target": "Machine Learning",
      "relation": "related",
      "description": "Reinforcement Learning is a core paradigm within the broader field of Machine Learning."
    },
    {
      "source": "Reinforcement Learning",
      "target": "RLHF",
      "relation": "related",
      "description": "RLHF (Reinforcement Learning from Human Feedback) is a method within reinforcement learning used for AI alignment."
    },
    {
      "source": "统计套利策略",
      "target": "深度学习",
      "relation": "related",
      "description": "Deep learning models can be seamlessly combined with statistical arbitrage strategies as part of a composite trading approach."
    },
    {
      "source": "大模型",
      "target": "深度学习",
      "relation": "related",
      "description": "Large Models, especially in NLP, are trained using Deep Learning techniques."
    },
    {
      "source": "大模型",
      "target": "机器学习",
      "relation": "related",
      "description": "Large Models are a product and a significant advancement within the field of Machine Learning, showcasing its potential."
    },
    {
      "source": "大模型",
      "target": "人工智能",
      "relation": "related",
      "description": "大模型是人工智能领域用于模拟人类智能的应用概念。"
    },
    {
      "source": "大模型",
      "target": "BERT",
      "relation": "related",
      "description": "BERT is a specific, well-known instance of a pre-trained Large Model in NLP."
    },
    {
      "source": "大模型",
      "target": "自然语言处理",
      "relation": "related",
      "description": "Large Models, particularly LLMs, are key enabling technologies that power advanced applications in Natural Language Processing."
    },
    {
      "source": "大模型",
      "target": "浙江大学人工智能教育教学研究中心",
      "relation": "related",
      "description": "该研究中心的研究展示了大模型在模拟人类语言理解中的应用。"
    },
    {
      "source": "大模型",
      "target": "AI黑话揭秘",
      "relation": "related",
      "description": "文章《AI黑话揭秘》旨在解释大模型及其相关概念。"
    },
    {
      "source": "Sequence Labeling",
      "target": "Bi-LSTM",
      "relation": "related",
      "description": "Bi-LSTM is a recommended deep learning approach for sequence labeling in practical applications due to its ability to capture long context and balance performance with complexity."
    },
    {
      "source": "Sequence Labeling",
      "target": "CRF",
      "relation": "related",
      "description": "Traditional CRF models are effectively used for sequence labeling tasks."
    },
    {
      "source": "Convolution Layer",
      "target": "Activation Function",
      "relation": "related",
      "description": "An activation function, such as ReLU, is applied to the output of a convolution layer."
    },
    {
      "source": "Convolution Layer",
      "target": "Convolutional Neural Network",
      "relation": "related",
      "description": "Convolution layers are core components of a Convolutional Neural Network where convolution operations occur."
    },
    {
      "source": "Python",
      "target": "Natural Language Toolkit",
      "relation": "related",
      "description": "The Natural Language Toolkit (NLTK) is written in the Python programming language."
    },
    {
      "source": "真实数据",
      "target": "深度学习欺诈侦测模型",
      "relation": "related",
      "description": "该模型使用真实业务数据进行仿真验证。"
    },
    {
      "source": "真实数据",
      "target": "三方工程师",
      "relation": "related",
      "description": "The three-party engineers used real data for their simulation verification."
    },
    {
      "source": "Partial Derivative",
      "target": "Training",
      "relation": "related",
      "description": "Partial derivatives are used during training to precisely calculate how changes in parameters affect the output."
    },
    {
      "source": "Partial Derivative",
      "target": "Error",
      "relation": "related",
      "description": "The partial derivative of the error with respect to a weight is calculated to determine how to adjust that weight."
    },
    {
      "source": "IBM watsonx.ai",
      "target": "生成式AI",
      "relation": "related",
      "description": "IBM watsonx.ai is a platform specifically built to train, validate, tune, and deploy generative AI.<SEP>IBM watsonx.ai is a platform used to train, validate, tune, and deploy generative AI."
    },
    {
      "source": "IBM watsonx.ai",
      "target": "IBM",
      "relation": "related",
      "description": "IBM is the organization that developed and offers the IBM watsonx.ai platform.<SEP>IBM developed and provides the IBM watsonx.ai enterprise AI development platform.<SEP>IBM watsonx.ai is an AI development platform created and offered by IBM."
    },
    {
      "source": "IBM watsonx.ai",
      "target": "基础模型",
      "relation": "related",
      "description": "IBM watsonx.ai supports the deployment of foundation models."
    },
    {
      "source": "IBM watsonx.ai",
      "target": "AI应用程序",
      "relation": "related",
      "description": "IBM watsonx.ai is used to build AI applications quickly and with minimal data.<SEP>AI applications can be built on the IBM watsonx.ai platform using a small amount of data."
    },
    {
      "source": "IBM watsonx.ai",
      "target": "AI构建器",
      "relation": "related",
      "description": "IBM watsonx.ai is a development platform built for use by AI builders."
    },
    {
      "source": "IBM watsonx.ai",
      "target": "Generative AI",
      "relation": "related",
      "description": "IBM watsonx.ai is a platform designed for deploying and managing Generative AI applications."
    },
    {
      "source": "Activation Function",
      "target": "Sigmoid Function",
      "relation": "related",
      "description": "The sigmoid function is a specific type of activation function used in neural networks."
    },
    {
      "source": "Activation Function",
      "target": "Hidden Layer Variable",
      "relation": "related",
      "description": "The activation function φ is applied element-wise to the intermediate variable z to produce the non-linear hidden layer variable h."
    },
    {
      "source": "Activation Function",
      "target": "Neuron",
      "relation": "related",
      "description": "A neuron applies an activation function to its total net input to produce its final output."
    },
    {
      "source": "Activation Function",
      "target": "ReLU",
      "relation": "related",
      "description": "ReLU is a common example of an activation function used in neural networks.<SEP>ReLU is a specific type of activation function used in neural networks."
    },
    {
      "source": "解码器",
      "target": "转换器",
      "relation": "related",
      "description": "The Transformer model architecture contains decoder layers that generate output sequences."
    },
    {
      "source": "上下文特征",
      "target": "深度学习",
      "relation": "related",
      "description": "深度学习(特别是LSTM)能够学习上下文特征，以解决长距离语义理解问题。"
    },
    {
      "source": "上下文特征",
      "target": "LSTM",
      "relation": "related",
      "description": "LSTM模型能够捕捉和学习上下文特征。"
    },
    {
      "source": "数据",
      "target": "人工智能",
      "relation": "related",
      "description": "人工智能系统通过算法和模型从大量数据中学习，并能够做出智能决策。"
    },
    {
      "source": "数据",
      "target": "AI模型",
      "relation": "related",
      "description": "AI模型的发展离不开数据的支持，通过对大量数据的分析和学习，AI模型能够不断提升性能。"
    },
    {
      "source": "数据",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理用于分析和处理数据。"
    },
    {
      "source": "Embedding",
      "target": "Transformer Encoder",
      "relation": "related",
      "description": "The Transformer Encoder applies an Embedding process to convert input tokens into vector representations, which are then scaled and combined with positional encoding."
    },
    {
      "source": "Embedding",
      "target": "Token",
      "relation": "related",
      "description": "A token is represented numerically as an embedding, which is then used for further processing."
    },
    {
      "source": "Embedding",
      "target": "Query, Key, Value Vectors",
      "relation": "related",
      "description": "Query, key, and value vectors are generated by transforming the original token embedding through specific weight matrices."
    },
    {
      "source": "天气现象预报方法",
      "target": "深度学习",
      "relation": "related",
      "description": "该预报方法基于深度学习技术。"
    },
    {
      "source": "AlphaFold",
      "target": "Deep Learning",
      "relation": "related",
      "description": "AlphaFold's technical core integrates deep learning as a key method."
    },
    {
      "source": "AlphaFold",
      "target": "DeepMind",
      "relation": "related",
      "description": "DeepMind is the company that developed the AlphaFold system for protein structure prediction.<SEP>DeepMind decided to improve the AlphaFold system, which initially did not meet expectations, leading to a re-evaluation."
    },
    {
      "source": "AlphaFold",
      "target": "江珀",
      "relation": "related",
      "description": "Jiang Po led a team to re-examine and improve the initial version of AlphaFold."
    },
    {
      "source": "AlphaFold",
      "target": "AlphaFold2",
      "relation": "related",
      "description": "AlphaFold2 is the significantly improved and breakthrough successor to the initial AlphaFold system."
    },
    {
      "source": "AlphaFold",
      "target": "Bioinformatics",
      "relation": "related",
      "description": "AlphaFold's technical core integrates bioinformatics as a key concept."
    },
    {
      "source": "传统机器学习",
      "target": "深度学习",
      "relation": "related",
      "description": "传统机器学习与深度学习各有优劣，前者依赖特征工程，后者可实现端到端学习，两者是相融相生的关系。"
    },
    {
      "source": "传统机器学习",
      "target": "特征工程",
      "relation": "related",
      "description": "传统机器学习90%的时间会花在特征工程上。"
    },
    {
      "source": "RLHF",
      "target": "强化学习",
      "relation": "related",
      "description": "Reinforcement Learning from Human Feedback is a technique used to align reinforcement learning models with human values."
    },
    {
      "source": "用户数据",
      "target": "风控建模方法",
      "relation": "related",
      "description": "该风控建模方法以用户数据作为主要处理对象。"
    },
    {
      "source": "Bias",
      "target": "Threshold",
      "relation": "related",
      "description": "Bias (`b`) is mathematically defined as the negative of the threshold value."
    },
    {
      "source": "Bias",
      "target": "Training",
      "relation": "related",
      "description": "Training involves the iterative adjustment of bias to optimize model performance."
    },
    {
      "source": "Data Processing Procedure",
      "target": "Deep Neural Network (DNN)",
      "relation": "related",
      "description": "Training a DNN model requires the significant computational power provided by the Data Processing Procedure."
    },
    {
      "source": "Weight Matrix WK",
      "target": "Linear Layer",
      "relation": "related",
      "description": "Another parallel subset of the linear layer contains the unique weight matrix WK."
    },
    {
      "source": "Michael Nielsen",
      "target": "神经网络与深度学习",
      "relation": "related",
      "description": "Michael Nielsen是《神经网络与深度学习》这本在线教科书的作者，该书内容涉及神经网络和反向传播。"
    },
    {
      "source": "感知器",
      "target": "神经元",
      "relation": "related",
      "description": "感知器模仿生物神经元的功能，接收输入并产生输出。"
    },
    {
      "source": "耦合模式比对计划第六阶段",
      "target": "深度学习地球系统模型",
      "relation": "related",
      "description": "The DLESyM model's performance is comparable to or better than CMIP6 models, while requiring significantly lower computational cost."
    },
    {
      "source": "自然語言處理",
      "target": "深度學習",
      "relation": "related",
      "description": "自然語言處理機制建立在深度學習之上，使其能夠進行更精準的上下文理解和情感分析。"
    },
    {
      "source": "自然語言處理",
      "target": "孫民",
      "relation": "related",
      "description": "孫民表示自然語言處理能提高情感分析精確度，但也指出其在文本生成方面的不穩定性和對訓練資料質量的依賴。"
    },
    {
      "source": "深脑",
      "target": "Google",
      "relation": "related",
      "description": "Google acquired the company DeepMind (深脑)."
    },
    {
      "source": "深脑",
      "target": "强化学习",
      "relation": "related",
      "description": "DeepMind integrated the concept of reinforcement learning from neuroscience with deep learning."
    },
    {
      "source": "深脑",
      "target": "AlphaGo",
      "relation": "related",
      "description": "DeepMind, led by its team, created the AlphaGo program."
    },
    {
      "source": "研究人员",
      "target": "人工智能",
      "relation": "related",
      "description": "Researchers are attempting to combine artificial intelligence with climatology."
    },
    {
      "source": "人机回圈",
      "target": "AI监管",
      "relation": "related",
      "description": "AI regulation emphasizes the importance of human-in-the-loop strategies for key decisions."
    },
    {
      "source": "DeepMind",
      "target": "CASP14",
      "relation": "related",
      "description": "DeepMind presented information about AlphaFold2 at the CASP14 competition."
    },
    {
      "source": "Chio et al.",
      "target": "Electronic Health Records",
      "relation": "related",
      "description": "Chio et al. used Electronic Health Records data to train their prediction model."
    },
    {
      "source": "Chio et al.",
      "target": "Recurrent Neural Network",
      "relation": "related",
      "description": "Chio et al. pioneered the application of Recurrent Neural Network methods for predicting Heart Failure."
    },
    {
      "source": "单层CNN",
      "target": "Max-Pooling",
      "relation": "related",
      "description": "The single-layer CNN uses max-pooling to obtain the largest feature from each feature map as its final output."
    },
    {
      "source": "技术逻辑",
      "target": "王田",
      "relation": "related",
      "description": "Wang Tian states that developing AI's \"philosophy\" requires ensuring innovation is not dominated by technological logic."
    },
    {
      "source": "技术逻辑",
      "target": "哲学思考",
      "relation": "related",
      "description": "Human philosophical thought must transcend the technological logic of AI to confirm the unique subjective value of human thinking."
    },
    {
      "source": "因子",
      "target": "深度学习",
      "relation": "related",
      "description": "Deep learning models in quantitative trading can also use factors as input features, and there is mention of using them to mine for new factors."
    },
    {
      "source": "因子",
      "target": "机器学习",
      "relation": "related",
      "description": "Machine learning models in quantitative trading use factors as their input features or data."
    },
    {
      "source": "三方工程师",
      "target": "深度学习欺诈侦测模型",
      "relation": "related",
      "description": "The three-party engineers conducted simulation verification for the new deep learning fraud detection model."
    },
    {
      "source": "三方工程师",
      "target": "仿真验证",
      "relation": "related",
      "description": "The three-party engineers performed multiple simulation verifications."
    },
    {
      "source": "数据分析",
      "target": "数据挖掘",
      "relation": "related",
      "description": "Data mining is a process closely related to data analysis, focused on discovering patterns in data."
    },
    {
      "source": "数据分析",
      "target": "大数据",
      "relation": "related",
      "description": "Data analysis is a key process applied to big data to extract insights."
    },
    {
      "source": "迁移学习",
      "target": "深度学习",
      "relation": "related",
      "description": "迁移学习是一种用于优化深度学习模型训练过程的技术，能显著减少对数据、时间和计算资源的需求。<SEP>迁移学习是深度学习领域关注的前沿技术之一。"
    },
    {
      "source": "迁移学习",
      "target": "PyTorch",
      "relation": "related",
      "description": "Transfer learning can be implemented using the PyTorch framework for training deep learning models, as referenced in the Azure Machine Learning documentation."
    },
    {
      "source": "搜索引擎",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理为搜索引擎提供支持。"
    },
    {
      "source": "神经网络与深度学习",
      "target": "反向传播",
      "relation": "related",
      "description": "在《神经网络与深度学习》教科书中，Michael Nielsen解释了反向传播算法，并将其与计算梯度的直观方法进行了效率比较。"
    },
    {
      "source": "3D Equivariant Structure Module",
      "target": "Residue Gas",
      "relation": "related",
      "description": "The Structure Module uses the Residue Gas representation to model the protein backbone."
    },
    {
      "source": "3D Equivariant Structure Module",
      "target": "蛋白质骨架初始Residue Gas",
      "relation": "related",
      "description": "The Structure Module is initialized with a starting Residue Gas representation of the protein backbone."
    },
    {
      "source": "3D Equivariant Structure Module",
      "target": "lDDT-Cα",
      "relation": "related",
      "description": "The Structure Module outputs an lDDT-Cα score to assess the accuracy of its predicted structure."
    },
    {
      "source": "Generative Summarization",
      "target": "News Headline Generation",
      "relation": "related",
      "description": "The task of generating a news headline from the first paragraph of an article is given as a simpler, practical example of generative summarization."
    },
    {
      "source": "GPT",
      "target": "大语言模型",
      "relation": "related",
      "description": "GPT是大型语言模型的一个具体实例和代表性模型。<SEP>GPT是大语言模型的一种具体实现。"
    },
    {
      "source": "GPT",
      "target": "Large Language Model",
      "relation": "related",
      "description": "GPT is a common example of a Large Language Model."
    },
    {
      "source": "图",
      "target": "结构数据",
      "relation": "related",
      "description": "Structural data is used to construct a graph for analysis."
    },
    {
      "source": "北半球大气阻塞事件",
      "target": "深度学习地球系统模型",
      "relation": "related",
      "description": "The DLESyM model accurately captures the frequency and spatial distribution of Northern Hemisphere atmospheric blocking events."
    },
    {
      "source": "Remote Sensing Image",
      "target": "Deep Learning",
      "relation": "related",
      "description": "Deep learning methods are applied to process and analyze remote sensing images for various applications."
    },
    {
      "source": "Transformers",
      "target": "BERT",
      "relation": "related",
      "description": "BERT is a specific, pre-trained implementation of the Transformer architecture for language tasks."
    },
    {
      "source": "Transformers",
      "target": "NLP",
      "relation": "related",
      "description": "The Transformers package supports the field of NLP."
    },
    {
      "source": "Convolutional Layer",
      "target": "Convolutional Neural Network (CNN)",
      "relation": "related",
      "description": "The convolutional layer is the core building block of a CNN, responsible for performing most of the computational work through convolution operations."
    },
    {
      "source": "Convolutional Layer",
      "target": "Kernel (Filter)",
      "relation": "related",
      "description": "The convolutional layer uses a kernel or filter as a feature detector that moves across the image's receptive fields to perform convolution."
    },
    {
      "source": "基础模型",
      "target": "watsonx.ai",
      "relation": "related",
      "description": "watsonx.ai is a platform for training, validating, tuning, and deploying foundation models."
    },
    {
      "source": "数据安全性",
      "target": "人工智能",
      "relation": "related",
      "description": "人工智能的发展带来了数据安全性等社会困境，迫使哲学进行反思。"
    },
    {
      "source": "技术指标",
      "target": "深度学习",
      "relation": "related",
      "description": "Deep learning's automatic feature extraction capability simplifies the traditional, manual process of designing technical indicators."
    },
    {
      "source": "算法",
      "target": "人工智能",
      "relation": "related",
      "description": "人工智能的核心在于算法和模型，这些算法和模型能够处理、分析和解释数据。"
    },
    {
      "source": "算法",
      "target": "模型",
      "relation": "related",
      "description": "算法是构成人工智能模型、使其能够从数据中学习并做出决策的要素。"
    },
    {
      "source": "算法",
      "target": "人工智能技术",
      "relation": "related",
      "description": "AI technology uses algorithms as a key tool, which shapes problems like inequality gaps."
    },
    {
      "source": "Talking Nets",
      "target": "Hinton",
      "relation": "related",
      "description": "An interview with Hinton is featured in the book \"Talking Nets\"."
    },
    {
      "source": "Talking Nets",
      "target": "Jim Anderson",
      "relation": "related",
      "description": "Jim Anderson co-authored the book \"Talking nets\"."
    },
    {
      "source": "Talking Nets",
      "target": "Lettvin",
      "relation": "related",
      "description": "The book \"Talking nets\" contains an interview with Lettvin, providing information about Pitts."
    },
    {
      "source": "Test Set",
      "target": "Area Under the Curve of Receiver Operating Characteristic (AUC)",
      "relation": "related",
      "description": "The performance of the fully trained model is evaluated using the Test Set data, measured by the AUC metric."
    },
    {
      "source": "Test Set",
      "target": "Deep Auto-Encoders",
      "relation": "related",
      "description": "The performance of the Deep Auto-Encoder model was evaluated on a test set that constituted 25% of the available data."
    },
    {
      "source": "编码器",
      "target": "转换器",
      "relation": "related",
      "description": "The Transformer model architecture contains encoder layers that process input sequences."
    },
    {
      "source": "Nature",
      "target": "Deep Learning",
      "relation": "related",
      "description": "The journal Nature published the 2015 review article titled \"Deep learning\"."
    },
    {
      "source": "Nature",
      "target": "AlphaFold2",
      "relation": "related",
      "description": "The paper detailing AlphaFold2 was published online in the journal Nature."
    },
    {
      "source": "CAJ文档",
      "target": "知网",
      "relation": "related",
      "description": "CNKI provides research papers in the CAJ document file format for download."
    },
    {
      "source": "前馈神经网络",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "Convolutional Neural Networks are a specific class of Feedforward Neural Networks.<SEP>卷积神经网络是前馈神经网络的一种特定类型。"
    },
    {
      "source": "前馈神经网络",
      "target": "自编码器",
      "relation": "related",
      "description": "自编码器是前馈神经网络的一种。"
    },
    {
      "source": "AI黑话揭秘",
      "target": "深度学习",
      "relation": "related",
      "description": "文章《AI黑话揭秘》旨在解释深度学习及其相关概念。"
    },
    {
      "source": "AI黑话揭秘",
      "target": "机器学习",
      "relation": "related",
      "description": "文章《AI黑话揭秘》旨在解释机器学习及其相关概念。"
    },
    {
      "source": "AI黑话揭秘",
      "target": "人工智能",
      "relation": "related",
      "description": "文章《AI黑话揭秘》旨在解释人工智能及其相关概念。"
    },
    {
      "source": "哲学史",
      "target": "人工智能",
      "relation": "related",
      "description": "当人类把认知“外包”给AI并习惯“加速”获取知识后，必然会挤压哲学积累的空间，使阅读、实践和反思等能力退化。"
    },
    {
      "source": "最佳模型",
      "target": "部署需求",
      "relation": "related",
      "description": "Balancing deployment requirements with other factors helps determine the best model."
    },
    {
      "source": "最佳模型",
      "target": "利益相关者要求",
      "relation": "related",
      "description": "Balancing stakeholder requirements with other factors helps determine the best model."
    },
    {
      "source": "Learning",
      "target": "Synapse",
      "relation": "related",
      "description": "Neuroscience finds that the modifiable strength of synapses is likely the material basis for learning."
    },
    {
      "source": "Traditional Fraud Detection Systems",
      "target": "Machine Learning",
      "relation": "related",
      "description": "Many traditional fraud detection systems are built using Machine Learning techniques."
    },
    {
      "source": "Traditional Fraud Detection Systems",
      "target": "Concept Drift",
      "relation": "related",
      "description": "Traditional fraud detection systems face the challenge of concept drift, where data patterns change over time."
    },
    {
      "source": "From Deep Learning to Rational Machines",
      "target": "Deep Learning",
      "relation": "related",
      "description": "The book \"From Deep Learning to Rational Machines\" introduces and discusses the philosophical implications of deep learning."
    },
    {
      "source": "人",
      "target": "人工智能",
      "relation": "related",
      "description": "AI technology impacts the understanding of humans, forcing a redefinition of human uniqueness and irreplaceability."
    },
    {
      "source": "梯度",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播的核心功能是计算梯度。<SEP>反向传播的主要目的是计算神经网络参数的梯度，以便使用优化算法进行更新。"
    },
    {
      "source": "梯度",
      "target": "链式规则",
      "relation": "related",
      "description": "链式规则是反向传播中用于计算复合函数(即神经网络)梯度的核心数学工具。"
    },
    {
      "source": "互联网时代",
      "target": "深度学习",
      "relation": "related",
      "description": "互联网时代带来的海量电子化数据是深度学习得以发展和应用的重要基础。"
    },
    {
      "source": "Scikit-learn",
      "target": "Credit Card Fraud Detection: A Deep Learning Approach",
      "relation": "related",
      "description": "The paper compares the performance of its proposed deep learning methods against various algorithms from the Scikit-learn library."
    },
    {
      "source": "Azure机器学习",
      "target": "深度学习",
      "relation": "related",
      "description": "Azure机器学习支持构建深度学习解决方案，应用于欺诈检测、语音识别、面部识别、情绪分析和时序预测等领域。"
    },
    {
      "source": "Azure机器学习",
      "target": "Microsoft Azure Global Edition",
      "relation": "related",
      "description": "Azure Machine Learning is a service within the Microsoft Azure Global Edition cloud platform, and its technical documentation is hosted there."
    },
    {
      "source": "机器学习",
      "target": "深度学习",
      "relation": "related",
      "description": "{\"实体列表\": [\"机器学习\", \"深度学习\", \"人工神经网络\", \"深度神经网络\", \"神经网络\", \"模式识别\"]}"
    },
    {
      "source": "机器学习",
      "target": "人工智能",
      "relation": "related",
      "description": "人工智能与机器学习之间的关系是子集与核心路径的关系。机器学习是人工智能（AI）领域的一个子集、子领域或重要分支。其核心目标是通过从数据中学习，让系统具备执行智能任务的能力。因此，机器学习是实现人工智能目标的一种核心路径和主要方法，专注于利用包括深度学习在内的各种技术进行优化与预测。"
    },
    {
      "source": "机器学习",
      "target": "特征提取",
      "relation": "related",
      "description": "在机器学习中，特征提取是一种关键技术，用于从数据中获取信息以指导算法进行准确预测。"
    },
    {
      "source": "机器学习",
      "target": "Amazon",
      "relation": "related",
      "description": "Amazon使用机器学习技术，根据客户数据向其推荐产品。"
    },
    {
      "source": "机器学习",
      "target": "watsonx.ai",
      "relation": "related",
      "description": "watsonx.ai is a platform for training, validating, tuning, and deploying machine learning capabilities."
    },
    {
      "source": "机器学习",
      "target": "蛋白质结构预测",
      "relation": "related",
      "description": "机器学习被应用于蛋白质结构预测领域。"
    },
    {
      "source": "机器学习",
      "target": "MIT 6.874",
      "relation": "related",
      "description": "MIT 6.874课程介绍了机器学习的基础知识。"
    },
    {
      "source": "机器学习",
      "target": "量化交易",
      "relation": "related",
      "description": "文中探讨了机器学习在量化交易中的应用，并评估了其在不同频率交易中的效能。"
    },
    {
      "source": "机器学习",
      "target": "中低频量化",
      "relation": "related",
      "description": "作者尝试将机器学习应用于中低频量化，但最终所有机器学习模型的表现都不如传统的线性模型。"
    },
    {
      "source": "机器学习",
      "target": "高频量化",
      "relation": "related",
      "description": "作者转到高频量化(日内T0)后，发现机器学习在此场景下展现了比较大的优势。"
    },
    {
      "source": "机器学习",
      "target": "线性模型",
      "relation": "related",
      "description": "文中将机器学习模型与线性模型在不同量化场景下的效能进行了对比。"
    },
    {
      "source": "机器学习",
      "target": "推荐系统",
      "relation": "related",
      "description": "以互联网行业的推荐系统为例，说明机器学习能应用好的前提是人本身也能把这件事(如个性化推荐)做得不错。<SEP>机器学习应用于推荐系统领域，例如使用协同过滤算法。"
    },
    {
      "source": "机器学习",
      "target": "反欺诈",
      "relation": "related",
      "description": "机器学习在互联网行业被用于反欺诈等任务。"
    },
    {
      "source": "机器学习",
      "target": "quant-computer",
      "relation": "related",
      "description": "The user 'quant-computer' considered transitioning to machine learning after leaving quantitative finance."
    },
    {
      "source": "机器学习",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理使用机器学习方法来使计算机理解人类语言。"
    },
    {
      "source": "机器学习",
      "target": "监督学习",
      "relation": "related",
      "description": "监督学习是机器学习的一种主要学习范式和方法类别。<SEP>Supervised Learning is one of the primary types and methodologies within Machine Learning."
    },
    {
      "source": "机器学习",
      "target": "强化学习",
      "relation": "related",
      "description": "Reinforcement Learning is one of the primary types and methodologies within Machine Learning."
    },
    {
      "source": "机器学习",
      "target": "深度学习地球系统模型",
      "relation": "related",
      "description": "Machine learning is the foundational methodology upon which the Deep Learning Earth System Model (DLESyM) is built."
    },
    {
      "source": "人工智能",
      "target": "深度学习",
      "relation": "related",
      "description": "Deep learning is a core subfield and a driving force within the broader domain of artificial intelligence.<SEP>深度学习是人工智能的一个子领域。<SEP>深度学习是人工智能领域的核心技术之一。"
    },
    {
      "source": "人工智能",
      "target": "生成式AI",
      "relation": "related",
      "description": "生成式AI是人工智能的一个子集，专门使用深度学习等技术来生成新的内容。"
    },
    {
      "source": "人工智能",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "Convolutional Neural Networks are a key technology within the broader field of Artificial Intelligence."
    },
    {
      "source": "人工智能",
      "target": "自然语言处理",
      "relation": "related",
      "description": "Natural language processing utilizes predictive artificial intelligence as a key component.<SEP>自然语言处理是人工智能的一个重要分支，致力于让机器理解人类语言。<SEP>自然语言处理是人工智能的一个子领域。<SEP>自然语言处理是人工智能涵盖的多个方面之一。<SEP>自然语言处理是人工智能领域的一个重要子领域和核心技术。<SEP>人工智能包含自然语言处理，自然语言处理是人工智能的一个子领域。<SEP>Natural Language Processing is a major subfield and application domain within Artificial Intelligence."
    },
    {
      "source": "人工智能",
      "target": "语言",
      "relation": "related",
      "description": "人工智能涉及对人类感官的模拟，语言对应自然语言处理技术。"
    },
    {
      "source": "人工智能",
      "target": "Knowledge Base",
      "relation": "related",
      "description": "知识数据库是人工智能的一种实现形式，尽管其智能程度可能有限。"
    },
    {
      "source": "人工智能",
      "target": "大语言模型",
      "relation": "related",
      "description": "大语言模型是人工智能领域的一个重要领域和分支。<SEP>大语言模型是人工智能技术发展中的关键组成部分和核心支柱，推动AI向通用AI迈进。"
    },
    {
      "source": "人工智能",
      "target": "模型",
      "relation": "related",
      "description": "模型是人工智能系统的核心，用来简化和理解真实世界的过程或对象。"
    },
    {
      "source": "人工智能",
      "target": "浙江大学人工智能教育教学研究中心",
      "relation": "related",
      "description": "该研究中心通过其研究成果展示了人工智能的应用。"
    },
    {
      "source": "人工智能",
      "target": "计算机视觉",
      "relation": "related",
      "description": "计算机视觉是人工智能涵盖的多个方面之一。<SEP>人工智能包含计算机视觉，计算机视觉是人工智能的一个子领域。<SEP>Computer Vision is a major subfield and application domain within Artificial Intelligence."
    },
    {
      "source": "人工智能",
      "target": "垂直模型",
      "relation": "related",
      "description": "在ChatGPT爆火之前，提到AI模型一般指的是垂直模型，这是传统AI的一种形式。"
    },
    {
      "source": "人工智能",
      "target": "大数据",
      "relation": "related",
      "description": "Artificial intelligence, particularly AI models, relies on big data for development and performance improvement."
    },
    {
      "source": "人工智能",
      "target": "谭铁牛",
      "relation": "related",
      "description": "Academician Tan Tieniu provided a definition for artificial intelligence in a published article."
    },
    {
      "source": "人工智能",
      "target": "哲学研究",
      "relation": "related",
      "description": "The development of Artificial Intelligence brings numerous challenges to the field of philosophical research."
    },
    {
      "source": "人工智能",
      "target": "大型语言模型",
      "relation": "related",
      "description": "Large Language Models are a specific and widely applied part of Artificial Intelligence technology."
    },
    {
      "source": "人工智能",
      "target": "哲学学者",
      "relation": "related",
      "description": "Philosophical scholars face practical challenges in their research from the capabilities of Artificial Intelligence."
    },
    {
      "source": "人工智能",
      "target": "赵立",
      "relation": "related",
      "description": "赵立analyzes Artificial Intelligence as an efficient technical integration of past thought that presents a significant challenge to contemporary philosophical thinking."
    },
    {
      "source": "人工智能",
      "target": "哲学思考",
      "relation": "related",
      "description": "The core of philosophical thinking, involving questioning and conceptual innovation, is contrasted with the informational efficiency of AI, highlighting a uniquely human capacity."
    },
    {
      "source": "人工智能",
      "target": "王田",
      "relation": "related",
      "description": "Wang Tian discusses that developing AI's \"philosophy\" requires considering social conditions and ensuring AI serves humanity."
    },
    {
      "source": "人工智能",
      "target": "技术哲学",
      "relation": "related",
      "description": "人工智能的普遍应用促使关于技术的深层思考成为哲学主要领域，可能推动技术哲学的兴起。<SEP>The widespread application of AI prompts the formation and elevation of the philosophy of technology as a major field."
    },
    {
      "source": "强化学习",
      "target": "深度学习",
      "relation": "related",
      "description": "根据David Silver的观点，深度学习与强化学习相结合可以构成人工智能。<SEP>强化学习是深度学习领域关注的前沿技术之一。"
    },
    {
      "source": "强化学习",
      "target": "AlphaGo",
      "relation": "related",
      "description": "AlphaGo utilizes a combination of deep learning and reinforcement learning."
    },
    {
      "source": "线性模型",
      "target": "中低频量化",
      "relation": "related",
      "description": "在中低频量化中，传统的线性模型被作为基准，其表现优于作者尝试的各种机器学习模型。"
    },
    {
      "source": "Training Phase",
      "target": "Training Set",
      "relation": "related",
      "description": "The training phase uses the Training Set to build and initially evaluate the model."
    },
    {
      "source": "学习率",
      "target": "SGD",
      "relation": "related",
      "description": "优化器SGD的学习率被设置为0.1。"
    },
    {
      "source": "杨媛",
      "target": "深度学习",
      "relation": "related",
      "description": "杨媛撰写了论文，从哲学角度审视深度学习的技术路径。"
    },
    {
      "source": "杨媛",
      "target": "华南师范大学马克思主义学院",
      "relation": "related",
      "description": "杨媛隶属于华南师范大学马克思主义学院。"
    },
    {
      "source": "杨媛",
      "target": "DOI: 10.12677/acpp.2025.145279",
      "relation": "related",
      "description": "杨媛是拥有该DOI的论文的作者。"
    },
    {
      "source": "Doctor of Philosophy",
      "target": "科学",
      "relation": "related",
      "description": "博士学位被称为Doctor of Philosophy，体现了科学和艺术领域之间的深层逻辑联系。"
    },
    {
      "source": "Fraud Detection",
      "target": "Machine Learning",
      "relation": "related",
      "description": "Machine learning is a method applied to the task of fraud detection."
    },
    {
      "source": "Fraud Detection",
      "target": "Deep Learning",
      "relation": "related",
      "description": "There is a transition from using machine learning to using deep learning for fraud detection, which has a significant business impact."
    },
    {
      "source": "Fraud Detection",
      "target": "Deep Learning Models",
      "relation": "related",
      "description": "Deep learning models improve the accuracy of fraud detection, enable real-time detection, and reduce false positives."
    },
    {
      "source": "Computer Vision",
      "target": "Convolutional Neural Network",
      "relation": "related",
      "description": "Convolutional Neural Networks have achieved great success in the field of computer vision."
    },
    {
      "source": "Computer Vision",
      "target": "Object Detection",
      "relation": "related",
      "description": "Object detection is a specific task within the field of computer vision."
    },
    {
      "source": "Computer Vision",
      "target": "Convolutional Neural Network (CNN)",
      "relation": "related",
      "description": "Convolutional neural networks are a powerful driving force for performing image recognition and computer vision tasks."
    },
    {
      "source": "Zero-Padding",
      "target": "Convolution Operation",
      "relation": "related",
      "description": "Zero-padding is a technique applied to input images to facilitate the convolution operation, especially with specific stride values."
    },
    {
      "source": "MNIST模型",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "MNIST模型是用于实现卷积神经网络的一个具体示例，常用于图像分类任务。"
    },
    {
      "source": "MNIST模型",
      "target": "SGD",
      "relation": "related",
      "description": "在MNIST模型训练中，采用SGD作为优化器，学习率设为0.1。"
    },
    {
      "source": "大型语言模型",
      "target": "生成式人工智能",
      "relation": "related",
      "description": "生成式人工智能涉及大型语言模型的交流技巧。"
    },
    {
      "source": "Image Comparison Algorithm",
      "target": "Threshold",
      "relation": "related",
      "description": "A threshold (like 85% confidence) is used with an image comparison algorithm to validate its probabilistic output."
    },
    {
      "source": "天善智能",
      "target": "数据挖掘",
      "relation": "related",
      "description": "Tianshan Intelligence is a vertical community focused on the field of data mining."
    },
    {
      "source": "Self-Attention Mechanism",
      "target": "Multi-Head Attention",
      "relation": "related",
      "description": "Multi-head attention is a specific technique used within the self-attention mechanism that enhances the model's performance."
    },
    {
      "source": "Self-Attention Mechanism",
      "target": "Transformer Model",
      "relation": "related",
      "description": "The self-attention mechanism is the core functional component that gives the transformer model its power to detect relationships in sequences."
    },
    {
      "source": "特征工程",
      "target": "深度学习",
      "relation": "related",
      "description": "深度学习颠覆了传统机器学习的过程，不需要手动做特征工程。<SEP>深度学习颠覆了传统机器学习流程，它不需要进行复杂的手动特征工程。"
    },
    {
      "source": "特征工程",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "Convolutional Neural Networks (CNN) automate the feature extraction process, greatly simplifying the traditional feature engineering workflow."
    },
    {
      "source": "IBM业界领先的AI专业知识和解决方案组合",
      "target": "IBM",
      "relation": "related",
      "description": "IBM possesses industry-leading AI expertise and a portfolio of solutions."
    },
    {
      "source": "IBM业界领先的AI专业知识和解决方案组合",
      "target": "AI应用程序",
      "relation": "related",
      "description": "IBM's AI expertise and solutions enable the effective functioning and development of AI applications in business."
    },
    {
      "source": "Deep Learning",
      "target": "PyTorch",
      "relation": "related",
      "description": "PyTorch is a framework used to implement deep learning models for remote sensing tasks."
    },
    {
      "source": "Deep Learning",
      "target": "Convolutional Neural Network",
      "relation": "related",
      "description": "Convolutional Neural Network is a model within the deep learning subfield of artificial intelligence.<SEP>Deep Learning encompasses architectures like Convolutional Neural Network, which are used for feature extraction.<SEP>Convolutional Neural Network is a type of architecture within deep learning used for the task."
    },
    {
      "source": "Deep Learning",
      "target": "Convolutional Neural Networks",
      "relation": "related",
      "description": "Convolutional Neural Networks are a representative example of deep learning."
    },
    {
      "source": "Deep Learning",
      "target": "Synapse",
      "relation": "related",
      "description": "The modifiable strength of biological synapses inspired the adjustable connection weights fundamental to deep learning algorithms."
    },
    {
      "source": "Deep Learning",
      "target": "Image Recognition",
      "relation": "related",
      "description": "Deep learning technology is applied in image recognition systems."
    },
    {
      "source": "Deep Learning",
      "target": "Yann LeCun",
      "relation": "related",
      "description": "Yann LeCun co-authored the introductory review article on deep learning."
    },
    {
      "source": "Deep Learning",
      "target": "Multi-Modal Learning",
      "relation": "related",
      "description": "Multi-modal learning represents a future direction for deep learning in quantitative trading, integrating diverse data types."
    },
    {
      "source": "Deep Learning",
      "target": "Quantitative Trading",
      "relation": "related",
      "description": "Deep Learning is actively reshaping the quantitative trading landscape by providing unprecedented analytical and decision-making tools."
    },
    {
      "source": "Deep Learning",
      "target": "Electronic Health Records",
      "relation": "related",
      "description": "Deep Learning methods are being used to analyze Electronic Health Records for building disease risk models."
    },
    {
      "source": "Deep Learning",
      "target": "Recurrent Neural Network",
      "relation": "related",
      "description": "Deep Learning encompasses architectures like Recurrent Neural Network, which are used for analyzing temporal sequences."
    },
    {
      "source": "Deep Learning",
      "target": "Deep Learning Models",
      "relation": "related",
      "description": "Deep learning models are the specific implementation of the deep learning method."
    },
    {
      "source": "Deep Learning",
      "target": "CRF",
      "relation": "related",
      "description": "Deep learning models can overcome the drawback of traditional CRF models, which struggle to capture long-range contextual dependencies that are crucial for certain semantic understanding tasks."
    },
    {
      "source": "Deep Learning",
      "target": "Evaluation System",
      "relation": "related",
      "description": "The evaluation system is established to assess the feasibility and performance of deep learning for the specified tasks."
    },
    {
      "source": "Deep Learning",
      "target": "DenseNet",
      "relation": "related",
      "description": "DenseNet is a specific deep learning model evaluated within the study.<SEP>DenseNet is part of the discussed evolution of deep learning model structures for optimization."
    },
    {
      "source": "Deep Learning",
      "target": "ResNet-18",
      "relation": "related",
      "description": "ResNet-18 is a specific deep learning model evaluated within the study."
    },
    {
      "source": "Deep Learning",
      "target": "Object Detection",
      "relation": "related",
      "description": "Deep learning provides the methodology for performing object detection tasks on remote sensing images."
    },
    {
      "source": "Deep Learning",
      "target": "AlexNet",
      "relation": "related",
      "description": "AlexNet is part of the discussed evolution of deep learning model structures for optimization."
    },
    {
      "source": "Deep Learning",
      "target": "GoogleNet",
      "relation": "related",
      "description": "GoogleNet is part of the discussed evolution of deep learning model structures for optimization."
    },
    {
      "source": "Deep Learning",
      "target": "Meteorological Elements Forecasting Method",
      "relation": "related",
      "description": "The Meteorological Elements Forecasting Method is based on the concept and techniques of Deep Learning."
    },
    {
      "source": "Deep Learning",
      "target": "Weather Forecasting",
      "relation": "related",
      "description": "Weather forecasting utilizes deep learning techniques for enhanced prediction models."
    },
    {
      "source": "GBDT→GRU→RF三明治结构",
      "target": "深度学习欺诈侦测模型",
      "relation": "related",
      "description": "该深度学习模型采用了GBDT→GRU→RF三明治结构作为其核心架构。"
    },
    {
      "source": "GBDT→GRU→RF三明治结构",
      "target": "GRU",
      "relation": "related",
      "description": "The GBDT→GRU→RF sandwich structure includes GRU as one of its components."
    },
    {
      "source": "AI构建器",
      "target": "生成式AI",
      "relation": "related",
      "description": "AI builders are the personnel who utilize generative AI to construct and deliver innovative solutions."
    },
    {
      "source": "经典因子模型",
      "target": "深度学习",
      "relation": "related",
      "description": "Deep learning models can be seamlessly integrated with classical factor models to form composite or hybrid trading strategies."
    },
    {
      "source": "GDPR",
      "target": "AI监管",
      "relation": "related",
      "description": "AI regulation involves ensuring compliance with data privacy laws like GDPR."
    },
    {
      "source": "正向传播",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播的梯度计算依赖于正向传播计算并存储的变量当前值。"
    },
    {
      "source": "正向传播",
      "target": "局部导数",
      "relation": "related",
      "description": "局部导数的定义来源于正向传播中的函数y=f(x)，是该函数的导数。"
    },
    {
      "source": "输入层",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播的计算过程最终到达输入层。"
    },
    {
      "source": "输入层",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "输入层是卷积神经网络的一个组成部分，负责接收原始图像数据。"
    },
    {
      "source": "NLP预处理",
      "target": "深度学习模型",
      "relation": "related",
      "description": "NLP预处理将文本转换成深度学习模型更容易分析的特定格式。"
    },
    {
      "source": "NLP预处理",
      "target": "原始文本",
      "relation": "related",
      "description": "NLP预处理以原始文本作为输入，对其进行处理以准备后续分析。"
    },
    {
      "source": "Encoder-Decoder Architecture",
      "target": "Encoder",
      "relation": "related",
      "description": "The Encoder is a core component that forms part of the Encoder-Decoder Architecture."
    },
    {
      "source": "Encoder-Decoder Architecture",
      "target": "Decoder",
      "relation": "related",
      "description": "The Decoder is a core component that forms part of the Encoder-Decoder Architecture."
    },
    {
      "source": "Sigmoid Function",
      "target": "Perceptron",
      "relation": "related",
      "description": "The sigmoid function is applied to the perceptron's output to create a continuous activation function."
    },
    {
      "source": "Sigmoid Function",
      "target": "Continuous Function",
      "relation": "related",
      "description": "The sigmoid function is a specific implementation used to create a continuous output function from the perceptron's result."
    },
    {
      "source": "深度学习技术",
      "target": "图像处理",
      "relation": "related",
      "description": "Deep learning technology has achieved breakthroughs in the field of image processing."
    },
    {
      "source": "转换器",
      "target": "深度学习",
      "relation": "related",
      "description": "转换器是深度学习中的一种模型架构，专门设计用于处理文本或时序数据等序列问题。"
    },
    {
      "source": "深度学习欺诈侦测模型",
      "target": "仿真验证",
      "relation": "related",
      "description": "该模型通过仿真验证方法来评估其性能和有效性。"
    },
    {
      "source": "BP算法",
      "target": "反向传播",
      "relation": "related",
      "description": "BP算法是反向传播思想的一种具体实现，用于训练神经网络。"
    },
    {
      "source": "BP算法",
      "target": "链式求导法则",
      "relation": "related",
      "description": "BP算法的推导依赖于链式求导法则来计算误差对网络权重的偏导数。"
    },
    {
      "source": "Token",
      "target": "Large Language Model (LLM)",
      "relation": "related",
      "description": "Large language models process text using tokens as their fundamental linguistic units."
    },
    {
      "source": "Token",
      "target": "Query, Key, Value Vectors",
      "relation": "related",
      "description": "Query, key, and value vectors are generated from the original token embeddings through linear transformations."
    },
    {
      "source": "Narrator",
      "target": "Weight",
      "relation": "related",
      "description": "The narrator relearned the meaning of the concept of weight clearly and profoundly."
    },
    {
      "source": "Narrator",
      "target": "Threshold",
      "relation": "related",
      "description": "The narrator relearned the meaning of the concept of threshold clearly and profoundly."
    },
    {
      "source": "客户支持",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理在自动化客户支持任务中特别有用。"
    },
    {
      "source": "Image",
      "target": "Convolutional Neural Network",
      "relation": "related",
      "description": "Convolutional Neural Networks are designed to process image data."
    },
    {
      "source": "Image",
      "target": "RGB Color Model",
      "relation": "related",
      "description": "Images are commonly represented using the RGB color model, which consists of three channels."
    },
    {
      "source": "Nature Communications",
      "target": "郑伟",
      "relation": "related",
      "description": "郑伟教授在Nature Communications期刊上发表过文章。"
    },
    {
      "source": "学习范式",
      "target": "深度学习",
      "relation": "related",
      "description": "学习范式是深度学习的一个关键方面，本文对其进行了哲学讨论。"
    },
    {
      "source": "高频量化",
      "target": "深度学习",
      "relation": "related",
      "description": "在高频量化中，深度学习比传统机器学习展现出更多的优势。"
    },
    {
      "source": "高频量化",
      "target": "信噪比",
      "relation": "related",
      "description": "作者认为高频量化信噪比较高，是机器学习能在此场景表现更好的原因之一。"
    },
    {
      "source": "高频量化",
      "target": "数据量",
      "relation": "related",
      "description": "作者指出高频量化(如使用Tick数据)数据量巨大，是机器学习能有效学习的前提。"
    },
    {
      "source": "Christian Ideology",
      "target": "Hinton",
      "relation": "related",
      "description": "Hinton expressed a critical view of Christian ideology, considering it \"complete rubbish\"."
    },
    {
      "source": "Appier",
      "target": "孙民",
      "relation": "related",
      "description": "孙民是Appier公司的首席人工智能科学家，他的观点代表了该公司的技术见解。"
    },
    {
      "source": "Appier",
      "target": "Appier Blog",
      "relation": "related",
      "description": "Appier publishes and maintains the Appier Blog to share insights and trends."
    },
    {
      "source": "Historical Data",
      "target": "Weather Forecasting",
      "relation": "related",
      "description": "Weather forecasting relies on historical weather data as a primary input for model training."
    },
    {
      "source": "Max-Pooling",
      "target": "CNN",
      "relation": "related",
      "description": "The described CNN model uses max-pooling to obtain the largest feature from each feature map for its final output."
    },
    {
      "source": "魏犇群",
      "target": "生成式人工智能",
      "relation": "related",
      "description": "魏犇群提出并分析了生成式人工智能给哲学研究视域带来的深刻变化。"
    },
    {
      "source": "魏犇群",
      "target": "情感",
      "relation": "related",
      "description": "Wei Benqun mentions that re-understanding human uniqueness in the AI era includes re-understanding emotion."
    },
    {
      "source": "魏犇群",
      "target": "人工智能的哲学",
      "relation": "related",
      "description": "Wei Benqun explains the two meanings of \"AI's philosophy\": philosophy about AI and philosophy created by AI."
    },
    {
      "source": "魏犇群",
      "target": "哲学价值",
      "relation": "related",
      "description": "Wei Benqun explains that philosophical value is manifested in critical insight and meaning creation."
    },
    {
      "source": "池化层",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "The pooling layer is a standard component within the architecture of a Convolutional Neural Network.<SEP>池化层是卷积神经网络的一个组成部分，用于对特征图进行下采样。<SEP>Convolutional Neural Networks incorporate pooling layers to reduce the spatial dimensions of the features extracted by convolutional layers.<SEP>池化层是卷积神经网络的核心组成部分之一，负责汇聚特征并减少数据维度。"
    },
    {
      "source": "池化层",
      "target": "过拟合",
      "relation": "related",
      "description": "池化层通过降低数据维度和减少训练参数，有助于避免过拟合问题。"
    },
    {
      "source": "Coursera",
      "target": "计算认知",
      "relation": "related",
      "description": "Coursera平台上有推荐的课程，用于加深对计算认知的理解。"
    },
    {
      "source": "High-Frequency Trading Strategy",
      "target": "CNN",
      "relation": "related",
      "description": "CNN serves as the underlying algorithmic model for another version of the high-frequency trading strategy."
    },
    {
      "source": "High-Frequency Trading Strategy",
      "target": "Back-Testing Results",
      "relation": "related",
      "description": "The high-frequency trading strategy is evaluated through back-testing results to measure its effectiveness."
    },
    {
      "source": "推荐系统",
      "target": "深度学习",
      "relation": "related",
      "description": "以互联网行业的推荐系统为例，说明深度学习能应用好的前提是人本身也能把这件事做得不错。"
    },
    {
      "source": "推荐系统",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "通过对卷积神经网络进行巧妙的调整，使其能够在推荐系统任务中发挥作用。"
    },
    {
      "source": "Generative AI",
      "target": "Vertex AI",
      "relation": "related",
      "description": "Generative AI is a category of AI models hosted and provided through the Vertex AI platform on Google Cloud."
    },
    {
      "source": "Generative AI",
      "target": "Large Language Model (LLM)",
      "relation": "related",
      "description": "The development of large language models catalyzed and enabled the field of generative AI."
    },
    {
      "source": "BERT",
      "target": "文本表示",
      "relation": "related",
      "description": "BERT adapts the text representation of a token to be context-dependent, unlike static embeddings."
    },
    {
      "source": "AlphaDev",
      "target": "Google DeepMind",
      "relation": "related",
      "description": "Google DeepMind trained the reinforcement learning agent AlphaDev."
    },
    {
      "source": "AlphaDev",
      "target": "Small Sorting Algorithm",
      "relation": "related",
      "description": "AlphaDev discovered small sorting algorithms from scratch."
    },
    {
      "source": "市场环境",
      "target": "深度学习",
      "relation": "related",
      "description": "Deep learning models can adapt to changing market environments through continuous data training and model updates."
    },
    {
      "source": "中低频量化",
      "target": "信噪比",
      "relation": "related",
      "description": "作者认为中低频量化信噪比太低，是导致机器学习模型效果不佳的原因之一。"
    },
    {
      "source": "中低频量化",
      "target": "数据量",
      "relation": "related",
      "description": "作者认为中低频量化可用的数据量太少，是导致机器学习模型效果不佳的另一个原因。"
    },
    {
      "source": "Image Recognition",
      "target": "Convolutional Neural Network (CNN)",
      "relation": "related",
      "description": "Convolutional Neural Networks are a class of models specifically designed for the task of image recognition."
    },
    {
      "source": "Convolutional Neural Network",
      "target": "Convolution Operation",
      "relation": "related",
      "description": "The convolution operation is the fundamental and namesake operation of Convolutional Neural Networks."
    },
    {
      "source": "Encoder",
      "target": "Decoder",
      "relation": "related",
      "description": "The decoder uses the contextual information generated by the encoder to produce its output."
    },
    {
      "source": "Encoder",
      "target": "Encoder Block",
      "relation": "related",
      "description": "The Encoder is composed of multiple stacked Encoder blocks."
    },
    {
      "source": "Deep Neural Network (DNN)",
      "target": "Area Under the Curve of Receiver Operating Characteristic (AUC)",
      "relation": "related",
      "description": "The performance of the trained DNN model is evaluated using the AUC metric."
    },
    {
      "source": "Large Language Model",
      "target": "Fine-Tuning",
      "relation": "related",
      "description": "Fine-tuning is a common method used to adapt pre-trained large language models to specific tasks."
    },
    {
      "source": "Large Language Model",
      "target": "Transformer Architecture",
      "relation": "related",
      "description": "Large Language Models are a class of models based on the Transformer architecture."
    },
    {
      "source": "Large Language Model",
      "target": "Retrieval-Augmented Generation",
      "relation": "related",
      "description": "Retrieval-Augmented Generation is a technique that combines Large Language Models with external knowledge bases."
    },
    {
      "source": "Large Language Model",
      "target": "Deep Dive Into Llms Like Chatgpt",
      "relation": "related",
      "description": "The video \"Deep Dive into LLMs like ChatGPT\" provides an explanation and introduction to Large Language Models."
    },
    {
      "source": "权重",
      "target": "神经网络",
      "relation": "related",
      "description": "神经网络通过学习调整连接神经元之间的权重来存储知识和做出预测。"
    },
    {
      "source": "权重",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播算法根据误差信号回传来修正神经网络每层的权重系数。"
    },
    {
      "source": "Credit Card Fraud Detection: A Deep Learning Approach",
      "target": "Multi-layer Feed-forward Neural Network",
      "relation": "related",
      "description": "The paper proposes using a Multi-layer Feed-forward Neural Network as its first deep learning model for detecting credit card fraud."
    },
    {
      "source": "Credit Card Fraud Detection: A Deep Learning Approach",
      "target": "Deep Auto-Encoders",
      "relation": "related",
      "description": "The paper introduces Deep Auto-Encoders as an unsupervised learning method to identify anomalous transaction patterns in imbalanced data."
    },
    {
      "source": "Credit Card Fraud Detection: A Deep Learning Approach",
      "target": "Bat Algorithm",
      "relation": "related",
      "description": "The paper employs the Bat Algorithm to optimize the performance of its deep learning models by selecting better features and reducing training costs."
    },
    {
      "source": "Credit Card Fraud Detection: A Deep Learning Approach",
      "target": "Concept Drift",
      "relation": "related",
      "description": "The paper aims to overcome the challenge of concept drift, which affects traditional fraud detection systems."
    },
    {
      "source": "Deep Auto-Encoders",
      "target": "Training Set",
      "relation": "related",
      "description": "The Deep Auto-Encoder model was trained on a training set that constituted 75% of the available data."
    },
    {
      "source": "词元",
      "target": "文本表示",
      "relation": "related",
      "description": "A token is the basic unit for which a text representation (vector) is learned during pre-training."
    },
    {
      "source": "深度学习",
      "target": "神经网络",
      "relation": "related",
      "description": "神经网络是深度学习算法的基础，深度学习算法由多层神经网络节点构成。<SEP>Deep learning is a subfield of machine learning that is fundamentally based on the architecture of neural networks.<SEP>深度学习依托于神经网络，特别是深层神经网络，来进行数据处理。<SEP>神经网络是深度学习的基本概念。"
    },
    {
      "source": "深度学习",
      "target": "GPU",
      "relation": "related",
      "description": "深度学习依赖于高端硬件如GPU，因为GPU能有效优化深度学习所需执行的大量矩阵乘法运算。<SEP>深度学习算法训练速度的大幅提升依赖于GPU等并行计算硬件的加速。"
    },
    {
      "source": "深度学习",
      "target": "生成对抗网络",
      "relation": "related",
      "description": "生成对抗网络是深度学习领域中的一种生成模型，专门用于创建逼真的合成内容。"
    },
    {
      "source": "深度学习",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "卷积神经网络（Convolutional Neural Network，简称CNN或卷积神经网络）是深度学习领域中的一种特定且经典的网络架构，属于深度学习算法的一个子集和应用。深度学习作为一个更广泛的领域，为构建和理解卷积神经网络模型提供了知识基础。卷积神经网络是深度学习的代表性范例和突出架构之一。在实践应用中，深度学习经常使用卷积神经网络作为对序列进行编码的重要方法，并利用此类模型在诸如医学影像识别等多个领域实现具体应用。"
    },
    {
      "source": "深度学习",
      "target": "卷积平摊",
      "relation": "related",
      "description": "The field of deep learning includes the concept of convolution flattening as part of its theoretical explanations."
    },
    {
      "source": "深度学习",
      "target": "计算认知",
      "relation": "related",
      "description": "掌握深度学习的基本知识是加深对计算认知理解的基础。"
    },
    {
      "source": "深度学习",
      "target": "AlphaGo",
      "relation": "related",
      "description": "AlphaGo's success in Go is considered a prime annotation of the deep learning revolution, demonstrating its capabilities."
    },
    {
      "source": "深度学习",
      "target": "蛋白质结构预测",
      "relation": "related",
      "description": "深度学习被应用于蛋白质结构预测领域。"
    },
    {
      "source": "深度学习",
      "target": "ESMFold",
      "relation": "related",
      "description": "ESMFold是基于深度学习的方法。"
    },
    {
      "source": "深度学习",
      "target": "MIT 6.874",
      "relation": "related",
      "description": "MIT 6.874课程介绍了深度学习的前沿挑战。"
    },
    {
      "source": "深度学习",
      "target": "量化交易",
      "relation": "related",
      "description": "Deep learning is applied within quantitative trading, bringing new perspectives and tools to the field.<SEP>文中提及深度学习在量化交易中的应用，特别是在高频场景下的优势。"
    },
    {
      "source": "深度学习",
      "target": "高维数据",
      "relation": "related",
      "description": "Deep learning models possess the capability to effectively process the high-dimensional data involved in quantitative trading."
    },
    {
      "source": "深度学习",
      "target": "维度灾难",
      "relation": "related",
      "description": "Deep learning models help to avoid the \"curse of dimensionality\" problem common in traditional statistical methods."
    },
    {
      "source": "深度学习",
      "target": "反欺诈",
      "relation": "related",
      "description": "深度学习在互联网行业被用于反欺诈等任务。"
    },
    {
      "source": "深度学习",
      "target": "quant-computer",
      "relation": "related",
      "description": "The user 'quant-computer' ultimately switched to working in deep learning (image processing)."
    },
    {
      "source": "深度学习",
      "target": "风控建模方法",
      "relation": "related",
      "description": "该风控建模方法基于深度学习技术构建。"
    },
    {
      "source": "深度学习",
      "target": "大数据",
      "relation": "related",
      "description": "Big data provides the context for the rapid development of deep learning."
    },
    {
      "source": "深度学习",
      "target": "自然语言处理",
      "relation": "related",
      "description": "深度学习在自然语言处理领域扮演着至关重要的角色，是推动其发展的秘密武器。<SEP>自然语言处理结合深度学习技术来识别、理解和生成文本和语音。"
    },
    {
      "source": "深度学习",
      "target": "语料库",
      "relation": "related",
      "description": "深度学习的语言学习过程需要通过分析大量文本(语料库)来进行。"
    },
    {
      "source": "深度学习",
      "target": "Clear Plaster",
      "relation": "related",
      "description": "Deep learning enables AI to correctly interpret the search query \"clear plaster\" as a first-aid item, demonstrating its practical application in NLP."
    },
    {
      "source": "深度学习",
      "target": "Seed Data",
      "relation": "related",
      "description": "In deep learning applications like keyword marketing, the process starts by inputting some seed data into the AI system."
    },
    {
      "source": "深度学习",
      "target": "孙民",
      "relation": "related",
      "description": "孙民阐述了深度学习如何解决传统方法的问题，使NLP更贴近人类学习模式。"
    },
    {
      "source": "深度学习",
      "target": "LSTM",
      "relation": "related",
      "description": "深度学习需要处理长时间依赖的特征时，可以使用LSTM。<SEP>LSTM是深度学习的一种具体实现方式，用于学习上下文特征。"
    },
    {
      "source": "深度学习",
      "target": "对抗网络",
      "relation": "related",
      "description": "对抗网络是深度学习领域关注的前沿技术之一。"
    },
    {
      "source": "深度学习",
      "target": "David Silver",
      "relation": "related",
      "description": "David Silver提出了“深度学习+强化学习=人工智能”的观点，将深度学习与人工智能关联起来。"
    },
    {
      "source": "深度学习",
      "target": "CNN",
      "relation": "related",
      "description": "深度学习需要提取局部文本特征时，现在可以使用CNN。<SEP>CNN是深度学习领域中一种典型的神经网络模型。"
    },
    {
      "source": "深度学习",
      "target": "RNN",
      "relation": "related",
      "description": "深度学习需要处理长时间依赖的特征时，可以使用RNN。<SEP>RNN是深度学习领域中用于处理序列数据的典型模型。"
    },
    {
      "source": "深度学习",
      "target": "N元语法模型",
      "relation": "related",
      "description": "深度学习需要提取局部特征时，传统上可以使用N元语法模型。"
    },
    {
      "source": "深度学习",
      "target": "浙江大学人工智能教育教学研究中心",
      "relation": "related",
      "description": "该研究中心的研究展示了深度学习在模拟人类语言理解中的应用。"
    },
    {
      "source": "深度学习",
      "target": "大语言模型",
      "relation": "related",
      "description": "大语言模型是基于Transformer架构的深度学习模型，是处理人类语言的杰出成果。<SEP>深度学习包含大语言模型，大语言模型是深度学习技术的杰出应用之一。"
    },
    {
      "source": "深度学习",
      "target": "医学影像识别",
      "relation": "related",
      "description": "深度学习应用于医学影像识别领域，例如使用卷积神经网络。"
    },
    {
      "source": "深度学习",
      "target": "深度学习框架",
      "relation": "related",
      "description": "Deep Learning Frameworks are essential software tools that have standardized and accelerated the development of Deep Learning models."
    },
    {
      "source": "深度学习",
      "target": "遥感图像目标检测",
      "relation": "related",
      "description": "遥感图像目标检测方法是基于深度学习技术实现的。"
    },
    {
      "source": "深度学习",
      "target": "技术哲学",
      "relation": "related",
      "description": "本文从技术哲学的角度对深度学习进行审视和反思。"
    },
    {
      "source": "深度学习",
      "target": "技术演进",
      "relation": "related",
      "description": "技术演进描述了深度学习的发展历程，是本文梳理的内容之一。"
    },
    {
      "source": "深度学习",
      "target": "DOI: 10.12677/acpp.2025.145279",
      "relation": "related",
      "description": "该DOI唯一标识了这篇关于深度学习的论文。"
    },
    {
      "source": "深度学习",
      "target": "Abstract",
      "relation": "related",
      "description": "论文的英文摘要部分对深度学习进行了概述。"
    },
    {
      "source": "深度学习",
      "target": "Technical Path and Philosophical Review of Deep Learning",
      "relation": "related",
      "description": "论文的英文标题直接表明其主题是关于深度学习的。"
    },
    {
      "source": "过拟合",
      "target": "全连接层",
      "relation": "related",
      "description": "全连接层参数众多，层数一多就容易导致模型过拟合。"
    },
    {
      "source": "神经元",
      "target": "神经网络",
      "relation": "related",
      "description": "神经网络由互连的节点或神经元组成。"
    },
    {
      "source": "神经元",
      "target": "分层结构",
      "relation": "related",
      "description": "神经元位于神经网络的分层结构中。"
    },
    {
      "source": "神经元",
      "target": "反向传播",
      "relation": "related",
      "description": "在反向传播过程中，误差被分配给每个神经元，然后根据其梯度更新与之相连的权重。"
    },
    {
      "source": "神经元",
      "target": "激活函数",
      "relation": "related",
      "description": "神经元通过激活函数f(e)对加权和进行非线性变换，产生输出y。"
    },
    {
      "source": "Watson Studio",
      "target": "IBM",
      "relation": "related",
      "description": "IBM provides the Watson Studio platform.<SEP>Watson Studio is an IBM platform that provides tools for CNN model development and deployment."
    },
    {
      "source": "Watson Studio",
      "target": "CNN",
      "relation": "related",
      "description": "Watson Studio provides tools for the full lifecycle of building, training, tuning, and deploying CNN models."
    },
    {
      "source": "输出层",
      "target": "神经网络",
      "relation": "related",
      "description": "神经网络的输出层接收来自隐藏层的处理结果，并生成模型的最终预测(如分类概率)。"
    },
    {
      "source": "输出层",
      "target": "反向传播",
      "relation": "related",
      "description": "反向传播从输出层开始计算误差。"
    },
    {
      "source": "输出层",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "输出层是卷积神经网络的一个组成部分，负责生成最终的输出结果。"
    },
    {
      "source": "大语言模型",
      "target": "语言",
      "relation": "related",
      "description": "语言在大语言模型中是核心，是模型的学习对象和推理过程中生成与理解的基础。"
    },
    {
      "source": "大语言模型",
      "target": "自然语言处理",
      "relation": "related",
      "description": "大语言模型是人工智能在自然语言处理领域的一种应用，是自然语言处理的重要组成部分。"
    },
    {
      "source": "大语言模型",
      "target": "ChatGPT",
      "relation": "related",
      "description": "ChatGPT是大语言模型的一种具体实现和应用实例，用于智能客服。<SEP>The popularity of ChatGPT brought significant attention to the concept and capabilities of large language models."
    },
    {
      "source": "大语言模型",
      "target": "Transformer架构",
      "relation": "related",
      "description": "大语言模型是基于Transformer架构的神经网络语言模型。<SEP>大语言模型是基于Transformer架构构建的。"
    },
    {
      "source": "图像分类",
      "target": "深度卷积网络",
      "relation": "related",
      "description": "深度卷积网络可用于图像分类任务，通过逐层学习更复杂的特征。"
    },
    {
      "source": "图像分类",
      "target": "卷积",
      "relation": "related",
      "description": "卷积作为特征提取的基础方法，是图像分类等深度学习应用的核心原理之一。"
    },
    {
      "source": "Self-Attention",
      "target": "Multi-Head Attention",
      "relation": "related",
      "description": "Multi-Head Attention is composed of multiple parallel Self-Attention mechanisms."
    },
    {
      "source": "Self-Attention",
      "target": "Attention Mechanism",
      "relation": "related",
      "description": "Self-Attention is a specific type of Attention Mechanism used within the encoder and decoder."
    },
    {
      "source": "Decoder Block",
      "target": "Decoder",
      "relation": "related",
      "description": "The Decoder is composed of multiple stacked Decoder blocks."
    },
    {
      "source": "Decoder Block",
      "target": "Multi-Head Attention",
      "relation": "related",
      "description": "A Decoder block contains two Multi-Head Attention layers, one of which is a Masked Multi-Head Attention."
    },
    {
      "source": "ReLU",
      "target": "激活函数",
      "relation": "related",
      "description": "ReLU是激活函数的一种具体类型。"
    },
    {
      "source": "反向传播",
      "target": "深度学习模型",
      "relation": "related",
      "description": "反向传播是训练各种深度学习模型(从多层感知器到复杂生成式AI网络)的基础学习机制。"
    },
    {
      "source": "反向传播",
      "target": "神经网络",
      "relation": "related",
      "description": "Back propagation is the core training algorithm and foundational method for learning in neural networks.<SEP>神经网络通过反向传播算法进行训练，以修正权重并减少误差。"
    },
    {
      "source": "反向传播",
      "target": "节点",
      "relation": "related",
      "description": "反向传播的计算顺序在节点间进行，每个节点将计算后的结果传递给下一个节点。"
    },
    {
      "source": "反向传播",
      "target": "生成式AI",
      "relation": "related",
      "description": "反向传播是训练用于生成式AI的复杂深度神经网络架构的关键使能技术。"
    },
    {
      "source": "反向传播",
      "target": "监督学习",
      "relation": "related",
      "description": "反向传播是在监督学习范式下训练神经网络的核心技术，旨在通过调整权重使模型做出更优质的预测。"
    },
    {
      "source": "反向传播",
      "target": "链式法则",
      "relation": "related",
      "description": "反向传播算法利用链式法则将输出层的误差反向传播至网络各层，以计算损失函数对每个权重的梯度。"
    },
    {
      "source": "反向传播",
      "target": "激活函数",
      "relation": "related",
      "description": "反向传播需要计算激活函数的导数，因为激活函数引入了非线性，使得损失函数成为复合函数。"
    },
    {
      "source": "反向传播",
      "target": "局部导数",
      "relation": "related",
      "description": "反向传播的计算过程依赖于节点的局部导数，通过将信号E乘以该导数来传递梯度。"
    },
    {
      "source": "反向传播",
      "target": "梯度下降算法",
      "relation": "related",
      "description": "反向传播使用梯度下降算法来计算梯度并更新神经网络的权重，以最小化误差。"
    },
    {
      "source": "反向传播",
      "target": "计算图",
      "relation": "related",
      "description": "计算图用于可视化反向传播过程中操作符和变量的依赖关系。<SEP>反向传播通常在计算图这一数据结构上执行，以高效地组织前向和反向计算。"
    },
    {
      "source": "反向传播",
      "target": "链式规则",
      "relation": "related",
      "description": "反向传播方法根据微积分中的链式规则来计算梯度。"
    },
    {
      "source": "反向传播",
      "target": "自动微分",
      "relation": "related",
      "description": "自动微分技术通过自动计算梯度简化了反向传播的实现。"
    },
    {
      "source": "SSD",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "SSD is a specific variant of Convolutional Neural Network architecture optimized for fast, single-stage object detection."
    },
    {
      "source": "SSD",
      "target": "Object Detection",
      "relation": "related",
      "description": "SSD is cited as an example of a one-stage model for object detection in remote sensing."
    },
    {
      "source": "霍克海默",
      "target": "科学",
      "relation": "related",
      "description": "Horkheimer theorized that understanding the crisis of science depends on a correct theory of the current social situation."
    },
    {
      "source": "霍克海默",
      "target": "王田",
      "relation": "related",
      "description": "Wang Tian cites the German philosopher Horkheimer's point about understanding the crisis of science."
    },
    {
      "source": "Google Cloud",
      "target": "AI",
      "relation": "related",
      "description": "Google Cloud provides products and solutions based on AI technology."
    },
    {
      "source": "Google Cloud",
      "target": "Vertex AI",
      "relation": "related",
      "description": "Google Cloud offers Vertex AI as one of its managed machine learning platform products.<SEP>Google Cloud provides Vertex AI as a service for accessing AI models like Gemini and building generative AI applications."
    },
    {
      "source": "Google Cloud",
      "target": "Machine Learning",
      "relation": "related",
      "description": "Google Cloud provides products and solutions based on Machine Learning technology."
    },
    {
      "source": "Google Cloud",
      "target": "Google DeepMind",
      "relation": "related",
      "description": "Google Cloud integrates innovative technologies developed and tested by Google DeepMind into its enterprise AI platform."
    },
    {
      "source": "聊天机器人",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理为聊天机器人(如Alexa、Siri、Cortana)提供支持。"
    },
    {
      "source": "聊天机器人",
      "target": "Amazon Alexa",
      "relation": "related",
      "description": "Amazon Alexa是聊天机器人的一个实例。"
    },
    {
      "source": "聊天机器人",
      "target": "Microsoft Cortana",
      "relation": "related",
      "description": "Microsoft Cortana是聊天机器人的一个实例。"
    },
    {
      "source": "孫民",
      "target": "深度學習",
      "relation": "related",
      "description": "孫民提到深度學習可以幫助企業從種子資料中尋找相似關鍵字，並對自然語言處理的未來發展充滿信心。"
    },
    {
      "source": "ESMFold",
      "target": "氨基酸序列",
      "relation": "related",
      "description": "ESMFold根据氨基酸序列进行预测。"
    },
    {
      "source": "Autoregressive Decoder-Only LLM",
      "target": "Large Language Model (LLM)",
      "relation": "related",
      "description": "Autoregressive decoder-only is a specific subcategory of large language model architecture."
    },
    {
      "source": "Autoregressive Decoder-Only LLM",
      "target": "GPT-3",
      "relation": "related",
      "description": "GPT-3 is an example of an autoregressive decoder-only large language model."
    },
    {
      "source": "Autoregressive Decoder-Only LLM",
      "target": "Claude",
      "relation": "related",
      "description": "Claude is an example of an autoregressive decoder-only large language model."
    },
    {
      "source": "Feed Forward",
      "target": "Neural Network",
      "relation": "related",
      "description": "The feed forward method is the process by which a neural network processes input data to generate a prediction."
    },
    {
      "source": "Feed Forward",
      "target": "Encoder Block",
      "relation": "related",
      "description": "An Encoder block contains a Feed Forward neural network layer as a core component."
    },
    {
      "source": "NLP",
      "target": "Transformer Model",
      "relation": "related",
      "description": "Transformer models are commonly associated with and applied in the field of Natural Language Processing."
    },
    {
      "source": "文本分类",
      "target": "卷积",
      "relation": "related",
      "description": "卷积不仅在图像处理中应用，在文本分类等自然语言处理任务中也用得非常好。"
    },
    {
      "source": "哲学研究",
      "target": "赵立",
      "relation": "related",
      "description": "Zhao Li states that philosophical research in the AI era must be \"based on humans, centered on humans, and for humans.\""
    },
    {
      "source": "高频交易",
      "target": "卷积神经网络",
      "relation": "related",
      "description": "Convolutional Neural Networks (CNN) are applied in the field of high-frequency trading to process large volumes of micro-market data."
    },
    {
      "source": "意图理解",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理使系统能够理解用户查询背后的意图。"
    },
    {
      "source": "卷积神经网络",
      "target": "GPU",
      "relation": "related",
      "description": "卷积操作很容易用GPU进行并行计算，这使得卷积神经网络能够高效地计算。"
    },
    {
      "source": "卷积神经网络",
      "target": "Google",
      "relation": "related",
      "description": "Google等公司投入巨资研究卷积神经网络，推动了各种变体模型的发展。"
    },
    {
      "source": "卷积神经网络",
      "target": "CNN",
      "relation": "related",
      "description": "CNN是卷积神经网络的常用缩写。<SEP>CNN是卷积神经网络的英文缩写，指代同一概念。<SEP>CNN是卷积神经网络的英文简称，两者指代同一种模型。"
    },
    {
      "source": "卷积神经网络",
      "target": "计算机视觉",
      "relation": "related",
      "description": "基于卷积神经网络架构的模型在计算机视觉领域占据主导地位，是当前图像识别、目标检测等应用的基础。<SEP>卷积神经网络是计算机视觉领域取得成功的关键技术。<SEP>Convolutional Neural Networks are a core and successful technology widely applied in the field of computer vision for tasks like image and video processing.<SEP>卷积神经网络最初相遇和应用在计算机视觉领域。"
    },
    {
      "source": "卷积神经网络",
      "target": "全连接层",
      "relation": "related",
      "description": "全连接层是卷积神经网络的一个组成部分，通常用于最终的处理和输出。<SEP>Convolutional Neural Networks utilize fully connected layers as a final component to perform classification or regression tasks.<SEP>全连接层是卷积神经网络结构中的一种层，通常用于最终的分类任务。<SEP>卷积神经网络最后往往保留全连接层，用于从全局出发做出最终结论，与前面的卷积层形成先局部后整体的学习结构。"
    },
    {
      "source": "卷积神经网络",
      "target": "图像处理",
      "relation": "related",
      "description": "Convolutional Neural Networks are a key deep learning algorithm applied to the field of image processing, driving its progress.<SEP>卷积神经网络是图像处理领域的关键技术之一。"
    },
    {
      "source": "卷积神经网络",
      "target": "生物视觉系统",
      "relation": "related",
      "description": "Convolutional Neural Networks are designed to simulate the processing mechanisms of the human biological visual system."
    },
    {
      "source": "卷积神经网络",
      "target": "知网",
      "relation": "related",
      "description": "CNKI provides access to research papers, including master's theses, which discuss the training and theoretical aspects of Convolutional Neural Networks."
    },
    {
      "source": "卷积神经网络",
      "target": "深度学习系统",
      "relation": "related",
      "description": "深度学习系统包含卷积神经网络作为其主要类型之一。"
    },
    {
      "source": "卷积神经网络",
      "target": "时间序列",
      "relation": "related",
      "description": "卷积神经网络能很好地对时间序列数据进行处理。"
    },
    {
      "source": "卷积神经网络",
      "target": "Yann LeCun",
      "relation": "related",
      "description": "法国学者Yann LeCun等人提出了基于梯度学习的卷积神经网络算法LeNet，标志着卷积与神经网络真正意义上的合体。<SEP>Yann LeCun invented the Convolutional Neural Network, inspired by extending the organizational structure of the brain's visual system to artificial neural networks."
    },
    {
      "source": "卷积神经网络",
      "target": "AlexNet",
      "relation": "related",
      "description": "AlexNet在2012年ImageNet竞赛中的成功，让学术界意识到了卷积神经网络改造的巨大潜力。"
    },
    {
      "source": "卷积神经网络",
      "target": "VGGNet",
      "relation": "related",
      "description": "VGGNet采用堆积的小卷积核替代大的卷积核，是卷积神经网络的一种重要变体。"
    },
    {
      "source": "卷积神经网络",
      "target": "GoogleNet",
      "relation": "related",
      "description": "GoogleNet增加了卷积神经网络的宽度并使用1x1卷积降维，是卷积神经网络的一种变体。"
    },
    {
      "source": "卷积神经网络",
      "target": "计算机学者",
      "relation": "related",
      "description": "卷积神经网络是由计算机学者受生理学家和数学家启发而创造出来的。"
    },
    {
      "source": "AI投资",
      "target": "生成式AI",
      "relation": "related",
      "description": "Generative AI is a key technology area within broader AI investments aimed at obtaining better returns."
    },
    {
      "source": "Google",
      "target": "神经网络",
      "relation": "related",
      "description": "Google的搜索算法是神经网络技术的一个著名应用实例。"
    },
    {
      "source": "时间序列",
      "target": "IBM Granite",
      "relation": "related",
      "description": "IBM Granite models have capabilities in time series."
    },
    {
      "source": "人与机器身份悖论",
      "target": "王田",
      "relation": "related",
      "description": "王田探讨了人工智能引发的人与机器身份悖论。"
    },
    {
      "source": "神经科学",
      "target": "Yann LeCun",
      "relation": "related",
      "description": "Yann LeCun drew inspiration from the principles of the nervous system, specifically the brain's visual system, to invent CNNs."
    },
    {
      "source": "Life Sciences",
      "target": "Protein Structure Prediction",
      "relation": "related",
      "description": "Accurate protein structure prediction is expected to have wide benefits in the life sciences space."
    },
    {
      "source": "ResNet-18",
      "target": "Test Datasets",
      "relation": "related",
      "description": "ResNet-18's relatively better performance is evaluated based on the test datasets."
    },
    {
      "source": "LeNet-5",
      "target": "CNN",
      "relation": "related",
      "description": "LeNet-5 is listed as a common CNN architecture."
    },
    {
      "source": "LeNet-5",
      "target": "Convolutional Neural Network (CNN)",
      "relation": "related",
      "description": "LeNet-5 is a classic and widely recognized architecture of a convolutional neural network."
    },
    {
      "source": "Transformer Encoder",
      "target": "Positional Encoding",
      "relation": "related",
      "description": "The Transformer Encoder utilizes Positional Encoding to incorporate sequence order information into its input embeddings by adding them together."
    },
    {
      "source": "郑伟",
      "target": "D-I-TASSER",
      "relation": "related",
      "description": "郑伟教授作为第一作者，开发了D-I-TASSER蛋白质结构预测算法。"
    },
    {
      "source": "郑伟",
      "target": "Nature Biotechnology",
      "relation": "related",
      "description": "郑伟教授作为第一作者在Nature Biotechnology期刊上发表了关于D-I-TASSER的研究论文。"
    },
    {
      "source": "郑伟",
      "target": "Nature Methods",
      "relation": "related",
      "description": "郑伟教授在Nature Methods期刊上发表过文章。"
    },
    {
      "source": "利益相关者要求",
      "target": "AI模型",
      "relation": "related",
      "description": "Stakeholder requirements are a key factor to consider when choosing an AI model."
    },
    {
      "source": "RAG",
      "target": "Knowledge Base",
      "relation": "related",
      "description": "RAG retrieves relevant information from a Knowledge Base to generate precise answers."
    },
    {
      "source": "MIT 6.874",
      "target": "计算机科学",
      "relation": "related",
      "description": "MIT 6.874课程广泛介绍了计算机科学领域的知识。"
    },
    {
      "source": "文本预处理",
      "target": "自然语言处理",
      "relation": "related",
      "description": "文本预处理是自然语言处理中将原始文本转换为可分析格式的步骤。"
    },
    {
      "source": "文本预处理",
      "target": "原始文本",
      "relation": "related",
      "description": "文本预处理将原始文本转换成机器更容易理解的格式。"
    },
    {
      "source": "三维空间结构",
      "target": "蛋白质结构预测",
      "relation": "related",
      "description": "蛋白质结构预测的目标是推断出蛋白质的三维空间结构。"
    },
    {
      "source": "激活函数",
      "target": "神经网络",
      "relation": "related",
      "description": "The activation function is a core component within neural network neurons that enables nonlinear transformations.<SEP>神经网络中的神经元使用激活函数(如tanh或softmax)对输入进行非线性变换，以决定其输出。"
    },
    {
      "source": "Threshold",
      "target": "Perceptron",
      "relation": "related",
      "description": "The threshold is used in the perceptron to determine whether the neuron activates (outputs 1) or not (outputs 0)."
    },
    {
      "source": "重要架构",
      "target": "Residue Gas",
      "relation": "related",
      "description": "Residue Gas is listed as an important architectural component."
    },
    {
      "source": "LSTM",
      "target": "GRU",
      "relation": "related",
      "description": "GRU比LSTM算法稍微简单，在层次深或复杂时运算效率更高，但实际精度可能稍差。"
    },
    {
      "source": "LSTM",
      "target": "Bi-LSTM",
      "relation": "related",
      "description": "Bi-LSTM是一种双向的LSTM，可以学到前后上下文的特征和语义。"
    },
    {
      "source": "Generative Ai",
      "target": "IBM Watsonx.Ai",
      "relation": "related",
      "description": "IBM Watsonx.Ai is a platform designed to train, validate, tune, and deploy generative AI models."
    },
    {
      "source": "Vertex AI",
      "target": "Gemini",
      "relation": "related",
      "description": "Vertex AI provides access to the Gemini model, allowing users to test and build applications using its multimodal capabilities."
    },
    {
      "source": "语言",
      "target": "IBM Granite",
      "relation": "related",
      "description": "IBM Granite models have capabilities in language."
    },
    {
      "source": "自监督学习",
      "target": "文本表示",
      "relation": "related",
      "description": "Self-supervised learning is the method used to pre-train text representations from large amounts of unlabeled text data."
    },
    {
      "source": "哲学思考",
      "target": "古希腊哲人",
      "relation": "related",
      "description": "Philosophical thinking, through its speculative power, provided conditions for transforming the world, as seen in ancient Greek philosophers' discussions on the world's origin."
    },
    {
      "source": "哲学思考",
      "target": "近代启蒙思想家",
      "relation": "related",
      "description": "Philosophical thinking, through its speculative power, inspired action, as seen in modern Enlightenment thinkers inspiring the pursuit of ideals."
    },
    {
      "source": "哲学思考",
      "target": "马克思主义",
      "relation": "related",
      "description": "Philosophical thinking, through its speculative power, provided conditions for transforming the world, as seen in Marxism revealing societal laws and providing guidance."
    },
    {
      "source": "Weight Matrix WV",
      "target": "Linear Layer",
      "relation": "related",
      "description": "Another parallel subset of the linear layer contains the unique weight matrix WV."
    },
    {
      "source": "AI Expert",
      "target": "Artificial General Intelligence (AGI)",
      "relation": "related",
      "description": "AI experts aspire to achieve Artificial General Intelligence (AGI), but this goal is criticized as vain because they ignore brain and mind research."
    },
    {
      "source": "Training",
      "target": "Weight",
      "relation": "related",
      "description": "Training involves the iterative adjustment of weights to optimize model performance."
    },
    {
      "source": "神经网络",
      "target": "深度学习模型",
      "relation": "related",
      "description": "神经网络是构成深度学习模型的底层技术基础。"
    },
    {
      "source": "神经网络",
      "target": "节点",
      "relation": "related",
      "description": "神经网络由互连的节点或神经元组成。<SEP>神经网络由节点作为基本单元构成。"
    },
    {
      "source": "神经网络",
      "target": "非线性动力学系统",
      "relation": "related",
      "description": "Neural networks are described as an instance of a higher-dimensional nonlinear dynamical system."
    },
    {
      "source": "神经网络",
      "target": "误差损失函数",
      "relation": "related",
      "description": "During training, a neural network's performance is evaluated and optimized using an error loss function."
    },
    {
      "source": "神经网络",
      "target": "隐藏层",
      "relation": "related",
      "description": "神经网络通过一个或多个隐藏层逐步提取和转换输入数据的关键特征。"
    },
    {
      "source": "神经网络",
      "target": "自编码器",
      "relation": "related",
      "description": "自编码器是一类特定的神经网络结构。"
    },
    {
      "source": "AI监管",
      "target": "HIPAA",
      "relation": "related",
      "description": "AI regulation involves ensuring compliance with data privacy laws like HIPAA."
    },
    {
      "source": "深度學習模型",
      "target": "RNN",
      "relation": "related",
      "description": "RNN is a specific type of deep learning model designed for handling sequential data."
    },
    {
      "source": "深度學習模型",
      "target": "CNN",
      "relation": "related",
      "description": "CNN is a specific type of deep learning model used for extracting local features from image-like financial data."
    },
    {
      "source": "命名实体识别",
      "target": "自然语言处理",
      "relation": "related",
      "description": "命名实体识别是自然语言处理中帮助处理文本数据的任务之一。"
    },
    {
      "source": "命名实体识别",
      "target": "中文分词",
      "relation": "related",
      "description": "中文分词和命名实体识别都属于中文自然语言处理中词级别的底层处理技术。"
    },
    {
      "source": "Machine Learning",
      "target": "GPU",
      "relation": "related",
      "description": "Complex machine learning models often depend on high-performance GPUs for efficient training through parallel computation."
    },
    {
      "source": "Machine Learning",
      "target": "IBM Watsonx.Ai",
      "relation": "related",
      "description": "IBM Watsonx.Ai enables the development and deployment of machine learning functionalities."
    },
    {
      "source": "Machine Learning",
      "target": "Weather Forecasting",
      "relation": "related",
      "description": "Weather forecasting utilizes machine learning algorithms to predict future conditions."
    },
    {
      "source": "Object Detection",
      "target": "Convolutional Neural Network (CNN)",
      "relation": "related",
      "description": "Convolutional Neural Networks are a class of models specifically designed for the task of object detection."
    },
    {
      "source": "语言翻译",
      "target": "自然语言处理",
      "relation": "related",
      "description": "自然语言处理有助于语言翻译，保留含义和上下文。"
    },
    {
      "source": "Retrieval-Augmented Generation",
      "target": "Knowledge Base",
      "relation": "related",
      "description": "Retrieval-Augmented Generation works by first retrieving relevant information from an external Knowledge Base."
    },
    {
      "source": "Artificial General Intelligence (AGI)",
      "target": "AI",
      "relation": "related",
      "description": "AGI is a goal within the field of AI, described as remaining an unrealized or vain dream."
    },
    {
      "source": "ChatGPT",
      "target": "GPT-3",
      "relation": "related",
      "description": "GPT-3 and similar models power the functionality of the AI chatbot ChatGPT."
    },
    {
      "source": "Jim Anderson",
      "target": "Lettvin",
      "relation": "related",
      "description": "Jim Anderson conducted an interview with Lettvin, which is referenced."
    },
    {
      "source": "Claude",
      "target": "Large Language Model (LLM)",
      "relation": "related",
      "description": "Claude is an example of a closed-source large language model."
    },
    {
      "source": "watsonx.ai",
      "target": "生成式AI",
      "relation": "related",
      "description": "watsonx.ai is a platform for training, validating, tuning, and deploying generative AI."
    },
    {
      "source": "watsonx.ai",
      "target": "IBM",
      "relation": "related",
      "description": "IBM provides the watsonx.ai platform.<SEP>watsonx.ai is an IBM platform that provides tools for CNN model development and deployment."
    },
    {
      "source": "watsonx.ai",
      "target": "AI应用程序",
      "relation": "related",
      "description": "watsonx.ai enables the building of AI applications quickly with a small amount of data."
    },
    {
      "source": "watsonx.ai",
      "target": "CNN",
      "relation": "related",
      "description": "watsonx.ai provides tools for the full lifecycle of building, training, tuning, and deploying CNN models."
    },
    {
      "source": "Artificial Neuron",
      "target": "Perceptron",
      "relation": "related",
      "description": "The perceptron is an early and enduring model of an artificial neuron."
    },
    {
      "source": "IBM Granite",
      "target": "生成式AI",
      "relation": "related",
      "description": "IBM Granite AI模型系列经过优化，可用于帮助企业扩展包括生成式AI在内的AI应用程序。"
    },
    {
      "source": "IBM Granite",
      "target": "IBM",
      "relation": "related",
      "description": "IBM developed and offers the IBM Granite series of AI models.<SEP>IBM Granite is IBM's series of AI models.<SEP>IBM Granite is a series of AI models developed and offered by IBM.<SEP>IBM Granite is a series of AI models developed and created by the company IBM."
    },
    {
      "source": "IBM Granite",
      "target": "AI应用程序",
      "relation": "related",
      "description": "IBM Granite AI models help scale AI applications."
    },
    {
      "source": "IBM Granite",
      "target": "Large Language Model (LLM)",
      "relation": "related",
      "description": "IBM Granite is an example of an open-source, enterprise-focused series of AI models."
    },
    {
      "source": "非线性动力学系统",
      "target": "混沌理论",
      "relation": "related",
      "description": "Chaos theory is a subfield that studies a specific type of behavior within nonlinear dynamical systems."
    },
    {
      "source": "Filter",
      "target": "Weight",
      "relation": "related",
      "description": "A filter (convolution kernel) is composed of a set of fixed weights."
    },
    {
      "source": "Filter",
      "target": "Convolution Operation",
      "relation": "related",
      "description": "The convolution operation uses a filter (convolution kernel) containing fixed weights to extract features."
    },
    {
      "source": "统计机器学习",
      "target": "自然语言处理",
      "relation": "related",
      "description": "统计机器学习技术的出现是自然语言处理领域的第一次重大突破。"
    },
    {
      "source": "统计机器学习",
      "target": "语料库",
      "relation": "related",
      "description": "统计机器学习模型的有效应用依赖于优质语料库的建设。"
    },
    {
      "source": "人工智能技术",
      "target": "赵立",
      "relation": "related",
      "description": "Zhao Li discusses how AI technology shapes the era and necessitates philosophical thinking and response."
    },
    {
      "source": "文本表示",
      "target": "自然语言处理",
      "relation": "related",
      "description": "Natural language processing relies on text representation as a foundational element for understanding and processing language."
    },
    {
      "source": "卷积",
      "target": "CNN",
      "relation": "related",
      "description": "CNN使用卷积操作，通过过滤器在输入上滑动相乘来提取特征。"
    },
    {
      "source": "Meteorological Elements Forecasting Method",
      "target": "Neural Network",
      "relation": "related",
      "description": "Neural Networks serve as a fundamental computational model for implementing the Meteorological Elements Forecasting Method."
    },
    {
      "source": "Multi-Modal Learning",
      "target": "Quantitative Trading",
      "relation": "related",
      "description": "Multi-Modal Learning is identified as an important development direction for building a more comprehensive market view in quantitative trading."
    },
    {
      "source": "Feature Extraction",
      "target": "Word2Vec",
      "relation": "related",
      "description": "Word2Vec is an advanced word embedding method used for feature extraction to capture semantic meaning."
    },
    {
      "source": "Gemini",
      "target": "Google DeepMind",
      "relation": "related",
      "description": "Google DeepMind developed the Gemini model, a multimodal AI with advanced reasoning and generation capabilities."
    },
    {
      "source": "链式法则",
      "target": "链式求导法则",
      "relation": "related",
      "description": "链式求导法则与链式法则指的是相同的数学原理，用于BP算法的推导。"
    },
    {
      "source": "D-I-TASSER",
      "target": "AlphaFold2",
      "relation": "related",
      "description": "D-I-TASSER算法在结构预测精度上显著优于AlphaFold2，在困难单结构域蛋白预测中84%的案例生成质量更高。"
    },
    {
      "source": "运营",
      "target": "AI",
      "relation": "related",
      "description": "AI can be used to reshape operations."
    },
    {
      "source": "运营",
      "target": "生成式AI",
      "relation": "related",
      "description": "Increasing the use of generative AI helps to reshape operations to maximize commercial value."
    },
    {
      "source": "Perceptron",
      "target": "Weight",
      "relation": "related",
      "description": "Weights are key parameters within the perceptron model used to calculate the weighted sum of inputs."
    },
    {
      "source": "Deep Pyramid CNN",
      "target": "CNN",
      "relation": "related",
      "description": "Deep Pyramid CNN is described as a deep version of CNN, addressing CNN's inherent limitation of limited width and semantic loss by using a stacked, identical block structure."
    },
    {
      "source": "氨基酸序列",
      "target": "蛋白质结构预测",
      "relation": "related",
      "description": "蛋白质结构预测以氨基酸序列作为输入信息进行结构推断。"
    },
    {
      "source": "Large Language Model (LLM)",
      "target": "Neural Network",
      "relation": "related",
      "description": "LLMs use neural networks trained on large text datasets to perform tasks, with accuracy improving as data increases."
    },
    {
      "source": "Large Language Model (LLM)",
      "target": "Transformer Model",
      "relation": "related",
      "description": "The transformer model is a neural network architecture that forms the foundation for most modern large language models."
    },
    {
      "source": "Large Language Model (LLM)",
      "target": "GPT-3",
      "relation": "related",
      "description": "GPT-3 is a prominent example of a large language model and served as a catalyst for the modern generative AI era."
    },
    {
      "source": "Encoder Block",
      "target": "Multi-Head Attention",
      "relation": "related",
      "description": "An Encoder block contains one Multi-Head Attention layer as a core component for self-attention."
    },
    {
      "source": "Bi-LSTM",
      "target": "CRF",
      "relation": "related",
      "description": "A model structure combines Bi-LSTM for feature engineering and CRF for label output, representing a perfect integration of deep learning and traditional methods to capture sequence dependencies."
    },
    {
      "source": "Training Set",
      "target": "Neural Network",
      "relation": "related",
      "description": "A neural network uses training sets to learn and adjust its internal parameters."
    },
    {
      "source": "Amazon",
      "target": "Amazon Alexa",
      "relation": "related",
      "description": "Amazon公司开发了Amazon Alexa语音助手。"
    },
    {
      "source": "Transformer Model",
      "target": "RNN",
      "relation": "related",
      "description": "The transformer model's architecture and performance, particularly with multi-head attention, surpassed previous state-of-the-art RNNs."
    },
    {
      "source": "Transformer Model",
      "target": "CNN",
      "relation": "related",
      "description": "The transformer model's architecture and performance, particularly with multi-head attention, surpassed previous state-of-the-art CNNs."
    },
    {
      "source": "Transformer Model",
      "target": "Positional Encoding",
      "relation": "related",
      "description": "Positional encoding is a technique used in transformer models to incorporate information about the order of tokens."
    },
    {
      "source": "Think Newsletter",
      "target": "IBM",
      "relation": "related",
      "description": "IBM publishes the weekly Think Newsletter, which provides curated insights on AI news.<SEP>The Think Newsletter is provided by IBM to share industry trends."
    },
    {
      "source": "自然语言处理",
      "target": "深度学习模型",
      "relation": "related",
      "description": "Natural language processing applies deep learning models as a methodology for processing language."
    },
    {
      "source": "自然语言处理",
      "target": "特征提取",
      "relation": "related",
      "description": "特征提取是自然语言处理中将文本转换为数字表示的过程。"
    },
    {
      "source": "自然语言处理",
      "target": "生成式人工智能",
      "relation": "related",
      "description": "自然语言处理的研究有助于推动生成式人工智能时代的发展。"
    },
    {
      "source": "自然语言处理",
      "target": "计算机科学",
      "relation": "related",
      "description": "自然语言处理是计算机科学的一个子领域。"
    },
    {
      "source": "自然语言处理",
      "target": "文本挖掘",
      "relation": "related",
      "description": "文本挖掘是自然语言处理的一个应用方向，旨在从文本中提取信息。<SEP>自然语言处理使用文本挖掘技术从非结构化文本数据中提取洞察信息。"
    },
    {
      "source": "自然语言处理",
      "target": "机器翻译",
      "relation": "related",
      "description": "机器翻译是自然语言处理领域的早期和核心应用之一。"
    },
    {
      "source": "自然语言处理",
      "target": "统计NLP",
      "relation": "related",
      "description": "自然语言处理结合统计NLP方法，利用机器学习。"
    },
    {
      "source": "生成式人工智能",
      "target": "IBM",
      "relation": "related",
      "description": "IBM提供关于如何利用生成式人工智能提高投资回报率的指南。"
    },
    {
      "source": "IBM",
      "target": "Convolutional Neural Network (CNN)",
      "relation": "related",
      "description": "IBM provides convolutional neural network (CNN) architecture support within its Watson Studio and watsonx.ai platforms."
    },
    {
      "source": "Real-Time Data",
      "target": "Weather Forecasting",
      "relation": "related",
      "description": "Weather forecasting incorporates real-time data to improve the accuracy of predictions."
    },
    {
      "source": "节点",
      "target": "分层结构",
      "relation": "related",
      "description": "节点位于神经网络的分层结构中。"
    },
    {
      "source": "VGGNet",
      "target": "CNN",
      "relation": "related",
      "description": "VGGNet is listed as a common CNN architecture."
    },
    {
      "source": "NNLM模型",
      "target": "深度学习模型",
      "relation": "related",
      "description": "NNLM模型是深度学习模型在语言建模中的一个经典范例。"
    },
    {
      "source": "蝴蝶效应",
      "target": "混沌理论",
      "relation": "related",
      "description": "The butterfly effect is a famous phenomenon and conceptual example within the broader study of chaos theory."
    },
    {
      "source": "DenseNet",
      "target": "Test Datasets",
      "relation": "related",
      "description": "DenseNet's performance, including its highest Precision@K, is evaluated based on the test datasets."
    },
    {
      "source": "AlexNet",
      "target": "CNN",
      "relation": "related",
      "description": "AlexNet is listed as a common CNN architecture."
    },
    {
      "source": "AlphaFold2",
      "target": "蛋白质结构预测",
      "relation": "related",
      "description": "AlphaFold2 solved the long-standing major problem of protein structure prediction in life sciences."
    },
    {
      "source": "AlphaFold2",
      "target": "Protein Structure Prediction",
      "relation": "related",
      "description": "AlphaFold2 solved the protein structure prediction problem, providing a breakthrough for life sciences research."
    },
    {
      "source": "AI模型",
      "target": "部署需求",
      "relation": "related",
      "description": "Deployment requirements are a key factor to consider when choosing an AI model."
    },
    {
      "source": "Linear Layer",
      "target": "Multi-Head Attention",
      "relation": "related",
      "description": "Multi-Head Attention uses a Linear Layer to project the concatenated outputs from its multiple heads into the final output."
    },
    {
      "source": "代理式AI",
      "target": "生成式AI",
      "relation": "related",
      "description": "代理式AI和生成式AI是两种不同类型的人工智能，常被放在一起进行对比。"
    }
  ],
  "total_nodes": 539,
  "total_edges": 805
}